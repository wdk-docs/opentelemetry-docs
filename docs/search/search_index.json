{"config":{"lang":["ja"],"separator":"[\\/\\s\\-\\.]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"OpenTelemetry","text":"<p>{{&lt; blocks/cover image_anchor=\"top\" height=\"max\" color=\"primary\" &gt;}}</p> <p></p> <p>{{% param description %}}</p>   - [Learn more](/docs/what-is-opentelemetry/) - [Try the demo](/docs/demo/)   Get started based on your role    - [Dev](/docs/getting-started/dev/) - [Ops](/docs/getting-started/ops/)   <p>{{&lt; /blocks/cover &gt;}}</p> <p>{{% blocks/lead color=\"white\" %}}</p> <p>OpenTelemetry is a collection of tools, APIs, and SDKs. Use it to instrument, generate, collect, and export telemetry data (metrics, logs, and traces) to help you analyze your software's performance and behavior.</p> <p>OpenTelemetry is generally available across several languages and is suitable for use.</p> <p>{{% /blocks/lead %}}</p> <p>{{% blocks/section color=\"dark\" type=\"row\" %}}</p> <p>{{% blocks/feature icon=\"fas fa-chart-line\" title=\"Traces, Metrics, Logs\"%}}</p> <p>Create and collect telemetry data from your services and software, then forward them to a variety of analysis tools. {{% /blocks/feature %}}</p> <p>{{% blocks/feature icon=\"fas fa-magic\" title=\"Drop-In Instrumentation\"%}}</p> <p>OpenTelemetry integrates with popular libraries and frameworks such as Spring, ASP.NET Core, Express, Quarkus, and more! Installation and integration can be as simple as a few lines of code.</p> <p>{{% /blocks/feature %}}</p> <p>{{% blocks/feature icon=\"fab fa-github\" title=\"Open Source, Vendor Neutral\" %}}</p> <p>100% Free and Open Source, OpenTelemetry is adopted and supported by industry leaders in the observability space.</p> <p>{{% /blocks/feature %}}</p> <p>{{% /blocks/section %}}</p> <p>{{% blocks/section color=\"secondary\" type=\"cncf\" %}}</p> <p>OpenTelemetry is a CNCF incubating project. Formed through a merger of the OpenTracing and OpenCensus projects.</p> <p></p> <p>{{% /blocks/section %}}</p>"},{"location":"status/","title":"Status","text":"<p>{{% blocks/section color=\"white\" %}}</p>"},{"location":"status/#param-title","title":"{{% param title %}}","text":"<p>OpenTelemetry is made up of several components, some language-specific and others language-agnostic. When looking for a status, make sure to look for the status from the right component page. For example, the status of a signal in the specification may not be the same as the signal status in a particular language SDK.</p> <p>For the development status, or maturity level, of a language SDK, see the status section of that language:</p>   - [C++](/docs/instrumentation/cpp/#status-and-releases) - [.NET](/docs/instrumentation/net/#status-and-releases) - [Erlang/Elixir](/docs/instrumentation/erlang/#status-and-releases) - [Go](/docs/instrumentation/go/#status-and-releases) - [Java](/docs/instrumentation/java/#status-and-releases) - [JavaScript](/docs/instrumentation/js/#status-and-releases) - [PHP](/docs/instrumentation/php/#status-and-releases) - [Python](/docs/instrumentation/python/#status-and-releases) - [Ruby](/docs/instrumentation/ruby/#status-and-releases) - [Rust](/docs/instrumentation/rust/#status-and-releases) - [Swift](/docs/instrumentation/swift/#status-and-releases)   <p>For the development status, or maturity level, of the collector and specification, see the following:</p>   - [Specification status](/docs/specs/status/) - [Collector status](/docs/collector/#status-and-releases)   <p>{{% /blocks/section %}}</p>"},{"location":"tags/","title":"tags","text":"<p>{{ tag_content }}</p>"},{"location":"blog/","title":"\u535a\u5ba2","text":"<p>{{ blog_content }}</p>"},{"location":"blog/2019/opentelemetry-governance-committee-explained/","title":"OpenTelemetry Governance Committee Explained","text":"<p>This article describes the functions and responsibilities of the OpenTelemetry Governance Committee, based on the charter document found here. It is an opinion, not the formal definition. The primary role of the Governance Committee is not to centralize power, but to enable and empower the broader community by establishing processes. Let me explain.</p> <p></p> <p>The main objective of the OpenTelemetry project is to make robust, portable telemetry a built-in feature of cloud-native software. The most effective way to do it is to build a community of passionate people, from existing ecosystem with the diverse expertise and experience. This community will build a project that is attractive to users, who will use it to instrument their software, as well as telemetry vendors, who will build solutions that work with the open standards.</p> <p>In other words, success of our project depends on building community \u2014 welcoming contributions from small to large. Making sure that contributions go towards contributor\u2019s interests while keeping balance with the interests of other community members.</p> <p>As we strive to keep a lean governance, the most scalable approach to represent contributors\u2019 interests is to allow self-governance of individual special interest groups. So these groups will be self-formed and autonomous. Maintainers of special interest groups make final calls on technical questions related to the group. The Governance Committee defines a clear way to become a maintainer through continuous contributions.</p> <p>With self-governance of special interest groups (SIGs), a big part of a Governance Committee\u2019s job is to keep project spirit and maintain its direction through defining, evolving, and upholding the vision, values and scope of the project. The main instrument of a Governance Committee is advocacy and building relationships with contributors.</p> <p>That said, the Governance Committee members are not project or product managers in an industry understanding of these roles. Governance Committee members have no power over day-to-day work of the SIGs (it is typical that active SIG members are members of Governance Committee and keep making decisions in this SIG). The Governance Committee delegates responsibility for technical alignment across all special interest groups to a Technical Committee. Members of this Technical Committee make sure that SIG maintainers are aligned with the overall project goals, specifications and design principles defined by Technical Committee.</p> <p>Where Governance Committee is limited in size and elected only once a year, Technical Committee membership is more agile. It allows more diverse set of people, representing various interests, to participate in defining project goals and writing specifications.</p> <p>The Governance Committee, alongside the CNCF, also holds keys for project resources and assets like artifact repositories, build and test infrastructure, web sites and their domains, blogs, social-media accounts, etc. It is also responsible for ensuring that releases of components and artifacts are aligned with the OpenTelemetry agenda, and with the project\u2019s advocacy and marketing needs.</p> <p>The Governance Committee meets once a month in a public forum, and privately when needed. Now that you have a better idea of what the Governance Committee does, I hope you feel informed about which questions you can bring to Governance Committee attention.</p> <p>Come meet the new members of Governance Committee November 14th 10:00 PT and ask your questions!</p> <p>Thanks Sarah Novotny for review and feedback!</p> <p>A version of this article was [originally posted][] on medium.com/opentelemetry.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/auto-instrumentation-k8s/","title":"Using OpenTelemetry auto-instrumentation/agents in Kubernetes (Medium)","text":"<p>This article introduces OpenTelemetry Operator\u2019s new feature that significantly simplifies instrumenting workloads deployed on Kubernetes. Read all the details from the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/collector/","title":"OpenTelemetry Collector achieves Tracing stability milestone (Medium)","text":"<p>The OpenTelemetry Collector has made its first GA release. For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/cpp/","title":"OpenTelemetry C++ v1.0 \u2014 what\u2019s there, and what next (Medium)","text":"<p>OpenTelemetry C++ released its v1.0 stable version last month, which implements the OpenTelemetry distributed tracing specification! For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/gc-election/","title":"Announcing the 2021 OpenTelemetry Governance Committee Election (Medium)","text":"<p>The OpenTelemetry project is excited to announce the 2021 OpenTelemetry Governance Committee (GC) election. For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/malabi/","title":"Trace-Based Testing with OpenTelemetry: Meet Open Source Malabi (Medium)","text":"<p>This article introduces you to to Malabi, a new open source tool for trace-based testing. For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/otel-gc/","title":"Welcome to the incoming 2021 OpenTelemetry Governance Committee (Medium)","text":"<p>The OpenTelemetry project just completed its 2021 election for the Governance Committee (GC). For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/python/","title":"Announcing OpenTelemetry Python 1.0 (Medium)","text":"<p>Today, OpenTelemetry Python distributed tracing API/SDK released its 1.0 version. For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/swift/","title":"OpenTelemetry Swift 1.0 Beta (Medium)","text":"<p>Today, OpenTelemetry Swift distributed tracing API/SDK has released its 1.0 version. For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2021/womens-day/","title":"OpenTelemetry Observes International Women's Day 2021 (Medium)","text":"<p>Happy International Women\u2019s Day! The OpenTelemetry project would like to extend our thanks to all our women contributors. For all the details, see the [original post][].</p> <p>[original post]: {{% param canonical_url %}}</p>"},{"location":"blog/2022/announcing-community-manager/","title":"Announcing the OpenTelemetry Community Manager","text":"<p>OpenTelemetry has demonstrated massive growth since its inception in 2019. What started as a handful of OpenTracing and OpenCensus maintainers and collaborators meeting at the Google campus and over Zoom, has now grown into the second-most popular project in the CNCF behind Kubernetes itself. Over 5400 contributors and 700 companies have contributed code, issues, documentation, and invaluable feedback.</p> <p>Our community isn\u2019t just composed of these contributors, however - our end-users, partners, integrators, and a whole host of other people make up the OpenTelemetry community. In order to serve the needs of the wider end-user community, the governance committee has formed a community manager role who can focus on the needs of this large, and growing, group of humans.</p> <p>Community managers are appointed by the Governance Committee and act as public stewards of the contributor and end-user community. They\u2019re responsible for organizing events, coordinating cross-SIG and WG efforts to improve contributor experience, managing the OpenTelemetry presence on social media, and working to nurture and grow the OpenTelemetry community overall. Effectively, this is a new project maintainer whose project is the OpenTelemetry community itself.</p> <p>With that said, I\u2019m happy to inform you that I have been designated the first Community Manager for the OpenTelemetry project! As a former OpenTracing maintainer, I\u2019ve been a part of OpenTelemetry since its inception, mostly working on projects such as the website, hosting OpenTelemetry Tuesdays, and helping organize events like OpenTelemetry Community Day. With this new role, I plan to more formally establish OpenTelemetry Community Days around the world as part of KubeCon/CloudNativeCon -- and additionally, help promote new end-user and contributor events like OTel Unplugged (more on that in a week or so.)</p> <p>What\u2019s next? I hope to hear from you about what you need! I\u2019ve started a thread on the Community Discussions in GitHub, and I\u2019d love for you to post your questions, comments, and suggestions for community initiatives and programs. This isn\u2019t just limited to end-users of OpenTelemetry, either -- how can I help in improving the existing and new contributor experience? Please let me know!</p> <p>If you\u2019d like to reach out in other ways, you can find me on Twitter or on the Cloud Native Community Slack.</p>"},{"location":"blog/2022/dotnet-instrumentation-first-beta/","title":"OpenTelemetry .NET Automatic Instrumentation Releases its first Beta","text":"<p>We're excited to announce the first beta release of the OpenTelemetry .NET Automatic Instrumentation project!</p> <p>Without this project, .NET developers need to use instrumentation packages to automatically generate telemetry data. For example, to instrument inbound ASP.NET Core requests, you need to use the ASP.NET Core instrumentation package and initialize it with the OpenTelemetry SDK.</p> <p>Now, developers can use automatic instrumentation to initialize signal providers and generate telemetry data for supported instrumented libraries. This approach has several benefits:</p> <ul> <li>A technical path forward to support automatic instrumentation via   byte-code instrumentation,   which can allow for more automatic instrumentation support than relying solely   on published instrumentation libraries</li> <li>No need to install and initialize an instrumentation library</li> <li>No need to modify and rebuild an application to add automatic instrumentation</li> <li>Less code needed to get started</li> </ul> <p>This first beta release is an important milestone because it establishes the technical foundation on which a rich set of automatic instrumentation capabilities can be built on. This release includes support for:</p> <ul> <li>Gathering trace data from .NET applications without requiring code   changes1</li> <li>Gathering trace data from .NET libraries that the SDK does not   support2</li> </ul> <p>See the examples for demonstrations of different instrumentation scenarios covered by the OpenTelemetry .NET Automatic Instrumentation.</p> <p>Over the next few months we plan to:</p> <ul> <li>Support additional   instrumentation libraries</li> <li>Improve dependency management</li> <li>Enable metrics support</li> </ul> <p>Please, give us your feedback (using your preferred method):</p> <ul> <li>Submit a GitHub issue.</li> <li>Write to us on Slack.   If you are new, you can create a CNCF Slack account   here.</li> </ul> <ol> <li> <p>The supported and unsupported scenarios documentation describe the current limits.\u00a0\u21a9</p> </li> <li> <p>The instrumentation library documentation contains the list of libraries we can gather telemetry data from.\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/2022/dotnet-instrumentation-metrics/","title":"OpenTelemetry .NET Automatic Instrumentation metric signal support","text":"<p>We're excited to announce the 0.2.0-beta.1 release of the OpenTelemetry .NET Automatic Instrumentation which adds metric signal support!</p> <p>Now you can easily export metrics from:</p> <ul> <li>.NET Runtime,</li> <li>ASP.NET Core,</li> <li>ASP.NET Framework,</li> <li>HTTP clients (<code>System.Net.Http.HttpClient</code> and <code>System.Net.HttpWebRequest</code>),</li> <li>measurements created using   <code>System.Diagnostics.Metrics</code>.</li> </ul> <p>Over the next few months we plan to support:</p> <ul> <li>additional   instrumentation libraries,</li> <li>the log signal.</li> </ul> <p>Please, give us your feedback (using your preferred method):</p> <ul> <li>Submit a GitHub issue.</li> <li>Write to us on Slack.   If you are new, you can create a CNCF Slack account   here.</li> </ul>"},{"location":"blog/2022/gc-candidates/","title":"Final list of candidates for the 2022 OpenTelemetry Governance Committee","text":"<p>The OpenTelemetry election committee is pleased to announce the final list of candidates running for one of the four available seats. We encourage all voters to take a moment and review all candidates, picking the one that best represents your interest. You can find their pictures, profile link, and descriptions on the candidates page, but here are their names:</p> <ul> <li>Alolita Sharma</li> <li>Daniel Dyla</li> <li>Ken Finnigan</li> <li>Michael Hausenblas</li> <li>Morgan McLean</li> <li>Pavol Loffay</li> <li>Phillip Carter</li> <li>Reese Lee</li> <li>Reiley Yang</li> <li>Sean Marciniak</li> <li>Severin Neumann</li> <li>Trask Stalnaker</li> <li>Tyler Yahn</li> <li>Vijay Samuel</li> </ul> <p>You can check your eligibility by reviewing this GitHub issue. If you are not listed there but believe you have the right to vote, please fill out this registration form.</p>"},{"location":"blog/2022/gc-election-results/","title":"Announcing the 2022 Governance Committee Election Results","text":"<p>The OpenTelemetry project is proud to announce the winners of the 2022 OpenTelemetry Governance Committee (GC) election! Before we get into the results, I'd like to share some statistics about the election!</p> <p>This year, 513 project members were eligible to vote. Of those, 219 cast ballots, for a participation rate of nearly 43%! For comparison, the 2021 election saw 169 ballots cast with 386 eligible voters. Participation was roughly flat year-over-year, and we're thrilled that we've welcomed so many new project members and maintained a high participation rate.</p> <p>With that out of the way, please join me in congratulating Alolita Sharma, Daniel Dyla, and Morgan McLean on their re-election! They will be joined by long-time contributor and maintainer of OpenTelemetry Java Instrumentation Trask Stalnaker! All will serve a two-year term.</p> <p>We'd like to thank everyone who participated -- candidates, voters, and the election organizers -- for their efforts. You can find the full results of the election here.</p>"},{"location":"blog/2022/gc-elections/","title":"Announcing the 2022 OpenTelemetry Governance Committee Election","text":"<p>The OpenTelemetry project is excited to announce the 2022 OpenTelemetry Governance Committee (GC) election. Nominations are due by end-of-day on 7 October 2022, with the ratification happening by 8 October 2022 and a list of eligible candidates will be shared on 9 October 2022. Voting will take place between 18 October 2022 and 20 October 2022, and the final election results will be announced 22 October 2022.</p>"},{"location":"blog/2022/gc-elections/#vote","title":"Vote!","text":"<p>If you are a member of standing in the OpenTelemetry community, we invite you to participate in this election to ensure that the community is well-represented in the Governance Committee. In this election four people must be elected, each with two-year terms.</p> <p>If you have made contributions to our ecosystem not measured by the automatic process, you can request an exception to participate in the election before 23:59 UTC on 17 October 2022. The voter roll with all members of standing and approved exceptions will be published here by 11 October 2022 and continuously updated.</p> <p>Voting will be open between 00:00 UTC on 18 October 2022 00:00 UTC and 20 October 2022 23:59 UTC on Helios Voting; voters will need to sign in with their GitHub account.</p> <p>To learn more about the election process, read about all of the details here.</p>"},{"location":"blog/2022/gc-elections/#interested-in-joining-the-governance-committee","title":"Interested in joining the Governance Committee?","text":"<p>If you\u2019ve been working on OpenTelemetry and seeing it grow, or are an end-user that wants to help us make OpenTelemetry better, now\u2019s the time to consider running for a seat on the Governance Committee. You can read about the Governance Committee's role in this blog post or refer to the charter document. You may nominate yourself (or others!) by submitting a Pull Request against the list of candidates by 7 October 2022 23:59 UTC \u2014 more detailed requirements about the nomination and ratification process can be found here.</p> <p>We would like to thank the GC members who have helped grow OpenTelemetry, and invite them to run for re-election if they so choose: Alolita Sharma, Daniel Dyla, Liz Fong-Jones and Morgan McLean. After this election, the Governance Committee will comprise 9 members with staggered 2-year terms, all elected by the community.</p>"},{"location":"blog/2022/gc-elections/#questions","title":"Questions?","text":"<p>For any election related questions, please file an issue on the community repo here and tag @jpkrohling, @bogdandrutu, and @bhs. Or send us a message on CNCF Slack in #opentelemetry if you have an urgent access issue during voting.</p> <p>See you at the polls!</p>"},{"location":"blog/2022/kubecon-na-project-update/","title":"OpenTelemetry Project and Roadmap Update from Kubecon","text":"<p>2022 has been an incredible year for OpenTelemetry. Metrics became a first-class signal type, and are being used on production services and infrastructure alongside OpenTelemetry\u2019s existing distributed tracing support to send critical performance data to any observability backend for processing. Everywhere we look we see OpenTelemetry being tested, rolled out, or already in use in organizations everywhere, from the largest to smallest, from the most cutting edge to the historically cautious.</p> <p>Since January, we\u2019ve delivered:</p> <ul> <li>Metrics: defined in the specification, and delivered in the Java, JS, .NET,   and Python SDKs and instrumentation, with support all the way through the   Collector and protocol. More language implementations are on the way.</li> <li>More instrumentation for all languages.</li> <li>A great demo application, which   includes services written in every supported language, already instrumented   with OpenTelemetry. This is a great way to see practical examples of   OpenTelemetry that you can learn from or experiment with, and the demo can   also be used to test out different observability analytics systems.</li> <li>Tracing stability in C++, Erlang, and a number of other new languages.</li> <li>Progress on Ruby, Erlang, Swift, and .NET auto instrumentation.</li> <li>Major progress on logs, OpenTelemetry\u2019s third signal type.</li> <li>Documentation!</li> <li>Various improvements to all components.</li> </ul> <p>The community also continues to grow substantially. We now have over 800 monthly-active developers on GitHub, from 150 different organizations. More and more of these contributors are end-users - 10 out of our top 25 contributing orgs - which is a very healthy signal for the project. People and companies are getting so much usefulness out of OpenTelemetry that they\u2019re contributing back and making it even more useful for everyone.</p> <p>We\u2019re publishing this post during KubeCon, where many community members and end users will be gathered discussing OpenTelemetry and how it\u2019s being used, how it can be improved, and where we should go from here. In May of this year at KubeCon EU we started a process to create a more formal OpenTelemetry roadmap, and we\u2019ll be continuing that process in Detroit. I\u2019m writing this post in advance of the conference, so I won\u2019t be able to post the full outcome, but here are some of the items that we think are most important:</p> <ul> <li>Finishing logs: completing the full specification and then implementing this   spec across each language.</li> <li>Making OpenTelemetry easier to use, both technically (new features and   functionality like an OpenTelemetry control plane), and through documentation,   collecting user feedback, etc.</li> <li>Client instrumentation: extending OpenTelemetry to capture performance data   from web, mobile, and desktop client applications. This can be used to capture   data from true user-facing SLOs, show end-to-end latency in traces, etc.</li> <li>Profiling, which will tie service performance (captured today through metrics   and traces) to actual function performance within code.</li> <li>Improving the contributor and maintainer experience.</li> </ul> <p>Our focus for the remainder of this year and next year will be on both rounding out OpenTelemetry\u2019s existing functionality across all languages, scenarios, and integrations, and on the roadmap items mentioned above. As mentioned above, in the coming weeks we\u2019ll be publishing a more formal roadmap document that incorporates these, though it\u2019s important to note that the prioritization and progress made on each is dependent on the amount of effort and number of community members that get engaged with each.</p> <p>Many of these, like logs, client instrumentation, and profiling, are already in-flight. We\u2019re excited about these new initiatives because they not only expand the project\u2019s usefulness and bring it closer to its original vision, but they have brought in a new wave of members to the community who are already adding their knowledge, experience, and zeal to OpenTelemetry. These are exciting days for the project, and it\u2019s invigorating for everyone involved to see it grow and be adopted so rapidly.</p>"},{"location":"blog/2022/kubecon-na/","title":"Join us for OpenTelemetry Talks and Activities at Kubecon NA 2022","text":"<p>The OpenTelemetry project maintainers, and members of the governance committee and technical committee are excited to be at KubeCon NA in a few weeks! Join in to meet up in person or virtually for OpenTelemetry activities in Detroit from October 24 - 28, 2022.</p> <p>There are talks, workshops, an unconference as well as a project booth where you are welcome to stop by, say Hi! and tell us about how you are using OpenTelemetry or contributing to the project.</p> <p>The talks, maintainer sessions and other project activities are listed below.</p>"},{"location":"blog/2022/kubecon-na/#kubecon-talks-and-maintainer-sessions","title":"KubeCon Talks and Maintainer Sessions","text":"<p>Jaeger: The Future with OpenTelemetry and Metrics by Jonah Kowall, Logz.io &amp; Joe Elliott, Grafana Wednesday, October 26 \u2022 4:30pm - 5:05pm</p> <p>OpenTelemetry: Meet the Community, Build the Roadmap by Morgan McLean, Splunk; Daniel Dyla, Dynatrace; Ted Young, Lightstep; Alolita Sharma, Apple Thursday October 27, 2022 5:25pm - 6:00pm EDT</p> <p>Tips And Tricks To Successfully Migrate From Jaeger To OpenTelemetry by Vineeth Pothulapati, Timescale Inc Friday, October 28 \u2022 4:55pm - 5:30pm</p>"},{"location":"blog/2022/kubecon-na/#other-co-located-events","title":"Other Co-located Events","text":"<p>OTel Unplugged is a one-day OpenTelemetry unconference event held at Colony Club Detroit on Tuesday, Oct 25, 2022. Join in to listen, learn about the latest features and get involved in the project. Network with OpenTelemetry maintainers, governance committee and technical committee members. For details, check out the event page.</p> <p>Open Observability Day has several OpenTelemetry sessions including panel discussions, workshops, individual talks and lightning talks. This event will be on Monday Oct 24, 2022 and is co-located with KubeCon NA. For talk details, see the schedule.</p> <p>eBPF Day also has some OpenTelemetry talks focused on profiling and tracing using eBPF events. This event will be held on Monday, Oct 24 2022 and is co-located with KubeCon NA. For details, check out the schedule.</p> <p>The OpenTelemetry project meeting is to meet and network with the OpenTelemetry maintainers and core contributors. This meeting will be held 3-5 PM ET on Tuesday Oct 25, 2022 in Room 336 at the conference venue, Huntington Place.</p>"},{"location":"blog/2022/kubecon-na/#come-visit-the-opentelemetry-project-booth","title":"Come Visit the OpenTelemetry Project Booth","text":"<p>Drop by and say Hi! at the OpenTelemetry project booth in the KubeCon NA Project Pavilion. If you\u2019re lucky, you may even pick up some OpenTelemetry swag!</p> <p>The pavilion hours are:</p> <ul> <li>Wednesday, October 26, 10:30 - 20:00 ET</li> <li>Thursday, October 27, 10:30 - 17:30 ET</li> <li>Friday, October 27, 10:30 - 16:00 ET</li> </ul> <p>We\u2019re super excited to learn from all of you about your experience with OpenTelemetry, how you are using OpenTelemetry, features you may need and issues you may be running into when using OpenTelemetry.</p> <p>Come join us to listen, learn and get involved in OpenTelemetry.</p> <p>See you in Detroit!</p>"},{"location":"blog/2022/metrics-announcement/","title":"OpenTelemetry Metrics Release Candidates","text":"<p>OpenTelemetry\u2019s metrics capabilities are now available as release candidates, starting with Java, .NET, and Python! This means that the specification, APIs, SDKs, and other components that author, capture, process, and otherwise interact with metrics now have the full set of OpenTelemetry metrics functionality and are ready for use. These release candidates will be promoted to general availability throughout the next few weeks.</p> <p>The 1.0 metrics release includes the following:</p> <ul> <li>Metrics functionality included in the OpenTelemetry language-specific APIs,   which provide language-specific interfaces that can create and manipulate   metrics, and associate metadata and attributes to each. These are useful for:</li> <li>Developers of shared libraries that are distributed to end-users, so that     these end users can natively use OpenTelemetry to capture metrics from     these. For example, gRPC uses these APIs to produce latency, throughput, and     error rate metrics for each RPC method on a given service.</li> <li>Developers who create and maintain web services or client applications, so     that they can produce custom metrics or interact with existing metrics. For     example, an e-commerce company could use the API to track how many purchases     are made over time.</li> <li>Metrics functionality included in the OpenTelemetry SDKs for Java, .NET,   Python, and JS (coming next week) SDKs, which capture metrics from the APIs   and perform some amount of processing. Metrics support for other languages is   still in development. These are useful for:</li> <li>Developers of applications that are used by other organizations, like     databases, message queues, etc., who will expose metrics over OTLP (or     Prometheus) so that their own end users are able to monitor the performance     of these apps. These applications could be open or closed source.</li> <li>Developers of applications within a technology organization, who want to     capture metrics generated by OpenTelemetry APIs within their applications,     either by their own developers or from shared libraries that their     applications depend on. These metrics can be exported through OTLP or     exported through any other OpenTelemetry exporter.</li> <li>Collector support for metrics includes the Collector\u2019s capability to capture   metrics from a rich variety of data sources like host metrics or pre-packaged   applications. The Collector also provides the ability to receive metrics from   data sources using multiple data protocols such as the native OpenTelemetry   protocol (OTLP) and OpenMetrics compliant protocols such as Prometheus. Also   supported is configuration-driven metric processing and native OTLP,   Prometheus and custom exporters to send observability metrics to on-cloud and   on-premises monitoring systems of your choice. This feature-set is useful for:</li> <li>Anyone who wants to capture metrics from their hosts (Linux VMs, Windows,     VMs, Kubernetes, etc.) or pre-packaged applications (databases, message     queues, etc.).</li> <li>Anyone who wants to capture metrics from existing sources like OTLP (from     OpenTelemetry SDKs, pre-packaged applications, etc.), Prometheus, or others.</li> <li>Anyone who wants to process / modify metrics and metric metadata captured     from these sources.</li> <li>Anyone who wants to convert metrics from one format to another. For example,     the Collector can capture metrics from a mix of OTLP and Prometheus sources,     and then send all of these to a single destination using OTLP (with the     standard OpenTelemetry semantic conventions), Prometheus, or any other     exporter.</li> <li>Full OpenTelemetry Protocol (OTLP) support for efficiently serializing and   transmitting metrics between systems.</li> <li>A metrics section of the specification, which defines different types of   metrics, their shapes, how to process them, and semantic conventions. This is   primarily used by OpenTelemetry contributors but also provides guidance to   OpenTelemetry users who are authoring metrics or metadata.</li> </ul> <p>All of this functionality is additive to OpenTelemetry\u2019s existing tracing support, and both signal types share the same metadata and semantic conventions. As of this announcement, the following languages have issued metrics release candidates:</p> <ul> <li>Java</li> <li>.NET</li> <li>Python</li> </ul> <p>The RC release for JS is planned for next week, and more languages will be issuing metrics release candidates throughout the coming months. Each of these releases will be followed by general availability after we receive feedback from users.</p>"},{"location":"blog/2022/metrics-announcement/#getting-started","title":"Getting Started","text":"<p>If you\u2019re already using a mix of the OpenTelemetry APIs, SDKs, language agents, and Collector, then you can access the release candidate metrics functionality by updating your OpenTelemetry artifacts to their latest versions. We're currently updating the official OpenTelemetry documentation for each artifact's metrics capabilities. Examples and supplementary documentation are also being added to each artifact\u2019s corresponding GitHub repository.</p>"},{"location":"blog/2022/metrics-announcement/#whats-next-for-opentelemetry","title":"What\u2019s Next for OpenTelemetry","text":"<p>Distributed traces and metrics were the two halves of OpenTelemetry\u2019s core promise when we announced it at KubeCon EU in 2019. With the general availability of metrics, we have produced the capabilities that we originally set out to create, meaning that we can shift our focus to further investing into the robustness and ease of use of each component, the number of data sources that OpenTelemetry can capture telemetry from (either through the OpenTelemetry APIs, OTLP, or otherwise), and new capabilities and signal types.</p> <p>Logging is the most visible release on the horizon, and we\u2019re running full speed ahead on this effort. Expect to hear a lot more about our progress on logging throughout the year (logs already have a stable data model and OTLP support), and anyone interested in this area is welcome to join the weekly logging SIG calls. Beyond logging, major new projects include formalizing and implementing client instrumentation and investigations into eBPF. With metrics complete, we may also turn our attention to more signal types.</p>"},{"location":"blog/2022/new-end-user-resources/","title":"Introducing new resources for OpenTelemetry end users to connect and discover best practices","text":"<p>The content of this post has moved to End-user Resources, where it will be kept up-to-date as more end-user resources become available.</p>"},{"location":"blog/2022/otel-in-practice/","title":"OpenTelemetry in Practice: Kubernetes & the Collector","text":""},{"location":"blog/2022/otel-in-practice/#about-the-series","title":"About the Series","text":"<p>Welcome to the OpenTelemetry in Practice series! This is a new experiment by some OpenTelemetry contributors in the End User Working Group.</p> <p>We\u2019re aiming to:</p> <ul> <li>Address practical problems that commonly stop development teams from   succeeding with OpenTelemetry</li> <li>Build stronger connections with developers focused on specific languages</li> <li>Improve the experience of implementing OpenTelemetry in production</li> </ul> <p>Each OpenTelemetry in Practice session will include a half hour of lightning talks and a half hour of open conversation about the topic. We are looking for people to join the OpenTelemetry in Practice team and people to give talks at future events. So if you\u2019re interested in shaping these conversations, reach out in the #otel-user-research channel of the CNCF Slack.</p> <p>Our first conversation will be on August 23rd, at 10 AM PDT, on Zoom, and the topic is Kubernetes &amp; The Collector.</p>"},{"location":"blog/2022/otel-in-practice/#talks","title":"Talks","text":"<p>Our lightning talks include the following.</p>"},{"location":"blog/2022/otel-in-practice/#collector-configuration-and-troubleshooting-in-kubernetes","title":"Collector Configuration and Troubleshooting in Kubernetes","text":"<p>\u2014 by Jessica Kerr, Honeycomb</p> <p>Let\u2019s talk about getting the OpenTelemetry Collector working in Kubernetes. Jess will run the Collector using the OpenTelemetry helm chart, and then tweak the configuration until it works. She\u2019ll demonstrate two techniques for troubleshooting and warn about some pitfalls. Then, share your victories and frustrations with the Collector.</p>"},{"location":"blog/2022/otel-in-practice/#observability-pipelines-for-kubernetes","title":"Observability Pipelines for Kubernetes","text":"<p>\u2014 by Daniel Kim, New Relic</p> <p>When doing observability, we need to collect signals from many different data sources, frameworks and programming languages. We can turn heterogeneous data across so many different signals into actionable insights through a framework like OpenTelemetry. In this talk Daniel will show you how to build an observability data pipeline using the OpenTelemetry Collector and open source plugins that can perform a wide variety of data processing, such as injecting infrastructure metadata into traces and metrics, implementing tail-based sampling, and exporting data to any backend via OTLP. Finally, he will share some of the challenges with running the Collector, so that you can take them into account as you build out your own observability pipeline with OpenTelemetry.</p>"},{"location":"blog/2022/otel-tuesday-v1-sunset/","title":"OpenTelemetry Tuesdays, Signing Off!","text":"<p>When we started running OpenTelemetry Tuesday live streams back in 2019, the world was a lot different than it is today. Back then, it was very challenging for external participants and observers to understand what was going on with the overall status of the project. There weren't as many good resources for learning about OpenTelemetry, or for figuring out how to contribute.</p> <p>However, the project has matured by leaps and bounds since we started, and the associated rate of change and lack of discoverability that drove the stream as a concept has lessened. OpenTelemetry updates and news can be found in various newsletters, Twitter feeds, and a thriving community on Slack.</p> <p>With this in mind, we'll be winding down the OpenTelemetry Tuesday stream going forward. That doesn't mean it's gone forever, or that we wouldn't be willing to bring it back, but the format just really wasn't giving a lot to the community at this point. If you're a content creator that's interested in working on this in the future, please come find us in the #otel-comms channel on Slack!</p> <p>Last, but not least, I'd like to extend a huge thanks to everyone that's helped host or guest on the stream in the past. Until next time, signing off.</p>"},{"location":"blog/2022/otel-unplugged-kubecon-na/","title":"OTel Unplugged at KubeCon NA 2022!","text":"<p>Are you excited about KubeCon NA 2022 in Detroit later this month? Maybe you\u2019re attending in-person or virtually, for the first time or the fifth -- either way, the OpenTelemetry community is excited to present a hybrid event that will take place on Tuesday, October 25th -- OTel Unplugged!</p>"},{"location":"blog/2022/otel-unplugged-kubecon-na/#what-is-otel-unplugged","title":"What Is OTel Unplugged?","text":"<p>If you attended OpenTelemetry Community Day earlier this year, then you\u2019ll be familiar with the format we\u2019ll be using -- an \u201cunconference\u201d, where in lieu of a bunch of pre-planned talks, you\u2019ll get to decide the format and content of discussion groups on that day. If you\u2019ve been to a DevOpsDays open space, then you should be rather familiar with this concept. We\u2019ll be offering tailored breakout sessions for in-person as well as virtual attendees, so nobody is left out.</p> <p>These small group discussions can be used for a wide variety of topics -- everything from tips and stories about operating the OpenTelemetry Collector, the best patterns to implement tracing in your .NET applications, discussions about OpenTelemetry Metrics and how to get started with them -- it\u2019s all fair game, and there\u2019ll be plenty of maintainers and contributors on-hand to join in on the discussions!</p> <p>We\u2019ll be presenting a panel discussion with our maintainers and a group of end-users as well, which promises to be extremely informative and enlightening! It wouldn\u2019t be an OpenTelemetry event without a few surprises that we can\u2019t wait to tell you about, too. Regardless of if you\u2019ll be in Detroit this October 25th for KubeCon NA 2022, this is sure to be the can\u2019t-miss OpenTelemetry event of the fall.</p>"},{"location":"blog/2022/otel-unplugged-kubecon-na/#how-do-i-attend","title":"How Do I Attend?","text":"<p>Registration for virtual and in-person attendance is now open! We\u2019re collecting a small fee for in-person attendance, which will be donated to Equality Michigan. Virtual registration is, of course, completely free. In addition, some scholarships are available - please contact us in the #otel-unplugged channel on CNCF Slack for more details. Be sure to register today, as tickets are limited. You can find the complete schedule on our Eventbrite page -- details coming soon!</p> <p>We\u2019re looking forward to welcoming you to OTel Unplugged later this month!</p>"},{"location":"blog/2022/troubleshooting-nodejs/","title":"Checklist for TroublesShooting OpenTelemetry Node.js Tracing Issues","text":"<p>I\u2019ll try to make this one short and to the point. You are probably here because you installed OpenTelemetry in your Node.js application and did not see any traces or some expected spans were missing.</p> <p>There can be many reasons for that, but some are more common than others. In this post, I will try to enumerate the common ones, along with some diagnostic methods and tips.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#requirements","title":"Requirements","text":"<p>I assume that you already have basic knowledge of what OpenTelemetry is and how it works and that you tried to set it up in your Node.js application.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#enable-logging","title":"Enable Logging","text":"<p>OpenTelemetry JS will by default not log anything to its diagnostic logger. Most of the SDK issues below are easily detected when a logger is enabled.</p> <p>You can log everything to the console by adding the following code as early as possible in your service:</p> <pre><code>// tracing.ts or main index.ts\nimport { diag, DiagConsoleLogger, DiagLogLevel } from '@opentelemetry/api';\ndiag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);\n// rest of your otel initialization code\n</code></pre> <p>This is useful for debugging. Logging everything to the console in production is not a good idea, so remember to remove or disable it when your issues are resolved.</p> <p>Pro tip: You can use the <code>OTEL_LOG_LEVEL</code> environment variable to set <code>DiagLogLevel</code> so we can easily turn it off and on.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#auto-instrumentation-libraries","title":"Auto Instrumentation Libraries","text":"<p>Many users choose to use auto Instrumentation libraries, which automatically create spans for interesting operations in popular and widely used packages (DB drivers, HTTP frameworks, cloud services SDKs, etc)</p> <p>Some initialization patterns and configuration options can cause your service to fail to create spans, to begin with.</p> <p>To rule out auto instrumentation libraries issues, try to create a manual span first. If you see manual spans but not spans from the installed auto instrumentation libraries, continue reading this section.</p> <pre><code>import { trace } from '@opentelemetry/api';\ntrace\n.getTracerProvider()\n.getTracer('debug')\n.startSpan('test manual span')\n.end();\n</code></pre>"},{"location":"blog/2022/troubleshooting-nodejs/#install-and-enable","title":"Install and Enable","text":"<p>To use an auto instrumentation library in your service, you\u2019ll need to:</p> <ol> <li>Install it: <code>npm install @opentelemetry/instrumentation-foo</code>. You can search    the OpenTelemetry Registry to find available instrumentations</li> <li>Create the instrumentation object: <code>new FooInstrumentation(config)</code></li> <li>Make sure instrumentation is enabled: call <code>registerInstrumentations(...)</code></li> <li>Verify you are using the right TracerProvider</li> </ol> <p>For most users, the following should cover it:</p> <pre><code>// First run `npm install @opentelemetry/instrumentation-foo @opentelemetry/instrumentation-bar\n// Replace foo and bar with the actual packages you need to instrument (http/mysql/redis etc)\nimport { FooInstrumentation } from '@opentelemetry/instrumentation-foo';\nimport { BarInstrumentation } from '@opentelemetry/instrumentation-bar';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\n// create TracerProvider, SpanProcessors and SpanExporters\nregisterInstrumentations({\ninstrumentations: [new FooInstrumentation(), new BarInstrumentation()],\n});\n</code></pre> <p>For advanced users who choose to use the low-level api instead of calling <code>registerInstrumentations</code>, make sure your instrumentation is set to use the right tracer provider and that you call <code>enable()</code> if appropriate.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#enable-before-require","title":"Enable Before Require","text":"<p>All instrumentations are designed such that you first need to enable them and only then require the instrumented package. A common mistake is to require packages before enabling the instrumentation libraries for them.</p> <p>Here is a bad example:</p> <pre><code>import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\nimport { HttpInstrumentation } from '@opentelemetry/instrumentation-http';\nimport {\nSimpleSpanProcessor,\nConsoleSpanExporter,\n} from '@opentelemetry/sdk-trace-base';\nimport http from 'http'; // \u21d0 BAD - at this point instrumentation is not registered yet\nconst provider = new NodeTracerProvider();\nprovider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));\nprovider.register();\nregisterInstrumentations({ instrumentations: [new HttpInstrumentation()] });\n// your application code which uses http\n</code></pre> <p>In most cases, the instrumentation code resides in a different file or package than the application code, which makes it tricky to discover. Some frameworks, such as serverless, can import packages before the instrumentation code has a chance to run. This can be easily missed.</p> <p>To diagnose this issue, enable logging and verify you are seeing your instrumentation package being loaded. For example:</p> <pre><code>@opentelemetry/instrumentation-http Applying patch for https@12.22.9\n</code></pre> <p>If missing, chances are your auto instrumentation library is not being applied.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#library-configuration","title":"Library Configuration","text":"<p>Some auto instrumentation libraries include a custom configuration that controls when instrumentation is skipped. For example, HTTP instrumentation has options such as <code>ignoreIncomingRequestHook</code> and <code>requireParentforOutgoingSpans</code></p> <p>In specific cases, some libraries are not instrumenting by default, and you have to specifically opt-in to get spans. For example, <code>ioredis</code> instrumentation should be configured with <code>requireParentSpan = true</code> to create spans for internal operation with no parent span.</p> <p>If you don\u2019t see spans for a library, maybe you need to tweak the configuration to make them appear.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#instrumented-library-version","title":"Instrumented Library Version","text":"<p>Auto instrumentation libraries usually don\u2019t support all versions of the library they instrument. If the version you are using is too old or very recent, it might not be supported and thus no spans will be created.</p> <p>Consult the documentation of the library you are using to verify if your version is compatible. This data is usually found in the README for the instrumentation, for example see the redis README.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#no-recording-and-non-sampled-spans","title":"No Recording and Non-Sampled Spans","text":"<p>Not all spans that are created in your application are exported. Spans can be marked as \u201cNot Sampled\u201d or \u201cNon-Recorded\u201d in which case you will not see them in your backend.</p> <p>To rule out these issues, you can hook in a \u201cdebug span processor\u201d which only prints the sampled decision. If \u201cspan sampled: false\u201d is printed to the console, continue reading this section.</p> <pre><code>import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';\nimport { ReadableSpan } from '@opentelemetry/sdk-trace-base';\nimport { trace, Span, Context, TraceFlags } from '@opentelemetry/api';\nconst provider = new NodeTracerProvider();\nprovider.addSpanProcessor({\nforceFlush: async () =&gt; {},\nonStart: (_span: Span, _parentContext: Context) =&gt; {},\nonEnd: (span: ReadableSpan) =&gt; {\nconst sampled = !!(span.spanContext().traceFlags &amp; TraceFlags.SAMPLED);\nconsole.log(`span sampled: ${sampled}`);\n},\nshutdown: async () =&gt; {},\n});\nprovider.register();\n</code></pre>"},{"location":"blog/2022/troubleshooting-nodejs/#nooptracerprovider","title":"NoopTracerProvider","text":"<p>If you don\u2019t create and register a valid TracerProvider, your app will run with the default TracerProvider which starts all the spans in your app as NonRecordingSpans.</p> <p>You need to have code similar to this as early as possible in your application:</p> <pre><code>import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';\nimport {\nConsoleSpanExporter,\nSimpleSpanProcessor,\n} from '@opentelemetry/sdk-trace-base';\nconst provider = new NodeTracerProvider();\nprovider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));\nprovider.register();\n</code></pre>"},{"location":"blog/2022/troubleshooting-nodejs/#remote-sampling-decision","title":"Remote Sampling Decision","text":"<p>The default sampling behavior (and a very popular one) is that each span inherits the sampling decision from its parent. If the component that invoked your service is configured not to sample, then you will not see spans from your service as well.</p> <p>Examples include:</p> <ul> <li>An API Gateway can be configured with sampling logic or have tracing turned   off, in which case it can affect all downstream tracing (including your   innocent service, which needs to be sampled).</li> <li>External users, which are calling your service, can also be instrumented and   derive their own sampling decisions (which you have no control of). These   sampling decisions are then propagated to your service and affect it.</li> <li>Other services in your system can derive sampling decisions based on their   local needs and viewpoint. It can be easy to configure an upstream service   endpoint to not sample an uninteresting endpoint without realizing that it   calls a very interesting and important endpoint downstream (which we do want   to sample).</li> </ul>"},{"location":"blog/2022/troubleshooting-nodejs/#local-sampler","title":"Local Sampler","text":"<p>You can configure your local sampler to sample some spans or none. If the configuration was written by someone else a long time ago, or if it is complex / non-intuitive \u2014 then spans are justifiably not sampled and exported, which can be easy to miss.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#exporting-issues","title":"Exporting Issues","text":"<p>It is possible that the service is generating spans, but they are not exported correctly to your backend or are being thrown in the collector for some reason.</p> <p>To rule out exporting issues, try to add \"ConsoleExporter\". If you see spans exported to console but not in the backend you export to, continue reading this section.</p> <pre><code>import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';\nimport {\nConsoleSpanExporter,\nSimpleSpanProcessor,\n} from '@opentelemetry/sdk-trace-base';\nconst provider = new NodeTracerProvider();\nprovider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));\nprovider.register();\n</code></pre>"},{"location":"blog/2022/troubleshooting-nodejs/#configuring-an-exporter","title":"Configuring an Exporter","text":"<p>Your service should have span exporting code similar to this:</p> <pre><code>import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-proto';\n// Create TracerProvider\nconst exporter = new OTLPTraceExporter();\nprovider.addSpanProcessor(new BatchSpanProcessor(exporter));\n</code></pre> <p>In this example, I used <code>@opentelemetry/exporter-trace-otlp-proto</code>, but there are other exporters to choose from, and each one has a few configuration options. An error in one of these options will fail to export, which is silently ignored by default.</p> <p>A a few common configuration errors are covered in the following subsections.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#otlp-exporters","title":"OTLP exporters","text":"<ul> <li>Format \u2014 OTLP supports <code>http/json</code>, <code>http/proto</code>, and <code>grpc</code> formats. You   need to choose an exporter package that matches the format your OTLP collector   support.</li> <li>Path \u2014 If you set HTTP collector endpoint (via config in code or   environment variables), you must also set the path:   <code>http://my-collector-host:4318/v1/traces</code>. If you forget the path, the export   will fail. In gRPC, you must not add path: \u201cgrpc://localhost:4317\u201d. This can   be a bit confusing to get right at first.</li> <li>Secure Connection \u2014 Check if your collector expects a secure or insecure   connection. In HTTP, this is determined by the URL scheme (<code>http:</code> /   <code>https:</code>). In gRPC, the scheme has no effect and the connection security is   set exclusively by the credentials parameter: <code>grpc.credentials.createSsl()</code>,   <code>grpc.credentials.createInsecure()</code>, etc. The default security for both HTTP   and gRPC is Insecure.</li> </ul>"},{"location":"blog/2022/troubleshooting-nodejs/#jaeger-exporter","title":"Jaeger Exporter","text":"<p>Jaeger exporter can work in \u201cAgent\u201d mode (over UDP) and \u201cCollector\u201d mode (over TCP). The logic to decide which one to use is a bit confusing and lacks documentation. If you pass the <code>endpoint</code> parameter in exporter config or set <code>OTEL_EXPORTER_JAEGER_ENDPOINT</code> environment variable, then the exporter will use \u201cCollector\u201d HTTP sender. Else, it will export in \u201cAgent\u201d mode with UDP sender to the <code>host</code> configured in the <code>param</code>, or, <code>OTEL_EXPORTER_JAEGER_AGENT_HOST</code> or <code>localhost:6832</code>.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#setting-vendor-credentials","title":"Setting Vendor Credentials","text":"<p>If you are using a vendor as your tracing backend, you might need to add additional info such as authentication headers. For example, if you send traces to Aspecto, you\u2019ll need to add your Aspecto token as an Authorization header, like this:</p> <pre><code>import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-proto';\n// Create TracerProvider\nconst exporter = new OTLPTraceExporter({\nurl: 'https://otelcol.aspecto.io/v1/trace',\nheaders: {\nAuthorization: 'YOUR_API_KEY_HERE',\n},\n});\nprovider.addSpanProcessor(new BatchSpanProcessor(exporter));\n</code></pre> <p>If not applied, you will not be able to see any data in your vendor\u2019s account.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#flush-and-shutdown","title":"Flush and Shutdown","text":"<p>When your service goes down or your lambda function ends, it is possible that not all spans are successfully exported to your collector yet. You need to call the shutdown function on your tracer provider and await the returned promise to ensure all data has been sent.</p> <pre><code>import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';\nconst provider = new NodeTracerProvider();\nprovider.register();\n// when your you terminate your service, call shutdown on provider:\nprovider.shutdown();\n</code></pre>"},{"location":"blog/2022/troubleshooting-nodejs/#package-versions-compatibility","title":"Package Versions Compatibility","text":"<p>Some issues can be a result of incompatible or old versions of SDK and instrumentation packages.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#sdk-versions","title":"SDK versions","text":"<p>It is recommended to check that your SDKs and API packages are not old and are compatible with each other. Make sure you don\u2019t have any peer dependency warnings when you npm install.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#other-apm-libraries","title":"Other APM libraries","text":"<p>OpenTelemetry is not guaranteed to be compatible with other APM libraries that use monkey patching to do their magic. If you have such a package installed, try to remove or disable it and check if the problem goes away.</p>"},{"location":"blog/2022/troubleshooting-nodejs/#whats-next","title":"What\u2019s Next?","text":""},{"location":"blog/2022/troubleshooting-nodejs/#where-to-get-help","title":"Where to Get Help","text":"<p>If none of the above solved your problems, you can ask for help on the following channels:</p> <ul> <li>CNCF <code>#otel-js</code> Slack   channel</li> <li>CNCF <code>#opentelemetry-bootcamp</code>   Slack channel</li> <li>GitHub   discussions page</li> </ul>"},{"location":"blog/2022/troubleshooting-nodejs/#resources","title":"Resources","text":"<ul> <li>Opentelemetry-js GitHub repo</li> <li>The OpenTelemetry Bootcamp</li> <li>OpenTelemetry docs</li> </ul>"},{"location":"blog/2022/troubleshooting-nodejs/#should-i-use-a-vendor","title":"Should I Use a Vendor?","text":"<p>Another alternative is to use a vendor\u2019s distribution of OpenTelemetry. These distributions can save you time and effort:</p> <ul> <li>Technical support</li> <li>Preconfigured with popular features for common and advanced users</li> <li>Up to date with latest OpenTelemetry versions</li> <li>Implementing best practices and avoiding the pitfalls mentioned above</li> </ul> <p>For a list of OpenTelemetry vendors, see Vendors.</p> <p>A version of this article was [originally posted][] on the Aspecto blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2022/v1.0-trio/","title":"OpenTelemetry Erlang/Elixir, Javascript, and Ruby v1.0 (Medium)","text":"<p>We are kicking off the new year with a bang! In the last couple months, three new languages (Ruby, Javascript, and Erlang/Elixir) have had their first 1.0 releases, joining the existing GA releases from C++, Go, Java, .Net, Python and Swift. Read all the details from the [announcement][].</p> <p>[announcement]: {{% param canonical_url %}}</p>"},{"location":"blog/2022/welcome/","title":"Welcome to the OpenTelemetry blog","text":"<p>Welcome to the OpenTelemetry blog! As of early 2022, we'll be publishing blog entries through the website rather than Medium. You can still find Medium posts at medium.com/opentelemetry.</p>"},{"location":"blog/2022/announcing-opentelemetry-demo-release/","title":"OpenTelemetry Demo now Generally Available!","text":"<p>Earlier this year, we announced a project to build an OpenTelemetry Demo, representing the breadth of OpenTelemetry features and languages. Today, the Demo SIG is proud to announce OpenTelemetry Demo v1.0! With this demo, you\u2019ll be able to quickly run a complete end-to-end distributed system instrumented with 100% OpenTelemetry Traces and Metrics.</p> <p></p> <p>One of our primary goals of this project has been to create a robust sample application for developers to use in learning OpenTelemetry, and we\u2019re proud to say that we\u2019ve done just that. Every OpenTelemetry language SDK except Swift is represented in this release -- yes, even PHP! We\u2019ve built complete tracing flows that demonstrate a breadth of common instrumentation tasks such as:</p> <ul> <li>Enriching spans from automatic instrumentation.</li> <li>Creating custom spans for richer, more useful traces.</li> <li>Propagating trace context automatically and manually.</li> <li>Handling observability baggage in order to pass attributes between services.</li> <li>Creating attributes, events, and other telemetry metadata.</li> </ul> <p>We\u2019ve also integrated OpenTelemetry Metrics across several services to capture runtime and business metric use cases.</p> <p>Now, it\u2019d be enough to just provide a great demonstration of OpenTelemetry, but one thing we wanted to focus on for our 1.0 release was showing not just the \u2018how\u2019, but the \u2018why\u2019, of OpenTelemetry. To that end, we\u2019ve built a framework for implementing failure scenarios gated by feature flags. In addition, we include pre-configured dashboards and walk-throughs in our docs on how to read and interpret the telemetry data each service emits to discover the underlying cause of performance regressions in the application.</p> <p>Another goal of this demo is to streamline the ability of vendors and commercial implementers of OpenTelemetry to have a standardized target for building demos around. We\u2019ve already seen quite a bit of adoption, with five companies including Datadog, Dynatrace, Honeycomb, Lightstep, and New Relic integrating the community demo application into their product demos (you can find a list here). We hope to encourage further contributions and collaboration along these lines.</p> <p>However, just because we reached 1.0, that doesn\u2019t mean we\u2019re stopping -- this demo is a living artifact, one that we intend to continue to improve. In the coming months we plan to continue to iterate and improve coverage of metrics and logs as more SDKs reach maturity.</p> <p>We also hope to add new instrumentation scenarios and patterns by extending the functionality of the application -- queues and async processing of requests, a hosted version in order to explore the demo with zero setup, adding in support for Swift, and more.</p> <p>We\u2019d love for you to take the demo for a spin and let us know what you think! Check out the docs, or run the demo using Docker or Kubernetes, and let us know your thoughts. If you\u2019d like to contribute, please file an issue on GitHub or join us on the CNCF Slack in #otel-community-demo.</p>"},{"location":"blog/2022/apisix/","title":"Apache APISIX Integrates with OpenTelemetry to Collect Tracing Data","text":"<p>This article introduces the Apache APISIX's <code>opentelemetry</code> plugin concept and how to enable and deploy the plugin.</p>"},{"location":"blog/2022/apisix/#background-information","title":"Background Information","text":"<p>OpenTelemetry is an open source telemetry data acquisition and processing system. It not only provides various SDKs for application side telemetry data collection and reporting, but also provides data collection side for data receiving, processing, and exporting. Export to any or more OpenTelemetry backends, such as Jaeger, Zipkin, and OpenCensus. You can view the list of plugins that have adapted the OpenTelemetry Collector in the registry.</p> <p></p>"},{"location":"blog/2022/apisix/#plugin-introduction","title":"Plugin Introduction","text":"<p>The <code>opentelemetry</code> plugin of Apache APISIX implements Tracing data collection and sends it to OpenTelemetry Collector through HTTP protocol. Apache APISIX starts to support this feature in v2.13.0.</p> <p>One of OpenTelemetry's special features is that the Agent/SDK of OpenTelemetry is not locked with back-end implementation, which gives users flexibilities on choosing their own back-end services. In other words, users can choose the backend services they want, such as Zipkin and Jaeger, without affecting the application side.</p> <p>The <code>opentelemetry</code> plugin is located on the Agent side. It integrates the OpenTelemetry Agent/SDK and adopts its features in Apache APISIX. It can collect traced requests, generate <code>trace</code>, and forward them to the OpenTelemetry Collector. It supports the <code>trace</code> protocol, and it will support the <code>logs</code> and <code>metrics</code> protocols of OpenTelemetry in the next version.</p>"},{"location":"blog/2022/apisix/#enable-the-plugin","title":"Enable the Plugin","text":"<p>You need to enable <code>opentelemetry</code> plugin and modify collector configuration in <code>conf/config.yaml</code> configuration file.</p> <p>We assume that you have already deployed the OpenTelemetry Collector on the same node as the APISIX and enabled the OTLP HTTP Receiver.</p> <p>Need help completing deployment of the OpenTelemetry Collector? See the scenario Example below.</p> <p>The default port of the OTLP HTTP Receiver is <code>4318</code>, and the address of the <code>collector</code> is the HTTP Receiver address of the OpenTelemetry Collector. For related fields, see the Apache APISIX documentation.</p> <p>A typical configuration might look like this:</p> <pre><code>plugins\n... # Other plugins that have been enabled\n- opentelemetry\nplugin_attr:\n...\nopentelemetry:\ntrace_id_source: x-request-id\nresource:\nservice.name: APISIX\ncollector:\naddress: 127.0.0.1:4318 # OTLP HTTP Receiver address\nrequest_timeout: 3\n</code></pre>"},{"location":"blog/2022/apisix/#method-1-enable-the-plugin-for-a-specific-route","title":"Method 1: Enable the Plugin for a Specific Route","text":"<p>In order to show the test effect more conveniently, <code>sampler</code> is temporarily set to full sampling in the example to ensure that <code>trace</code> data is generated after each request is traced, so that you can view <code>trace</code> related data on the Web UI. You can also set relevant parameters according to the actual situation.</p> <pre><code>curl http://127.0.0.1:9080/apisix/admin/routes/1 \\\n-H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \\\n-X PUT -d '\n{\n    \"uri\": \"/get\",\n    \"plugins\": {\n        \"opentelemetry\": {\n            \"sampler\": {\n                \"name\": \"always_on\"\n            }\n        }\n    },\n    \"upstream\": {\n        \"type\": \"roundrobin\",\n        \"nodes\": {\n            \"httpbin.org:80\": 1\n        }\n    }\n}'\n</code></pre>"},{"location":"blog/2022/apisix/#method-2-enable-the-plugin-globally","title":"Method 2: Enable the Plugin Globally","text":"<p>You can also enable <code>opentelemetry</code> plugin through the Apache APISIX Plugins feature. After the global configuration is complete, you still need to create the route, otherwise it will not be possible to test.</p> <pre><code>curl 'http://127.0.0.1:9080/apisix/admin/global_rules/1' \\\n-H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \\\n-X PUT -d '{\n    \"plugins\": {\n        \"opentelemetry\": {\n            \"sampler\": {\n                \"name\": \"always_on\"\n            }\n        }\n    }\n}'\n</code></pre>"},{"location":"blog/2022/apisix/#method-3-customize-labels-for-span-through-additional_attributes","title":"Method 3: Customize Labels for Span through additional_attributes","text":"<p>For the configuration of <code>sampler</code> and <code>additional_attributes</code>, see the Apache APISIX documentation, where <code>additional_attributes</code> is a series of <code>Key:Value</code> pairs, you can use it to customize the label for Span, and can follow Span to display on the Web UI. Add <code>route_id</code> and <code>http_x-custom-ot-key</code> to the span of a route through <code>additional_attributes</code>, see the following configuration:</p> <pre><code>curl http://127.0.0.1:9080/apisix/admin/routes/1001 \\\n-H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \\\n-X PUT -d '\n{\n    \"uri\": \"/put\",\n    \"plugins\": {\n        \"opentelemetry\": {\n            \"sampler\": {\n                \"name\": \"always_on\"\n            },\n            \"additional_attributes\":[\n                \"route_id\",\n                \"http_x-custom-ot-key\"\n            ]\n        }\n    },\n    \"upstream\": {\n        \"type\": \"roundrobin\",\n        \"nodes\": {\n            \"httpbin.org:80\": 1\n        }\n    }\n}'\n</code></pre>"},{"location":"blog/2022/apisix/#test-and-verify-the-plugin","title":"Test and Verify the Plugin","text":"<p>You can enable <code>opentelemetry</code> plugin in any of the above three methods. The following example uses the example of method three to create a route. After the creation is successful, see the following commands to access the route:</p> <pre><code>curl -X PUT -H `x-custom-ot-key: test-ot-val` http://127.0.0.1:9080/put\n</code></pre> <p>After the access is successful, you can see the details of the span similar to <code>/put</code> in the Jaeger UI, and you can see that the custom tags in the route are displayed in the Tags list: <code>http_x-custom-ot-key</code> and <code>route_id</code>.</p> <p></p> <p>You need to note that the <code>additional_attributes</code> configuration is set to take values from Apache APISIX and NGINX variables as <code>attribute</code> values, so <code>additional_attributes</code> must be a valid Apache APISIX or NGINX variable. It also includes HTTP Header, but when fetching http*header, you need to add <code>http*</code>as the prefix of the variable name. If the variable does not exist, the<code>tag</code> will not be displayed.</p>"},{"location":"blog/2022/apisix/#example","title":"Example","text":"<p>This scenario example deploys Collector, Jaeger, and Zipkin as backend services by simply modifying the OpenTelemetry Collector example, and starts two sample applications (Client and Server), where Server provides an HTTP service, and Client will cyclically call the server provided by the server. HTTP interface, resulting in a call chain consisting of two spans.</p>"},{"location":"blog/2022/apisix/#step-1-deploy-opentelemetry","title":"Step 1: Deploy OpenTelemetry","text":"<p>The following uses <code>docker compose</code> as an example. For other deployments, see Getting Started.</p> <p>You can see the following command to deploy1:</p> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-collector-contrib.git\ncd opentelemetry-collector-contrib/examples/demo\ndocker compose up -d\n</code></pre> <p>Visit http://127.0.0.1:16886 (Jaeger UI) or http://127.0.0.1:9411/zipkin (Zipkin UI) in your browser. If it can be accessed normally, the deployment is successful.</p> <p>The following screenshots show an example of successful access.</p> <p></p> <p></p>"},{"location":"blog/2022/apisix/#step-2-configure-the-test-environment","title":"Step 2: Configure the Test Environment","text":"<p>The Apache APISIX service is introduced, and the topology of the final application is shown in the following figure.</p> <p></p> <p>The Trace data reporting process is as follows. Among them, since Apache APISIX is deployed separately and not in the network of docker-compose, Apache APISIX accesses the OTLP HTTP Receiver of OpenTelemetry Collector through the locally mapped port (<code>127.0.0.1:4138</code>).</p> <p></p> <p>You need to make sure you have enabled the <code>opentelemetry</code> plugin and reload Apache APISIX.</p> <p>You can see the following example to create a route and enable the<code>opentelemetry</code> plugin for sampling:</p> <pre><code>curl http://127.0.0.1:9080/apisix/admin/routes/1 \\\n-H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \\\n-X PUT -d '\n{\n  \"uri\": \"/hello\",\n  \"plugins\": {\n      \"opentelemetry\": {\n          \"sampler\": {\n            \"name\": \"always_on\"\n          }\n      }\n  },\n  \"upstream\": {\n      \"type\": \"roundrobin\",\n      \"nodes\": {\n          \"127.0.0.1:7080\": 1\n      }\n  }\n}'\n</code></pre> <p>Modify the <code>./examples/demo/otel-collector-config.yaml</code> file to add the OTLP HTTP Receiver.</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp: ${ip:port} # add OTLP HTTP Receiver\uff0cdefault port is 4318\n</code></pre> <p>Modify <code>docker-compose.yaml</code> file.</p> <p>You need to modify the configuration file, change the interface address of Client calling Server to the address of Apache APISIX, and map the ports of OTLP HTTP Receiver and Server services to local.</p> <p>The following example is the complete <code>docker-compose.yaml</code> after the configuration is modified:</p> <pre><code>version: '2'\nservices:\n# Jaeger\njaeger-all-in-one:\nimage: jaegertracing/all-in-one:latest\nports:\n- '16686:16686' # jaeger ui port\n- '14268'\n- '14250'\n# Zipkin\nzipkin-all-in-one:\nimage: openzipkin/zipkin:latest\nports:\n- '9411:9411'\n# Collector\notel-collector:\nimage: ${OTELCOL_IMG}\ncommand: ['--config=/etc/otel-collector-config.yaml', '${OTELCOL_ARGS}']\nvolumes:\n- ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\nports:\n- '1888:1888' # pprof extension\n- '8888:8888' # Prometheus metrics exposed by the collector\n- '8889:8889' # Prometheus exporter metrics\n- '13133:13133' # health_check extension\n- '4317' # OTLP gRPC receiver\n- '4318:4318' # Add OTLP HTTP Receiver port mapping\n- '55670:55679' # zpages extension\ndepends_on:\n- jaeger-all-in-one\n- zipkin-all-in-one\ndemo-client:\nbuild:\ndockerfile: Dockerfile\ncontext: ./client\nenvironment:\n- OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317\n- DEMO_SERVER_ENDPOINT=http://172.17.0.1:9080/hello # APISIX address\ndepends_on:\n- demo-server\ndemo-server:\nbuild:\ndockerfile: Dockerfile\ncontext: ./server\nenvironment:\n- OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317\nports:\n- '7080:7080' # Map the Server port to the host\ndepends_on:\n- otel-collector\nprometheus:\ncontainer_name: prometheus\nimage: prom/prometheus:latest\nvolumes:\n- ./prometheus.yaml:/etc/prometheus/prometheus.yml\nports:\n- '9090:9090'\n</code></pre> <p>It should be noted that <code>demo-client.environment.DEMO_SERVER_ENDPOINT</code> needs to be changed to your Apache APISIX address, and ensure that it can be accessed normally in the container.</p> <p>Of course, you can also deploy Apache APISIX through <code>docker-compose.yaml</code>. For details, see Installation via Docker.</p>"},{"location":"blog/2022/apisix/#step-3-verify-the-outputs","title":"Step 3: Verify the Outputs","text":"<p>After the redeployment is completed, you can access the Jaeger UI or Zipkin UI to see that the Span of APISIX is included in the Trace, as shown below:</p> <p></p> <p></p> <p>When demo-server is not instrumented, you can still getting visibility of the demo-server behavior by enabling this plugin. Although this is not a typical case, it is a poor-man substitute of a real instrumentation of demo-server and provides a lot of value.</p> <p></p> <p>When the request does not reach the demo-server, the output would not include the span of demo-server.</p> <p></p>"},{"location":"blog/2022/apisix/#disable-the-plugin","title":"Disable the Plugin","text":"<p>If you do not need trace collection of a route temporarily, you only need to modify the route configuration and delete the part of <code>opentelemetry</code> under <code>plugins</code> in the configuration.</p> <p>If you enabled <code>opentelemetry</code> globally by binding Global Rules, you can remove the configuration of the <code>opentelemetry</code> global plugin.</p> <p>Note that disabling the <code>opentelemetry</code> plugin only results in disconnecting the APISIX span, the client and server spans will remain connected.</p>"},{"location":"blog/2022/apisix/#summary","title":"Summary","text":"<p>After Apache APISIX integrates OpenTelemetry, it can easily connect with many Trace systems on the market. Apache APISIX is also actively cooperating with communities to create a more powerful ecosystem.</p> <p>Apache APISIX is also currently working on additional plugins to support integration with more services, if you're interested, feel free to start a discussion on GitHub, or communicate via the mailing list.</p> <p>A version of this article was [originally posted][] on the Apache APISIX blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/2022/collector-builder-sample/","title":"Using the Collector Builder with Sample Configs on GCP","text":"<p>The OpenTelemetry Collector is a versatile tool for processing and exporting telemetry data. It supports ingestion from many different sources and routing to just as many observability backends thanks to its modular design. This design, based on individual receivers, processors, and exporters, enables third-party development of new backend support. It also allows users to configure telemetry pipelines that are customized to their use case.</p> <p>The collector-builder tool takes that customizability a step further, offering a way to easily compile a Collector binary built with only certain ingestion and export components. In contrast with publicly available binary releases (which bundle in a number of components by default), custom Collectors can be slimmed down to only include the components you really care about. This means the compiled Collector can be smaller, faster, and more secure than a public release.</p> <p>Google Cloud recently launched a sample GitHub repository for building and deploying your own custom OpenTelemetry Collector on GCP. This takes the guesswork out of running the collector on GCP, but leaves you free to extend it to meet your use-cases.</p> <p>This repository will help you:</p> <ul> <li> <p>Compile a custom Collector designed for GCP with the collector-builder.   Low-overhead Collector builds are possible with the upstream collector-builder   tool, so we\u2019ve provided the setup files for building a lightweight collector   with GCP services in mind. This is GCP's recommended base set of components to   use when running on GCP or working with GCP services. OpenTelemetry can be   complex and intimidating, and we are providing a curated and tested   configuration as a starting point.</p> </li> <li> <p>Adapt existing tutorials for the OpenTelemetry Collector to GCP use cases.   By distilling the wide breadth of available information on using the Collector   and abstracting setup into a few simple commands, this repository reduces the   process for setting up a custom collector to a few simple Make commands.</p> </li> <li> <p>Keep your Collector deployment up-to-date. By incorporating custom   Collectors into your CI/CD pipeline, you can automate builds to ensure your   Collector stays current with the latest features and fixes. In this repo,   we'll show one way to do that with Cloud Build.</p> </li> </ul> <p>Each of these represents part of the \u201cGetting Started\u201d process with OpenTelemetry Collector, so by identifying and consolidating these steps we hope to expedite and ease the experience down to a few clicks.</p>"},{"location":"blog/2022/collector-builder-sample/#build-an-opentelemetry-collector-that-suits-your-needs","title":"Build an OpenTelemetry Collector that suits your needs","text":"<p>While there are public Docker images for the Collector published by the OpenTelemetry community, these images can be as large as 40MB. This is due to all of the receivers, processors, and exporters that are bundled into the image by default. With all of these default components, there is also the potential for security issues to arise, part of the reason why the Collector maintainers recommend only enabling necessary components in your Collector.</p> <p>The collector-builder tool accelerates compiling stripped-down Collector images with a simple YAML config file. This file declares which components to include in the build, and collector-builder includes only those components (and nothing else). This is in contrast to a default Collector build, where many more components are included in the compiled binary (even if they are not being enabled in the Collector\u2019s runtime configuration). This difference is how you can achieve improvements over public images that include many excess components, with extra dependencies adding weight and security burden. Now, those extra components can\u2019t take up space because they aren\u2019t even available in the custom build.</p> <p>To show how this works we start with a sample config file in this repository which has been pre-filled with a few of the most relevant OpenTelemetry components for GCP. However, we encourage you to modify that sample file to fit your use case.</p> <p>For example, the following build file includes only the OTLP receiver and exporter, along with a logging exporter:</p> <pre><code>receivers:\n- import: go.opentelemetry.io/collector/receiver/otlpreceiver\ngomod: go.opentelemetry.io/collector v0.57.2\nexporters:\n- import: go.opentelemetry.io/collector/exporter/otlpexporter\ngomod: go.opentelemetry.io/collector v0.57.2\n- import: go.opentelemetry.io/collector/exporter/loggingexporter\ngomod: go.opentelemetry.io/collector v0.57.2\n</code></pre> <p>Edit this file in the repository and run <code>make build</code> to automatically generate a local binary, or <code>make docker-build</code> to compile a container image.</p>"},{"location":"blog/2022/collector-builder-sample/#get-up-and-running-quickly-on-gke","title":"Get up and running quickly on GKE","text":"<p>For convenience, this repository includes the minimum Kubernetes manifests used to deploy the Collector in a GKE cluster, with a compatible runtime configuration for the sample collector-builder components built by default. When used together, the Make commands provided to build and push an image to Artifact Registry will automatically update those manifests in the repository to use the newly-created image, offering an end-to-end build and deployment reference.</p>"},{"location":"blog/2022/collector-builder-sample/#deploying-the-collector-in-gke","title":"Deploying the Collector in GKE","text":"<p>As mentioned earlier in this post, the collector offers vendor-agnostic routing and processing for logs, metrics, and tracing telemetry data. For example, while you may already be using a collection agent on GKE (such as for metrics and logs), the collector can provide a pathway for exporting traces. Those traces can be sent to an observability backend of your choice. It then opens up flexibility to process and export your other telemetry signals to any backend.</p> <p>With the provided Kubernetes manifests, you only need one <code>kubectl</code> command to deploy the Collector:</p> <pre><code>kubectl apply -f k8s/manifest.yaml -n otel-collector\n</code></pre> <p>Using a Collector generated from the build file shown earlier in this post, a matching OpenTelemetry Collector configuration would look like the following:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nexporters:\notlp:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [otlp]\n</code></pre> <p>The Collector in GKE consumes this config file through a Kubernetes ConfigMap that is mounted by the Collector Pod. This ConfigMap is created with a basic <code>kubectl</code> command:</p> <pre><code>kubectl create configmap otel-config --from-file=./otel-config.yaml -n otel-collector\n</code></pre>"},{"location":"blog/2022/collector-builder-sample/#modifying-the-collector-config","title":"Modifying the Collector Config","text":"<p>The OpenTelemetry config file format allows hot-swapping Collector configurations to re-route telemetry data with minimal disruption. For example, it may be useful to temporarily enable the <code>logging</code> exporter, which provides debugging insights into the Collector. This is done by editing the local config file from above to add two lines:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nexporters:\notlp:\nlogging:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [otlp, logging]\n</code></pre> <p>The runtime config can then be re-applied with <code>kubectl apply</code>:</p> <pre><code>kubectl create configmap otel-config --from-file=./otel-config.yaml --dry-run=client -n otel-collector -o yaml | kubectl apply -f -\n</code></pre> <p>After restarting the Collector pod (such as with <code>kubectl delete</code> or by applying a new manifest, as we\u2019ll show below), the new config changes will take effect. This workflow can be used to enable or disable any OpenTelemetry exporter, with exporters available for many popular observability backends.</p>"},{"location":"blog/2022/collector-builder-sample/#adding-a-receiver-and-processor","title":"Adding a receiver and processor","text":"<p>You can add more components and follow the same process as above to build and deploy a new Collector image. For example, you can enable the Zipkin exporter (for sending traces to a Zipkin backend service) and the batch processor by editing your builder config from earlier like so:</p> <pre><code>receivers:\n- import: go.opentelemetry.io/collector/receiver/otlpreceiver\ngomod: go.opentelemetry.io/collector v0.57.2\nprocessors:\n- import: go.opentelemetry.io/collector/processor/batchprocessor\ngomod: go.opentelemetry.io/collector v0.57.2\nexporters:\n- import: go.opentelemetry.io/collector/exporter/otlpexporter\ngomod: go.opentelemetry.io/collector v0.57.2\n- import: go.opentelemetry.io/collector/exporter/loggingexporter\ngomod: go.opentelemetry.io/collector v0.57.2\n- import: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/zipkinexporter\ngomod:\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/zipkinexporter\nv0.57.2\n</code></pre> <p>Running <code>make docker-build</code> then compiles a new version of your Collector image. If you have an Artifact Registry set up for hosting Collector images, you can also run <code>make docker-push</code> with environment variables set to make the image available in your GKE cluster (setup steps for this are documented in the README).</p> <p>Enabling the new receiver and processor also follows the same steps as above, starting with editing your local Collector config:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nprocessors:\nbatch:\nsend_batch_max_size: 200\nsend_batch_size: 200\nexporters:\notlp:\nlogging:\nzipkin:\nendpoint: http://my-zipkin-service:9411/api/v2/spans\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp, logging, zipkin]\n</code></pre> <p>Update the config in your cluster by running the same <code>kubectl apply</code> command from earlier:</p> <pre><code>kubectl create configmap otel-config --from-file=./otel-config.yaml --dry-run=client -n otel-collector -o yaml | kubectl apply -f -\n</code></pre> <p>Now, once your Collector pod restarts with the new image it will start using the new exporter and processor. When you ran <code>make docker-build</code>, the command automatically updated the Kubernetes deployment manifests provided in the repository to point to your new Collector image. So updating an existing running Collector with the new image only requires running <code>kubectl apply</code> again:</p> <pre><code>kubectl apply -f manifest.yaml -n otel-collector\n</code></pre> <p>This will trigger a new rollout of your Collector deployment, picking up the config changes and new components as compiled into the updated image.</p>"},{"location":"blog/2022/collector-builder-sample/#automate-builds-for-secure-up-to-date-images","title":"Automate builds for secure, up-to-date images","text":"<p>Building your own Collector allows you to control updates and rollouts of the Collector image. In this repo, we have some samples of how you can own your Collector build on GCP.</p> <p>Using a Cloud Build configuration supports serverless, automated builds for your Collector. By doing so you can benefit from new releases, features, and bug fixes in Collector components with minimal delay. Combined with Artifact Registry, these builds can be pushed as Docker images in your GCP project. This provides portability and accessibility of your images, as well as enabling container vulnerability scanning in Artifact Registry to ensure the supply-chain safety of your Collector deployment.</p> <p>Serverless builds and vulnerability scanning are valuable aspects of a reliable CI/CD pipeline. Here, we hope to abstract away some of the complication around these processes by shipping sample configs with this repository. And while we're providing some sample steps toward setting these up with GCP, similar approaches are possible with many other vendors as well.</p>"},{"location":"blog/2022/collector-builder-sample/#wrapping-up","title":"Wrapping Up","text":"<p>The OpenTelemetry Collector makes it easy to ingest and export telemetry data. This is thanks to OpenTelemetry\u2019s vendor-agnostic data model, but also to the active community of contributors supporting custom components for different backends. These components provide the flexibility for OpenTelemetry to support a wide variety of use cases.</p> <p>We hope this sample, as well as some of the example use cases we\u2019ve discussed here, help smooth over the friction some experience when getting started with OpenTelemetry. If you would like to provide some feedback, don\u2019t hesitate to report any feature requests or issues by opening an issue on GitHub.</p>"},{"location":"blog/2022/debug-otel-with-otel/","title":"How we used OpenTelemetry to fix a bug in OpenTelemetry","text":"<p>OpenTelemetry is here to help us find the root cause of issues in our software quickly. We recently had an issue that we were able to fix by using one feature of OpenTelemetry to identify the root cause of bug in another feature.</p> <p>In this blog post, we want to share this interesting experience with you. By that, you will learn that minor differences in the language-specific implementations can have interesting implications and that you have a feature for java &amp; python, which is here to help you to debug context propagation issues.</p>"},{"location":"blog/2022/debug-otel-with-otel/#the-issue","title":"The issue","text":""},{"location":"blog/2022/debug-otel-with-otel/#describe-the-bug","title":"Describe the bug","text":"<p>For the blog post Learn how to instrument NGINX with OpenTelemetry we created a small sample app that had a frontend application in Node.js, that called an NGINX, which acted as a reverse proxy for a backend application in python.</p> <p>Our goal was to create a re-usable <code>docker-compose</code> that would not only show people how to instrument NGINX with OpenTelemetry, but also how a distributed trace crossing the web server would look like.</p> <p>While Jaeger showed us a trace flowing from the frontend application down to the NGINX, the connection between NGINX and python app was not visible: we had two disconnected traces.</p> <p>This came as a surprise, because in a prior test with a Java application as backend we were able to see traces going from NGINX to that downstream application.</p>"},{"location":"blog/2022/debug-otel-with-otel/#steps-to-reproduce","title":"Steps to reproduce","text":"<p>Follow the instructions on how you can put NGINX between two services. Replace the java-based application with a python application, e.g. put following three files into the <code>backend</code> folder instead:</p> <ul> <li><code>app.py</code>:</li> </ul> <pre><code>import time\nimport redis\nfrom flask import Flask\napp = Flask(__name__)\ncache = redis.Redis(host='redis', port=6379)\ndef get_hit_count():\nretries = 5\nwhile True:\ntry:\nreturn cache.incr('hits')\nexcept redis.exceptions.ConnectionError as exc:\nif retries == 0:\nraise exc\nretries -= 1\ntime.sleep(0.5)\n@app.route('/')\ndef hello():\ncount = get_hit_count()\nreturn 'Hello World! I have been seen {} times.\\n'.format(count)\n</code></pre> <ul> <li><code>Dockerfile</code>:</li> </ul> <pre><code>FROM python:3.10-alpine\nWORKDIR /code\nENV FLASK_APP=app.py\nENV FLASK_RUN_HOST=0.0.0.0\nRUN apk add --no-cache gcc musl-dev linux-headers\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\nRUN opentelemetry-bootstrap -a install\nEXPOSE 5000\nCOPY . .\nCMD [\"opentelemetry-instrument\", \"--traces_exporter\", \"otlp_proto_http\", \"--metrics_exporter\", \"console\", \"flask\", \"run\"]\n</code></pre> <ul> <li><code>requirements.txt</code>:</li> </ul> <pre><code>flask\nredis\nopentelemetry-distro\nopentelemetry-exporter-otlp-proto-http\n</code></pre> <p>Update the <code>docker-compose.yml</code> with the following:</p> <pre><code>version: '2'\nservices:\njaeger:\nimage: jaegertracing/all-in-one:latest\nports:\n- '16686:16686'\ncollector:\nimage: otel/opentelemetry-collector:latest\ncommand: ['--config=/etc/otel-collector-config.yaml']\nvolumes:\n- ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\nnginx:\nimage: nginx-otel\nvolumes:\n- ./opentelemetry_module.conf:/etc/nginx/conf.d/opentelemetry_module.conf\n- ./default.conf:/etc/nginx/conf.d/default.conf\nbackend:\nbuild: ./backend\nimage: backend-with-otel\nenvironment:\n- OTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4318/v1/traces\n- OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n- OTEL_SERVICE_NAME=python-app\nredis:\nimage: 'redis:alpine'\nfrontend:\nbuild: ./frontend\nimage: frontend-with-otel\nports:\n- '8000:8000'\nenvironment:\n- OTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4318/\n- OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n- OTEL_SERVICE_NAME=frontend\n</code></pre> <p>Spin up that environment by running <code>docker compose up</code>1 and send some requests to the frontend with <code>curl localhost:8000</code></p>"},{"location":"blog/2022/debug-otel-with-otel/#what-did-you-expect-to-see","title":"What did you expect to see?","text":"<p>In the Jaeger UI at localhost:16686 you would expect to see traces going from the <code>frontend</code> through NGINX down to the <code>python-app</code>.</p>"},{"location":"blog/2022/debug-otel-with-otel/#what-did-you-see-instead","title":"What did you see instead?","text":"<p>In the Jaeger UI at localhost:16686 you will see two traces, one going from the <code>frontend</code> down to NGINX, and another one only for the <code>python-app</code>.</p>"},{"location":"blog/2022/debug-otel-with-otel/#the-solution","title":"The solution","text":""},{"location":"blog/2022/debug-otel-with-otel/#the-hints","title":"The hints","text":"<p>Since the setup worked with a java application in the backend, we knew that the problem was either caused by the python application or by the combination of the NGINX instrumentation and the python application.</p> <p>We could quickly rule out that the python application alone was the issue: trying out a simple Node.js application as backend, we got the same result: two traces, one from frontend to NGINX, another one for the Node.js application alone.</p> <p>With that, we knew that we had a propagation issue: the trace context was not transferred successfully from NGINX down to the python and Node.js application.</p>"},{"location":"blog/2022/debug-otel-with-otel/#the-analysis","title":"The analysis","text":"<p>Knowing that the issue does not occur with java and that it is likely a broken propagation, we knew what we had to do: we needed to see the trace headers.</p> <p>Gladly, the instrumentations for Java and Python have a feature that allows us to capture HTTP request &amp; response headers as span attributes easily.</p> <p>By providing a comma-separated list of HTTP header names via the environment variables <code>OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST</code> and <code>OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_RESPONSE</code> we can define which HTTP headers we want to capture. In our case we put all potential propagation headers:</p> <pre><code>OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST=tracestate,traceparent,baggage,X-B3-TraceId\n</code></pre> <p>In our <code>docker-compose</code>-based example we simply can add it to the definition of our backend service:</p> <pre><code>backend:\nbuild: ./backend\nimage: backend-with-otel\nenvironment:\n- OTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4318/v1/traces\n- OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n- OTEL_SERVICE_NAME=python-app\n- OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST=tracestate,traceparent,baggage,X-B3-TraceId\n</code></pre> <p>Once again we ran <code>docker compose up</code>1 to bring up our sample app and we send some request with <code>curl localhost:8080</code> to the frontend application.</p> <p>In Jaeger we still see that the traces are disconnected. However, when we look into one of those traces, we can see the collected request headers from NGINX to backend:</p> <p></p> <p>There it is! The trace headers (<code>baggage</code>, <code>traceparent</code>, <code>tracestate</code>) are send as multiple header fields: the NGINX module added the value of each of those headers again and again, and since having multi value headers is covered by RFC7230, this didn't lead to an issue immediately.</p> <p>We tested the capability to correlate from NGINX to a downstream service with a Java application. And, without reading into the source code of the OTel Java SDK, it looks like that Java is flexible in taking a <code>traceparent</code> with multiple values, even though such format is invalid per the W3C Trace Context specification. So propagation from NGINX to the Java service worked, while in contrast, Python (and other languages) do not provide that flexibility and propagation from NGINX to the downstream service silently fails.</p> <p>Note, that we are not suggesting that the other languages should have the same flexibility as Java has with reading <code>traceparent</code> or vice-versa: the bug lives in the NGINX module and we need to fix that.</p>"},{"location":"blog/2022/debug-otel-with-otel/#the-fix","title":"The fix","text":"<p>To fix our problem we added some checks to the module for NGINX, that make sure that the trace headers are only set once.</p> <p>This fix is contained in the v1.0.1 release of the otel-webserver-module. This means you can update the <code>Dockerfile</code> to install the NGINX module like the following:</p> <pre><code>FROM nginx:1.18\nADD https://github.com/open-telemetry/opentelemetry-cpp-contrib/releases/download/webserver%2Fv1.0.1/opentelemetry-webserver-sdk-x64-linux.tgz /opt\nRUN cd /opt ; tar xvfz opentelemetry-webserver-sdk-x64-linux.tgz\nRUN cd /opt/opentelemetry-webserver-sdk; ./install.sh\nENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/opentelemetry-webserver-sdk/sdk_lib/lib\nRUN echo \"load_module /opt/opentelemetry-webserver-sdk/WebServerModule/Nginx/ngx_http_opentelemetry_module.so;\\n$(cat /etc/nginx/nginx.conf)\" &gt; /etc/nginx/nginx.conf\nCOPY default.conf /etc/nginx/conf.d\nCOPY opentelemetry_module.conf /etc/nginx/conf.d\n</code></pre> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"blog/2022/demo-announcement/","title":"Announcing a Community Demo for OpenTelemetry","text":""},{"location":"blog/2022/demo-announcement/#tldr","title":"TL;DR","text":"<p>The OpenTelemetry community has taken a good pre-existing demo (thanks, Google!) and is in the process of making it even better. Every GA SDK (besides Swift) will be represented, demo support will be extended to Metrics and Logs, and canonical scenarios will be documented for each signal, with fault injection, and more!</p> <p>If you want to skip the details then clone our repo then run <code>docker compose up</code>1 from the command line. There are a couple technology requirements so be sure to check those out too.</p> <p>The demo takes 15-20 minutes to build the first time so we encourage you to do some stretching and take a water break in the meantime.</p> <p>Your command line output should look like this:</p> <p></p> <ul> <li> <p>Once the images are built you can access the Webstore at:   http://localhost:8080</p> </li> <li> <p>And the Jaeger UI at: http://localhost:8080/jaeger/ui</p> </li> </ul> <p>Congratulations! You can now indulge in retail therapy and submit telemetry. A true victory.</p>"},{"location":"blog/2022/demo-announcement/#success-of-the-commons","title":"Success of the Commons","text":"<p>There are a couple universal problems that are the driving force behind our joint demo effort.</p> <p>As OpenTelemetry matures, users and enterprises are increasingly looking for best practice guides on how to onboard their services to the new paradigm or demo applications so that they can try out the new tools themselves. However, community working groups and vendors lack a singular sophisticated platform to demonstrate their technologies on. Greeting the world can only get us so far.</p> <p>Multiple vendors have written their own demo applications but are wholly responsible for the development and ongoing support. The existing demos are all feature incomplete in their own ways with missing languages, restrictions on backend choice, and they\u2019re overly reliant on instrumentation libraries.</p>"},{"location":"blog/2022/demo-announcement/#project-goals","title":"Project Goals","text":"<ul> <li>Provide developers with a robust sample application they can use in learning   OpenTelemetry instrumentation.</li> <li>Provide observability vendors with a single, well-supported, demo platform   that they can further customize or simply use OOB.</li> <li>Provide the OpenTelemetry community with a living artifact that demonstrates   the features and capabilities of OTel APIs, SDKs, and tools.</li> <li>Provide OpenTelemetry maintainers and working groups a platform to demonstrate   new features/concepts in real world like scenarios.</li> </ul>"},{"location":"blog/2022/demo-announcement/#current-state","title":"Current State","text":"<p>As a starting point, we have selected a fork of the popular GCP microservices demo. Our first feature additions have been to simplify local deployment by consolidating the project onto a single docker compose file, updating the documentation, and replacing a pre-existing service with a Ruby example. Otherwise the pre-existing feature set from the GCP demo remains the same:</p> <ul> <li>10 application microservice with support for 6 languages (C#, Go, Java,   Node.js, Python, and Ruby)</li> <li>Ruby support was added within the last 2 weeks of publishing date</li> <li>Designed to work on docker locally</li> <li>Uses redis cache</li> <li>Auto-instrumentation using instrumentation libraries Tracing support for the   gRPC, Redis, and HTTP libraries</li> <li>Jaeger visualizations for distributed traces, forwarded by OpenTelemetry   collector</li> <li>Always on sampling (100% of telemetry is submitted) and synthetic load   generation</li> </ul>"},{"location":"blog/2022/demo-announcement/#current-architecture","title":"Current Architecture","text":""},{"location":"blog/2022/demo-announcement/#byob-bring-your-own-backend","title":"BYOB (Bring Your Own Backend)","text":"<p>Jaeger is great (really) but what if you want to try this out with your APM vendor of choice? You can send data to your preferred backend by simply changing the Collector config file to use their Collector exporter or by using your vendor's fork of our demo.</p> <p>Lightstep has an excellent blog they just published on how to get started sending data to power their experiences from their forked version of our demo.</p>"},{"location":"blog/2022/demo-announcement/#future-state","title":"Future State","text":""},{"location":"blog/2022/demo-announcement/#upcoming-new-features","title":"Upcoming New Features","text":"<p>We have a lot of exciting improvements that are planned or in progress to turn this application into the canonical example of the full power of OpenTelemetry. Below is a semi-exhaustive list of upcoming features but we're not limiting ourselves to just the items listed here.</p> <ul> <li>Language examples for   C++,   Erlang/elixir,   PHP, and   Rust</li> <li>Extend support to   Metrics and   Logs for all   GA SDKs</li> <li>Visualization components to consume Metrics</li> <li>Implementation of multiple instrumentation techniques</li> <li>Auto-instrumentation using the agent in a sidecar</li> <li>Manual instrumentation of all signals</li> <li>Service Level Objective (SLO)   definition and tracking</li> <li>Additional instrumentation libraries introduced where needed</li> <li>Demonstratations of the ability to add   Baggage and   other custom tags</li> <li>Continue to build on other cloud-native technologies like:</li> <li>Kubernetes</li> <li>gRPC</li> <li>OpenFeature</li> <li>OpenSLO</li> <li>etc.</li> <li>An enhanced OpenTelemetry collector gateway capabilities for ingestion,   transformation, and export</li> <li>Probability based sampling</li> <li>Feature flag service to demonstrate various scenarios like fault injection and   how to emit telemetry from a feature flag reliant service</li> </ul>"},{"location":"blog/2022/demo-announcement/#future-architecture","title":"Future Architecture","text":""},{"location":"blog/2022/demo-announcement/#going-forward","title":"Going Forward","text":"<p>We\u2019re still at the beginning of our journey but there\u2019s great momentum behind this project. If you\u2019re interested in contributing we\u2019d love your support. There are links in our GitHub repo on how to get involved and you can track our overall progress from there.</p>"},{"location":"blog/2022/demo-announcement/#interesting-links","title":"Interesting Links","text":"<ul> <li>Demo Requirements</li> <li>Get Involved</li> </ul> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/2022/end-user-discussion-group-apac/","title":"End User Discussion Group: New APAC Sessions Announcement!","text":"<p>Since July, end users have been getting together to discuss their OpenTelemetry adoption and implementation practices in a vendor-neutral space known as the Monthly Discussion Groups (also referenced as the End User Discussion Groups).</p> <p>Previously, they were only available in the EMEA and AMER regions; the End User Working Group is pleased to announce that APAC sessions will now be available, starting in January 2023!</p>"},{"location":"blog/2022/end-user-discussion-group-apac/#the-what","title":"The what","text":"<p>As mentioned above, these Discussion Groups are monthly meetings for end users to discuss the challenges they're facing in their OTel implementations and to learn from each other, as well as to talk about the project itself and what is working, what isn't, and what they'd like to see.</p> <p>We encourage you to attend and ask questions to learn how other users have implemented OpenTelemetry in their organizations, resolved common issues, and more. Example topics that have been discussed include tail sampling, collector scaling, and OpAMP; there really is no limit to the topics! We simply ask that you be respectful and abide by the Chatham House Rule.</p>"},{"location":"blog/2022/end-user-discussion-group-apac/#the-why","title":"The why","text":"<p>This group started as a result of direct feedback from end users in the community! Past participants have shared with us that these have been helpful and valuable for them as they migrate their observability instrumentation to OpenTelemetry.</p> <p>Additionally, the End User Working Group is also improving the process to share any collected user feedback* with the appropriate project maintainers to help improve the user experience and increase adoption.</p> <p>*Information shared in the groups can be discussed publicly, but not the identity of the person who said it or their affiliation.</p>"},{"location":"blog/2022/end-user-discussion-group-apac/#the-when","title":"The when","text":"<p>If this is your first time hearing about these meetings, you are invited to participate in any of the upcoming sessions that fit your schedule. Look for the meetings by filtering them in one of the community's publicly available calendars, and duplicate the event to your own. There will also be periodic reminders in the general CNCF Slack <code>#opentelemetry</code> channel.</p> <p>Upcoming sessions:</p> <ul> <li>EMEA: every third Tuesday of the month at 11AM CET (GMT +1), join   here</li> <li>December 20, 2022</li> <li>January 17, 2023</li> <li>APAC: every third Wednesday of the month at 11AM IST (GMT +5.5), join   here</li> <li>March 15, 2023 (register here)</li> <li>April 19, 2023</li> <li>AMER: every third Thursday of the month at 9AM PST (GMT -8), join   here</li> <li>December 15, 2022</li> <li>January 19, 2023</li> </ul> <p>See y'all soon!</p>"},{"location":"blog/2022/exponential-histograms/","title":"Exponential Histograms: Better Data, Zero Configuration","text":"<p>Histograms are a powerful tool in the observability tool belt. OpenTelemetry supports histograms because of their ability to efficiently capture and transmit distributions of measurements, enabling statistical calculations like percentiles.</p> <p>In practice, histograms come in several flavors, each with its own strategy for representing buckets and bucket counts. The first stable metric release for OpenTelemetry included explicit bucket histograms, and now OpenTelemetry is introducing a new exponential bucket histogram option. This exciting new format automatically adjusts buckets to reflect measurements and is more compressed to send over the wire. This blog post dives into the details of exponential histograms, explaining how they work, the problem they solve, and how to start using them now.</p>"},{"location":"blog/2022/exponential-histograms/#intro-to-metrics-in-opentelemetry","title":"Intro to metrics in OpenTelemetry","text":"<p>Before talking about exponential bucket histograms, let's do a quick refresher on some general OpenTelemetry metrics concepts. If you're already up to speed, skip ahead to Anatomy of a histogram.</p> <p>Metrics represent aggregations of many measurements. We use them because it's often prohibitively expensive to export and analyze measurements individually. Imagine the cost of exporting the time of each request for an HTTP server responding to one million requests per second! Metrics aggregate measurements to reduce data volume and retain a meaningful signal.</p> <p>Like tracing (and someday soon logs), OpenTelemetry metrics are broken into the API and SDK. The API is used to instrument code. Application owners can use the API to write custom instrumentation specific to their domain, but more commonly they install prebuilt instrumentation for their library or framework. The SDK is used to configure what happens with the data collected by the API. This typically includes processing it and exporting it out of process for analysis, often to an observability platform.</p> <p>The API entry point for metrics is the meter provider. It provides meters for different scopes, where a scope is just a logical unit of application code. For example, instrumentation for an HTTP client library would have a different scope and therefore a different meter than instrumentation for a database client library. You use meters to obtain instruments. You use instruments to report measurements, which consist of a value and set of attributes. This Java code snippet demonstrates the workflow:</p> <pre><code>OpenTelemetry openTelemetry = // declare OpenTelemetry instance\nMeter meter = openTelemetry.getMeter(\"my-meter-scope\");\nDoubleHistogram histogram =\nmeter\n.histogramBuilder(\"my-histogram\")\n.setDescription(\"The description\")\n.setUnit(\"ms\")\n.build();\nhistogram.record(10.2, Attributes.builder().put(\"key\", \"value\").build());\n</code></pre> <p>The SDK provides implementations of meter provider, meter, and instruments. It aggregates measurements reported by instruments and exports them as metrics according to the application configuration.</p> <p>There are currently six types of instruments in OpenTelemetry metrics: counter, up down counter, histogram, async counter, async up down counter, and async gauge. Carefully consider which instrument type to select, since each implies certain information about the nature of the measurements it records and how they are analyzed. For example, use a counter when you want to count things and when the sum of the things is more important than their individual values (such as tracking the number of bytes sent over a network). Use a histogram when the distribution of measurements is relevant for analysis. For example, a histogram is a natural choice for tracking response times for HTTP servers, because it's useful to analyze the distribution of response times to evaluate SLAs and identify trends. To learn more, see the guidelines for instrument selection.</p> <p>I mentioned earlier that the SDK aggregates measurements from instruments. Each instrument type has a default aggregation strategy (or simply aggregation) that reflects the intended use of the measurements as implied by the instrument type selection. For example, counters and up down counters aggregate to a sum of their values. Histograms aggregate to a histogram aggregation. (Note that histogram is both a type of instrument and an aggregation.)</p>"},{"location":"blog/2022/exponential-histograms/#anatomy-of-a-histogram","title":"Anatomy of a histogram","text":"<p>What is a histogram? Putting OpenTelemetry aside for a moment, we're all somewhat familiar with histograms. They consist of buckets and counts of occurrences within those buckets.</p> <p>For example, a histogram could track the number of times a particular number was rolled with the sum of two six-sided dice, with one bucket for each possible outcome, from 2-12. Over a large number of rolls, you expect the 7 bucket to have the highest count because you are more likely to roll a combined total of 7, and the 2 and 12 buckets to have the least because these are the least likely rolls, as shown in this example histogram.</p> <p></p> <p>OpenTelemetry has two types of histograms. Let's start with the relatively simpler explicit bucket histogram. It has buckets with boundaries explicitly defined during initialization. For example, if you configure it with boundaries [0,5,10], there are N+1 buckets with boundaries (-\u221e, 0],(0,5],(5,10], (10,+\u221e]. Each bucket tracks the number of occurrences of values within its boundaries. Additionally, the histogram tracks the sum of all values, the count of all values, the maximum value, and the minimum value. See the opentelemetry-proto for the complete definition.</p> <p>Before we talk about the second type of histogram, pause and think about some of the questions you can answer when data is structured like this. Assuming you're using a histogram to track the number of milliseconds it took to respond to a request, you can determine:</p> <ul> <li>The number of requests.</li> <li>The minimum, maximum, and average request latency.</li> <li>The percentage of requests that had latency less than a particular bucket   boundary. For example, if buckets boundaries are [0,5,10], you can take the   sum of the counts of buckets (-\u221e,0],(0,5],(5,10], and divide by the total   count to determine the percentage of requests that took less than 10   milliseconds. If you have an SLA that 99% of requests must be resolved in more   than 10 milliseconds, you can determine whether or not you met it.</li> <li>Patterns, by analyzing the distribution. For example, you might find that most   requests resolve quickly but a small number of requests take a long time and   bring down the average.</li> </ul> <p>The second type of OpenTelemetry histogram is the exponential bucket histogram. Exponential bucket histograms have buckets and bucket counts, but instead of explicitly defining the bucket boundaries, the boundaries are computed based on an exponential scale. More specifically, each bucket is defined by an index i and has bucket boundaries (base**i, base**(i+1)], where base**i means that base is raised to the power of i. The base is derived from a scale factor that is adjustable to reflect the range of reported measurements and is equal to 2**2**-scale. Bucket indexes must be continuous, but a non-zero positive or negative offset can be defined. For example, at scale 0, base = 2**2**-0 = 2 , and the bucket boundaries for indexes [-2,2] are defined as (.25,.5],(.5,1],(1,2],(2,4],(4,8]. By adjusting the scale, you can represent both large and small values. Like explicit bucket histograms, exponential bucket histograms also track the sum of all values, the count of all values, the maximum value, and the minimum value. See the opentelemetry-proto for the complete definition.</p>"},{"location":"blog/2022/exponential-histograms/#why-use-exponential-bucket-histograms","title":"Why use exponential bucket histograms","text":"<p>On the surface, exponential bucket histograms don't seem very different from explicit bucket histograms. In reality, their subtle differences yield dramatically different results.</p> <p>Exponential bucket histograms are a more compressed representation. Explicit bucket histograms encode data with a list of bucket counts and a list of N-1 bucket boundaries, where N is the number of buckets. Each bucket count and bucket boundary is an 8-byte value, so an N bucket explicit bucket histogram is encoded as 2N-1 8-byte values.</p> <p>In contrast, bucket boundaries for exponential bucket histograms are computed based on a scale factor and an offset defining the starting index of the buckets. Each bucket count is an 8-byte value, so an N bucket exponential bucket histogram is encoded as N+2 8-byte values (N bucket counts and 2 constants). Of course, both of these representations are commonly compressed when sent over a network, so further size reduction is likely, but exponential bucket histograms contain fundamentally less information.</p> <p>Exponential bucket histograms are basically configuration-free. Explicit bucket histograms need an explicitly defined set of bucket boundaries that need to be configured somewhere. A default set of boundaries is provided, but use cases of histograms vary wildly enough that it's likely you'll need to adjust the boundaries to better reflect your data. The view API helps, with mechanisms to select specific instruments and redefine the explicit bucket histogram aggregation bucket boundaries.</p> <p>In contrast, the only configurable parameter of exponential bucket histograms is the number of buckets, which defaults to 160 for positive values. The implementation automatically chooses the scale factor, based on the range of values recorded and the number of buckets available to maximize the bucket density around the recorded values. I can't overstate how useful this is.</p> <p>Exponential bucket histograms capture a high-density distribution of values automatically adjusted for the scale and range of measurements, with no configuration. The same histogram that captures nanosecond scale measurements is equally good at capturing second scale measurements. They retain fidelity regardless of scale.</p> <p>Consider the scenario of capturing HTTP request time milliseconds. With an explicit bucket histogram, you make guesses on bucket boundaries which you hope will accurately capture the distribution of values. But if conditions change and latency spikes, your assumptions might not hold and all values could be lumped together. Suddenly, you've lost visibility into the distribution of data. You know latency is high overall. But you can't know how many requests are high but tolerable versus terribly slow. In contrast, with an exponential bucket histogram, the scale automatically adjusts to the latency spikes to choose the optimal range of buckets. You retain insight into the distribution, even with a large range of measurement values.</p>"},{"location":"blog/2022/exponential-histograms/#example-scenario-explicit-bucket-histograms-vs-exponential-bucket-histograms","title":"Example scenario: explicit bucket histograms vs. exponential bucket histograms","text":"<p>Let's bring everything together with a proper demonstration comparing explicit bucket histograms to exponential bucket histograms. I've put together some example code that simulates tracking response time to an HTTP server in milliseconds. It records one million samples to an explicit bucket histogram with the default buckets, and to an exponential bucket histogram with a number of buckets that produces roughly the same size of OTLP -encoded, Gzip-compressed payload as the explicit bucket defaults. Through trial and error, I determined that ~40 exponential buckets produce an equivalent payload size to the default explicit bucket histogram with 11 buckets. (Your results may vary.)</p> <p>I wanted the distribution of samples to reflect what we might see in an actual HTTP server, with bands of response times corresponding to different operations. It will look something like this example:</p> <p></p> <p>To achieve this, I used a variety of different probability distributions, each corresponding to different bands in the curve, and each accounting for some percentage of the samples.</p> <p>I ran the simulation, and exported the histograms via to compare the explicit bucket histogram to the exponential bucket histogram. The next two charts show the results. The exponential bucket histogram has significantly more detail, which simply isn't available with the more limited buckets of the explicit bucket histogram.</p> <p>Note: These visualizations are from the New Relic platform, which I used because they employ me, and it's the easiest way for me to visualize histograms. Every platform will have its own mechanism for storing and retrieving histograms, which typically perform some lossy translation of buckets into a normalized storage format\u2014New Relic is no exception. Additionally, the visualization doesn't clearly delineate buckets, which causes adjacent buckets with the same count to appear as a single bucket.</p> <p>Here's the millisecond scale exponential bucket histogram:</p> <p></p> <p>Here's the millisecond scale explicit bucket histogram:</p> <p></p> <p>This demonstration is fairly generous to the explicit bucket histogram because I choose to report values in an optimum range for the default buckets (for example, 0 to 1000). The next two examples show what happens when the same values are recorded in nanosecond precision instead of milliseconds (all values are multiplied by 106). This is where the no-configuration autoscaling nature of exponential bucket histograms really shines. Left with the default explicit bucket boundaries, all the samples fall into a single bucket with the explicit bucket histogram. The exponential variety loses some definition compared to the millisecond version in the previous example, but you can still see the response time bands.</p> <p>Here's the nanosecond scale exponential bucket histogram:</p> <p></p> <p>Here's the nanosecond scale explicit bucket histogram:</p> <p></p>"},{"location":"blog/2022/exponential-histograms/#next-steps","title":"Next steps","text":"<p>Exponential bucket histograms are a powerful new tool for metrics. While implementations are still in progress at the time of publishing this post, you'll definitely want to enable them when you're using OpenTelemetry metrics.</p> <p>If you're using opentelemetry-java (and eventually other languages), the easiest way to enable exponential bucket histograms is by setting the environment variable with this command:</p> <pre><code>export OTEL_EXPORTER_OTLP_METRICS_DEFAULT_HISTOGRAM_AGGREGATION=exponential_bucket_histogram\n</code></pre> <p>For instructions on enabling in other languages, check the relevant documentation on instrumentation or github.com/open-telemetry.</p> <p>A version of this article was [originally posted][] on the New Relic blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2022/frontend-overhaul/","title":"Front-end Overhaul of the OpenTelemetry Demo (Go to Next.js)","text":"<p>One of the OpenTelemetry Project's many Special Interest Groups (SIG) is the OpenTelemetry Community demo SIG. The SIG supports a set of instrumented microservices and a front-end web app which are used to show how to instrument a distributed system with OpenTelemetry.</p> <p>The main focus of the web app is to demonstrate how to instrument an application, no matter what programming language, platform or OS it uses. The web app also shows different instrumentation techniques: automatic and manual, metrics, and baggage. All while following the standards and conventions prescribed in the official OTel documentation. More about the specific requirements can be found here.</p> <p>My company was focused on becoming part of and embracing the OpenTelemetry community. One of our goals this summer was to get more involved with a core OpenTelemetry project where we could provide a meaningful contribution. The OTel demo was the best match for our goal, as contributing would not only help the community, but also provide a great example to test and showcase our product with.</p> <p>The first thing we did was to get in contact with Carter Socha, the organizer of the OTel Demo SIG. Carter was really welcoming and helped us identify where our contributions could be the most impactful. We started looking at the issue created by Austin Parker referencing a complete front-end overhaul that would involve moving the application away from Go server-side render (SSR) to an architecture that included a browser-side client (client-side render or CSR), as well as improving the overall style, theme, and user experience.</p> <p>A fun aspect of the work was the request to move the store from a \"normal\" store to an astronomy store to match the OpenTelemetry project\u2019s overall branding.</p> <p>Once we got the green light from the rest of the OTel demo SIG, then we started working on the different changes that were part of the front-end architecture overhaul.</p>"},{"location":"blog/2022/frontend-overhaul/#opentelemetry-demo-application-description-and-tech-stack","title":"OpenTelemetry Demo Application Description and Tech Stack","text":"<p>The demo app is an astronomy store, with basic eCommerce features such as a shopping cart, currency selector, payment, and checkout. It also includes the ability to display promotions (ads) and related products depending on the user\u2019s context.</p> <p>The demo\u2019s stack includes multiple microservices in different languages, covering each of the following OTel-supported languages:</p> <ul> <li>C++</li> <li>.NET</li> <li>Erlang/Elixir</li> <li>Go</li> <li>Node.js</li> <li>PHP</li> <li>Python</li> <li>Ruby</li> <li>Rust</li> </ul> <p>Every microservice has a specific goal and can communicate with others by using a global gRPC definition. Persistent information is saved into a PostgreSQL database and there are outbound services that connect with third-party services to trigger events (such as confirmation emails). All of the microservices, including the front-end, are connected to the same OpenTelemetry collector instance, which uses Jaeger as one of the data stores for the tracing data.</p> <p> </p> <p>Prior to re-architecting, the front-end consisted of a Golang SSR app, which sent complete HTML to the browser for display. Every request and call redirected to the server so new information was shown.</p>"},{"location":"blog/2022/frontend-overhaul/#web-app-styling-improvements-theme-updates-and-user-experience-redesign","title":"Web App Styling Improvements, Theme Updates, and User Experience Redesign","text":"<p>Before starting the development process, the front-end application wasn\u2019t matching the theme that OpenTelemetry had been using in terms of colors, products, and overall user experience. In addition, the demo lacked a real front-end (browser side) application as the current implementation was a Go application.</p> <p></p> <p>The first task at hand was to bring the demo to the modern age by updating the design, color schemes, and user experience. Olly Babiak walked into the fray to help us achieve this by creating a modernized version of the application. It included an improved way to display the products landing page, an updated product details page, a mini cart, and a fully compatible mobile version of the application.</p> <p></p> <p>Now we had an application design that would match the rest of the OpenTelemetry themes and colors and look more like the OpenTelemetry.io website.</p>"},{"location":"blog/2022/frontend-overhaul/#front-end-application-architecture-overhaul","title":"Front-end Application Architecture Overhaul","text":"<p>We worked on an initial proposal that included the following:</p> <ul> <li>Framework and tooling (Scaffolding, I/O, styling, UI library)</li> <li>Code Architecture and structure (Directories, coding patterns)</li> <li>Instrumentation</li> <li>Deployment &amp; Distribution</li> <li>Testing (E2E, unit test)</li> </ul> <p>This proposal was presented to the OpenTelemetry demo SIG during one of the weekly Monday meetings and we were given the green light to move ahead. As part of the changes, we decided to use Next.js to not only work as the primary front-end application but also to work as an aggregation layer between the front-end and the gRPC back-end services.</p> <p></p> <p>As you can see in the diagram, the application has two major connectivity points, one coming from the browser side (REST) to connect to the Next.js aggregation layer and the other from the aggregation layer to the back-end services (gRPC).</p>"},{"location":"blog/2022/frontend-overhaul/#opentelemetry-instrumentation","title":"OpenTelemetry Instrumentation","text":"<p>The next big thing we worked was a way to instrument both sides of the Next.js app. To do this we had to connect the app twice to the same collector used by all the microservices.</p> <p>A simple back-end solution was designed using the official gRPC exporter in combination with the Node.js SDK.</p> <p>You can find the full implementation here. The basic instrumentation includes auto instrumentation for most of the commonly used libraries and tools for Node.js. As part of providing a better example for users, a manual instrumentation in the form of route middleware was added. This would catch the incoming HTTP request and create a span based on it, including the context propagation. The implementation can be found here.</p> <p>The front-end was a little trickier, as the initial rendering is server-side. We had to make sure to load the tracer from the browser side when the JavaScript code is executed.</p> <p>After adding validations to check the browser side, we then loaded the custom front-end tracing module, which included creating the web tracer provider and the automatic web instrumentations.</p> <p>The automatic front-end instrumentation captures the most common user actions such as clicks, fetch requests, and page loads. In order to allow the browser side to interact with the collector, a config change is needed: enable incoming CORS requests from the web app.</p> <p>Once the setup is complete, by loading the application from Docker and interacting with the different features, we can start looking at the full traces that begin from the front-end user events all the way to the back-end gRPC services.</p> <p></p>"},{"location":"blog/2022/frontend-overhaul/#contributing-to-opentelemetry-was-rewarding","title":"Contributing to OpenTelemetry was Rewarding","text":"<p>As a team focused on building an open source tool in the Observability space, the opportunity to help the overall OpenTelemetry community was important to us. In addition, having a complex microservice-based application that uses multiple different languages and technologies is directly useful for our team. We really enjoyed the process of making a contribution to the OpenTelemetry project and are actively looking for more opportunities to contribute!</p> <p>Oscar Reyes and Olly Babiak also are working on Tracetest, an open source tool that allows you to develop and test your distributed system with OpenTelemetry. It works with any OTel compatible system and enables trace\u2013based tests to be created. Check it out at https://github.com/kubeshop/tracetest.</p>"},{"location":"blog/2022/go-web-app-instrumentation/","title":"Go Web-app Instrumentation","text":"<p>In this blog post, you will learn hands-on how to create and visualize traces with OpenTelemetry Go without prior knowledge.</p> <p>We will start with creating a simple to-do app that uses Mongo and the Gin framework. Then, we will send tracing data to Jaeger Tracing for visualization. You can find all the relevant files in this Github repository.</p> <p></p>"},{"location":"blog/2022/go-web-app-instrumentation/#hello-world-opentelemetry-go-example","title":"Hello world: OpenTelemetry Go example","text":"<p>We will start by creating our to-do service and installing two libraries (Gin and Mongo) to understand how instrumentations work.</p>"},{"location":"blog/2022/go-web-app-instrumentation/#step-1-create-maingo-file-for-our-to-do-app","title":"Step 1: Create main.go file for our to-do app","text":"<ol> <li>Install Gin and Mongo-driver</li> </ol> <pre><code>go get -u github.com/gin-gonic/gin\ngo get go.mongodb.org/mongo-driver/mongo\n</code></pre> <ol> <li> <p>Set up gin and mongo to listen on \u201c/todo\u201d</p> </li> <li> <p>Create some to-do\u2019s to seed Mongo</p> </li> </ol> <pre><code>package main\nimport (\n\"context\"\n\"net/http\"\n\"github.com/gin-gonic/gin\"\n\"go.mongodb.org/mongo-driver/bson\"\n\"go.mongodb.org/mongo-driver/mongo\"\n\"go.mongodb.org/mongo-driver/mongo/options\"\n)\nvar client * mongo.Client\nfunc main() {\nconnectMongo()\nsetupWebServer()\n}\nfunc connectMongo() {\nopts: = options.Client()\nopts.ApplyURI(\"mongodb://localhost:27017\")\nclient, _ = mongo.Connect(context.Background(), opts)\n//Seed the database with todo's\ndocs: = [] interface {} {\nbson.D {\n{\n\"id\", \"1\"\n}, {\n\"title\", \"Buy groceries\"\n}\n},\nbson.D {\n{\n\"id\", \"2\"\n}, {\n\"title\", \"install Aspecto.io\"\n}\n},\nbson.D {\n{\n\"id\", \"3\"\n}, {\n\"title\", \"Buy dogz.io domain\"\n}\n},\n}\nclient.Database(\"todo\").Collection(\"todos\").InsertMany(context.Background(), docs)\n}\nfunc setupWebServer() {\nr: = gin.Default()\nr.GET(\"/todo\", func(c * gin.Context) {\ncollection: = client.Database(\"todo\").Collection(\"todos\")\n//Important: Make sure to pass c.Request.Context() as the context and not c itself - TBD\ncur, findErr: = collection.Find(c.Request.Context(), bson.D {})\nif findErr != nil {\nc.AbortWithError(500, findErr)\nreturn\n}\nresults: = make([] interface {}, 0)\ncurErr: = cur.All(c, &amp; results)\nif curErr != nil {\nc.AbortWithError(500, curErr)\nreturn\n}\nc.JSON(http.StatusOK, results)\n})\n_ = r.Run(\":8080\")\n}\n</code></pre> <p>Now that our small todo app is ready, let\u2019s introduce OpenTelemetry.</p>"},{"location":"blog/2022/go-web-app-instrumentation/#step-2-install-opentelemetry-go","title":"Step 2: Install OpenTelemetry Go","text":"<p>We will be configuring OpenTelemetry to instrument our Go app.</p> <ol> <li>To install the OTel SDK, run:</li> </ol> <pre><code>go get go.opentelemetry.io/otel /\ngo.opentelemetry.io/otel/sdk /\n</code></pre> <ol> <li> <p>Instrument our Gin and Mongo libraries to generate traces.</p> </li> <li> <p>Gin &amp; Mongo instrumentation: Install otelgin &amp; otelmongo</p> </li> </ol> <pre><code>go get go.opentelemetry.io/contrib/instrumentation/github.com/gin-gonic/gin/otelgin /\ngo get go.opentelemetry.io/contrib/instrumentation/go.mongodb.org/mongo-driver/mongo/otelmongo\n</code></pre>"},{"location":"blog/2022/go-web-app-instrumentation/#gin-instrumentation-gincontext","title":"Gin instrumentation: gin.Context","text":"<p>We previously discussed the idea of context propagation \u2013 the way to transfer metadata between distributed services to correlate events in our system.</p> <p>The Gin framework has its own type gin.Context which gets passed as a parameter to an HTTP handler. However, the context that should be passed down to the mongo operations is the standard Go library Context object, available in gin.Context.Request.Context.</p> <pre><code>//Make sure to pass c.Request.Context() as the context and not c itself\ncur, findErr := collection.Find(c.Request.Context(), bson.D{})\n</code></pre> <p>So make sure that you pass the Context to the mongodb operation. Check out this issue for more info.</p> <p>We now have our todo app ready and instrumented. It\u2019s time to utilize OpenTelemetry to its full potential. Our ability to visualize traces is where the true troubleshooting power of this technology comes into play.</p> <p>For visualization, we\u2019ll be using the open source Jaeger Tracing.</p>"},{"location":"blog/2022/go-web-app-instrumentation/#visualization-with-jaeger","title":"Visualization with Jaeger","text":""},{"location":"blog/2022/go-web-app-instrumentation/#opentelemetry-go-and-jaeger-tracing-export-traces-to-jaeger","title":"OpenTelemetry Go and Jaeger Tracing: Export traces to Jaeger","text":"<p>Jaeger Tracing is a suite of open source projects managing the entire distributed tracing \u201cstack\u201d: client, collector, and UI. Jaeger UI is the most commonly used open source to visualize traces.</p> <p>Here\u2019s what the setup looks like:</p> <ol> <li>Install the Jaeger exporter</li> </ol> <pre><code>go get go.opentelemetry.io/otel/exporters/jaeger\n</code></pre> <ol> <li> <p>Create a tracing folder and a jaeger.go file</p> </li> <li> <p>Add the following code to the file</p> </li> </ol> <pre><code>package tracing\nimport (\n\"go.opentelemetry.io/otel/exporters/jaeger\"\n\"go.opentelemetry.io/otel/sdk/resource\"\nsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\nsemconv \"go.opentelemetry.io/otel/semconv/v1.4.0\"\n)\nfunc JaegerTraceProvider()(*sdktrace.TracerProvider, error) {\nexp, err: = jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(\"http://localhost:14268/api/traces\")))\nif err != nil {\nreturn nil, err\n}\ntp: = sdktrace.NewTracerProvider(\nsdktrace.WithBatcher(exp),\nsdktrace.WithResource(resource.NewWithAttributes(\nsemconv.SchemaURL,\nsemconv.ServiceNameKey.String(\"todo-service\"),\nsemconv.DeploymentEnvironmentKey.String(\"production\"),\n)),\n)\nreturn tp, nil\n}\n</code></pre> <ol> <li>Go back to the main.go file and modify our code to use the    JaegerTraceProvider function we just created</li> </ol> <pre><code>func main() {\ntp, tpErr: = tracing.JaegerTraceProvider()\nif tpErr != nil {\nlog.Fatal(tpErr)\n}\notel.SetTracerProvider(tp)\notel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext {}, propagation.Baggage {}))\nconnectMongo()\nsetupWebServer()\n}\n</code></pre> <p>Next, we are going to hook up the instrumentations we installed.</p> <ol> <li>Add the Mongo instrumentation. In our connectMongo function by adding this    line</li> </ol> <pre><code>opts.Monitor = otelmongo.NewMonitor()\n</code></pre> <p>The function should look like this:</p> <pre><code>func connectMongo() {\nopts: = options.Client()\n//Mongo OpenTelemetry instrumentation\nopts.Monitor = otelmongo.NewMonitor()\nopts.ApplyURI(\"mongodb://localhost:27017\")\nclient, _ = mongo.Connect(context.Background(), opts)\n//Seed the database with some todo's\ndocs: = [] interface {} {\nbson.D {\n{\n\"id\", \"1\"\n}, {\n\"title\", \"Buy groceries\"\n}\n},\nbson.D {\n{\n\"id\", \"2\"\n}, {\n\"title\", \"install Aspecto.io\"\n}\n},\nbson.D {\n{\n\"id\", \"3\"\n}, {\n\"title\", \"Buy dogz.io domain\"\n}\n},\n}\nclient.Database(\"todo\").Collection(\"todos\").InsertMany(context.Background(), docs)\n}\n</code></pre> <p>Now, add the Gin instrumentation.</p> <ol> <li>Go to the startWebServer function and add this line right after we create the    gin instance</li> </ol> <pre><code>r.Use(otelgin.Middleware(\"todo-service\"))\n</code></pre> <p>The function should look like this</p> <pre><code>func startWebServer() {\nr: = gin.Default()\n//Gin OpenTelemetry instrumentation\nr.Use(otelgin.Middleware(\"todo-service\"))\nr.GET(\"/todo\", func(c * gin.Context) {\ncollection: = client.Database(\"todo\").Collection(\"todos\")\n//make sure to pass c.Request.Context() as the context and not c itself\ncur, findErr: = collection.Find(c.Request.Context(), bson.D {})\nif findErr != nil {\nc.AbortWithError(500, findErr)\nreturn\n}\nresults: = make([] interface {}, 0)\ncurErr: = cur.All(c, &amp; results)\nif curErr != nil {\nc.AbortWithError(500, curErr)\nreturn\n}\nc.JSON(http.StatusOK, results)\n})\n_ = r.Run(\":8080\")\n}\n</code></pre> <p>For the complete <code>main.go</code> file, see below. Now we\u2019re finally ready to export    to Jaeger.</p> <pre><code>package main\nimport (\n\"context\"\n\"log\"\n\"net/http\"\n\"github.com/aspecto-io/opentelemetry-examples/tracing\"\n\"github.com/gin-gonic/gin\"\n\"go.mongodb.org/mongo-driver/bson\"\n\"go.mongodb.org/mongo-driver/mongo\"\n\"go.mongodb.org/mongo-driver/mongo/options\"\n\"go.opentelemetry.io/contrib/instrumentation/github.com/gin-gonic/gin/otelgin\"\n\"go.opentelemetry.io/contrib/instrumentation/go.mongodb.org/mongo-driver/mongo/otelmongo\"\n\"go.opentelemetry.io/otel\"\n\"go.opentelemetry.io/otel/propagation\"\n)\nvar client * mongo.Client\nfunc main() {\n//Export traces to Jaeger\ntp, tpErr: = tracing.JaegerTraceProvider()\nif tpErr != nil {\nlog.Fatal(tpErr)\n}\notel.SetTracerProvider(tp)\notel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext {}, propagation.Baggage {}))\nconnectMongo()\nstartWebServer()\n}\nfunc connectMongo() {\nopts: = options.Client()\n//Mongo OpenTelemetry instrumentation\nopts.Monitor = otelmongo.NewMonitor()\nopts.ApplyURI(\"mongodb://localhost:27017\")\nclient, _ = mongo.Connect(context.Background(), opts)\n//Seed the database with some todo's\ndocs: = [] interface {} {\nbson.D {\n{\n\"id\", \"1\"\n}, {\n\"title\", \"Buy groceries\"\n}\n},\nbson.D {\n{\n\"id\", \"2\"\n}, {\n\"title\", \"install Aspecto.io\"\n}\n},\nbson.D {\n{\n\"id\", \"3\"\n}, {\n\"title\", \"Buy dogz.io domain\"\n}\n},\n}\nclient.Database(\"todo\").Collection(\"todos\").InsertMany(context.Background(), docs)\n}\nfunc startWebServer() {\nr: = gin.Default()\n//gin OpenTelemetry instrumentation\nr.Use(otelgin.Middleware(\"todo-service\"))\nr.GET(\"/todo\", func(c * gin.Context) {\ncollection: = client.Database(\"todo\").Collection(\"todos\")\n//Make sure to pass c.Request.Context() as the context and not c itself\ncur, findErr: = collection.Find(c.Request.Context(), bson.D {})\nif findErr != nil {\nc.AbortWithError(500, findErr)\nreturn\n}\nresults: = make([] interface {}, 0)\ncurErr: = cur.All(c, &amp; results)\nif curErr != nil {\nc.AbortWithError(500, curErr)\nreturn\n}\nc.JSON(http.StatusOK, results)\n})\n_ = r.Run(\":8080\")\n}\n</code></pre>"},{"location":"blog/2022/go-web-app-instrumentation/#export-traces-to-jaeger","title":"Export traces to Jaeger","text":"<ol> <li>Run the todo-service with <code>go run main.go</code>.</li> <li>To generate some traces, make an HTTP GET request to    http://localhost:8080/todo.</li> <li>To view the traces, open Jaeger at http://localhost:16686/search.</li> </ol> <p>You can now see the Jaeger UI. Select todo-service and click on Find traces. You should see your trace on the right:</p> <p></p> <p>Jaeger UI displays OpenTelemetry traces in go for our todo-service By clicking the trace, you can drill down and see more details about it that allow you to further investigate on your own:</p> <p></p>"},{"location":"blog/2022/go-web-app-instrumentation/#summary","title":"Summary","text":"<p>That\u2019s all folks! We hope this guide was informative and easy to follow. You can find all files ready to use in our Github repository.</p> <p>A version of this article was [originally posted][] on the Aspecto blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2022/instrument-apache-httpd-server/","title":"Learn how to instrument Apache Http Server with OpenTelemetry","text":"<p>If you are using Apache HTTP Server and in dire need of some observability tool to monitor your web server, the OpenTelemetry Module for Apache HTTP Server is the right candidate for you: it enables tracing of incoming requests to the server and it will capture the response time of many modules (including <code>mod_proxy</code>) involved in such an incoming request. With that you will get hierarchical time consumption by each module. This article demonstrates the monitoring capabilities of the OpenTelemetry Module for Apache HTTP Server and quick guide to get started with the module.</p>"},{"location":"blog/2022/instrument-apache-httpd-server/#getting-started-with-opentelemetry-module","title":"Getting Started with OpenTelemetry Module","text":""},{"location":"blog/2022/instrument-apache-httpd-server/#building-the-module","title":"Building the module","text":"<p>Getting started with the OpenTelemetry module for apache httpd is pretty simple, all you need is a docker engine and git. Download the source code from github and then build the docker image on CentOS71:</p> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-cpp-contrib\ncd  instrumentation/otel-webserver-module\ndocker compose --profile centos7 build\n</code></pre> <p>These commands download all required dependencies, builds the OpenTelemetry module for Apache HTTP Server and installs the same on the docker image.</p> <p>Note: The above commands might take around 1 hour to complete.</p> <p>When the build is finished, run the docker image, by typing the following command1:</p> <pre><code>docker compose --profile centos7 up -d\n</code></pre> <p>The above command starts up the centos7 image in a docker container named <code>webserver_centos7</code> along with the OpenTelemetry Collector and a Zipkin backend.</p> <p>OpenTelemetry Module for Apache HTTP Server will be configured and installed in the desired location and Apache HTTP Server will be started with the OpenTelemetry Module.</p>"},{"location":"blog/2022/instrument-apache-httpd-server/#viewing-spans-on-the-backend","title":"Viewing spans on the backend","text":"<p>As mentioned in docker-compose.yml, <code>webserver_centos7</code> listens on port 9004, Zipkin listens on port 9411 and the OpenTelemetry Collector listens on port 4317.</p> <p>To send a request to Apache HTTP Server you can either use curl from terminal (<code>curl localhost:9004</code>), or visit localhost:9004 in any browser. A default landing page saying \"Testing 123...\" for Apache HTTP Server on Centos will be displayed as below:</p> <p></p> <p>Now, traces and spans can be seen on the Zipkin backend. To view them, visit localhost:9411 in your browser and click on Run Query button. Following is the screenshot from Zipkin UI showing spans emitted by the Apache HTTP Server.</p> <p></p> <p>This shows a list of queries or endpoints that have been triggered to Apache HTTP Server, such as <code>/noindex/css</code>.</p> <p>To see the details click on any of the SHOW buttons. Below is the screenshot from the Zipkin UI showing the span hierarchy.</p> <p></p> <p>The above shows that as a part of this request, <code>mod_proxy</code>, <code>mod_proxy_balancer</code> and <code>mod_dav</code> got involved in the request processing and time consumed in each of the modules.</p>"},{"location":"blog/2022/instrument-apache-httpd-server/#how-can-module-level-details-be-beneficial","title":"How can module level details be beneficial?","text":"<p>To demonstrate the benefits of module level details, we'll introduce an artificial delay in a PHP script and see how the delay gets displayed in the Zipkin backend. The following steps are required to be done.</p> <ul> <li>Login to the container and install the PHP module.</li> </ul> <pre><code>docker exec -it webserver_centos7 /bin/bash\nyum install php -y\n</code></pre> <ul> <li>Add <code>AddType application/x-httpd-php .html</code> in <code>/etc/httpd/conf/httpd.conf</code> as   mentioned below:</li> </ul> <p></p> <ul> <li>Create a file named as <code>index.html</code> in the /var/www/html directory and add   the following text</li> </ul> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;PHP Test Page&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;?php\n      echo date('h:i:s') . \"&lt;br&gt;\"; echo \"Introduce delay of 1 seconds\" . \"&lt;br /&gt;\";\n    sleep(1); echo date('h:i:s'); ?&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <ul> <li>Restart the server:</li> </ul> <pre><code>httpd -k restart\n</code></pre> <ul> <li>Now, visit localhost:9004/index.html. You should see something like this:</li> </ul> <p></p> <ul> <li>Now, traces and spans can be seen on the Zipkin backend. To view them, type   localhost:9411 on the browser and click on the Run Query Button. To   see the details, click on the SHOW button corresponding to <code>/index.html</code>.</li> </ul> <p></p> <ul> <li>We can see that, <code>mod_php5.c_handler</code> consumes around 1 second which   contributes to the overall time-consumption of the request.</li> </ul> <p>As the HTTP request flows through individual modules, delay in execution or errors might occur at any of the modules involved in the request. To identify the root cause of any delay or errors in request processing, module wise information (such as response time of individual modules) would enhance the debuggability of the Apache HTTP Server.</p>"},{"location":"blog/2022/instrument-apache-httpd-server/#installing-opentelemetry-module-in-target-system","title":"Installing OpenTelemetry Module in Target System","text":"<p>To make use of the OpenTelemetry module for Apache HTTP Server, use the following steps to extract the package and install on the target system where Apache HTTP Server is installed.</p> <ul> <li>In order to clone the source code, execute the following</li> </ul> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-cpp-contrib\ncd  opentelemetry-cpp-contrib/instrumentation/otel-webserver-module\n</code></pre> <ul> <li>Trigger the build command to generate the package inside the docker image1</li> </ul> <pre><code>docker compose --profile centos7 build\n</code></pre> <p>The above might take around an hour to build. This would build on Centos 7 image as <code>apache_centos7</code></p> <ul> <li>Once the build is complete, it's time to extract the image. We need to startup   the container which can be done by the following command</li> </ul> <pre><code>docker run -idt --name &lt;container_name&gt; apache_centos7 /bin/bash\n</code></pre> <p>The above command would run the container and can be verified using the <code>docker ps</code> command.</p> <ul> <li>The generated package inside the container is available inside   <code>/otel-webserver-module/build</code> directory. The same can be extracted to the   host system as</li> </ul> <pre><code>docker cp &lt;container_name&gt;:/otel-webserver-module/build/opentelemetry-webserver-sdk-x64-linux.tgz &lt;target-directory&gt;\n</code></pre> <p>Note: The above package should work on any linux distribution having x86-64 instruction set and glibc version greater than 2.17. At the point of writing this blog, support for other architectures is not provided.</p> <ul> <li> <p>Transfer the above package along with opentelemetry_module.conf to the   target system.</p> </li> <li> <p>Uncompress the package <code>opentelemetry-webserver-sdk-x64-linux.tgz</code> to <code>/opt</code>   directory.</p> </li> </ul> <pre><code>tar -xvf opentelemetry-webserver-sdk-x64-linux.tgz -C /opt\n</code></pre> <ul> <li>Now, install the module by executing the following</li> </ul> <pre><code>cd /opt/opentelemetry-webserver-sdk\n./install.sh\n</code></pre> <ul> <li> <p>In the case of Centos, Apache HTTP Server configuration is generally located   in <code>/etc/httpd/conf/</code>. Hence copy the opentelemetry_module.conf to   <code>/etc/httpd/conf</code>.</p> </li> <li> <p>Edit the <code>/etc/httpd/conf/httpd.conf</code> and add   <code>Include conf/opentelemetry_module.conf</code> at the end of the file as mentioned   below:</p> </li> </ul> <p></p> <ul> <li> <p>Now let\u2019s look at opentelemetry_module.conf and its contents:</p> </li> <li> <p>The below LoadFile are the dependent libraries that come with the package.</p> <p></p> </li> <li> <p>The below configuration are for the OpenTelemetry Module</p> <p></p> <p>In the case of Apache HTTP Server 2.2, <code>libmod_apache_otel22.so</code> needs to be used instead of <code>libmod_apache_otel.so</code></p> </li> <li> <p>The following directive should be ON for the OpenTelemetry module to be     enabled, else it would be disabled.</p> <p></p> </li> <li> <p>Since the module works with the Collector and sends data in OLTP format, the     following directives are necessary.</p> <p></p> <p>ApacheModuleOtelExporterEndpoint should point to the endpoint of the collector</p> </li> <li> <p>ServiceNamespace, ServiceName and ServiceInstanceId should be provided by     the following directives.</p> <p></p> </li> <li> <p>All other directives are either optional and can be kept as it is for this     guide</p> </li> <li> <p>To verify whether the OpenTelemetry Module is properly enabled into Apache   HTTP Server, type <code>httpd -M</code> and look for <code>otel_apache_module (shared)</code></p> </li> </ul> <p></p> <ul> <li>Now, restart the Apache HTTP Server and OpenTelemetry module should be   instrumented.</li> </ul> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"blog/2022/instrument-kafka-clients/","title":"Instrumenting Apache Kafka clients with OpenTelemetry","text":"<p>Nowadays, Apache Kafka is chosen as the nervous system in a distributed environment. Different services communicate with each other by using Apache Kafka as a messaging system but even more as en event or data streaming platform.</p> <p>Taking into account the cloud-native approach for developing microservices, quite often Kubernetes is also used to run the workloads. In this scenario, you can also easily deploy and manage an Apache Kafka cluster on top of it, by using a project like Strimzi. It takes care of the overall Kafka infrastructure, while you can focus on developing applications which use it.</p> <p>Within the overall picture, because of the distributed nature, it is quite difficult to track how messages are moved around. This is where OpenTelemetry comes into the picture. It provides multiple instrumentation libraries for adding tracing to messaging based applications. Of course, there is one for Apache Kafka clients. It also defines the specification of semantic conventions for messaging systems.</p> <p>But usually, the architecture can even be more complicated: having applications not able to connect directly to the Apache Kafka cluster and talking its own custom protocol but using a different one, like for example HTTP. In this case, tracing how messages are produced and consumed via HTTP through Apache Kafka is really complex. The Strimzi project provides a bridge, with the OpenTelemetry support, for adding tracing data by using the corresponding instrumentation library.</p> <p>In this article, you will learn how it is possible to enable tracing on Apache Kafka based client applications in different ways. We will refer to the Java based instrumentation. You can also find all the examples in this repository.</p>"},{"location":"blog/2022/instrument-kafka-clients/#enable-tracing-on-the-kafka-clients","title":"Enable tracing on the Kafka clients","text":"<p>Let's assume you have an application using the Kafka clients API for producing and consuming messages. In order to simplify the scenario, let's also assume you don't want to add any additional tracing information within your business logic. You are interested to add tracing to the Kafka related parts only. You want to trace how the messages are produced and consumed via the Kafka clients.</p> <p>In order to do so, there are two different ways:</p> <ul> <li>using an external agent running alongside your application to add tracing.</li> <li>enabling the tracing directly on the Kafka clients used by your application.</li> </ul> <p>The former is actually an \"automatic\" approach which is about not touching your application at all. The agent, running alongside the application, is able to intercept messages coming in and out and adds tracing information to them.</p> <p>The latter is mostly a \"manual\" approach which is about instrumenting your application directly. It means adding some specific dependencies to your project and make code changes.</p>"},{"location":"blog/2022/instrument-kafka-clients/#instrumenting-by-using-the-agent","title":"Instrumenting by using the agent","text":"<p>The simpler and automatic approach is by adding tracing to your application with no changes or additions into your application code. You also don't need to add any dependencies to OpenTelemetry specific libraries. It is possible by using the OpenTelemetry agent you can download from here. This agent has to run alongside your application in order to inject the logic for tracing messages sent and received to/from a Kafka cluster.</p> <p>Run the producer application in the following way.</p> <pre><code>java -javaagent:path/to/opentelemetry-javaagent.jar \\\n-Dotel.service.name=my-kafka-service \\\n-Dotel.traces.exporter=jaeger \\\n-Dotel.metrics.exporter=none \\\n-jar kafka-producer-agent/target/kafka-producer-agent-1.0-SNAPSHOT-jar-with-dependencies.jar\n</code></pre> <p>Run the consumer application similarly.</p> <pre><code>java -javaagent:path/to/opentelemetry-javaagent.jar \\\n-Dotel.service.name=my-kafka-service \\\n-Dotel.traces.exporter=jaeger \\\n-Dotel.metrics.exporter=none \\\n-Dotel.instrumentation.messaging.experimental.receive-telemetry.enabled=true \\\n-jar kafka-consumer-agent/target/kafka-consumer-agent-1.0-SNAPSHOT-jar-with-dependencies.jar\n</code></pre> <p>The agent leverages the auto-configuration SDK extension, you will see in a bit, by setting the main parameters through system properties.</p>"},{"location":"blog/2022/instrument-kafka-clients/#instrumenting-the-apache-kafka-clients","title":"Instrumenting the Apache Kafka clients","text":"<p>The OpenTelemetry project provides the <code>opentelemetry-kafka-clients-2.6</code> module which provides tracing instrumentation for Kafka clients. First, you need to add the corresponding dependency to your application.</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry.instrumentation&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-kafka-clients-2.6&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Depending on the exporter that you want to use for exporting tracing information, you have to add the corresponding dependency as well. For example, in order to use the Jaeger exporter, the dependency is the following one.</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-exporter-jaeger&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>In this way, you have the minimum set up for enabling the tracing on your Kafka based application.</p>"},{"location":"blog/2022/instrument-kafka-clients/#setting-up-the-opentelemetry-instance","title":"Setting up the OpenTelemetry instance","text":"<p>The entire tracing instrumentation is handled by an <code>OpenTelemetry</code> instance in your code. It needs to be created and registered globally in order to be made available to the Kafka clients instrumentation library.</p> <p>This can be done in two different ways:</p> <ul> <li>using an SDK extension for environment-based auto-configuration.</li> <li>using SDK builders classes for programmatic configuration.</li> </ul>"},{"location":"blog/2022/instrument-kafka-clients/#using-the-sdk-auto-configuration","title":"Using the SDK auto-configuration","text":"<p>It is possible to configure a global <code>OpenTelemetry</code> instance by using environment variables thanks to the SDK extension for auto-configuration, enabled by adding the following dependency to your application.</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-sdk-extension-autoconfigure&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>When the Kafka clients instrumentation library is used, it checks if there is an <code>OpenTelemetry</code> instance already created and registered. If it is not, the library code checks if the SDK auto-configure module is in the classpath and in this case initializes it for creating the <code>OpenTelemetry</code> instance automatically. The corresponding configuration happens through environment variables (or corresponding system properties). This is really a way to simplify the initialization of tracing.</p> <p>The main environment variables to be set are the following:</p> <ul> <li><code>OTEL_SERVICE_NAME</code>: specify the logical service name. This is really useful   when using a tracing UI (i.e. Jaeger UI) for showing data and it is   recommended to set it.</li> <li><code>OTEL_TRACES_EXPORTER</code>: the list of exporters to be used for tracing. For   example, by using <code>jaeger</code> you also need to have the corresponding dependency   in the application.</li> </ul> <p>Instead of using the above environment variables, it is also possible to use corresponding system properties to be set programmatically in the code or on the command line when launching the application They are <code>otel.service.name</code> and <code>otel.traces.exporter</code>.</p>"},{"location":"blog/2022/instrument-kafka-clients/#using-the-sdk-builders","title":"Using the SDK builders","text":"<p>In order to build your own <code>OpenTelemetry</code> instance and not relying on the auto-configuration, it is possible to do so by using the SDK builders classes programmatically. The OpenTelemetry SDK dependency is needed in order to have such SDK builders available in your code.</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-sdk&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>The following code snippet sets the main attributes like the service name, then it configures the Jaeger exporter. Finally, it creates the <code>OpenTelemetry</code> instance and registers it globally so that it can be used by the Kafka clients instrumentation library.</p> <pre><code>Resource resource = Resource.getDefault()\n.merge(Resource.create(Attributes.of(ResourceAttributes.SERVICE_NAME, \"my-kafka-service\")));\nSdkTracerProvider sdkTracerProvider = SdkTracerProvider.builder()\n.addSpanProcessor(BatchSpanProcessor.builder(JaegerGrpcSpanExporter.builder().build()).build())\n.setSampler(Sampler.alwaysOn())\n.setResource(resource)\n.build();\nOpenTelemetry openTelemetry = OpenTelemetrySdk.builder()\n.setTracerProvider(sdkTracerProvider)\n.setPropagators(ContextPropagators.create(W3CTraceContextPropagator.getInstance()))\n.buildAndRegisterGlobal();\n</code></pre>"},{"location":"blog/2022/instrument-kafka-clients/#using-the-interceptors","title":"Using the interceptors","text":"<p>The Kafka clients API provides a way to \"intercept\" messages before they are sent to the brokers as well as messages received from the broker before being passed to the application. This approach is heavily used when you need to add some logic or content to the messages right before they are sent. At same time, it is useful to handle consumed messages right before they are passed to the upper application layer. It fits pretty well with tracing when you need to create or close spans on sending and receiving messages.</p> <p>The Kafka clients instrumentation library provides two interceptors to be configured to add tracing information automatically. The interceptor classes have to be set in the properties bag used to create the Kafka client within the application.</p> <p>Use the <code>TracingProducerInterceptor</code> for the producer in order to create a \"send\" span automatically, each time a message is sent.</p> <pre><code>props.setProperty(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, TracingProducerInterceptor.class.getName());\n</code></pre> <p>Use the <code>TracingConsumerInterceptor</code> for the consumer in order to create a \"receive\" span automatically, each time a message is received.</p> <pre><code>props.setProperty(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, TracingConsumerInterceptor.class.getName());\n</code></pre>"},{"location":"blog/2022/instrument-kafka-clients/#wrapping-the-clients","title":"Wrapping the clients","text":"<p>The other way is by wrapping the Kafka client with a tracing enabled one.</p> <p>On the producer side, assuming you have a <code>Producer&lt;K, V&gt;</code> instance, you can wrap it in the following way.</p> <pre><code>KafkaTelemetry telemetry = KafkaTelemetry.create(GlobalOpenTelemetry.get());\nProducer&lt;String, String&gt; tracingProducer = telemetry.wrap(producer);\n</code></pre> <p>Then use the <code>tracingProducer</code> as usual for sending messages to the Kafka cluster.</p> <p>On the consumer side, assuming you have a <code>Consumer&lt;K, V&gt;</code> instance, you can wrap it in the following way.</p> <pre><code>KafkaTelemetry telemetry = KafkaTelemetry.create(GlobalOpenTelemetry.get());\nConsumer&lt;String, String&gt; tracingConsumer = telemetry.wrap(this.consumer);\n</code></pre> <p>Then use the <code>tracingConsumer</code> as usual for receiving messages from the Kafka cluster.</p>"},{"location":"blog/2022/instrument-kafka-clients/#instrumentation-in-action","title":"Instrumentation in action","text":"<p>In order to practice with the instrumentation of Kafka clients by using the provided examples, first of all you need an Apache Kafka cluster. The easiest way is to download it from the official website and running just one ZooKeeper node together with one Kafka broker. You can follow the quick start to have such a cluster up and running in a few minutes. Analyzing tracing information is also simpler if using a Web UI, for example the one provided by Jaeger. Even in this case downloading it from the official website and running it locally is really simple.</p> <p>When the environment is ready, the first try is about running the producer and consumer applications instrumented by using interceptors or wrappers. Just sending one message and consuming it provides the following tracing.</p> <p></p> <p>As you can see the \"send\" and \"receive\" spans are both in the same trace and the \"receive\" span is defined as <code>CHILD_OF</code> the \"send\" one. You can also see that the semantic defines some specific messaging related tags on the spans with the <code>messaging.</code> prefix. This semantic is not actually right because the send operation doesn't depend on the receive (which is the meaning of <code>CHILD_OF</code> relationship). It is anyway going to change, per this GitHub discussion and the new messaging semantic conventions that is going to be stabilized via this new OTEP (OpenTelemetry Enhancement Proposal). The goal is to have the \"send\" and \"receive\" spans in two different traces but linked together with a <code>FOLLOW_FROM</code> relationship.</p> <p>This approach is more reflected when using the agent with the \"send\" span living in its own trace as following.</p> <p></p> <p>On the receiving side, there are also a \"receive\" and \"process\" spans referring to the producer one.</p> <p></p>"},{"location":"blog/2022/instrument-kafka-clients/#conclusion","title":"Conclusion","text":"<p>Apache Kafka is just one of the messaging platforms that can be used for microservices communication in a distributed system. Monitoring how the messages are exchanged and troubleshooting problems is really complex. This is where the OpenTelemetry project comes into the picture to put tracing in your hands. In this article, we saw how the Kafka clients instrumentation library makes really simple to add tracing information to your Kafka based applications. You can get more information about how producers and consumers are behaving and keeps track of each message from one end to the other. So ... what else? Give it a try!</p>"},{"location":"blog/2022/instrument-kafka-clients/#references","title":"References","text":"<ul> <li>Apache Kafka</li> <li>Strimzi</li> <li>Website</li> <li>GitHub</li> <li>Bridge</li> <li>Kubernetes</li> </ul>"},{"location":"blog/2022/instrument-nginx/","title":"Learn how to instrument NGINX with OpenTelemetry","text":"<p>Apache HTTP Server and NGINX are the most popular web servers. It's most likely that you are using one of them in your application. In a previous blog post, you learned how to use the OpenTelemetry Module for Apache HTTP Server to add observability to Apache HTTP Server. In this blog post, you will learn how you can get observability for NGINX!</p>"},{"location":"blog/2022/instrument-nginx/#install-the-module-for-nginx","title":"Install the module for NGINX","text":"<p>In the following, you are going to use docker to run a NGINX server with the <code>ngx_http_opentelemetry_module.so</code> enabled and configured. Of course, you can use the same set of commands used in the <code>Dockerfile</code> below to configure a NGINX server on a bare-metal machine.</p> <p>Start from an empty directory. Create a file called <code>Dockerfile</code> and copy the following content into it:</p> <pre><code>FROM nginx:1.18\nRUN apt-get update ; apt-get install unzip\nADD https://github.com/open-telemetry/opentelemetry-cpp-contrib/releases/download/webserver%2Fv1.0.0/opentelemetry-webserver-sdk-x64-linux.tgz.zip /opt\nRUN cd /opt ; unzip opentelemetry-webserver-sdk-x64-linux.tgz.zip; tar xvfz opentelemetry-webserver-sdk-x64-linux.tgz\nRUN cd /opt/opentelemetry-webserver-sdk; ./install.sh\nENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/opentelemetry-webserver-sdk/sdk_lib/lib\nRUN echo \"load_module /opt/opentelemetry-webserver-sdk/WebServerModule/Nginx/ngx_http_opentelemetry_module.so;\\n$(cat /etc/nginx/nginx.conf)\" &gt; /etc/nginx/nginx.conf\nCOPY opentelemetry_module.conf /etc/nginx/conf.d\n</code></pre> <p>What this <code>Dockerfile</code> does:</p> <ul> <li>Pull a base image with NGINX 1.18 pre-installed</li> <li>Install <code>unzip</code></li> <li>Download the opentelemetry-webserver-sdk-x64-linux package</li> <li>Unpack the package, put it into <code>/opt</code> &amp; run <code>./install.sh</code></li> <li>Add the dependencies at <code>/opt/opentelemetry-webserver-sdk/sdk_lib/lib</code> to the   library path (<code>LD_LIBRARY_PATH</code>)</li> <li>Tell NGINX to load the <code>ngx_http_opentelemetry_module.so</code></li> <li>Add the configuration of the modules to NGINX.</li> </ul> <p>Next, create another file called <code>opentelemetry_module.conf</code> and copy the following content into it:</p> <pre><code>NginxModuleEnabled ON;\nNginxModuleOtelSpanExporter otlp;\nNginxModuleOtelExporterEndpoint localhost:4317;\nNginxModuleServiceName DemoService;\nNginxModuleServiceNamespace DemoServiceNamespace;\nNginxModuleServiceInstanceId DemoInstanceId;\nNginxModuleResolveBackends ON;\nNginxModuleTraceAsError ON;\n</code></pre> <p>This will enable the OpenTelemetry and apply the following configuration:</p> <ul> <li>Send spans via OTLP to localhost:4317</li> <li>Set the attributes <code>service.name</code> to <code>DemoService</code>, <code>service.namespace</code> to   <code>DemoServiceNamespace</code> and the <code>service.instance_id</code> to <code>DemoInstanceId</code></li> <li>Report traces as errors, so you will see them in the NGINX log</li> </ul> <p>To learn all the settings available, see the full list of directives.</p> <p>With the <code>Dockerfile</code> and NGINX config in place, build your docker image and run the container:</p> <pre><code>$ docker build -t nginx-otel --platform linux/amd64 .\n$ docker run --platform linux/amd64 --rm -p 8080:80 nginx-otel\n...\n2022/08/12 09:26:42 [error] 69#69: mod_opentelemetry: ngx_http_opentelemetry_init_worker: Initializing Nginx Worker for process with PID: 69\n</code></pre> <p>With the container up and running, send requests to NGINX using, for example, <code>curl localhost:8080</code>.</p> <p>Since the configuration above has <code>NginxModuleTraceAsError</code> set to <code>ON</code> and you will see your traces dump to the error log of NGINX:</p> <pre><code>2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: startMonitoringRequest: Starting Request Monitoring for: / HTTP/1.1\nHost, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: startMonitoringRequest: WebServer Context: DemoServiceNamespaceDemoServiceDemoInstanceId, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: startMonitoringRequest: Request Monitoring begins successfully , client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_startInteraction: Starting a new module interaction for: ngx_http_realip_module, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_payload_decorator: Key : tracestate, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_payload_decorator: Value : , client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_payload_decorator: Key : baggage, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_payload_decorator: Value : , client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_payload_decorator: Key : traceparent, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_payload_decorator: Value : 00-987932d28550c0a1c0a82db380a075a8-fc0bf2248e93dc42-01, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_startInteraction: Interaction begin successful, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n2022/08/12 09:31:12 [error] 70#70: *3 mod_opentelemetry: otel_stopInteraction: Stopping the Interaction for: ngx_http_realip_module, client: 172.17.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost:8080\"\n</code></pre>"},{"location":"blog/2022/instrument-nginx/#viewing-spans-in-jaeger","title":"Viewing spans in Jaeger","text":"<p>At this point the telemetry data generated by NGINX is not send to an OpenTelemetry collector or any other observability backend. You can easily change that by creating a <code>docker-compose</code> file, that starts the NGINX server, the collector and Jaeger:</p> <p>Create a file called <code>docker-compose.yml</code> and add the following content:</p> <pre><code>version: '2'\nservices:\njaeger:\nimage: jaegertracing/all-in-one:latest\nports:\n- '16686:16686'\ncollector:\nimage: otel/opentelemetry-collector:latest\ncommand: ['--config=/etc/otel-collector-config.yaml']\nvolumes:\n- ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\nnginx:\nimage: nginx-otel\nvolumes:\n- ./opentelemetry_module.conf:/etc/nginx/conf.d/opentelemetry_module.conf\nports:\n- 8080:80\n</code></pre> <p>Create a file called <code>otel-collector-config.yaml</code> containing the following:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nexporters:\njaeger:\nendpoint: jaeger:14250\ntls:\ninsecure: true\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [jaeger]\n</code></pre> <p>Before spinning up the containers, update line 3 in <code>opentelemetry_module.conf</code> to have the right exporter endpoint:</p> <pre><code>NginxModuleEnabled ON; NginxModuleOtelSpanExporter otlp;\nNginxModuleOtelExporterEndpoint collector:4317;\n</code></pre> <p>You don't need to rebuild your docker image, because the <code>docker-compose.yaml</code> above loads the <code>opentelemetry_module.conf</code> as a file volume on container startup.</p> <p>Get everything up and running1:</p> <pre><code>$ docker compose up\n</code></pre> <p>In another shell, create some traffic:</p> <pre><code>$ curl localhost:8080\n</code></pre> <p>In your browser open localhost:16686 and search for traces from <code>DemoService</code> and drill into one of them.</p> <p></p> <p>You will see one span for each NGINX module being executed during the request. With that you can easily spot issues with certain modules, for example, a rewrite going mad.</p>"},{"location":"blog/2022/instrument-nginx/#put-nginx-between-two-services","title":"Put NGINX between two services","text":"<p>Of course, NGINX is rarely used as a standalone solution! Most of the time it is used as a reverse proxy or load balancer in front of another service. And, there might be a service calling NGINX to reach that down stream service.</p> <p>Add two more services to the running example:</p> <ul> <li>A Node.js service called <code>frontend</code> that sits at the front and calls the NGINX</li> <li>A java service called <code>backend</code> that sits behind the NGINX</li> </ul> <p>Update the <code>docker-compose</code> file to contain those 2 services and to overwrite the <code>default.conf</code> in NGINX:</p> <pre><code>version: '2'\nservices:\njaeger:\nimage: jaegertracing/all-in-one:latest\nports:\n- '16686:16686'\ncollector:\nimage: otel/opentelemetry-collector:latest\ncommand: ['--config=/etc/otel-collector-config.yaml']\nvolumes:\n- ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\nnginx:\nimage: nginx-otel\nvolumes:\n- ./opentelemetry_module.conf:/etc/nginx/conf.d/opentelemetry_module.conf\n- ./default.conf:/etc/nginx/conf.d/default.conf\nbackend:\nbuild: ./backend\nimage: backend-with-otel\nenvironment:\n- OTEL_TRACES_EXPORTER=otlp\n- OTEL_METRICS_EXPORTER=none\n- OTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4318/\n- OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n- OTEL_SERVICE_NAME=backend\nfrontend:\nbuild: ./frontend\nimage: frontend-with-otel\nports:\n- '8000:8000'\nenvironment:\n- OTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4318/\n- OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n- OTEL_SERVICE_NAME=frontend\n</code></pre> <p>Create the <code>default.conf</code> that will pass requests to NGINX down to the backend service:</p> <pre><code>server {\nlisten       80;\nlocation / {\nproxy_pass http://backend:8080;\n}\n}\n</code></pre> <p>Create two empty folders <code>backend</code> and <code>frontend</code>.</p> <p>In the frontend folder, create a simple Node.js app:</p> <pre><code>const opentelemetry = require('@opentelemetry/sdk-node');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\nconst {\nOTLPTraceExporter,\n} = require('@opentelemetry/exporter-trace-otlp-http');\nconst sdk = new opentelemetry.NodeSDK({\ntraceExporter: new OTLPTraceExporter(),\ninstrumentations: [getNodeAutoInstrumentations()],\n});\nsdk.start().then(() =&gt; {\nconst express = require('express');\nconst http = require('http');\nconst app = express();\napp.get('/', (_, response) =&gt; {\nconst options = {\nhostname: 'nginx',\nport: 80,\npath: '/',\nmethod: 'GET',\n};\nconst req = http.request(options, (res) =&gt; {\nconsole.log(`statusCode: ${res.statusCode}`);\nres.on('data', (d) =&gt; {\nresponse.send('Hello World');\n});\n});\nreq.end();\n});\napp.listen(parseInt(8000, 10), () =&gt; {\nconsole.log('Listening for requests');\n});\n});\n</code></pre> <p>To finalize the frontend service, create an empty <code>Dockerfile</code> with the following content:</p> <pre><code>FROM node:16\nWORKDIR /app\nRUN npm install @opentelemetry/api @opentelemetry/auto-instrumentations-node @opentelemetry/exporter-trace-otlp-http @opentelemetry/sdk-node express\nCOPY app.js .\nEXPOSE 8000\nCMD [ \"node\", \"app.js\" ]\n</code></pre> <p>For the backend service, you are going to use Tomcat with the OpenTelemetry Java agent installed. For this, create a <code>Dockerfile</code> like the following in the <code>backend</code> folder</p> <pre><code>FROM tomcat\nADD https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar javaagent.jar\nENV JAVA_OPTS=\"-javaagent:javaagent.jar\"\nCMD [\"catalina.sh\", \"run\"]\n</code></pre> <p>As you can see, the <code>Dockerfile</code> downloads and adds the OpenTelemetry Java agent for you automatically.</p> <p>You should now have the following files in your top level directory:</p> <ul> <li>./default.conf</li> <li>./docker-compose.yml</li> <li>./Dockerfile</li> <li>./opentelemetry_module.conf</li> <li>./otel-collector-config.yaml</li> <li>./backend/Dockerfile</li> <li>./frontend/Dockerfile</li> <li>./frontend/app.js</li> </ul> <p>With everything in place, you can now start the demo environment1:</p> <pre><code>$ docker compose up\n</code></pre> <p>Within a few moments you should have five docker containers up and running:</p> <ul> <li>Jaeger</li> <li>OTel Collector</li> <li>Nginx</li> <li>Frontend</li> <li>Backend</li> </ul> <p>Send a few requests to the frontend with <code>curl localhost:8000</code> and then check the Jaeger UI in your browser at localhost:16686. You should see traces going from frontend to NGINX to backend.</p> <p>The frontend trace should indicate an error, since NGINX is forwarding the <code>Page Not Found</code> from Tomcat.</p> <p></p>"},{"location":"blog/2022/instrument-nginx/#whats-next","title":"What's next?","text":"<p>You should now be able to apply what you have learned from this blog post to your own installation of NGINX. We would love to hear about your experience! If you run into any problems, create an issue.</p> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"blog/2022/jaeger-native-otlp/","title":"Supporting Jaeger with native OTLP","text":"<p>Back in May of 2022, the Jaeger project announced native support for the OpenTelemetry Protocol (OTLP). This followed a generous deprecation cycle for the Jaeger client libraries across many languages. With these changes, OpenTelemetry users are now able to send traces into Jaeger with industry-standard OTLP, and the Jaeger client library repositories have been finally archived.</p> <p>We intend to deprecate Jaeger exporters from OpenTelemetry in the near future, and are looking for your feedback to determine the length of the depreation phase. The best way to provide feedback is by filling out a 4-question survey or commenting on the existing draft pull request.</p>"},{"location":"blog/2022/jaeger-native-otlp/#opentelemetry-support","title":"OpenTelemetry Support","text":"<p>This interoperability is a wonderful victory both for Jaeger users and for OpenTelemetry users. However, we're not done yet. The OpenTelemetry specification still requires support for Jaeger client exporters across languages.</p> <p>This causes challenges for both Jaeger users and OpenTelemetry maintainers:</p> <ol> <li> <p>Confusing Choices</p> <p>Currently, users are faced with a choice of exporter (Jaeger or OTLP), and this can be a source of confusion. A user might be inclined, when exporting telemetry to Jaeger, to simply choose the Jaeger exporter because the name matches (even though Jaeger now actively encourages the use of OTLP).</p> <p>If we can eliminate this potentially confusing choice, we can improve the user experience and continue standardizing on a single interoperable protocol. We love it when things \"just work\" out of the box!</p> </li> <li> <p>Maintenance and duplication</p> <p>Because the Jaeger client libraries are now archived, they will not receive updates (including security patches). To continue properly supporting Jaeger client exporters, OpenTelemetry authors would be required to re-implement some of the functionality it had previously leveraged from the Jaeger clients.</p> <p>Now that Jaeger supports OTLP, this feels like a step backwards: It results in an increased maintenance burden with very little benefit.</p> </li> </ol>"},{"location":"blog/2022/jaeger-native-otlp/#user-impact","title":"User Impact","text":"<p>The proposal is to deprecate the following exporters from OpenTelemetry in favor of using native OTLP into Jaeger:</p> <ul> <li>Jaeger Thrift over HTTP</li> <li>Jaeger protobuf via gRPC</li> <li>Jaeger Thrift over UDP</li> </ul> <p>In addition to application configuration changes, there could be other architectural considerations. HTTP and gRPC should be straightforward replacements, although it may require exposing ports 4317 and 4318 if they are not already accessible.</p> <p>Thrift over UDP implies the use of the Jaeger Agent. Users with this deployment configuration will need to make a slightly more complicated change, typically one of the following:</p> <ol> <li>Direct ingest. Applications will change from using Thrift+UDP to sending OTLP    traces directly to their <code>jaeger-collector</code> instance. This may also have    sampling implications.</li> <li>Replacing the Jaeger Agent with a sidecar    OpenTelemetry Collector    instance. This could have sampling implications and requires changes to your    infrastructure deployment code.</li> </ol>"},{"location":"blog/2022/jaeger-native-otlp/#intent-to-deprecate-wed-like-your-feedback","title":"Intent to Deprecate - We'd Like Your Feedback!","text":"<p>In order to better support users and the interop between OpenTelemetry and Jaeger, we intend to deprecate and eventually remove support for Jaeger client exporters in OpenTelemetry.</p> <p>We would like your feedback! We want to hear from users who could be impacted by this change. To better make a data-informed decision, we have put together a short 4-question survey.</p> <p>Your input will help us to choose how long to deprecate before removal.</p> <p>A draft PR has been created in the specification to support this deprecation. If would like to contribute and provide feedback, visit the link above and add some comments. We want to hear from you.</p>"},{"location":"blog/2022/k8s-metadata/","title":"Improved troubleshooting using k8s metadata","text":"<p>Attaching Kubernetes resource metadata to OpenTelemetry traces is useful to identify which resource (such as a pod) is failing or having performance problems. It is also useful for correlating across other signals, for example: you can correlated logs and spans that were generated by the same pod.</p> <p>In this article, you'll learn how to configure the OpenTelemetry collector to use the k8sattributesprocessor in different scenarios.</p> <p>Details of the OpenTelemetry collector pipeline won't be covered in this post. For those details, refer to the collector documentation.</p>"},{"location":"blog/2022/k8s-metadata/#how-k8s-attributes-are-attached","title":"How K8s attributes are attached","text":"<p>At a high level, K8s attributes are attached to traces as resources. This is for two reasons:</p> <ol> <li>K8s attributes fit the definition of what a resource is: an entity for which    telemetry is recorded</li> <li>It centralizes this metadata, which is relevant for any generated span.</li> </ol> <p>Let's dive in and see how to do it!</p>"},{"location":"blog/2022/k8s-metadata/#using-k8sattributes-processor","title":"Using k8sattributes processor","text":"<p>This is an OpenTelemetry processor that automatically discovers pod metadata and attaches it to a resource associated with the spans generated by that pod. If the pod belongs to a <code>Deployment</code> or a <code>ReplicaSet</code>, it will also discover it's attributes.</p> <p>Some attributes we can attach to the resource are:</p> <ul> <li>Node name <code>k8s.node.name</code></li> <li>Pod name <code>k8s.pod.name</code></li> <li>Pod UID <code>k8s.pod.uid</code></li> <li>Namespace <code>k8s.namespace.name</code></li> <li>Deployment name, <code>k8s.deployment.name</code> if the pod was created by a deployment</li> </ul> <p>Such attributes adhere to OpenTelemetry semantic conventions. For details, see the Kubernetes resource semantic conventions.</p> <p>The processor internally maintains a list of pods and an associated attribute, usually the IP address of the pod, and uses this attribute to know which pod generates a certain span.</p> <p></p> <p>In the figure above you can see how the data flows: The table of pods is fetched using Kubernetes API, while the pod IP is extracted from the connection context between the pod and the collector.</p> <p>The <code>k8sattributesprocessor</code> can work in different modes depending on how the collector is configured. Let's explore one common scenario, when the collector is deployed as daemonset.</p>"},{"location":"blog/2022/k8s-metadata/#daemonset-mode","title":"Daemonset mode","text":"<p>Let\u2019s take a look at how we can configure the collector in daemonset mode, also known as an agent mode in the k8sattributes documentation.</p> <p>When we deploy the collector in daemonset mode, we have one collector pod per node. We need to configure the collector service account to have permissions to fetch all pod information. In order to do that, we will create a <code>ClusterRole</code> with the necessary permissions.</p> <p>Here are the minimum permissions required to make the <code>k8sattributesprocessor</code> work:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\nname: otel-collector\nrules:\n- apiGroups: ['']\nresources: ['pods', 'namespaces']\nverbs: ['get', 'watch', 'list']\n</code></pre> <p>Next, deploy the collector in daemonset mode. We recommend that you set a filter to only fetch the pods that belong to the node in which the collector is deployed. This is because if you have a large cluster, you don\u2019t want to maintain a huge list of pods.</p> <p>This is the manifest used in this blog to show how the processor works:</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\nname: otel-collector-daemonset\nspec:\nmode: daemonset\nimage: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.47.0\nserviceAccount: attributes-account\nenv:\n- name: KUBE_NODE_NAME\nvalueFrom:\nfieldRef:\napiVersion: v1\nfieldPath: spec.nodeName\nconfig: |\nreceivers:\njaeger:\nprotocols:\ngrpc:\nthrift_binary:\nthrift_compact:\nthrift_http:\notlp:\nprotocols:\ngrpc:\nhttp:\nprocessors:\nk8sattributes:\nfilter:\nnode_from_env_var: KUBE_NODE_NAME\nexporters:\njaeger:\nendpoint: jaeger-all-in-one-collector:14250\ntls:\ninsecure: true\nservice:\npipelines:\ntraces:\nreceivers: [otlp, jaeger]\nprocessors: [k8sattributes]\nexporters: [jaeger]\n</code></pre> <p>The main parts to note are that it uses the contrib collector image. The <code>k8sattributesprocessor</code> is not part of the OpenTelemetry collector core, but the contrib distribution has it. Other things to notice are the filter mentioned above, and the use of a previously-created specific service account, which contains the permissions to fetch the pod list.</p> <p>Next, deploy the manifest and the vert.x example app to generate some traces.</p> <p></p> <p>As you can see, each span of the trace now has the corresponding pod attributes attached to it.</p> <p>You can restrict the configuration above to a certain namespace if you add the namespace on the <code>k8sattributesprocessor</code> filter like this:</p> <pre><code>processors:\nk8sattributes:\nfilter:\nnamespace: my_namespace\n</code></pre> <p>In this way, you can create a <code>Role</code> and don\u2019t need to create a <code>ClusterRole</code>, reducing the scope of the collector service account to a single namespace.</p>"},{"location":"blog/2022/k8s-metadata/#using-resource-detector-processor","title":"Using Resource detector processor","text":"<p>As of recently, the OpenTelemetry operator sets the <code>OTEL_RESOURCE_ATTRIBUTES</code> environment variable on the collector container with the K8s pod attributes. This lets you to use the resource detector processor, which attaches the environment variable values to the spans. This only works when the collector is deployed in sidecar mode.</p> <p>For example, if you deploy the following manifest:</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\nname: sidecar-for-my-app\nspec:\nmode: sidecar\nimage: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.47.0\nconfig: |\nreceivers:\njaeger:\nprotocols:\ngrpc:\nthrift_binary:\nthrift_compact:\nthrift_http:\notlp:\nprotocols:\ngrpc:\nhttp:\nprocessors:\nresourcedetection:\ndetectors: [env]\ntimeout: 2s\noverride: false\nexporters:\njaeger:\nendpoint: jaeger-all-in-one-collector:14250\ntls:\ninsecure: true\nservice:\npipelines:\ntraces:\nreceivers: [otlp, jaeger]\nprocessors: [resourcedetection]\nexporters: [jaeger]\n</code></pre> <p>And then deploy the vert.x example app, you can see the <code>OTEL_RESOURCE_ATTRIBUTES</code> environment variable gets injected with some values in the sidecar container. Some of them use the Kubernetes downward API to get the attribute values.</p> <p>Here's an example of the value of the environment variable:</p> <pre><code>- name: OTEL_RESOURCE_ATTRIBUTES\nvalue: k8s.deployment.name=dep-vert-x,k8s.deployment.uid=ef3fe26b-a690-4746-9119-d2dbd94b469f,\nk8s.namespace.name=default,k8s.node.name=$(OTEL_RESOURCE_ATTRIBUTES_NODE_NAME),k8s.pod.name=\n(OTEL_RESOURCE_ATTRIBUTES_POD_NAME),k8s.pod.uid=$(OTEL_RESOURCE_ATTRIBUTES_POD_UID),k8s.replicaset\nname=dep-vert-x-59b6f76585,k8s.replicaset.uid=5127bc38-e298-40e1-95df-f4a777e3176c\n</code></pre>"},{"location":"blog/2022/k8s-metadata/#learn-more","title":"Learn more","text":"<p>This post covers how to configure the OpenTelemetry collector to attach Kubernetes resource metadata as resource attributes to OpenTelemetry traces. The scenarios covered, although basic, illustrate how to add this kind of metadata to traces so that you can incorporate the technique into other more sophisticated scenarios. If you want to learn more about different scenarios or options for configure the processors you can see the K8sattributes processor documentation where you can find more scenarios like sidecar, or when one collector as an agent report to another collector.</p>"},{"location":"blog/2022/k8s-metadata/#references","title":"References","text":"<ul> <li>K8sattributes processor documentation</li> <li>K8sattributes processor RBAC</li> <li>OpenTelemetry Kubernetes attributes</li> <li>Resource detector processor</li> </ul>"},{"location":"blog/2022/k8s-otel-expose/","title":"Exposing a Collector for cross cluster communication","text":"<p>Exposing an OpenTelemetry Collector currently requires a number of configuration steps. The goal of this blog post is to demonstrate <code>how to establish a secure communication</code> between two collectors in different Kubernetes clusters.</p> <p>Details of CRDs and dependency installations are not covered by this post.</p>"},{"location":"blog/2022/k8s-otel-expose/#overview","title":"Overview","text":"<p>When it comes to making collectors publicly accessible, the first thing that comes to mind is the secure transmission of user data via TLS. However, authentication to the server is at least as important to prevent unauthorized services from sending data.</p> <p>The OpenTelemetry Collector supports different authentication methods. The most used are probably:</p> <ol> <li>TLS Authentication</li> <li>OpenID Connect (OIDC-Authentication)</li> <li>HTTP Basic Authentication</li> </ol> <p>This article focuses on HTTP Basic Authentication for simplicity. It is intended to show how a secure setup can be operated without key management or further third party services.</p> <p>For more information about TLS configuration I would like to refer to the article How TLS provides identification, authentication, confidentiality, and integrity and the Collector TLS-Config description on Github.</p> <p>If you are interested in using an external authentication provider, I advise you to have a look at the article Securing your OpenTelemetry Collector by Juraci Paix\u00e3o Kr\u00f6hling on this topic. He explains how OpenTelemetry collectors can be secured using the OIDC-Authenticator extension, and how Keycloak can be configured as an authentication provider.</p>"},{"location":"blog/2022/k8s-otel-expose/#basic-authentication","title":"Basic Authentication","text":"<p>The HTTP Basic Authentication mechanism is quite simple. An HTTP user agent (e.g., a web browser) provides a username and password combination on every request. Transmitted credentials are included in the HTTP header by the key <code>Authorization</code> when the connection is established. As a value the authentication method <code>basic</code> is mentioned first, followed by the encoded credentials. Note that the credential form is <code>username:password</code>.</p> <p>In the following example, <code>dXNlci0xOjEyMzQK</code> is the encoding for a combination of <code>username=user-1</code> and <code>password=1234</code>. Note to encode or decode base64 values, you can use</p> <pre><code># HTTP Header key: value pair\nAuthorization: Basic &lt;credentials-base64-encoded&gt;\n# example: user: user-1 password: 1234\nAuthorization: Basic dXNlci0xOjEyMzQK\n</code></pre> <p>You can easily create your own user password combination using the base64 cli tool.</p> <pre><code># encode\n$ echo \"user-1:1234\" | base64\ndXNlci0xOjEyMzQK\n\n# decode\n$ echo \"dXNlci0xOjEyMzQK\" | base64 -d\nuser-1:1234\n</code></pre>"},{"location":"blog/2022/k8s-otel-expose/#data-flow","title":"Data flow","text":"<p>The following graph illustrates the target topology. The goal is to transfer traces generated by a test application via a dedicated collector to a publicly accessible cluster. The receiving collector uses the transmitted 'Basic' HTTP Authentication credentials to check whether the sender is authorized to store data. Finally, transmitted traces are stored in a Jaeger in-memory</p> <p></p>"},{"location":"blog/2022/k8s-otel-expose/#prerequisites","title":"Prerequisites","text":"<p>Interfaces and behavior may change in the future. Therefore, the versions used in this setup are mentioned in brackets.</p> <ul> <li>A Kubernetes[v1.23.3] cluster with a public address with   ingress-nginx-controller[v1.2.1]   installed.</li> <li>A Kubernetes[v1.23.3] edge cluster to create a test cluster. Using   Kind is recommended.</li> <li>Installed OpenTelemetry Operator[v0.58.0]   on both ends.</li> <li>Installed   Jaeger Operator[v1.37.0]   on your public cluster.</li> <li>Installed cert-manager[v1.9.1] on your public   cluster.</li> </ul>"},{"location":"blog/2022/k8s-otel-expose/#remote-cluster-configuration","title":"Remote cluster configuration","text":"<p>Since all components except the Jaeger backend depend on a following component, we begin by deploying the backend.</p> <pre><code>apiVersion: jaegertracing.io/v1\nkind: Jaeger\nmetadata:\nname: my-in-memory\n</code></pre> <p>In the next step we create an OpenTelemetry Collector using the <code>OpenTelemetryCollector</code> CRD. The most important entries are <code>mode</code>, <code>image</code> and the configured basicauth extension. In the manifest below the mode <code>deployment</code> was chosen to guarantee that at least one collector pod is available for processing incoming information. Furthermore the default collector image was overwritten with the contrib version. This is necessary because the core version does not contain the basicauth extension. This extension was configured with the name <code>basicauth/server</code> and registered in <code>otlp/basicauth</code>. As otlp exporter endpoint the Jaeger in-memory service was configured.</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\nname: otel-collector-app\nspec:\nmode: deployment\nimage: otel/opentelemetry-collector-contrib:0.58.0\nconfig: |\nextensions:\nbasicauth/server:\nhtpasswd:\ninline: |\n&lt;REPLACE: your backend credentials, e.g.: \"user-1:1234\"&gt;\nreceivers:\notlp/basicauth:\nprotocols:\ngrpc:\nauth:\nauthenticator: basicauth/server\nexporters:\notlp/jaeger:\nendpoint: my-in-memory-collector:4317\ntls:\ninsecure: true\ninsecure_skip_verify: true\nservice:\nextensions: [basicauth/server]\npipelines:\ntraces:\nreceivers: [otlp/basicauth]\nexporters: [otlp/jaeger]\n</code></pre> <p>After a successful installation, a pod for the Jaeger backend and the OpenTelemetry collector should be created in the selected namespace.</p> <pre><code>NAME                                            READY   STATUS    RESTARTS   AGE\nmy-in-memory-6c5f5f87c5-rnp99                   1/1     Running   0          4m\notel-collector-app-collector-55cccf4b7d-llczt   1/1     Running   0          3m\n</code></pre> <p>Also the following services should be available:</p> <pre><code>NAME                                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                    AGE\nmy-in-memory-agent                        ClusterIP   None            &lt;none&gt;        5775/UDP,5778/TCP,6831/UDP,6832/UDP                         7m\nmy-in-memory-collector                    ClusterIP   10.245.43.185   &lt;none&gt;        9411/TCP,14250/TCP,14267/TCP,14268/TCP,4317/TCP,4318/TCP    7m\nmy-in-memory-collector-headless           ClusterIP   None            &lt;none&gt;        9411/TCP,14250/TCP,14267/TCP,14268/TCP,4317/TCP,4318/TCP    7m\nmy-in-memory-query                        ClusterIP   10.245.91.239   &lt;none&gt;        16686/TCP,16685/TCP                                         7m\notel-collector-app-collector              ClusterIP   10.245.5.134    &lt;none&gt;        4317/TCP                                                    5m\notel-collector-app-collector-headless     ClusterIP   None            &lt;none&gt;        4317/TCP                                                    5m\notel-collector-app-collector-monitoring   ClusterIP   10.245.116.38   &lt;none&gt;        8888/TCP                                                    5m\n</code></pre> <p>Finally, cert-manager is configured to automatically request TLS certificates from Let\u2019s Encrypt and make it available to the Ingress TLS configuration. The following <code>ClusterIssuer</code> and <code>Ingress</code> entries expose the <code>otel-collector-app-collector</code> service. Note that you'll need to replace values for the <code>email</code> and <code>host</code> fields.</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\nname: letsencrypt\nnamespace: cert-manager\nspec:\nacme:\nserver: https://acme-v02.api.letsencrypt.org/directory\nemail: your-email-address-here@example.com # REPLACE\nprivateKeySecretRef:\nname: letsencrypt\nsolvers:\n- http01:\ningress:\nclass: nginx\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\nname: ingress-otel\nannotations:\nkubernetes.io/ingress.class: nginx\nnginx.ingress.kubernetes.io/backend-protocol: GRPC\ncert-manager.io/cluster-issuer: letsencrypt\nspec:\ntls:\n- hosts:\n- your-host # REPLACE your domain endpoint, e.g., traces@example.com\nsecretName: letsencrypt\nrules:\n- host: your-host # REPLACE your domain endpoint, e.g., traces@example.com\nhttp:\npaths:\n- pathType: Prefix\npath: '/'\nbackend:\nservice:\nname: otel-collector-app-collector\nport:\nnumber: 4317\n</code></pre>"},{"location":"blog/2022/k8s-otel-expose/#edge-cluster-configuration","title":"Edge Cluster configuration","text":"<p>In order to be able to determine the origin of the transmitted traces, the span-tags are extended by identifying metadata with the help of the k8sattributes processor. It is available in the OpenTelemetry Collector contrib version. In the next step we create a service account with the necessary permissions. If you want to learn more about the K8s metadata, you can read this post \"Improved troubleshooting using K8s metadata\".</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\nname: attributes-role\nrules:\n- apiGroups:\n- ''\nresources:\n- pods\nverbs:\n- get\n- list\n- watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\nname: attributes-rolebinding\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: attributes-role\nsubjects:\n- kind: ServiceAccount\nname: attributes-account\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\nname: attributes-account\n</code></pre> <p>Let's have a quick look on the most important edge collector settings. A <code>daemonset</code> is used as deployment mode to ensure that one collector instance per node exists. The <code>basicauth</code> extension contains <code>username</code> and <code>password</code> to identify itself to the exposed remote collector. More container and node specific information are provided by the <code>k8sattributes</code> processor via the kubernetes Kubernetes downward-api. What is not covered is the cluster availability zone and the cluster name. To be able to identify the reported spans later, they are inserted manually with the help of the <code>resource</code> processor. Last, the OTLP exporter endpoint has also been given a placeholder value that must be replaced with your remote cluster domain.</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\nname: otel-collector-app\nspec:\nmode: daemonset\nimage: otel/opentelemetry-collector-contrib:0.58.0\nserviceAccount: attributes-account\nenv:\n- name: KUBE_NODE_NAME\nvalueFrom:\nfieldRef:\napiVersion: v1\nfieldPath: spec.nodeName\nconfig: |\nextensions:\nbasicauth/client:\nclient_auth: # credentials must be consistent with those of the receiving collector.\nusername: &lt;REPLACE: your basicauth username, e.g.: \"user-1\"&gt;\npassword: &lt;REPLACE: your basicauth password, e.g.: \"1234\"&gt;\nreceivers:\notlp:\nprotocols:\ngrpc:\nprocessors:\nresource:\nattributes:\n- key: cloud.availability_zone\nvalue: &lt;REPLACE: your availability zone, e.g.: \"eu-west-1\"&gt;\naction: insert\n- key: k8s.cluster.name\nvalue: &lt;REPLACE: your cluster name, e.g.: \"edge-cluster-1\"&gt;\naction: insert\nk8sattributes:\nfilter:\nnode_from_env_var: KUBE_NODE_NAME\nexporters:\notlp:\nendpoint: \"&lt;REPLACE: your domain endpoint, e.g.: \"traces.example.com:443\"&gt;\"\nauth:\nauthenticator: basicauth/client\nlogging:\nservice:\nextensions: [basicauth/client]\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [k8sattributes]\nexporters: [otlp,logging]\n</code></pre> <p>After a successful installation, a <code>daemonset</code> with the name <code>otel-collector-app-collector</code> should have been created. This ensures that each cluster node has a local collector instance up and running.</p>"},{"location":"blog/2022/k8s-otel-expose/#deploy-trace-generator-to-generate-test-data","title":"Deploy trace generator to generate test data","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: trace-gen\nspec:\nselector:\nmatchLabels:\napp: trace-gen\ntemplate:\nmetadata:\nlabels:\napp: trace-gen\nspec:\ncontainers:\n- name: trace-gen\nimage: ghcr.io/frzifus/jaeger-otel-test:latest\nargs:\n[\n'-otel.agent.host=otel-collector-app-collector',\n'-otel.agent.port=4317',\n]\nenv:\n- name: OTEL_SERVICE_NAME\nvalue: 'local-test-service'\n</code></pre>"},{"location":"blog/2022/k8s-otel-expose/#testing","title":"Testing","text":"<p>Now spans generated in the edge cluster should be extended with origin metadata. These are then transferred to the remote cluster and stored in the Jaeger backend. Jaeger itself provides a UI for inspecting transmitted data.</p> <p>An easy way to reach the UI is by port forwarding to your local system.</p> <pre><code>$ kubectl port-forward deployments/my-in-memory 16686\nForwarding from 127.0.0.1:16686 -&gt; 16686\n</code></pre> <p></p>"},{"location":"blog/2022/k8s-otel-expose/#conclusion","title":"Conclusion","text":"<p>Configurations like <code>Ingress</code>, <code>ClusterIssuer</code> and <code>OpenTelemetryCollector</code> on client and server side have to be configured manually. Depending on installed Kubernetes components, the configurations differ a lot. Overall the configuration is very error-prone. In the future the exposing of the collector should be simplified with the help of the OpenTelemetry operator. If you are interested in the development, you can follow Github issue #902 to stay updated.</p>"},{"location":"blog/2022/k8s-otel-expose/#references","title":"References","text":"<ul> <li>Securing your OpenTelemetry Collector</li> <li>Jaeger Tracing</li> <li>OpenTelemetry-Collector</li> <li>Distributions:     contrib,     core</li> <li>Extensions:     basicauth,     oidc</li> <li>Processors:     resource,     k8sattributes</li> <li>Exporters:     otlp,     logging</li> <li>Test-Application</li> <li>Basic HTTP Authentication</li> <li>Kubernetes Downward-API</li> <li>Let\u2019s Encrypt</li> <li>Ingress NGINX gRPC example</li> <li>OpenTelemetry-Collector TLS-Config</li> <li>How TLS provides identification, authentication, confidentiality, and integrity</li> </ul>"},{"location":"blog/2022/knative/","title":"Distributed tracing in Knative","text":"<p>In this article, you will learn how distributed tracing works in Knative and we will explore how the OpenTelemetry project can make tracing support in this environment easier. We will explore Knative under the hood to understand what distributed tracing capabilities it provides out-of-the-box and which parts of the system need additional instrumentation.</p>"},{"location":"blog/2022/knative/#about-knative","title":"About Knative","text":"<p>Knative is a serverless platform built on top of Kubernetes as a set of <code>CustomResourceDefinitions</code> (CRDs). The project is split into two logical parts:</p> <ul> <li>serving - facilitates the creation, deployment and scaling of   workload/services</li> <li>eventing - facilitates event-driven communication between workloads to enable   loosely coupled architectures</li> </ul> <p>In this article we will not cover Knative fundamentals, please refer to the Knative documentation to get familiar with the project.</p>"},{"location":"blog/2022/knative/#knative-data-flow","title":"Knative data flow","text":"<p>Before we deep dive into tracing let's take a look at a data flow example. It will help us to understand Knative architecture and which parts of the system need to be instrumented in order to understand the timing characteristics of the request or transaction. On the diagram below there are two user workloads (first and second) and an incoming request marked as (1. HTTP) that goes to use workload first and then to the workload second as a cloud event message.</p> <p></p> <p>There are two important facts about this diagram:</p> <ol> <li>all the traffic goes through queue-proxy sidecar</li> <li>all traffic goes through Knative component(s). The Knative components in the    diagram are abstract. It can be a Knative activator service, Knative event    broker, dispatcher etc.</li> </ol> <p>From the telemetry perspective, the purpose of queue-proxy is similar to istio-proxy from Istio service mesh. It is a proxy that intercepts all traffic going to the workload and it emits telemetry data for any communication going to or from the workload.</p>"},{"location":"blog/2022/knative/#distributed-tracing-in-knative","title":"Distributed tracing in Knative","text":"<p>The Knative project comes with a solid distributed tracing integration. Major parts of the system are already instrumented and the system creates trace data for transactions/requests that go to user workloads.</p> <p>Internally at the moment, Knative uses OpenCensus instrumentation libraries that export data in Zipkin format. The inter-process context propagation uses Zipkin B3 and W3C Trace-Context standards. The Zipkin B3 propagation format is most likely used for legacy reasons to allow trace context propagation with older workloads instrumented with older technology. As a best practice, use the standard W3C Trace-Context which is natively used by the OpenTelemetry project.</p> <p>Now let's take a look at an example trace with two workloads (first and second). The workflow is similar to the diagram from the previous section: the first service receives an HTTP call and sends a cloud event to the second service. The full demo source code can be found in pavolloffay/knative-tracing.</p> <p></p> <p>The trace shows the following services interacting: activator, first workload, broker-ingress, imc-dispatcher, broker-filter, activator, and second workload. There are many services, right? A simple interaction of two workloads resulted in a trace that shows many Knative internal components. From the observability perspective, this is great because it can show issues in the infrastructure and additionally show cost associated with Knative request processing.</p> <p>Let's briefly example the data flow. The incoming HTTP request first goes through an activator service that is responsible for scaling up a workload, then its execution reaches the first workload. The first workload sends a cloud event which goes through the broker and dispatcher and finally reaches the second workload.</p> <p>Now let's take a closer look at the user workloads. The first service is a Golang service with a single REST API endpoint. The endpoint implementation creates a cloud event and sends it to the broker. Let's take a look at important facts from the observability perspective:</p> <ul> <li>REST API is instrumented with OpenTelemetry. This allows us to link traces   started in the Knative activator service with spans created in the workload   and further link it with outbound spans - e.g. to calls to the second service.</li> <li>The workload is using instrumented   Cloudevents client/SDK -   similarly to the previous point it allows us to continue the trace in the   outbound request (in this scenario to the second service).</li> </ul> <p>How is the trace-context (<code>traceId</code>, <code>spanId</code>, <code>sampled</code> flag) being propagated in our example applications? The trace-context is propagated in HTTP headers both for incoming HTTP requests into the first service and as well for cloud events sent to the second service. The trace-context is not attached directly to the event extensions/attributes.</p> <p>Follows log output with request headers from the first service:</p> <pre><code>2022/02/17 12:53:48 Request headers:\n2022/02/17 12:53:48     X-B3-Sampled: [1]\n2022/02/17 12:53:48     X-B3-Spanid: [af6c239eb7b39349]\n2022/02/17 12:53:48     X-B3-Traceid: [5f2c4775e0e36efc1d554a0b6c456cc1]\n2022/02/17 12:53:48     X-Forwarded-For: [10.244.0.12, 10.244.0.5]\n2022/02/17 12:53:48     Accept-Language: [en,fr;q=0.9,de;q=0.8,sk;q=0.7]\n2022/02/17 12:53:48     Cookie: [_ga=GA1.2.260863911.1644918876]\n2022/02/17 12:53:48     Accept: [text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9]\n2022/02/17 12:53:48     K-Proxy-Request: [activator]\n2022/02/17 12:53:48     Upgrade-Insecure-Requests: [1]\n2022/02/17 12:53:48     User-Agent: [Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36]\n2022/02/17 12:53:48     X-Request-Id: [ee2797b5-1ee9-408e-b1ff-d5e5431977e6]\n2022/02/17 12:53:48     Cache-Control: [max-age=0]\n2022/02/17 12:53:48     X-Forwarded-Proto: [http]\n2022/02/17 12:53:48     Traceparent: [00-5f2c4775e0e36efc1d554a0b6c456cc1-af6c239eb7b39349-01]\n2022/02/17 12:53:48     Accept-Encoding: [gzip, deflate]\n2022/02/17 12:53:48     Forwarded: [for=10.244.0.12;proto=http]\n2022/02/17 12:53:48 Response headers:\n2022/02/17 12:53:48     Traceparent: [00-5f2c4775e0e36efc1d554a0b6c456cc1-1cf3f827eba96bf2-01]\n2022/02/17 12:53:48\n</code></pre> <p>Now let's take a look at logging from the second service which exposes API to consume Knative events. The event API in this case is just an HTTP endpoint which is a cloud event implementation detail:</p> <pre><code>2022/02/17 13:39:36 Event received: Context Attributes,\n  specversion: 1.0\n  type: httpbody\n  source: github/com/pavolloffay\n  id: fad4139c-b3fb-48b2-b0f4-fee44addc5f1\n  time: 2022-02-17T13:39:34.426355726Z\n  datacontenttype: text/plain\nExtensions,\n  knativearrivaltime: 2022-02-17T13:39:34.491325425Z\nData,\n  hello from first, traceid=5f2c4775e0e36efc1d554a0b6c456cc1\n</code></pre> <p>We see that the trace context is not directly present in the event object. However, it is encoded in the incoming transport message - HTTP headers.</p>"},{"location":"blog/2022/knative/#future-improvements","title":"Future improvements","text":"<p>In the previous section, it was mentioned that the Knative serving and eventing components are instrumented with OpenCensus SDK. The instrumentation will change in the future to OpenTelemetry which is tracked in knative/eventing/#3126 and knative/pkg#855. The SDK change might not have an immediate impact on the user, however, it will enable users to start natively reporting data in OpenTelemetry format (OTLP).</p> <p>Another recently merged change is the addition of Cloudevents semantic attributes into the OpenTelemetry specification. The document standardizes attributes related to CloudEvents. The screenshot below is from the demo application that is still not using the standardized attribute names:</p> <p></p>"},{"location":"blog/2022/knative/#configuration","title":"Configuration","text":"<p>Tracing in Knative can be easily enabled. Please follow the official documentation for a step-by-step guide. Let's briefly describe the process here:</p> <ol> <li>Deploy a tracing system that can ingest tracing data in Zipkin format -    Zipkin, Jaeger, or OpenTelemetry collector</li> <li>Enable tracing in    Knative eventing</li> <li>Enable tracing in    Knative serving</li> </ol> <p>In the beginning, I recommended using 100% sampling rate configuration to capture trace data for all traffic in the cluster. This will help to avoid any issues with sampling, do not forget to change this configuration once moving to the production environment.</p>"},{"location":"blog/2022/knative/#conclusion","title":"Conclusion","text":"<p>We have learned what distributed tracing capabilities Knative project provides out-of-the-box and which parts need more work from the user. Generally speaking Knative emits rich tracing data, however, as always the user is responsible to instrument the workload and make sure trace-context is propagated from inbound to outbound requests or events. This is exactly the same situation as implementing distributed tracing in service meshes.</p> <p>OpenTelemetry can help to instrument the user workload and correctly propagate the trace-context. Depending on the language, the user can initialize instrumentation libraries explicitly in the code or even dynamically inject OpenTelemetry auto-instrumentation into the workload.</p>"},{"location":"blog/2022/knative/#references","title":"References","text":"<ul> <li>Knative docs</li> <li>Knative serving tracing config</li> <li>Knative eventing tracing config</li> <li>Cloud events</li> <li>Zipkin B3</li> <li>W3C Trace-Context</li> <li>OpenTelemetry instrumentation for Cloudevents Golang SDK</li> <li>Cloudevents OpenTelemetry attributes</li> <li>Knative tracing demo</li> </ul>"},{"location":"blog/2022/opamp/","title":"Using OpenTelemetry OpAMP to modify service telemetry on the go","text":"<p>How verbose should your service telemetry be? Should a service output all traces, metrics, and logs 100% of the time? How much of the service traffic should be sampled? I would like to suggest the answer of \u201cit depends\u201d. Desired telemetry data differs in a service lifecycle from development to continuous deployment. It changes when clients face an error or a service has been thrown into a major scale.</p> <p>It is possible to change a service telemetry configuration or sampling rate. Usually, it requires only a minimal code change and a deployment process. It might not seem a lot, but whenever facing a change like this across an entire system, we tend to avoid it. Instead, it is common to collect as much data as possible, which causes an issue by itself. Can we dynamically modify service telemetry without those barriers? Thanks to OpAMP protocol and the people behind it, I believe that the answer is about to change.</p> <p>OpAMP stands for Open Agent Management Protocol. It aims at managing large fleets of data collection agents, and its GoLang implementation is at the Beta stage. It allows configuration changes as well as package downloads. It defines the communication between the OpAMP server and OpAMP client but does not assume any particular client-agent relationship giving it a lot of flexibility.</p> <p>In the following example, we\u2019ll create a simple GoLang server, instrument it, and then control it with an OpAMP server and supervisor. We won\u2019t dive into OpAMP implementation itself, but rather focus on its implications using these examples.</p> <p>First, consider this basic go server:</p> <pre><code>package main\nimport (\n\"fmt\"\n\"log\"\n\"net/http\"\n)\nfunc httpHandler(w http.ResponseWriter, r *http.Request) {\nfmt.Fprintf(w, \"Hi! This action could create a trace!\")\n}\nfunc main() {\nhandler := http.HandlerFunc(httpHandler)\nhttp.Handle(\"/\", handler)\nfmt.Println(\"Starting server on port 8080\")\nlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n</code></pre> <p>Next, add a basic configuration file named <code>effective.yaml</code>. Place it in the same folder as our main.go file with this configuration:</p> <pre><code>instrument: false\n</code></pre> <p>Let\u2019s add a basic configuration handler to our server:</p> <pre><code>package main\nimport (\n\"fmt\"\n\"gopkg.in/yaml.v3\"\n\"io/ioutil\"\n\"log\"\n\"net/http\"\n\"path/filepath\"\n)\ntype configurations struct {\nInstrument bool\n}\nfunc httpHandler(w http.ResponseWriter, r *http.Request) {\nfmt.Fprintf(w, \"Hi! This action could create a trace!\")\n}\nfunc main() {\nfilename, _ := filepath.Abs(\"./effective.yaml\")\nyamlFile, _ := ioutil.ReadFile(filename)\nvar config configurations\nyaml.Unmarshal(yamlFile, &amp;config)\nhandler := http.HandlerFunc(httpHandler)\nhttp.Handle(\"/\", handler)\nfmt.Println(\"Starting server on port 8080\")\nlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n</code></pre> <p>Next, let's wrap our handler with instrumentation and condition it with our configuration file. Something like this:</p> <pre><code>package main\nimport (\n\"context\"\n\"fmt\"\n\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n\"go.opentelemetry.io/otel\"\n\"go.opentelemetry.io/otel/exporters/stdout/stdouttrace\"\nsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n\"go.opentelemetry.io/otel/trace\"\n\"gopkg.in/yaml.v3\"\n\"io/ioutil\"\n\"log\"\n\"net/http\"\n\"os\"\n\"path/filepath\"\n)\ntype configurations struct {\nInstrument bool\n}\nvar tracer trace.Tracer\nfunc newConsoleExporter() (sdktrace.SpanExporter, error) {\nreturn stdouttrace.New(\nstdouttrace.WithWriter(os.Stdout),\nstdouttrace.WithPrettyPrint(),\n)\n}\nfunc httpHandler(w http.ResponseWriter, r *http.Request) {\nfmt.Fprintf(w, \"Hi! This action could create a trace!\")\n}\nfunc setHandler(handler http.Handler, config configurations) http.Handler {\nif config.Instrument {\nreturn otelhttp.NewHandler(handler, \"instrumentation activated by OpAMP\")\n}\nreturn http.HandlerFunc(httpHandler)\n}\nfunc main() {\nfilename, _ := filepath.Abs(\"./effective.yaml\")\nyamlFile, _ := ioutil.ReadFile(filename)\nvar config configurations\nyaml.Unmarshal(yamlFile, &amp;config)\nexp, _ := newConsoleExporter()\ntp := sdktrace.NewTracerProvider(sdktrace.WithBatcher(exp))\ndefer func() { _ = tp.Shutdown(context.Background()) }()\notel.SetTracerProvider(tp)\ntracer = tp.Tracer(\"ControlledOpAMPAgentDemo\")\nhandler := http.HandlerFunc(httpHandler)\nhttp.Handle(\"/\", setHandler(handler, config))\nfmt.Println(\"Starting server on port 8080\")\nlog.Fatal(http.ListenAndServe(\":8080\", nil))\n}\n</code></pre> <p>Build and run this app:</p> <pre><code>go build .\ngo run .\n</code></pre> <p>Open a browser and visit http://localhost:8080. Nothing special will be shown. It\u2019s time to add some opamp. Git clone opamp-go and run the server with:</p> <pre><code>cd internal/examples/server\ngo run .\n</code></pre> <p>Visit http://localhost:4321 to verify that the server is running. Notice that no agent is displayed:</p> <p></p> <p>Next, edit internal/examples/supervisor/bin/supervisor.yaml to point at our agent. It should look like this:</p> <pre><code>server:\nendpoint: ws://127.0.0.1:4320/v1/opamp\nagent:\nexecutable: &lt;absolute|relative path to previous build&gt;\n</code></pre> <p>Then open a new terminal and run the following command:</p> <pre><code>cd internal/examples/supervisor/bin\ngo build -o ./supervisor ../main.go\n./supervisor\n</code></pre> <p>We have now a system consisting of OpAMP server supervisor and our server</p> <p></p> <p>Via the supervisor we can now see our agent running at http://localhost:4321. Select it and pass <code>instrument: true</code> to its configurations.</p> <p></p> <p>You can see the changes over the supervisor console log:</p> <pre><code>Received remote config from server, hash=0008886301f3ccb3520216823cfa09a.\nEffective config changed.\nConfig is changed. Signal to restart the agent.\nRestarting the agent with the new config.\nStopping agent process, PID=19206\nAgent process PID=19206 successfully stopped.\nStarting agent &lt;agent path&gt;\nAgent process started, PID=19506\n</code></pre> <p>Finally, visit http://localhost:8080. Traces should now appear in <code>internal/examples/supervisor/bin/agent.log</code>.</p> <pre><code>Starting server on port 8080\n{\n   \"Name\": \"instrumentation activated by OpAMP server\",\n   \"SpanContext\": {\n      \"TraceID\": \"d2f76958023624d4c1def3f44899b6d4\",\n      \"SpanID\": \"085510f551dc31a1\",\n      \"TraceFlags\": \"01\",\n      \"TraceState\": \"\",\n      \"Remote\":false\n   ...\n</code></pre> <p>These lines are the trace itself!</p> <p>To sum up, we have here a server that controls whether our service will generate traces. Try setting it off using the <code>instrument: false</code> configuration.</p> <p>This is a very basic implementation. Wrapping a system above OpAMP could perform as an instrumentation orchestrator. The starting point is being able to externally add and match tailor-made dynamic telemetry for your system. Imagine what AI can achieve on this type of system. It could collect metrics over the entire system, automatically and dynamically adding trace/log collections onto any detected bottlenecks. Using this protocol enables many new possibilities, I believe it has the potential to change how we think about telemetry.</p>"},{"location":"blog/2022/otel-demo-app-nomad/","title":"Running the OpenTelemetry Demo App on HashiCorp Nomad","text":"<p>Y\u2019all\u2026 I\u2019m so excited, because I finally got to work on an item on my tech bucket list. Last week, I began the process of translating OpenTelemetry Demo App\u2019s Helm Charts to HashiCorp Nomad job specs. Today I\u2019ll be talking about how to run the OpenTelemetry Demo App on Nomad, using my favorite Hashi-in-a-box tool, HashiQube.</p> <p>Let\u2019s do this!</p> <p></p>"},{"location":"blog/2022/otel-demo-app-nomad/#deployment","title":"Deployment","text":""},{"location":"blog/2022/otel-demo-app-nomad/#assumptions","title":"Assumptions","text":"<p>Before we move on, I am assuming that you have a basic understanding of:</p> <ul> <li>Nomad. If not, head on over to my   Nomad intro post.   This blog post by   Daniela Baron is also great.</li> <li>Observability   (o11y) and OpenTelemetry (OTel). If not,   see Observability primer.</li> </ul>"},{"location":"blog/2022/otel-demo-app-nomad/#pre-requisites","title":"Pre-Requisites","text":"<p>In order to run the example in this tutorial, you\u2019ll need the following:</p> <ul> <li>Docker (version 20.10.21 at the time of this writing)</li> <li>Vagrant (version 2.3.1 at the time of this writing)</li> </ul>"},{"location":"blog/2022/otel-demo-app-nomad/#tutorial-repos","title":"Tutorial Repos","text":"<p>Below are the repos that we\u2019ll be using for today\u2019s tutorial:</p> <ul> <li>My modified HashiQube Repo (fork of   servian/hashiqube). If you\u2019re curious,   you can see what modifications I\u2019ve made   here.</li> <li>My Nomad Conversions repo</li> </ul>"},{"location":"blog/2022/otel-demo-app-nomad/#hashiqube-setup","title":"HashiQube Setup","text":"<p>Before you start, just a friendly reminder that HashiQube by default runs Nomad, Vault, and Consul on Docker. In addition, we\u2019ll be deploying 21 job specs to Nomad. This means that we\u2019ll need a decent amount of CPU and RAM, so please make sure that you have enough resources allocated in your Docker desktop. For reference, I\u2019m running an M1 Macbook Pro with 8 cores and 32 GB RAM. My Docker Desktop Resource settings are as follows:</p> <ul> <li>CPUs: 3</li> <li>Memory: 9.5GB</li> <li>Swap: 3GB</li> </ul> <p>Here\u2019s a screenshot of my Docker Preferences Resources settings, if you need a visual:</p> <p></p> <p>For more, check out the Docker docs on how to change your resources settings for Mac, Windows, and Linux.</p>"},{"location":"blog/2022/otel-demo-app-nomad/#1-update-etchosts","title":"1- Update /etc/hosts","text":"<p>We use the Traefik load-balancer to expose our services, which we access as subdomains of localhost. In order ensure that we can access our Traefik-exposed services (and also the Traefik dashboard itself, you\u2019ll need to add the following entries to <code>/etc/hosts</code> on your host machine:</p> <pre><code>127.0.0.1   traefik.localhost\n127.0.0.1   otel-demo.localhost\n</code></pre>"},{"location":"blog/2022/otel-demo-app-nomad/#2-provision-a-local-hashi-environment-with-hashiqube","title":"2- Provision a Local Hashi Environment with HashiQube","text":"<p>Start HashiQube by following the detailed instructions here.</p> <p>NOTE: Be sure to check out the Gotchas section, if you get stuck.</p> <p>Once everything is up and running (this will take several minutes, by the way), you\u2019ll see this in the tail-end of the startup sequence, to indicate that you are good to go:</p> <p></p> <p>You can now access the apps using the URLs below:</p> <ul> <li>Vault: http://localhost:8200</li> <li>Nomad: http://localhost:4646</li> <li>Consul: http://localhost:8500</li> <li>Traefik: http://traefik.localhost</li> </ul> <p>Don\u2019t forget to download and install the Nomad CLI and the Vault CLI.</p> <p>If you need to SSH into HashiQube, open up a new terminal window on your host machine and run the following command:</p> <pre><code>vagrant ssh\n</code></pre>"},{"location":"blog/2022/otel-demo-app-nomad/#3-deploy-the-otel-demo-app","title":"3- Deploy the OTel Demo App","text":"<p>We\u2019re finally ready to deploy the OTel Demo App!</p> <p>First, let\u2019s clone the repo, and go to our working directory:</p> <pre><code>git clone https://github.com/avillela/nomad-conversions.git\ncd nomad-conversions\n</code></pre> <p>Next, let\u2019s enable Memory Oversubscription in Nomad. This is a one-time setting.</p> <pre><code>nomad operator scheduler set-config -memory-oversubscription true\n</code></pre> <p>Memory Oversubscription allows Nomad to use more memory than is allotted to the job. For example, consider this setting in the <code>resources</code> stanza:</p> <pre><code>resources {\ncpu    = 55\nmemory = 1024\nmemory_max = 2048\n}\n</code></pre> <p>We\u2019ve allocated 55Mz of processing power to our job (<code>cpu</code> setting), along with 1024MB RAM (<code>memory</code> setting). In this case, when Memory Oversubscription is enabled, and the job requires more memory than the allotted 1024MB, Nomad will allocate as much as 2048MB RAM to the job (<code>memory_max</code> setting). Note that if Memory Oversubscription is not enabled,Nomad will ignore the <code>memory_max</code> setting.</p> <p>Next, let\u2019s deploy the services:</p> <pre><code>nomad job run -detach otel-demo-app/jobspec/traefik.nomad\nnomad job run -detach otel-demo-app/jobspec/redis.nomad\nnomad job run -detach otel-demo-app/jobspec/ffspostgres.nomad\nnomad job run -detach otel-demo-app/jobspec/otel-collector.nomad\nnomad job run -detach otel-demo-app/jobspec/adservice.nomad\nnomad job run -detach otel-demo-app/jobspec/cartservice.nomad\nnomad job run -detach otel-demo-app/jobspec/currencyservice.nomad\nnomad job run -detach otel-demo-app/jobspec/emailservice.nomad\nnomad job run -detach otel-demo-app/jobspec/featureflagservice.nomad\nnomad job run -detach otel-demo-app/jobspec/paymentservice.nomad\nnomad job run -detach otel-demo-app/jobspec/productcatalogservice.nomad\nnomad job run -detach otel-demo-app/jobspec/quoteservice.nomad\nnomad job run -detach otel-demo-app/jobspec/shippingservice.nomad\nnomad job run -detach otel-demo-app/jobspec/checkoutservice.nomad\nnomad job run -detach otel-demo-app/jobspec/recommendationservice.nomad\nnomad job run -detach otel-demo-app/jobspec/frontend.nomad\nnomad job run -detach otel-demo-app/jobspec/loadgenerator.nomad\nnomad job run -detach otel-demo-app/jobspec/frontendproxy.nomad\nnomad job run -detach otel-demo-app/jobspec/grafana.nomad\nnomad job run -detach otel-demo-app/jobspec/jaeger.nomad\nnomad job run -detach otel-demo-app/jobspec/prometheus.nomad\n</code></pre> <p>Since we\u2019re running the jobs in detached mode, Nomad won\u2019t wait to start the next job until the current one has deployed successfully. This means that your output will look something like this:</p> <pre><code>Job registration successful\nEvaluation ID: d3eaa396-954e-241f-148d-6720c35f34bf\nJob registration successful\nEvaluation ID: 6bba875d-f415-36b7-bfeb-2ca4b9982acb\nJob registration successful\nEvaluation ID: 16dc8ef8-5e26-68f4-89b6-3d96b348775b\nJob registration successful\nEvaluation ID: 34de0532-a3b5-8691-bf18-51c0cc030573\nJob registration successful\nEvaluation ID: 7310e6a2-9945-710b-1505-c01bd58ccd35\n...\n</code></pre> <p>A reminder that the <code>Evaluation ID</code> values will be different on your machine.</p>"},{"location":"blog/2022/otel-demo-app-nomad/#4-see-it-in-nomad","title":"4- See it in Nomad!","text":"<p>As things are deploying, you can mozy on over to the Nomad UI at http://localhost:4646 to see how things are coming along:</p> <p></p> <p>It will take some time for all of the services to come up (sometimes up to 10 minutes), especially since Nomad needs to download the images and initialize the services, so be patient! Since some services depend on other services in order to run, you may see services in limbo or some going up and down for a while, per the above screen capture. DON\u2019T PANIC! IT WILL ALL BE OKAY!!</p> <p>Once all of the jobs are up and running, you\u2019ll see everything look green, like this:</p> <p></p> <p>You can also head on over to Consul at http://localhost:8500 to see the health of the services:</p> <p></p> <p>By default, unhealthy services show up at the top, with a red \u201cx\u201d next to them. Since we don\u2019t see any nasty red \u201cx\u201ds in the above screen shot, we know that our services are lookin\u2019 good!</p>"},{"location":"blog/2022/otel-demo-app-nomad/#5-access-the-otel-demo-app","title":"5- Access the OTel Demo App","text":"<p>The OTel Demo App uses Envoy to expose a number of front-end services: the Webstore, Jaeger, Grafana, Load Generator, and Feature Flag. These are all managed by the frontendproxy service. Traefik makes the frontendproxy service available via the <code>otel-demo.localhost</code> address.</p> <p>This is configured via the code snippet below, in the <code>service</code> stanza of frontendproxy.nomad:</p> <pre><code>tags = [        \"traefik.http.routers.frontendproxy.rule=Host(`otel-demo.localhost`)\",\n\"traefik.http.routers.frontendproxy.entrypoints=web\",\n\"traefik.http.routers.frontendproxy.tls=false\",\n\"traefik.enable=true\",\n]\n</code></pre> <p>Note that the <code>Host</code> is set to <code>otel-demo.localhost</code>.</p> <p>The services are accessed via the URLs below.</p> <p>Webstore: http://otel-demo.localhost/</p> <p></p> <p>Go ahead and explore the amazing selection of telescopes and accessories, and buy a few. \ud83d\ude09\ud83d\udd2d</p> <p>Jaeger UI: http://otel-demo.localhost/jaeger/ui/</p> <p></p> <p>In the screen capture above, we can see a sample Trace from the checkoutservice.</p> <p>Grafana: http://otel-demo.localhost/grafana/</p> <p></p> <p></p> <p>The Demo App comes bundled with a two Grafana dashboards, which showcase Metrics emitted with OpenTelemetry.</p> <p>Feature Flags UI: http://otel-demo.localhost/feature/</p> <p></p> <p>Load Generator UI: http://otel-demo.localhost/loadgen/</p> <p></p>"},{"location":"blog/2022/otel-demo-app-nomad/#gotchas","title":"Gotchas","text":"<p>While I think I\u2019ve managed to iron out a lot of the kinks as far as running the OTel Demo App in Nomad, I have run into a few hiccups when deploying the services.</p>"},{"location":"blog/2022/otel-demo-app-nomad/#services-sometimes-cant-connect-to-the-collector","title":"Services sometimes can\u2019t connect to the Collector","text":"<p>Although all of the services appear to start up properly, in some cases, some services appear to be unable to connect to the OTel Collector. I haven\u2019t quite figured out why this is happening, so for now, I just restart otel-collector.nomad. If things are looking a little weird in the Webapp UI (like missing products or currency), I also restart frontend.nomad. Usually a good indicator that services aren\u2019t sending telemetry to the Collector is to look at the number of services showing up in Jaeger. You should see 14 services, including the <code>jaeger-query</code> service.</p> <p></p>"},{"location":"blog/2022/otel-demo-app-nomad/#low-memory-on-host-machine","title":"Low memory on host machine","text":"<p>Yup\u2026as beefy as my machine is, I do also sometimes run low on memory on my host machine. It probably doesn\u2019t help that I have a zillion tabs open in Chrome and Safari. Plus, let\u2019s face it: HashiQube + 21 jobs in Nomad can be a bit memory intensive. I\u2019ve made a few tweaks to the memory settings in HashiQube and Docker to try to minimize memory issues, but in case the Memory Monster gets you, I suggest closing browsers and other apps, and re-opening them to free up some memory. And if this does happen to you, please let me know!</p>"},{"location":"blog/2022/otel-demo-app-nomad/#a-work-in-progress","title":"A Work in Progress","text":"<p>Please bear in mind that this project is a work in progress. If you have any suggestions for improvement, or would like to collaborate further on the Nomad jobspecs, please hit me up!</p>"},{"location":"blog/2022/otel-demo-app-nomad/#final-thoughts","title":"Final Thoughts","text":"<p>Well, there you have it, folks! You now have an example of how to deploy OpenTelemetry Demo App (a multi-micro-service app running OpenTelemetry) to HashiCorp Nomad. Main highlights:</p> <ul> <li>We used HashiQube to stand up a local   HashiCorp environment in Docker via Nomad so that we could run the OTel Demo   App in Nomad using Traefik as our load balancer.</li> <li>We saw the OTel Demo App in action, by accessing the following services   exposed through the   frontendproxy:   Webstore,   Grafana,   Jaeger,   Feature Flags UI,and the   Load Generator UI.</li> </ul> <p>Before I wrap this up, I do want to give a HUGE shoutout to Luiz Aoqui of HashiCorp, who helped me tweak my Nomad jobspecs, and to Riaan Nolan, for his continued work on HashiQube. (Aside, both Luiz and Riaan were my guests on the On-Call Me Maybe Podcast!)</p> <p>I will now leave you with a picture of Phoebe the rat, peering out of a pink basket. Doesn\u2019t she look cute? \ud83e\udd70</p> <p></p> <p>Peace, love, and code. \ud83e\udd84 \ud83c\udf08 \ud83d\udcab</p> <p>Have questions about the OTel Demo App on Nomad? Feel free to connect through Mastodon or LinkedIn.</p> <p>The OpenTelemetry community is always looking for contributions! Join us! If you're on Mastodon, be sure to follow OpenTelemetry on Mastodon</p>"},{"location":"blog/2022/tail-sampling/","title":"Tail Sampling with OpenTelemetry: Why it\u2019s useful, how to do it, and what to consider","text":"<p>Tail sampling is useful for identifying issues in your distributed system while saving on observability costs. In this post, you\u2019ll learn how to implement tail sampling using the OpenTelemetry collector. I will also share some general and OpenTelemetry-specific concerns to consider as you develop your sampling strategy.</p>"},{"location":"blog/2022/tail-sampling/#what-is-sampling-and-why-should-you-do-it","title":"What is sampling, and why should you do it?","text":"<p>With distributed tracing, you observe requests as they move from one service to another in a distributed system. It\u2019s superbly practical for a number of reasons, such as understanding your service connections and diagnosing latency issues, among many other benefits. If distributed tracing is a new topic for you, make sure to read this post on distributed tracing and sampling.</p> <p>However, if the majority of all your requests are successful 200s and finish without latency or errors, do you really need all that data? Here\u2019s the thing\u2014you don\u2019t always need a ton of data to find the right insights. You just need the right sampling of data.</p> <p></p> <p>The idea behind sampling is to control the spans you send to your observability backend, resulting in lower ingest costs. Different organizations will have their own reasons for not just why they want to sample, but also what they want to sample. You might want to customize your sampling strategy to:</p> <ul> <li>Manage costs: You risk incurring heavy charges from the relevant cloud   provider or vendor if you\u2019re exporting and storing all your spans.</li> <li>Focus on interesting traces: For example, your frontend team may only want   to see traces with specific user attributes.</li> <li>Filter out noise: For example, you may want to filter out health checks.</li> </ul>"},{"location":"blog/2022/tail-sampling/#what-is-tail-based-sampling","title":"What is tail-based sampling?","text":"<p>Tail-based sampling is where the decision to sample a trace happens after all the spans in a request have been completed. This is in contrast to head-based sampling, where the decision is made at the beginning of a request when the root span begins processing. Tail-based sampling gives you the option to filter your traces based on specific criteria, which isn\u2019t an option with head-based sampling.</p> <p></p> <p>Tail sampling lets you see only the traces that are of interest to you. You also lower data ingest and storage costs because you\u2019re only exporting a predetermined subset of your traces. For instance, as an app developer, I may only be interested in traces with errors or latency for debugging.</p>"},{"location":"blog/2022/tail-sampling/#how-to-implement-tail-sampling-in-the-opentelemetry-collector","title":"How to implement tail sampling in the OpenTelemetry collector","text":"<p>To use tail sampling in OpenTelemetry, you need to implement a component called the tail sampling processor. This component samples traces based on a set of policies that you can choose from and define. First, to ensure that you\u2019re capturing all spans, use either the default sampler or the AlwaysOn sampler in your SDKs.</p> <p>Now, let\u2019s walk through a sample configuration of the tail-sampling processor, aptly placed in the <code>processors</code> section of the collector configuration file:</p> <pre><code>processors:\ntail_sampling:\ndecision_wait: 10s\nnum_traces: 100\nexpected_new_traces_per_sec: 10\npolicies:\n[\n{\n          name: errors-policy,\n          type: status_code,\n          status_code: { status_codes: [ERROR] },\n},\n{\n          name: randomized-policy,\n          type: probabilistic,\n          probabilistic: { sampling_percentage: 25 },\n},\n]\n</code></pre> <ul> <li><code>tail_sampling</code> is the name of the processor you\u2019ll use to implement tail   sampling.</li> <li>The first three lines are optional configurable settings:</li> <li><code>decision_wait</code> is the time, in seconds, after the first span of a trace is     created before the sampling decision is made. The default is 30 seconds.</li> <li><code>num_traces</code> is the number of traces to be kept in memory. The default is     50,000.</li> <li><code>expected_new_traces_per_sec</code> is the expected number of new traces, which     helps in allocating data structures. The default is 0.</li> <li><code>policies</code> is where you define your sampling policies. There is no default,   and this is the only required section of the processor configuration. In this   case, two policies are defined:</li> <li><code>status_code</code>, which is named <code>errors-policy</code>, since this example will     filter traces with the status code <code>ERROR</code>.</li> <li><code>probabilistic</code>, which is named <code>randomized-policy</code>. In addition to     filtering all traces with errors, there will also be a randomized sampling     of 25% of traces without errors.</li> </ul> <p>The next image is an example of what you might see in your backend if you implement this sample configuration.</p> <p></p> <p>The blue dots and rectangle on the right side indicate that the sampling decision occurs at the end of a trace when all the spans for a given request have been completed. The green dots represent sampled spans while the gray dots represent unsampled spans. Finally, the red dots represent spans where errors were detected. With this configuration, you\u2019ll get all traces with errors as well as a random sampling of other traces based on the rate we\u2019ve configured.</p> <p>If you want to just sample based on a specific filter such as errors, you could remove the probabilistic policy. But having a random sampling of all other traces can help surface other issues and give you a broader view of your software\u2019s performance and behavior. Here\u2019s what you'll see with only the status code policy defined.</p> <p></p> <p>You also have the flexibility to add other policies. Here are a few examples:</p> <ul> <li><code>always_sample</code>: Sample all traces.</li> <li><code>latency</code>: Sample based on the duration of the trace. For example, you could   sample all traces that take longer than 5 seconds.</li> <li><code>string_attribute</code>: Sample based on string attribute values, both exact and   regex value matches are supported. For example, you could sample based on   specific custom attribute values.</li> </ul>"},{"location":"blog/2022/tail-sampling/#potential-issues-with-tail-sampling","title":"Potential issues with tail sampling","text":"<ul> <li>Potentially unpredictable costs: While sampling generally helps manage   data ingest and storage costs, you may occasionally have spikes in activity.   For example, if you\u2019re sampling traces with latency and you experience severe   network congestion, your tracing solution will export a high number of traces   with latency issues, leading to an unexpected spike in costs during this   period. However, this is also why tail sampling exists\u2014 so we can quickly see   these kinds of problems and act on them.</li> <li>Performance: If you are storing telemetry data locally, you will need to   store spans until sampling decisions are completed. This can consume resources   from your application if it\u2019s stored locally, or additional network bandwidth   if not.</li> <li>Figuring out the right policies: Also, while you don\u2019t necessarily need a   ton of data to get the right insights, you do need the right sampling, and   figuring that out can be challenging. You\u2019ll have to ask a lot of questions,   such as: what does the baseline for a healthy request look like? How many   resources are you able to set aside for tail sampling? Otherwise, you may   inadvertently filter out requests that could otherwise reveal issues in your   system, or consume more resources than you originally expected.</li> <li>Establishing a wait period for tail sampling: Another challenge with tail   sampling is that it\u2019s hard to predict when a trace will actually be finished.   Since a trace is essentially a graph of spans where the child spans reference   their parents, a new span could be added at any given time. To resolve this,   you can establish an acceptable period of time to wait before making a   sampling decision. The assumption here is that a trace should be complete   within the configured period, but it means that you risk potentially losing   interesting spans that complete outside that time window, which can result in   fragmented traces. Fragmented traces occur when spans are missing and can   create gaps in visibility.</li> </ul>"},{"location":"blog/2022/tail-sampling/#limitations-of-opentelemetry","title":"Limitations of OpenTelemetry","text":"<p>There are also some limitations to consider that are related to OpenTelemetry. Note that some of these limitations also apply more broadly to any client-hosted tail-based sampling solution, not just OpenTelemetry.</p> <p>First, you have to stand up a collector. While the collector can ultimately be quite practical in terms of centralizing configuration and processing data, it\u2019s one more piece in your system to implement and maintain. Furthermore, for tail sampling to work, all the spans of a particular trace have to be processed in the same collector, which leads to scalability challenges.</p> <p>For a simple setup, one collector will suffice, and no load balancing is needed. However, the more requests that are being held in memory, the more memory you\u2019ll need, and you\u2019ll also need additional processing and computing power to look at each span attribute. As your system grows, you can\u2019t do all this with just a single collector, which means you have to think about your collector deployment pattern and load balancing.</p> <p>Since one collector is insufficient, you have to implement a two-layer setup in which the collector is deployed in an agent-collector configuration. You also need each collector to have a full view of the traces it receives. This means that all spans with the same trace ID need to go to the same collector instance, or you\u2019ll end up with fragmented traces. You can use a load-balancing exporter if you're running multiple instances of the agent/collector with the tail sampling processor. This exporter ensures that all spans with the same trace ID end up in the same agent/collector. But there may be additional overhead with implementing this exporter, such as configuring it.</p> <p>Another limitation to consider is that since OpenTelemetry does not propagate metadata that would let a backend re-weight counts \u2013 for example, P95, P99, and total events \u2013 you\u2019re only getting a look at the measurements of sampled data, not accurate measurements in regards to all data. Let\u2019s say you\u2019ve configured your sampler to keep 25% of all traces. If the backend doesn\u2019t know it\u2019s only operating on 25% of all data, any measurement it produces will be inaccurate. One way to get around this is to attach metadata to your spans that tells the backend what the sample rate is, that will allow the backend to then accurately measure things such as total span count for a given period of time. The Sampling SIG is currently working on this concept.</p> <p>Finally, as OpenTelemetry is still an evolving project, many components are under active development, including the tail sampling processor and the collector. For the tail sampling processor, there is currently an open issue in the collector-contrib repo to discuss the future of this processor that centers around replacing it with separate processors, so that the chain of events is well-defined and understood. One of the main issues the community is trying to figure out is whether using separate processors to do tail sampling will be more performant than just the tail sampling processor. It's important to note that nothing will be released without a backward-compatible solution. For the collector, there are limited options to monitor the collector, which is critical for troubleshooting. See here for more information.</p> <p>A version of this article was [originally posted][] on the New Relic blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/","title":"Why and How eBay Pivoted to OpenTelemetry","text":"<p>eBay makes a crucial pivot to OpenTelemetry to better align with industry standards for Observability.</p> <p></p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#introduction","title":"Introduction","text":"<p>Observability provides the eyes and ears to any organization. A major benefit to observability is in preventing the loss of revenue by efficiently surfacing ongoing issues in critical workflows that could potentially impact customer experience. The Observability landscape is an ever-changing one and recent developments in the OpenTelemetry world forced us to rethink our strategy in order to pivot to using it. eBay\u2019s observability platform Sherlock.io provides developers and Site Reliability Engineers (SREs) with a robust set of cloud-native offerings to observe the various applications that power the eBay ecosystem. Sherlock.io supports the three pillars of observability \u2014 metrics, logs and traces. The platform\u2019s metric store is a clustered and sharded implementation of the Prometheus storage engine. We use the Metricbeat agent to scrape around 1.5 million Prometheus endpoints every minute, which are ingested into the metric stores. These endpoints along with recording rules result in ingesting around 40 million samples per second. The ingested samples result in 3 billion active series being stored on Prometheus. As a result, eBay\u2019s observability platform operates at an uncommonly massive scale, which brings with it new challenges.</p> <p>As an observability platform provider, eBay was one of the first companies to use agents to scrape metric endpoints and tail log files. As we have discussed in previous blog posts, we have heavily relied on the Elastic Beats offering to accept signals into the platform. Beats is a lightweight shipper of operational data like metrics and logs. For five years, from 2016 to 2020, we ran both Filebeat and Metricbeat as DaemonSets on all our Kubernetes clusters. DaemonSets allow users to deploy a given workload on every node on a Kubernetes cluster. However, an experiment performed during an internal hack week provided some surprising conclusions and led to us reconsidering our usage of DaemonSets. In this blog post, we discuss some of the problems we ran into, especially for metrics scraping, and how we evolved our own solution. We will also discuss in detail about how we have been navigating the evolving open source landscape with regards to licensing and how we intend to align with OpenTelemetry as an initiative.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#metrics-instrumentation","title":"Metrics Instrumentation","text":"<p>Metrics instrumentation at eBay has more or less been standardized on Prometheus endpoints. Endpoints from various applications are exposed as a result of a variety of instrumentation practices such as (but not limited to):</p> <ul> <li>Official Prometheus clients (including Java, Go, Python and others)</li> <li>Micrometer</li> <li>OTel SDK with Prometheus exporter</li> <li>Custom code that emits a Prometheus endpoint when requested</li> </ul> <p>Frameworks offered by eBay\u2019s platform engineering group bake in an instrumentation client and also expose various metric endpoints that represent server-side, client-side and DB client metrics. Depending on the nature of the application, Prometheus endpoints can be exposed, which require scraping. The application owner can also expose an endpoint of their own to instrument their business KPIs.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#autodiscover","title":"Autodiscover","text":"<p>Most of the applications that power the eBay ecosystem run on Tess, eBay\u2019s internal Kubernetes provider. eBay runs hundreds of Tess-powered Kubernetes clusters, and an application can run on any number and combination of those clusters. Application owners can choose to onboard their application metrics along with the metrics that are freely available from the framework-level instrumentation. Our agents need to know exactly which endpoints are being exposed by the currently running Kubernetes Pod. In order to provide the agent this information, we helped enrich the Beats platform to perform a task called \u201chints based autodiscover.\u201d Autodiscover is a Beats construct that allows a dynamic source like the Kubernetes API server to deliver to the agent information such as:</p> <ul> <li>What is the endpoint that needs scraping?</li> <li>What kind of endpoint \u2014 Dropwizard, Prometheus, Foobar, something else \u2014 is   it?</li> <li>How often should it be scraped?</li> <li>Is there any other additional information that the agent should be aware of,   like an SSL certificate?</li> </ul> <p>With more and more complex discovery patterns required, we worked with the Beats open source community to enhance the power of autodiscover for our specific needs. Some of the features we contributed include:</p> <ul> <li>Discovering multiple sets of configurations:   Conventional annotation-based scraping is very limiting in that it only allows   the user to provide simple configurations for the scrape manager to target.   Given that each endpoint can have dynamic needs like varied processing and   scrape intervals, we enhanced autodiscover to accept more than one set of   configurations.</li> <li>Discovering targets from namespace annotations:   The prescribed method to announce scrape targets calls for adding annotations   to the Pod spec. However, adding them there would mean that a change would   incur a Pod restart. This is undesirable if the change is intended for a   metric that is being instrumented on the framework and is available on every   deployed application. To avoid restarting all Pods, we added support for   autodiscover to additionally look at namespace-level annotations.</li> </ul> <p>These features make Beats Autodiscover one of the more versatile and feature-rich discovery mechanisms for identifying targets deployed on Kubernetes clusters.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#limitations-of-metrics-scraping-via-daemonsets","title":"Limitations of Metrics Scraping via DaemonSets","text":"<p>Our first attempt to run Metricbeat at scale involved running it as DaemonSets on each and every Kubernetes cluster. Each Pod was given one CPU and 1GB of memory to handle all metrics exposed on that node. When Metricbeat starts up, it requests the API server for all the namespaces on that cluster along with Pods deployed on the node it runs on. With this information, for each Pod, it creates configurations by collating annotations on the Pod and the Pod\u2019s namespace. Some of the observations we observed as a result include:</p> <ul> <li>Resource fragmentation: Given that we run N beats per N node cluster, if a   single Beat pipeline takes up 50MB of bootstrapping cost, we essentially waste   50*N MB of resources. That adds up to 150GB on a 3000 node Kubernetes   cluster!</li> <li>OOM issues when large endpoints are polled: We have seen customers expose   endpoints as large as 150,000 entries per endpoint. Some gigantic endpoints   like \"kube-state-metrics\" reach three million entries, and generate 600MB of   data with each poll. Scraping becomes unreliable when such use cases land on a   node.</li> </ul> <p>The following diagram represents how any Beats instance, like Metricbeat, Filebeat and Auditbeat, would interface with the Sherlock.io platform when deployed as a DaemonSet:</p> <p></p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#moving-to-cluster-local-scrapes","title":"Moving To Cluster Local Scrapes","text":"<p>During work on an unrelated project, we took the shortcut of running Metricbeat as a single instance for all targets across the cluster. When we observed the total CPU plus memory usage for running Metricbeat, the numbers were simply stunning. We saw the following during the deployment:</p> <ul> <li>Number of Kubernetes nodes: 2851</li> <li>CPU usage: 29 cores</li> <li>Memory usage: 57GB</li> <li>Ingest rate: 238K samples per second</li> <li>Endpoints monitored per node: 4</li> <li>Average memory usage per node monitored: 20MB</li> <li>Average CPU usage per node monitored: 0.01 cores</li> </ul> <p>A single metricbeat instance monitoring a similar amount of endpoints on a node in DaemonSet mode was consuming about 200MB (10x) and approximately 0.6 cores (60x). Across the cluster, that would accumulate to 570GB and around 1700 CPUs. The overall savings by moving to a cluster local instance was roughly 90%.</p> <p>This forced us to rethink the approach of handling scrapes. Running a single instance for an entire cluster would mean that when the instance goes through an upgrade or failure, 100% of scrapes would be down at that point in time. In order to mitigate failures, we deployed Metricbeat as a statefulset with N replicas. The entire list of pods are sharded N-ways based on the number of Metricbeat instances, and each instance monitors its assigned shard:</p> <p><code>xxHash(pod uid) % statefulset_size == instance number</code></p> <p>Each instance makes a full scan against the API server, but ignores everything except what it alone is supposed to monitor. This model works well for Metricbeat, as it primarily scrapes Prometheus endpoints, and this activity can happen outside of the Tess node. A large 3000 node Kubernetes cluster has as many as 30 instances with higher number of CPUs and memory allowing it to scrape substantially larger endpoints than it would as a daemon on the node. If one Metricbeat instance goes through a restart, scraping blips only for endpoints that are monitored by that instance alone, the failure percentage is reduced to 1/Nth of the total number of instances.</p> <p>The new deployment pattern can be visualized as follows:</p> <p></p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#decoupling-autodiscover","title":"Decoupling Autodiscover","text":"<p>While moving to cluster local scrapes got us to scale much higher than when using DaemonSets, the model had room for improvement. A new set of problems arose, especially on larger clusters, with higher Pod density. Given that every Metricbeat instance has to scan all Pods and pick the ones that it needs to monitor, depending on how many Pods are present in a given cluster, it can take a very long time to do the initial scan. This became extremely problematic during roll-outs when a new Metricbeat Pod would take as long as 10 minutes to restart scrapes once it came back up. Depending on the number of instances, this technique also puts undue strain on the API server due to the number of WATCHes placed against it for the various resources Metricbeat requests.</p> <p>After further evaluation, we decided to move Autodiscover out of the agent and into its own control loop. The control loop would:</p> <ul> <li>Implement a similar parser to the Beats autodiscover logic;</li> <li>Discover all the agents that can do the work of scraping;</li> <li>Pick one of these agents;</li> <li>And pass a configuration to the selected agent to monitor the target.</li> </ul> <p>The control loop would make important decisions like shuffling workloads around in the event of agent crashes, agent over-allocation and other failure scenarios. Given that the logic to parse annotations has been decoupled from the agent, it is very simple to generate configurations for any agent as long as there exists a mapping between a feature that Beats exposes versus the new agent.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#advent-of-opentelemetry","title":"Advent of OpenTelemetry","text":"<p>In 2019, the Open Tracing and Open Census communities agreed to join forces and bring about OpenTelemetry. The OpenTelemetry initiative set out with a goal to provide vendor agnostic APIs, SDKs and tools for ingesting, transforming and sending data to any Observability backend. Investing in such an initiative seemed a natural fit to how we consume Open Source at eBay, given our choice of Kubernetes, which also provides vendor-agnostic APIs to manage containers on the cloud. In 2021, we started experimenting with distributed tracing to figure out how it might be useful for our developers.</p> <p>At the time, looking at the OpenTelemetry Collector codebase, we saw significant potential in some of its features, including defined types for metrics, logs and traces, and usage of the Prometheus scrape manager to collect metrics from OpenMetrics endpoints. We chose OpenTelemetry Collector, along with the OpenTelemetry SDK, for our adoption of distributed tracing. It only made sense that we should subsequently figure out how we would move metrics and logs collection into the OpenTelemetry Collector. This wouldn\u2019t be an easy effort, given that we need to plug all feature gaps, build relationships with a new open source community and swap a massive metrics collection infrastructure without downtime. In the beginning of 2022, we began the difficult undertaking of moving metrics scraping into OpenTelemetry Collector.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#the-migration","title":"The Migration","text":"<p>Given that we decoupled our discovery logic from the agent, actual migration only meant that we needed to generate configurations that the OpenTelemetry Collector could understand. These configurations had to be pushed every time a new Pod is spun up and cleaned up when that Pod dies. However, the OpenTelemetry Collector has a crucial gap: it can\u2019t dynamically reload configurations. The OpenTelemetry Collectors have the notion of \u201cpipelines\u201d that define how a metric needs to be received, processed and exported. To facilitate dynamic reloading of pipelines, we came up with a \u201cfilereloadreceiver\u201d that can look at a directory consisting of files describing \u201cpartial pipelines\u201d that plug into the overall pipeline of the collector. Each Pod that requires metrics scraping has a partial pipeline that the autodiscover controller generates and pushes into the collector. Yet another complex exercise during this process was the creation of a mapping table between every feature that we depended on in the Beats platform and the OpenTelemetry Collector. For example, fields in Beats would translate to using the attribute processor on OpenTelemetry. With such mappings and the filereloadreceiver in place, we were able to generate new configurations for the OpenTelemetry Collector as follows.</p> <p></p> <p>As shown above, we were able to keep the end user contract of Pod/Namespace annotations the same and simply swap the agent under the hood. This greatly simplified the actual task of rolling out the new agent. The final obstacle involved mismatches in semantics between Elastic Beats, OpenTelemetry and sometimes even the Prometheus scrape manager. This is where we spent months before we could finally replace all of Metricbeat in production. Some of the discrepancies we saw and helped patch up on the OpenTelemetry Collector project include:</p> <ul> <li>Align sanitizing labels and metric names that start with \u201c_\u201d with Prometheus</li> <li>Ability to disable label sanitization</li> <li>Correctly handle metric names starting with \u201c:\u201d</li> <li>Ability to extract pod labels using regular expressions</li> </ul> <p>These issues proved difficult to catch, and sometimes only surfaced when we attempted to upgrade a Kubernetes cluster to use OpenTelemetry Collector. Once we hit such an issue, rollback was the only option and we were forced to go back to the drawing board. One partial solution involved writing a comparison script that can scrape an endpoint using Metricbeat and OpenTelemetry Collector, simultaneously ingest them to the metric store and compare the metric name and labels to ensure that the scrapes are on par with each other. This greatly improved our confidence in moving forward.</p> <p>Sometimes moving forward simply means dropping support for certain features. We did just that with support for Dropwizard metrics and had users migrate away from the same. Outside of semantic differences, we are also actively working on adding features that we feel are critical for the project, like supporting Exemplars.</p> <p>After months of hard work and support from the community, we are happy to announce that we have fully decommissioned Metricbeat and replaced it with OpenTelemetry Collector. We are busy working on doing the same for Filebeat at this point and early performance benchmarks are very promising. We have so far made 10+ contributions to the project, but it is just the start to a very fruitful collaboration.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#conclusion","title":"Conclusion","text":"<p>Over the past five years, we at eBay have encountered several spikes in demand that forced us to rethink conventional wisdom. We started off with DaemonSets, and saw that it was cost-prohibitive and unreliable at scale. We moved to a cluster local model which cut the cost of agents by about 90 percent, but we had redundancies in the amount of work being done on the API server and the agents themselves. We decoupled the discovery, moved it into a control loop that performs scheduling and made the agents into stateless processes that can accept scrape targets. Given the growing maturity of OpenTelemetry we pivoted to using OpenTelemetry Collector for metrics and are actively working towards doing the same for logs. We will continue to learn from running agents at scale and keep pivoting as needed. We will continue to work with the OpenTelemetry community as it continues to pave the way for standardization within the Observability ecosystem. Now that we\u2019re using OpenTelemetry, we can provide our developers with an industry-approved open standard to send telemetry into Sherlock.io. As the community grows to offer support for newer features like profiling, we will adopt them into the platform to benefit our developer community.</p>"},{"location":"blog/2022/why-and-how-ebay-pivoted-to-opentelemetry/#credits","title":"Credits","text":"<p>A lot of these optimizations/directional changes would not be possible without the many thought leaders who have been involved in these activities:</p> <ul> <li>Premendra Singh</li> <li>Peter Deng</li> <li>Aishwarya Yandapalli</li> <li>Santanu Bhattacharya</li> <li>John Feldmeier</li> <li>Rami El-Charif</li> </ul> <p>We are extremely grateful to both the Elastic Beats community of the past and the present OpenTelemetry community for supporting and working with us as we strive to build world-class Observability offerings for our eBay developer community.</p> <p>Elastic community:</p> <ul> <li>Monica Sarbu</li> <li>Tudor Golubenco</li> <li>Nicolas Ruflin</li> <li>Steffen Siering</li> <li>Carlos P\u00e9rez-Aradros</li> <li>Andrew Kroh</li> <li>Christos Markou</li> <li>Jaime Soriano Pastor</li> </ul> <p>OpenTelemetry Collector community:</p> <ul> <li>Tigran Nigaryan</li> <li>Bogdan Drutu</li> <li>David Ashpole</li> <li>Anthony Mirabella</li> <li>Juraci Paix\u00e3o Kr\u00f6hling</li> <li>Albert Teoh</li> </ul> <p>A version of this article was [originally posted][] on the eBay Tech Blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2023/ecs-otel-semconv-convergence/","title":"Announcing the Elastic Common Schema (ECS) and OpenTelemetry Semantic Convention Convergence","text":"<p>Today, we're very excited to make a joint announcement with Elastic about the future of Elastic Common Schema (ECS) and the OpenTelemetry Semantic Conventions.</p> <p>The goal is to achieve convergence of ECS and OTel Semantic Conventions into a single open schema that is maintained by OpenTelemetry, so that OpenTelemetry Semantic Conventions truly is a successor of the Elastic Common Schema. OpenTelemetry shares the same interest of improving the convergence of observability and security in this space. We believe this schema merge brings huge value to the open source community because:</p> <ul> <li>ECS has years of proven success in the logs, metrics, traces and security   events schema, providing great coverage of the common problem domains.</li> <li>ECS provides schema for security domain fields, which is an important aspect   of telemetry.</li> <li>Converging two separate standards into one single standard will help to boost   the ecosystem (e.g. instrumentation libraries, tools and consumption   experiences), which benefits both the telemetry producers and consumers.</li> <li>This joint effort would benefit from domain experts across logging,   distributed tracing, metrics and security events. As a result, we expect to   have more consistent signals across different pillars of observability and   security events.</li> </ul> <p>Both Elastic and the OpenTelemetry community understand that converging two widely used standards into one singular common schema, and having a smooth transition is critical for users. A dedicated OpenTelemetry Semantic Convention working group will be created with domain experts from both Elastic and OpenTelemetry joining. We're also welcoming domain experts who are passionate about data schemas and semantic conventions to join us. If you're interested in contributing, join our OTel Semantic Conventions working group, and join the discussion on our Slack channel.</p>"},{"location":"blog/2023/ecs-otel-semconv-convergence/#references","title":"References","text":"<ul> <li>Announcement from Elastic</li> <li>OpenTelemetry Semantic Conventions</li> <li>OTEP 199: Merge Elastic Common Schema with OpenTelemetry Semantic   Conventions</li> <li>OTEP Issue 197: Proposal: Add support for Elastic Common Schema (ECS) in   OpenTelemetry</li> <li>OTEP Pull Request 199: Support Elastic Common Schema in OpenTelemetry</li> <li>OTEP Pull Request 222: Support Elastic Common Schema (ECS) in   OpenTelemetry</li> </ul>"},{"location":"blog/2023/end-user-discussions-01/","title":"OpenTelemetry End-User Discussions Summary for January 2023","text":"<p>With contributions from Henrik Rexed (Dynatrace), Michael Hausenblas (AWS), Pranay Prateek (Signoz), Rynn Mancuso (Honeycomb), and Reese Lee (New Relic).</p> <p>Each month, users in the OpenTelemetry (OTel) community gather to talk about how they use OpenTelemetry in real life. Sessions are held for users in the Americas (AMER), Europe Middle-East &amp; Africa (EMEA), and Asia-Pacific (APAC). The discussions take place using a Lean Coffee format, whereby folks are invited to post their topics to the Agile Coffee board like this one, and everyone in attendance votes on what they want to talk about.</p> <p>This is a great way to meet other users in the OpenTelemetry community, and to learn about and share practical experience on how OpenTelemetry is being used in the wild. Each meeting is attended by an OTel Governance Committee member and/or maintainer to help answer questions, listen to user feedback, and provide additional context and insight into the topics discussed.</p> <p>This is the first in a series of blog posts summarizing our monthly OTel End User Discussions, starting with our January 2023 sessions.</p>"},{"location":"blog/2023/end-user-discussions-01/#what-we-talked-about","title":"What we talked about","text":"<p>We saw a few common themes this month across our three sessions:</p> <ul> <li>OpenTelemetry adoption &amp; enablement</li> <li>Connectors   (Collector)</li> <li>Service Graph Processor   (Collector)</li> <li>Signal correlation (e.g., metrics/traces correlation, logs/traces correlation)</li> </ul> <p>We\u2019ll dig into these and more!</p>"},{"location":"blog/2023/end-user-discussions-01/#discussion-highlights","title":"Discussion highlights","text":"<p>Below is a summary of this month\u2019s discussions.</p>"},{"location":"blog/2023/end-user-discussions-01/#opentelemetry-collector","title":"OpenTelemetry Collector","text":""},{"location":"blog/2023/end-user-discussions-01/#1-opentelemetry-transformation-language-ottl","title":"1- OpenTelemetry Transformation Language (OTTL)","text":"<p>Q: Will exporters support OTTL (a language for transforming OpenTelemetry data)? Use case: data needs to be transformed, but don\u2019t want to do it in a processor.</p> <p>A: Due to separation of concerns, it is unlikely that OTTL will be added to exporters; however, this may be a use case for either connectors (a new Collector component that acts as an exporter/receiver pair to join pipelines together) or the routing processor. A routing processor reads data from an HTTP request or attribute, and routes it to a specified exporter.</p>"},{"location":"blog/2023/end-user-discussions-01/#2-service-graph-processor","title":"2- Service Graph Processor","text":"<p>Q: How can OpenTelemetry be used to generate a service graph, generate metrics, and send the data to a visualization tool?</p> <p>A: The Service Graph Processor generates a service graph. This processor is still in alpha, and as a result, some known issues around the Service Graph regarding the dependency mapping. One span doesn\u2019t have the entire context, and in order to get the complete picture, you will have to send the spans to a centralized service.</p>"},{"location":"blog/2023/end-user-discussions-01/#3-bifurcating-data-in-a-pipeline","title":"3- Bifurcating data in a pipeline","text":"<p>Q: If I want to use the Collector to send different sets of data to different back-ends, what\u2019s the best way to go about it?</p> <p>A: Connectors (a new Collector component that acts as an exporter/receiver pair to join pipelines together) can be used to solve this. Connectors will be launching soon. For more info, see the Connector PR here.</p> <p>Another approach would be to use a routing processor. A routing processor reads data from an HTTP request or attribute, and routes it to a specified exporter. This is done by making new network connections, which can make this approach inefficient.</p>"},{"location":"blog/2023/end-user-discussions-01/#4-managing-time-drift-in-telemetry-data","title":"4- Managing time drift in telemetry data","text":"<p>Q: When clocks on servers are not in sync, you can end up with some data points being recorded in the future. Can something be implemented on the OTel Collector to mitigate this?</p> <p>A: Clock skew is always going to happen. There is no way for clocks to be synchronized, especially in microservices architectures. The owner of the system that generates the telemetry is in a better position to understand the clock nuances. The Collector is not suited to address this.</p>"},{"location":"blog/2023/end-user-discussions-01/#5-advanced-collector-deployment-and-configuration","title":"5- Advanced Collector deployment and configuration","text":"<p>Q: When should I be horizontally scaling my pod vs modifying config of an individual collector? When do I add more collectors or change collector config?</p> <p>A: There are a few things to consider when deploying and configuring Collectors.</p> <ul> <li>If you only have stateless components in your Collector, you can scale (add   more replicas) based on metrics.</li> <li>You may want to shard your pipelines based on the type of processing that   you\u2019re doing. For example, creating one metrics pipeline, one logs pipeline,   and one traces pipeline, because the workload for each of these pipelines is   different.</li> <li>You might want to split your Collectors based on the type of data being   processed. If there\u2019s one namespace where there\u2019s more data that comes in with   personally identifiable information (PII),   you might want to have a dedicated Collector for that namespace that uses the   attributes processor.</li> </ul>"},{"location":"blog/2023/end-user-discussions-01/#opentelemetry-adoption-enablement","title":"OpenTelemetry Adoption &amp; Enablement","text":"<p>Q: So you\u2019ve decided to go with OpenTelemetry at your organization\u2026now what? What\u2019s the best way to promote OpenTelemetry adoption, and get developers excited about using OpenTelemetry, without overwhelming them?</p> <p>A: Some suggestions from the community:</p> <ul> <li>Find folks who are willing to be OpenTelemetry champions</li> <li>Pair developers new to OpenTelemetry with those who are more familiar with it</li> <li>The real value of OpenTelemetry won\u2019t be seen until you instrument a few   services, to see how things are stitched together.</li> <li>Developers must be mentally ready to start instrumenting their code. Keep in   mind that it may mean going into existing code to instrument it.</li> <li>A \u201cbig bang\u201d approach may not be the best way to adopt OpenTelemetry, as it   may be too overwhelming for an organization. Start with a component or two.</li> </ul>"},{"location":"blog/2023/end-user-discussions-01/#opentelemetry-language-api-sdks","title":"OpenTelemetry Language API &amp; SDKs","text":""},{"location":"blog/2023/end-user-discussions-01/#1-new-language-instrumentation","title":"1- New language instrumentation","text":"<p>Q: How do you find information on OTel implementations for different languages, for example, Dart and Lua?</p> <p>A: CNCF Slack is always a good place to start your search. There are language-specific channels, which follow the naming convention otel-&lt;language_name&gt;. If you don\u2019t find a channel for your language, feel free to start a discussion on the OpenTelemetry CNCF Slack channel, or on GitHub, like with this issue for OTel for Perl. Please also check out this page for more info.</p>"},{"location":"blog/2023/end-user-discussions-01/#2-python-instrumentation","title":"2- Python instrumentation","text":"<p>Q: How mature is auto-instrumentation for Python and what has been the experience of folks working with OpenTelemetry Python?</p> <p>A: Python auto-instrumentation is in beta; however, there are companies using OTel Python in production, so it likely won\u2019t cause any issues in prod. As a SIG, OTel Python tries to minimize shipping breaking changes, but as with everything, there is no guarantee that there will be no breaking changes. There is no firm timeframe on when Python instrumentation will be marked as stable.</p>"},{"location":"blog/2023/end-user-discussions-01/#misc-items","title":"Misc Items","text":""},{"location":"blog/2023/end-user-discussions-01/#1-opentelemetry-exemplars","title":"1- OpenTelemetry exemplars","text":"<p>Q: Where can users learn more about Exemplars and how they are being used in the real world?</p> <p>A: Exemplars are used to correlate OpenTelemetry metrics to traces. Exemplars are currently in the early stages of development, and more work still needs to be done. For more on the state of exemplars, check out the #otel-metrics channel on CNCF Slack. Please also check out Michael Hausenblas\u2019 recent talk on this topic.</p>"},{"location":"blog/2023/end-user-discussions-01/#2-correlation-between-traces-and-logs","title":"2- Correlation between traces and logs","text":"<p>Q: Is there a way to more easily correlate traces to logs?</p> <p>A: Implementing correlation takes time and is a work in progress. Correlation work is more mature for some languages (e.g. Java, Go) than for others. The best approach is to raise this issue in one of the language-specific repos that pertains to your situation. A possible work-around is to start traces at the log level, whereby every log will have its own associated trace.</p>"},{"location":"blog/2023/end-user-discussions-01/#3-profiling","title":"3- Profiling","text":"<p>Q: What is the status of Profiling in OpenTelemetry?</p> <p>A: There is an OTel proposal on profiling, which has been accepted and is being actively being worked on and discussed. The current focus is on finalizing the protocol, before SDK work can start. You can check out the profiling repo on GitHub, as well as the Profiling Vision pull request on GitHub.</p>"},{"location":"blog/2023/end-user-discussions-01/#4-context-propagation","title":"4- Context propagation","text":"<p>Q: Browsers cannot track context propagation automatically, and must therefore be done manually. Current workarounds have come with a lot of overhead. How can this be addressed?</p> <p>A: The way to address this is to join the JavaScript SIG and to raise the issue there. If anyone is actively working on an API to solve this internally, it would be great to contribute this back to the OTel community.</p>"},{"location":"blog/2023/end-user-discussions-01/#meeting-notes-recordings","title":"Meeting Notes &amp; Recordings","text":"<p>For a deeper dive on the above topics, check out the following:</p> <ul> <li>AMER   meeting notes +   Session Recording</li> <li>EMEA   meeting notes</li> <li>APAC   meeting notes</li> </ul> <p>Going forward, we will be recording all End-User Discussion meetings.</p>"},{"location":"blog/2023/end-user-discussions-01/#join-us","title":"Join us!","text":"<p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End-User Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p>"},{"location":"blog/2023/end-user-discussions-02/","title":"OpenTelemetry End-User Discussions Summary for February 2023","text":"<p>With contributions from Henrik Rexed (Dynatrace), Michael Hausenblas (AWS), Rynn Mancuso (Honeycomb), Reese Lee (New Relic), and Adriana Villela (Lightstep).</p> <p>The OpenTelemetry end-user group meet takes place every month for users in the Americas (AMER), Europe Middle-East &amp; Africa (EMEA), and Asia-Pacific (APAC).</p> <p>The discussions take place using a Lean Coffee format, whereby folks are invited to post their topics to the Agile Coffee board like this one, and everyone in attendance votes on what they want to talk about.</p>"},{"location":"blog/2023/end-user-discussions-02/#what-we-talked-about","title":"What we talked about","text":"<p>Some interesting topics that were discussed this month were:</p> <ul> <li>Sampling for traces</li> <li>Emitting business metrics</li> <li>Monitoring the health of OpenTelemetry Collector</li> <li>Backup/Buffer capabilities of OTel Collector</li> </ul>"},{"location":"blog/2023/end-user-discussions-02/#discussion-highlights","title":"Discussion Highlights","text":"<p>Below is the summary of this month's discussions.</p>"},{"location":"blog/2023/end-user-discussions-02/#opentelemetry-collector","title":"OpenTelemetry Collector","text":""},{"location":"blog/2023/end-user-discussions-02/#1-monitoring-otel-collectors-health","title":"1 - Monitoring OTel Collector's health","text":"<p>Q: Are there any suggestions for monitoring OTel Collector's health or patterns for collecting agent telemetry?</p> <p>A: Collectors can be used to collect telemetry data from other Collectors, which doesn't really need to be a disparate telemetry system. Users should also think about collecting multiple signals so that even if one signal fails, they get alerted by another. Here's an article discussing this.</p>"},{"location":"blog/2023/end-user-discussions-02/#2-timeline-for-opamp-extension","title":"2 - Timeline for OpAMP extension","text":"<p>Q: Is there any timeline for implementing the OpAMP spec for agent management?</p> <p>A: It's not a top priority as of now. It would be good to have a maintainer from the community for OpAMP. To track progress, see issue #16462.</p>"},{"location":"blog/2023/end-user-discussions-02/#3-buffer-capabilities-of-otel-collector","title":"3 - Buffer capabilities of OTel Collector","text":"<p>Q: What are some backup/retry buffer capabilities of OTel Collector when endpoints are unavailable?</p> <p>A: There is an experimental storage extension that is currently under development to support buffering and data persistence.</p>"},{"location":"blog/2023/end-user-discussions-02/#4-periodically-profiling-collectors-to-improve-performance","title":"4 - Periodically profiling Collectors to improve performance","text":"<p>Q: Is there any effort to periodically profile the Collector and improve performance on an ongoing basis?</p> <p>A: There is a GitHub action that runs load test on OpenTelemetry Collector, but no one is working to improve it.</p>"},{"location":"blog/2023/end-user-discussions-02/#opentelemetry-language-api-sdks","title":"OpenTelemetry Language API &amp; SDKs","text":""},{"location":"blog/2023/end-user-discussions-02/#1-timeline-for-go-sdk","title":"1 - Timeline for Go SDK","text":"<p>Q: What is the timeline for full specification compliance for OTel Go SDK?</p> <p>A: In the Go OTel SDK, the current progress is mostly around metrics. The logging development is frozen. Major work is being done on the metrics SDK. To track progress on Go metrics, see the Metric project tables. Once metrics are done, logs will be taken care of.</p>"},{"location":"blog/2023/end-user-discussions-02/#opentelemetry-traces","title":"OpenTelemetry Traces","text":""},{"location":"blog/2023/end-user-discussions-02/#1-sampling-for-traces","title":"1 - Sampling for traces","text":"<p>Q: Is there a way to sample traces based on the span counts? Example: Drop/truncate traces which have more than 1000 spans in a single trace.</p> <p>More context: Sometimes, due to issues in the application itself, some traces generate a lot of spans that are not needed. Is there a way in OpenTelemetry to control this? More specifically, is there a way in which we can set up a condition where if a certain trace has more than \u2018n\u2019 number of spans, we can drop or truncate the number of spans.</p> <p>A: Tail-based sampling processor provides users with a bunch of sampling policies. Span count is one such policy. You can also combine multiple policies. Here's the link to tail sampling processor. The span count policy is based on min span count. Some users might look for some kind of exclusion policy.</p>"},{"location":"blog/2023/end-user-discussions-02/#2-use-cases-of-span-links","title":"2 - Use cases of span links","text":"<p>Q: What are the use cases of span links?</p> <p>A: Span links are used for implying a causal relationship between one or more spans. It was a part of the original traces specification, and its status is now stable. It can be used to link traces that are related but runs asynchronously.</p> <p>For example, span links can be used in batched operations to link spans initiated by multiple initiating spans. Spans can have many-to-many mappings via links. Jaeger supports span links in its UI.</p>"},{"location":"blog/2023/end-user-discussions-02/#opentelemetry-metrics","title":"OpenTelemetry Metrics","text":""},{"location":"blog/2023/end-user-discussions-02/#1-supporting-other-metrics-format","title":"1 - Supporting other metrics format","text":"<p>Q: Can OTel Collector support metrics generated from other libraries like statsd library?</p> <p>A: The OpenTelemetry Collector contrib has a lot of receivers for different types of metrics that can be used. For example, if you are sending out metrics in Prometheus format, you can configure your OTel Collector to scrape Prometheus metrics. There is also a statsd receiver that is available. If you have something that is already working, then you don\u2019t need to change it. You can check the list of receivers here.</p>"},{"location":"blog/2023/end-user-discussions-02/#2-emitting-business-metrics","title":"2 - Emitting business metrics","text":"<p>Q: What signals are you using to emit business metrics? For instance, at an arbitrary point in time, emit something that resembles a counter but only emit it once.</p> <p>A: There is a current issue regarding this which you can track. An example of business metric can be users landing on a particular page which can be tracked with a counter.</p>"},{"location":"blog/2023/end-user-discussions-02/#opentelemetry-adoption-enablement","title":"OpenTelemetry Adoption &amp; Enablement","text":""},{"location":"blog/2023/end-user-discussions-02/#1-improving-contributions-from-apac-region","title":"1 - Improving contributions from APAC region","text":"<p>Q: How do we improve contributions from APAC region?</p> <p>A: Suggestions from the community:</p> <ul> <li>Reach out to current OpenTelemetry maintainers and share the challenges</li> <li>Create a list of maintainers from APAC region to whom people can reach to</li> <li>Local in-person meetups for OpenTelemetry users</li> <li>A good place to start would be <code>good first issues</code> in any of the OTel repos,   and ask for help in GitHub issues</li> <li>Join   OTel slack community   and ping in relevant channels</li> </ul>"},{"location":"blog/2023/end-user-discussions-02/#other-important-discussion-points","title":"Other Important discussion points","text":"<p>The community also discussed these important points:</p>"},{"location":"blog/2023/end-user-discussions-02/#auto-discovery-of-sources-to-collect-telemetry-data","title":"Auto-discovery of sources to collect telemetry data","text":"<p>Q: Can OTel Collector automatically discover known sources and collect telemetry from them?</p> <p>A: The idea is to let OTel Collector self-configure itself to collect telemetry from known sources. Prometheus has automatic service discovery in Kubernetes. Currently, there is nothing in the Collector which solves this.</p> <p>There is a receiver creator which can instantiate other receivers at runtime based on whether an observed endpoint matches a configured rule. To use the receiver creator, you must first configure one or more observers. Using Kubernetes observer, users should be able to detect and report Kubernetes pod, port, and node endpoints via the Kubernetes API.</p>"},{"location":"blog/2023/end-user-discussions-02/#hosting-pattern-suggestion-of-the-otel-collector-within-azure","title":"Hosting pattern suggestion of the OTel Collector within Azure","text":"<p>Q: Are there any suggestions for hosting pattern of the Collector within Azure to collect telemetry from Azure App Services and Azure functions?</p> <p>A: Usually, the community relies on folks from Microsoft to provide best practices. There is some issue with the latest version of OTel and Azure functions. You can track it here.</p>"},{"location":"blog/2023/end-user-discussions-02/#meeting-notes-recordings","title":"Meeting Notes &amp; Recordings","text":"<p>For a deeper dive into the above topics, check out the following:</p> <ul> <li>AMER   meeting notes</li> <li>EMEA   meeting notes</li> <li>APAC   meeting notes</li> </ul>"},{"location":"blog/2023/end-user-discussions-02/#join-us","title":"Join us!","text":"<p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End-User Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p>"},{"location":"blog/2023/end-user-discussions-03/","title":"OpenTelemetry End-User Discussions Summary for March 2023","text":"<p>With contributions from Henrik Rexed (Dynatrace), Michael Hausenblas (AWS), Rynn Mancuso (Honeycomb), Adriana Villela (Lightstep), and Pranay Prateek (SigNoz).</p> <p>The OpenTelemetry end-user group meet takes place every month for users in the Americas (AMER), Europe Middle-East &amp; Africa (EMEA), and Asia-Pacific (APAC).</p> <p>The discussions take place using a Lean Coffee format, whereby folks are invited to post their topics to the Agile Coffee board like this one, and everyone in attendance votes on what they want to talk about.</p>"},{"location":"blog/2023/end-user-discussions-03/#what-we-talked-about","title":"What we talked about","text":"<p>Sampling and collector capabilities continue to be topics of interest, along with questions about instrumentation and adoption.</p>"},{"location":"blog/2023/end-user-discussions-03/#discussion-highlights","title":"Discussion Highlights","text":"<p>Below is the summary of this month's discussions.</p>"},{"location":"blog/2023/end-user-discussions-03/#opentelemetry-collector","title":"OpenTelemetry Collector","text":""},{"location":"blog/2023/end-user-discussions-03/#1-losing-grpc-with-azure-app-services","title":"1 - Losing gRPC with Azure App Services","text":"<p>Q: When looking at the hosting models in Azure for the OTel Collector, only HTTP is supported (for running in Azure App Service). What are the risks associated with losing gRPC capability?</p> <p>A: If HTTP2 is supported in Azure, gRPC might work there, since gRPC is HTTP under the hood with extra complications built on top of HTTP2. One suggestion is to follow up with Microsoft about gRPC support, as it may have very long-running connections.</p>"},{"location":"blog/2023/end-user-discussions-03/#2-uptime-monitoringsynthetics","title":"2 - Uptime monitoring/synthetics","text":"<p>Q: Does the OTel Collector have the capability to do uptime monitoring/ synthetics? If not, are there any plans to work towards such a thing?</p> <p>A: The health check might be a helpful reference. Also check out the HTTP check receiver.</p>"},{"location":"blog/2023/end-user-discussions-03/#3-collector-distributions","title":"3 - Collector distributions","text":"<p>Q: Should I use a vendor distribution versus the community collector distribution?</p> <p>A: Each vendor distribution will come with customizations, whereas the community Collector distribution will include everything: receivers and exporters. If you need the flexibility, then you should use the OTel Collector distro.</p>"},{"location":"blog/2023/end-user-discussions-03/#4-rate-limiting-on-receivers","title":"4 - Rate limiting on receivers","text":"<p>Q: Are there any plans for enabling rate limiting and circuit breaks on receivers? Imagine having lots of clients sending telemetry to the same set of OTel collectors.</p> <p>More context: How do I rate-limit in a situation where I have collectors for traces, metrics, and logs, and I\u2019m receiving traffic from more than 100 individual apps? If I have even one customer who is generating heavy traffic, it might impact the overall health of my collectors.</p> <p>A: Use a reverse proxy. Something to note is that once the data is inside the collector, the data is already being deserialized, and you\u2019ve already started firehosing the collector, so it\u2019s a bit late to rate limit at that point. One approach might be to add additional headers when you configure your SDKs that contain the additional information, which would help with load balancing.</p>"},{"location":"blog/2023/end-user-discussions-03/#5-connectors","title":"5 - Connectors","text":"<p>Q: What is a connector?</p> <p>A: A connector is a collector component that consumes telemetry signals as an exporter in one pipeline, and emits it as a receiver in another pipeline. Read more here.</p>"},{"location":"blog/2023/end-user-discussions-03/#6-definitions-of-upstream-downstream-and-distro","title":"6 - Definitions of upstream, downstream, and distro","text":"<p>Q: What is upstream? Downstream? Distro?</p> <p>A: The terms \"upstream\" and \"downstream\" refer to how services or components in a system are connected to each other. Check out this article for more information as it applies to different situations in software.</p> <p>The term \"distro\" is short for distribution. For a list of vendors that provide distros, see Vendors.</p>"},{"location":"blog/2023/end-user-discussions-03/#sampling","title":"Sampling","text":""},{"location":"blog/2023/end-user-discussions-03/#1-tail-sampling","title":"1 - Tail sampling","text":"<p>Q: What are the perceived downsides of tail sampling, for example, on all HTTP requests that have errors or long latencies, instead of just relying on head-based sampling? Are there best practices around trace sampling? Tail sampling can get very expensive.</p> <p>A: Generally, head sampling is not recommended, as you aren\u2019t going to be able to do 100% of what you want to do with it, but it is true that tail sampling is expensive. The reason why sampling is such a complicated discussion is that there really isn\u2019t a universal answer; furthermore, it also depends on what kind of features are offered by your data analysis tool. For example, do you have a data ingest or storage cost? If you have ingest cost, you\u2019ll want to sample before the data gets ingested; if it\u2019s storage cost, you\u2019ll have to delete a lot of the data, so it depends on the tradeoffs.</p> <p>One thing to consider is that you can use tail sampling on attributes, such as if there\u2019s an error on a span, but it does require more memory. Suggested further exploration:</p> <ul> <li>Column data store for OpenTelemetry</li> <li>OpAMP</li> <li>Your backend vendor\u2019s tail-based sampling strategies</li> <li>Paper by Uber</li> <li>Tail sampling processor</li> </ul>"},{"location":"blog/2023/end-user-discussions-03/#adoption-migration-and-implementation","title":"Adoption, Migration, and Implementation","text":""},{"location":"blog/2023/end-user-discussions-03/#1-common-migration-challenges","title":"1 - Common migration challenges","text":"<p>Q: What are common challenges faced by developers when migrating to OpenTelemetry?</p> <p>More context: We have hundreds of microservices that need to be migrated, including big monolith systems with a lot of custom tracing locked into specific vendors and their libraries. Setting up agents to facilitate this migration is like having two different sets of observability systems running at the same time.</p> <p>A: One user shared their journey: They started by using a backend that supports OpenTelemetry. The two challenges they faced were: a cultural change in the engineer\u2019s mindset, and raising awareness of OpenTelemetry, which are bigger than the technical challenges. The key is to not propose one big change; the journey of moving from a vendor-based solution to OpenTelemetry should be a step-by-step process, rather than going into a full transformation.</p> <p>Additional suggestions:</p> <ul> <li>Start with dev or testing environments first to build trust in the software</li> <li>Choose a stack where OTel is more robust, such as Java and Node.js</li> <li>For countering developer resistance, using auto-instrumentation modules to</li> <li>start with is a good step</li> </ul>"},{"location":"blog/2023/end-user-discussions-03/#2-starting-and-scaling","title":"2 - Starting and scaling","text":"<p>Q: What is a good place to start from with OpenTelemetry? For example, from infra to data collection, or starting in the application? And how do you scale it up?</p> <p>More context: Our use case is end-to-end visibility; currently, we are using a vendor for monitoring logs, metrics, and traces. We are also using things like RUM (real user monitoring). Can we do the same with OpenTelemetry, and at scale?</p> <p>A: It depends on if you are starting to use OTel in a new project, or trying to re-orchestrate an existing or old project. It\u2019s best to start with a transition plan, make sure the performance impact is not bad, and scale up what you need. One suggestion is to start experimenting with Java OTel instrumentation, as the overall performance impact is negligible.</p> <p>Another suggestion is to try infrastructure monitoring with OpenTelemetry using the host metrics receiver in the Collector, as it covers a lot of metrics, and has no dependencies. One user noticed a 20% reduction in CPU usage when they moved from a vendor-specific agent to the host metrics receiver for infrastructure monitoring.</p>"},{"location":"blog/2023/end-user-discussions-03/#3-auto-instrumentation","title":"3 - Auto-instrumentation","text":"<p>Q: Is there a way to automatically create spans without code changes?</p> <p>A: It depends on the use cases:</p> <ul> <li>Auto instrumentation options are   maturing in OTel; for example, the Java JAR agent takes care of instrumenting   most libraries   that are used by applications. Auto-instrumentation is also available for   Python,   .NET, and   Node.js.</li> <li>If you\u2019re using Kubernetes, they can use the   OTel operator,   which takes care of instrumentations for applications deployed on K8s. The   OTel Operator also supports injecting and configuring auto-instrumentation   libraries where available (see point above).</li> <li>If you\u2019re using AWS lambda, you should check out the   OTel Lambda extension.</li> </ul>"},{"location":"blog/2023/end-user-discussions-03/#4-leveraging-telemetry-from-otel","title":"4 - Leveraging telemetry from OTel","text":"<p>Q: Has there been work toward telecommand standards to leverage the telemetry from OTel?</p> <p>A: Telecommand is a command sent to control a remote system or systems that are not directly connected to the place from which the telecommand is sent (per Wikipedia). Check out this paper, and OpAMP.</p>"},{"location":"blog/2023/end-user-discussions-03/#5-message-brokers","title":"5 - Message brokers","text":"<p>Q: What are some use cases for message brokers?</p> <p>A: IoT use cases (car manufacturer). There is also ongoing work for semantic conventions support for messages.</p>"},{"location":"blog/2023/end-user-discussions-03/#updates-and-communications","title":"Updates and Communications","text":""},{"location":"blog/2023/end-user-discussions-03/#1-unified-query-standard","title":"1 - Unified query standard","text":"<p>Q: Is there an update on the upcoming Unified Query Standard working group for observability data and discussion at O11y Day at KubeCon EU?</p> <p>A: The Observability TAG within CNCF is working to launch a working group that is going to analyze the various query languages that are out there and come up with use cases, such as, what are your most common alert and diagnostic types, and what are some uncommon patterns that you\u2019d like to have available? Then, we\u2019d like to see if there\u2019s any way we can come up with a recommendation for a unified standard language across vendors. Maybe SQL-ish?</p> <p>We\u2019re officially launching the working group at the end of the month; the charter is open for comments. View here. We are going to start making the conference circuit and gather feedback, the first place will be at Observability Day. Join the discussion at #telemetry-analysis in CNCF\u2019s Slack instance.</p>"},{"location":"blog/2023/end-user-discussions-03/#2-documentation-and-searches","title":"2 - Documentation and searches","text":"<p>Q: Where do you go to find documentation and answers to your questions?</p> <p>A: We have many resources, including official documentation and Github repos.</p> <p>To help us improve our resources, it would be helpful to gather feedback from you as an end user \u2013 what is your process for finding OTel information? Do you search for answers or post questions on Stack Overflow? The community is researching options that make sense so that questions can be indexed for searching. One option is Stack Overflow. Please share your answers using one of the avenues below!</p>"},{"location":"blog/2023/end-user-discussions-03/#meeting-notes-recordings","title":"Meeting Notes &amp; Recordings","text":"<p>For a deeper dive into the above topics, check out the following:</p> <ul> <li>AMER   meeting notes</li> <li>EMEA   meeting notes</li> <li>APAC   meeting notes</li> </ul>"},{"location":"blog/2023/end-user-discussions-03/#join-us","title":"Join us","text":"<p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End-User Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p>"},{"location":"blog/2023/end-user-discussions-04/","title":"OpenTelemetry End-User Discussions Summary for April 2023","text":"<p>For the month of April 2023, the OpenTelemetry end-user group meet took place for users in the Asia-Pacific (APAC) region. Due to KubeCon EU, the AMER and EMEA sessions did not take place; however, we will have meetings for all 3 regions again in May.</p> <p>The discussions take place using a Lean Coffee format, whereby folks are invited to post their topics to the Agile Coffee board like this one, and everyone in attendance votes on what they want to talk about.</p>"},{"location":"blog/2023/end-user-discussions-04/#what-we-talked-about","title":"What we talked about","text":"<p>We talked about evangelizing the adoption of OpenTelemetry in a big organization and also discussed how to optimize observability data at scale.</p>"},{"location":"blog/2023/end-user-discussions-04/#discussion-highlights","title":"Discussion Highlights","text":"<p>Below is the summary of this month's discussion.</p> <p>Note: The answers are provided by a mix of OTel community members and end-users to the best of their knowledge. The answers are not official recommendations by OpenTelemetry.</p>"},{"location":"blog/2023/end-user-discussions-04/#evangelizing-adoption-of-opentelemetry-in-a-big-organization","title":"Evangelizing adoption of OpenTelemetry in a big organization","text":"<p>Q: How do you evangelize the adoption of OpenTelemetry in a big organization?</p> <p>A: In a big organization, the first step would be to put out the current pain points of observability to leadership. There are benefits of having an open source standard for observability. If there is no standard in place, it gets very difficult to communicate across different teams. If you use OpenTelemetry, you do not have to depend on any vendor agents, and you have the flexibility to send data to multiple backends.</p>"},{"location":"blog/2023/end-user-discussions-04/#how-to-optimize-observability-data-at-scale","title":"How to optimize observability data at scale?","text":"<p>Q: In a big organization, observability data can be in the range of TBs per day, which comes with associated costs. But there is always a feeling that 80% of captured data is unusable. None of the vendors help you understand what data is accessed and how to bring that visibility to the engineering teams sending the data.</p> <p>A: One of the ways to optimize observability at scale is sampling. Here's an article on tail sampling with OpenTelemetry. There are a number of options for you to reduce the data volumes at the SDKs level and the collector level.</p> <p>Also, there is active work going on the OpenTelemetry Collector side to handle data at scale more efficiently. For example, there is work going around using Apache Arrow for serialization to optimize network costs.</p> <p>One of the other ways to optimize observability data at scale is to decide how much of it you want to store for future use. You should optimize data storage so that you incur less cost.</p>"},{"location":"blog/2023/end-user-discussions-04/#other-important-discussion-points","title":"Other Important discussion points","text":""},{"location":"blog/2023/end-user-discussions-04/#maturity-model-for-opentelemetry","title":"Maturity model for OpenTelemetry","text":"<p>Q: Is there some literature available around understanding steps to reach a certain maturity level in adopting OTel in your organization? For example, I should be able to go to a team and tell them to start with X, and then do Y to move ahead. In a big enterprise, you have to provide something for people to understand the maturity of OpenTelemetry.</p> <p>A: For teams adopting OpenTelemetry, a good idea is to start with minimal changes. For example, teams can start with languages that have auto-instrumentation support. Seeing value from small changes can build more confidence in the team to go deeper into OpenTelemetry adoption.</p> <p>There are also several OpenTelemetry receivers available. These receivers help to collect the telemetry end-users already have. For example, Prometheus receiver can help you receive metrics data in Prometheus format. Using these receivers, you can start sending telemetry data from different components of your application.</p>"},{"location":"blog/2023/end-user-discussions-04/#meeting-notes-recordings","title":"Meeting Notes &amp; Recordings","text":"<p>For a deeper dive into the above topics, check out the following:</p> <ul> <li>APAC   meeting notes</li> </ul>"},{"location":"blog/2023/end-user-discussions-04/#join-us","title":"Join us!","text":"<p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End-User Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p>"},{"location":"blog/2023/end-user-q-and-a-01/","title":"End-User Q&A Series: Using OTel with GraphQL","text":"<p>With contributions from Rynn Mancuso (Honeycomb) and Reese Lee (New Relic).</p> <p>On Thursday, January 26th, 2023, the OpenTelemetry End User Working Group hosted the first of its monthly End User Q&amp;A sessions of 2023. This series is a monthly casual discussion with a team using OpenTelemetry in production. The goal is to learn more about their environment, their successes, and the challenges that they face, and to share it with the community, so that together, we can help make OpenTelemetry awesome!</p> <p>This month, Dynatrace\u2019s Henrik Rexed spoke with J, who works at a financial services organization, about how they use OpenTelemetry with GraphQL.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#overview","title":"Overview","text":"<p>J and his team embarked on their OpenTelemetry journey for two main reasons:</p> <ul> <li>J\u2019s company uses a few different observability back-ends. His team had   switched to a vendor back-end that was different from the back-end used by   other teams that they interfaced with. OpenTelemetry allowed them to continue   to get end-to-end Traces in spite of using different vendors.</li> <li>His team was using GraphQL, and needed to be able to better understand what   was happening behind the scenes with their GraphQL calls.</li> </ul> <p>J also shared:</p> <ul> <li>His team\u2019s OpenTelemetry setup</li> <li>How he and his team have helped other teams start using OpenTelemetry</li> <li>His quest to make OpenTelemetry a standard at his organization</li> <li>Challenges that he and his team encountered in their OpenTelemetry journey,   along with a few suggestions for improvement.</li> </ul>"},{"location":"blog/2023/end-user-q-and-a-01/#qa","title":"Q&amp;A","text":""},{"location":"blog/2023/end-user-q-and-a-01/#why-opentelemetry","title":"Why OpenTelemetry?","text":"<p>J\u2019s company has a diverse tech ecosystem, ranging from on-premise old-school mainframes, to AWS Cloud and Azure Cloud, where they run both Windows and Linux servers. They also use a number of different languages, including Node.js, .NET, Java, C, C++, and PL/I (mainframe).</p> <p>Across the organization, different teams have chosen to use different observability platforms to suit their needs, resulting in a mix of both open source and proprietary observability tools.</p> <p>J\u2019s team had recently migrated from one observability back-end to another. After this migration, they started seeing gaps in trace data, because other teams that they integrated with were still using a different observability back-end. As a result, they no longer had an end-to-end picture of their traces. The solution was to use a standard, vendor-neutral way to emit telemetry: OpenTelemetry.</p> <p>Another reason that his team took to using OpenTelemetry was GraphQL, which they had been using for four years. GraphQL is an open source language used to query and manipulate APIs. With GraphQL, everything is held in the body of data: request, response and errors, and as a result everything returns an HTTP status of 200, giving the impression that even failures are successful. This meant that J and his team had no visibility into what was going on behind the scenes.</p> <p>They pass a lot of data into a GraphQL response, because they have a main gateway that brings all of the different GraphQL endpoints into a single one, so it all looks like one massive query. OpenTelemetry exposed massive amounts of data from their GraphQL systems\u2013with traces as large as three to four thousand spans! Instrumentation has been done around Node.js GraphQL systems, and instrumentation has also started for their .NET GraphQL systems.</p> <p>Another black box that they are still facing is around AWS, and they are looking to add some distributed tracing around components like Lambdas and ECS.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#how-are-applications-deployed-into-production","title":"How are applications deployed into production?","text":"<p>The team is on GitLab, and uses GitLab pipelines for CI/CD, leveraging Ansible Tower to manage deployments. The GitLab custom pipelines deploy Kubernetes YAML files (without Helm) to an EKS cluster.</p> <p>The team is currently in the early stages of planning to use Amazon\u2019s cdk8s to deploy to Kubernetes, and Flagger to manage those deployments (including Canary deployments).</p>"},{"location":"blog/2023/end-user-q-and-a-01/#how-are-queries-built-in-graphql","title":"How are queries built in GraphQL?","text":"<p>There are two systems for building gateways in GraphQL. One is using Apollo Federation, and the other is through Schema Stitching. Schema stitching allows users to run a single query that spans across multiple GraphQL APIs. J\u2019s team chose Schema Stitching because, unlike Apollo which is getting more locked down, it is more open source, flexible, and less proprietary.</p> <p>This allows users to query or mutate as much data as they want. Uses of GraphQL include microservices development, and extracting data for analysis.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#how-do-you-generate-traces","title":"How do you generate traces?","text":"<p>To instrument their code, they configure the Node.js SDK and use a number of Node.js auto-instrumentation plug-ins. While the team is currently only using auto-instrumentation to generate traces and spans, they do occasionally add more data to a span (e.g. attributes). They do this by grabbing the context to find the span, and injecting custom attributes into that spans.</p> <p>There are currently no plans for the team to create custom spans, and in fact, J is currently discouraging teams from creating their own custom spans. Since they do a lot of asynchronous programming, it can be very difficult for developers to understand how the context is going to behave across asynchronous processes.</p> <p>Traces are sent to their observability back-end using that vendor\u2019s agent, which is installed on all of their nodes.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#besides-traces-do-you-use-other-signals","title":"Besides traces, do you use other signals?","text":"<p>The team has implemented a custom Node.js plugin for getting certain metrics data about GraphQL, such as deprecated field usage and overall query usage, which is something that they can\u2019t get from their traces. These metrics are being sent to the observability back-end through the OpenTelemetry Collector\u2019s OTLP metrics receiver.</p> <p>There is a long-term goal to have this plugin contributed back to the OpenTelemetry community. At the moment, however, the plugin is currently coupled to their own systems, and needs to be modified for more generic use cases. In addition, the plugin needs to be reviewed by the organization\u2019s open source Software group before it can be shared externally.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#do-you-do-any-logging","title":"Do you do any logging?","text":"<p>The team uses Amazon Elasticache and the ELK stack for logging. They are currently doing a proof-of-concept (POC) of migrating .NET logs to their observability back-end. The ultimate goal is to have metrics, logs, and traces under one roof.</p> <p>They have currently been able to automatically link traces to logs in ELK using Node.js Bunyan. They are hoping to leverage OpenTelemetry\u2019s Exemplars to link traces and metrics.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#how-is-the-organization-sending-telemetry-data-to-various-observability-back-ends","title":"How is the organization sending telemetry data to various observability back-ends?","text":"<p>J\u2019s team uses a combination of the proprietary back-end agent and the OpenTelemetry Collector (for metrics). They are one of the primary users of OpenTelemetry at J\u2019s company, and he hopes to help get more teams to make the switch.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#who-has-access-to-the-instrumentation-data","title":"Who has access to the instrumentation data?","text":"<p>Traces are used for diagnostic purposes. If there\u2019s an issue in production, traces help developers pinpoint where the problem might be.</p> <p>Because GraphQL mostly returns HTTP 200s, it gives the impression that it returns no errors, when in fact, there might be errors lurking behind the scenes. Having traces enables developers to see if there\u2019s actually an error in the response body. For example, when accessing a database, if there\u2019s a connection hangup, GraphQL will report HTTP 200, but the Trace will show that there\u2019s an error, and where.</p> <p>The SRE team also uses the observability data for the purposes of improving system reliability and performance.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#how-would-you-describe-the-overall-opentelemetry-adoption-experience","title":"How would you describe the overall OpenTelemetry adoption experience?","text":"<p>The team\u2019s initial adoption was super fast and easy\u201380% of their tracing needs were met right away. The next 20% required some additional proof of concept work, which was completed relatively quickly. Overall, it was a very positive experience.</p> <p>J\u2019s team has convinced a couple of other groups to use OpenTelemetry; however, they have been met with a few challenges. For example, J wants to make sure that these teams move away from proprietary software, such as Apollo Studio, since OpenTelemetry already meets these same needs.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#are-there-plans-to-use-opentelemetry-across-the-organization","title":"Are there plans to use OpenTelemetry across the organization?","text":"<p>The team has recently been talking to their internal Open Source Software (OSS) and Enterprise Architecture (EA) groups to make OpenTelemetry an enterprise standard. They are hoping to use their own success with their production-ready OpenTelemetry system to illustrate the benefits of OpenTelemetry across the organization.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#are-you-seeing-the-benefits-of-using-opentelemetry-with-graphql-in-your-production-environments","title":"Are you seeing the benefits of using OpenTelemetry with GraphQL in your production environments?","text":"<p>Using the GraphQL OpenTelemetry plugin-for Node.js made it super easy to identify an issue with a GraphQL resolver that was acting up in production.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#were-the-outputs-produced-by-the-instrumentation-libraries-that-you-used-meaningful-to-you-or-did-you-have-to-make-any-adjustments","title":"Were the outputs produced by the instrumentation libraries that you used meaningful to you, or did you have to make any adjustments?","text":"<p>On the Node.js side, the team used auto-instrumentation for HTTP, Express, GraphQL, and also the AWS SDK on some systems.</p> <p>The most useful instrumentation was GraphQL and AWS SDK. Although GraphQL auto-instrumentation has been very useful, there are still some areas for improvement, such as adding the ability to ignore certain fields. J has opened a pull request to address this.</p> <p>The team didn\u2019t see much benefit in auto-instrumentation for HTTP and Express. They found HTTP instrumentation to be a little too noisy. Express is being used very minimally, and therefore there was no real value in having that instrumentation. Also, the team plans to migrate from Express to GraphQL Yoga in the near future. They expect there to be some instrumentation gaps when they move to GraphQL Yoga, and are therefore planning on writing an OpenTelemetry plugin for it, which they intend to give back to the OpenTelemetry community.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#are-you-planning-on-instrumenting-mainframe-code","title":"Are you planning on instrumenting mainframe code?","text":"<p>The observability back-end used by J\u2019s team provided native instrumentation for the mainframe. J and his team would have loved to instrument mainframe code using OpenTelemetry. Unfortunately, there is currently no OpenTelemetry SDK for PL/I (and other mainframe languages such as FORTRAN and COBOL). The team would love to have OpenTelemetry available for the mainframe, but aren\u2019t sure if there\u2019s enough appetite out there for undertaking such an effort.</p> <p>NOTE: If anyone is interested in or ends up creating an OpenTelemetry implementation for the mainframe, please reach out to us!</p>"},{"location":"blog/2023/end-user-q-and-a-01/#challengesmoving-forward","title":"Challenges/Moving Forward","text":"<p>As part of our conversation with J, he also shared some areas and suggestions for improvement.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#javascript-maintenance","title":"JavaScript Maintenance","text":"<p>OpenTelemetry has a small number of language maintainers, and as a result, they don\u2019t necessarily have enough cycles to work on all the things. Thus, they currently focus on keeping up with spec changes to update the SDK and API. This means that they often don\u2019t have time (and sometimes not even the expertise) to manage the contrib repos (e.g. GraphQL). This is a known problem, and there is currently no solution in place. The OpenTelemetry Community welcomes any suggestions for improvement!</p> <p>There is also a huge focus on stabilizing semantic conventions, and as part of that effort, maintainers plan to go through the existing instrumentation packages and to make sure that they\u2019re all up to date with the latest conventions. While it\u2019s very well-maintained for certain languages, such as Java, that is not the case for other languages, such as Node.js.</p> <p>JavaScript environments are akin to the Wild West of Development due to:</p> <ul> <li>Multiple facets: web side vs server side</li> <li>Multiple languages: JavaScript, TypeScript, Elm</li> <li>Two similar, but different server-side runtimes: Node.js and   Deno</li> </ul> <p>One of J\u2019s suggestions is to treat OTel Javascript as a hierarchy, which starts with a Core JavaScript team that splits into two subgroups: front-end web group, and back-end group. Front-end and back-end would in turn split. For example, for the back-end, have a separate Deno and Node.js group.</p> <p>Another suggestion is to have a contrib maintainers group, separate from core SDK and API maintainers group.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#javascript-contributions","title":"JavaScript Contributions","text":"<p>Making OpenTelemetry JavaScript contributions has been slow-moving at times, specifically around plug-ins. Much of the plug-in maintenance relies on the plug-in\u2019s original owner; however, the original owner is gone in many cases, or maintainers don\u2019t check GitHub very frequently, and as a result, movement on some pull requests (PRs) is very slow. One way to mitigate this is to get contributors more involved, which could potentially help bring in more contributors.</p>"},{"location":"blog/2023/end-user-q-and-a-01/#documentation","title":"Documentation","text":"<p>J and his team have also experienced some challenges with documentation, noting that there are some gaps in the online docs:</p> <ul> <li>Under metrics for JavaScript, there is no mention of the Observable Gauge at   all. J had to go into the code to find it.</li> <li>There are some short, very high-level metric API examples. Those examples   currently don't show which libraries you need to bring in. It also doesn't   talk about how to export items.</li> <li>In .NET, it is very hard to keep a trace going in your work due to all the   async/await and it jumping between threads. .NET docs lack some detail around   context propagation in this particular scenario.</li> </ul>"},{"location":"blog/2023/end-user-q-and-a-01/#final-thoughts","title":"Final Thoughts","text":"<p>OpenTelemetry is all about community, and we wouldn\u2019t be where we are without our contributors, maintainers, and users. Hearing stories of how OpenTelemetry is being implemented in real life is only part of the picture. We value user feedback, and encourage all of our users to share your experiences with us, so that we can continue to improve OpenTelemetry. \u2763\ufe0f</p> <p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End Users Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Sign up for one of our monthly interview/feedback sessions</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p>"},{"location":"blog/2023/end-user-q-and-a-02/","title":"End-User Q&A Series: Using OTel at Uplight","text":"<p>With contributions from Rynn Mancuso (Honeycomb) and Reese Lee (New Relic).</p> <p>On Thursday, March 2nd, 2023, the OpenTelemetry (OTel) End User Working Group hosted its second End User Q&amp;A session of 2023. This series is a monthly casual discussion with a team using OpenTelemetry in production. The goal is to learn more about their environment, their successes, and the challenges that they face, and to share it with the community, so that together, we can help make OpenTelemetry awesome!</p> <p>This month, I spoke with Doug Ramirez, Principal Architect at Uplight.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#overview","title":"Overview","text":"<p>Doug loves observability, and by extension, OpenTelemetry, because of the excitement that he gets from getting feedback for code that he has written.</p> <p>In this session, Doug shared:</p> <ul> <li>His organization\u2019s OpenTelemetry journey</li> <li>How he has evangelized OpenTelemetry at Uplight</li> <li>Challenges that he encountered in Uplight\u2019s OpenTelemetry journey, along with   a few suggestions for improvement.</li> </ul>"},{"location":"blog/2023/end-user-q-and-a-02/#qa","title":"Q&amp;A","text":""},{"location":"blog/2023/end-user-q-and-a-02/#tell-us-about-your-role","title":"Tell us about your role?","text":"<p>Uplight is made up of a number of companies that were brought together as a result of mergers and acquisitions, and now all exist under the Uplight brand. Its mission is to save the planet, by helping utilities operate their grid to minimize resource consumption and offset CO2 emissions. The organization has a main data platform that centralizes large data sets for utilities. As they\u2019ve grown, the Uplight data platform has become an extremely important component that enables the apps that ultimately deliver value to its customers.</p> <p>Doug\u2019s role as Principal Architect on the platform is to help design and architect the platform in ways that satisfy business requirements, while also allowing developers to easily leverage the platform. To help achieve that, he has optimized on observability as an architecture characteristic, having spent a significant amount of time in the past year talking about and thinking about observability, and baking it into everything</p>"},{"location":"blog/2023/end-user-q-and-a-02/#what-do-you-think-that-observability-will-help-you-solve","title":"What do you think that Observability will help you solve?","text":"<p>Because Uplight is a conglomerate of companies, it means that there are different tech stacks, different design patterns, and different ways to approach the same problems.</p> <p>In spite of having all these different systems with different stacks, Doug feels that it is essential to be able observe them all running together, as a cohesive unit. He wants to create the same experience for developers across the company to observe their code, irrespective of the tech stack that they\u2019re using \u2013 i.e. a common path to observability. This is being achieved by leaning into OpenTelemetry as the standard and tool to get there.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#what-is-your-architecture-like","title":"What is your architecture like?","text":"<p>Uplight uses \u201ceverything\u201d, including a lot of Ruby, Java, Python, some .NET, and as a result, it\u2019s hard to describe the tech stack. There\u2019s a lot of legacy code. There are many monoliths. New development work is being written in Python, and they are leveraging FastAPI for micro-services work.</p> <p>With so many different languages and frameworks being used, the question was, how do you get observability and OTel injected or baked into these different platforms?</p> <p>The ultimate goal was to get folks to understand OpenTelemetry and the long-term vision around observability. Most developers are familiar and comfortable with logs \u2013 they just want to be able to write a log and see what happens. So, Doug started by getting developers to add OpenTelemetry (structured) logs to all of the services across their various platforms. In order to leverage OTel logs, developers had to add the OpenTelemetry language-specific SDKs into their code. Once they got past that initial hump and got the SDKs into their code, it then became easier for developers to add other signals (such as metrics and traces) to the code as well, since the OTel scaffolding was already in place!</p> <p>Doug and his team realized that the problem of structured logging had already been solved by OpenTelemetry. Contributors and maintainers have thought long and hard about logging and standardization on structure, and it didn\u2019t make sense to reinvent the wheel. The log spec already existed, so Uplight chose to ride the coattails of OTel, in order for developers to get to their observability path more quickly and easily. Again, in adopting OpenTelemetry logs, adopting traces and metrics became a natural next step.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#what-is-your-build-and-deployment-process-like","title":"What is your build and deployment process like?","text":"<p>Builds are done using CircleCI and Jenkins. Everything is run in containers, and they use all of the cloud providers. They are working to standardize on tooling and processing for deploying to the cloud.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#otel-logs-are-relatively-new-why-use-something-so-new","title":"OTel logs are relatively new. Why use something so new?","text":"<p>As one of the newer OpenTelemetry signals, there was a lot of concern around the maturity of logs. There were also many concerns about whether OTel itself would go away, or whether logs would be eliminated from the spec. All of that unease was put to rest once the folks at Uplight began exploring and using log correlation \u2013 i.e. linking logs to traces.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#what-were-some-of-the-challenges-on-the-road-to-otel","title":"What were some of the challenges on the road to OTel?","text":"<p>One of the biggest challenges faced internally at Uplight was defending against vendor lock-in, while still emitting meaningful telemetry data in order to achieve observability. Some folks at Uplight felt that the SDKs provided by their APM vendor did the job; however, that meant vendor lock-in.</p> <p>Providing a good developer experience was key. It was important to show developers that they could instrument their code easily, using a framework that has become the de facto standard for instrumentation, and which is also portable, so it won\u2019t keep them locked into a particular vendor.</p> <p>The hearts and minds of developers began to change after they were able to experience OpenTelemetry in action:</p> <ul> <li>Seeing structured logs, being able to correlate traces and logs, and emitting   metrics.</li> <li>Experiencing the benefits of   context propagation \u2013 i.e. spans and   traces interacting across different operations to provide an end-to-end view   of a service call.</li> </ul>"},{"location":"blog/2023/end-user-q-and-a-02/#how-did-you-promote-opentelemetry-across-the-organization","title":"How did you promote OpenTelemetry across the organization?","text":"<p>There was a lot of internal debate on whether or not OpenTelemetry was mature enough to warrant adoption. As a result, Doug spent a lot of time educating folks on OpenTelemetry, to show that OpenTelemetry was not bleeding edge (it\u2019s been around for a while), and that it has the support of the major Observability vendors. In fact, these vendors are all talking about it on their blogs. These efforts helped get buy-in from both Uplight\u2019s leadership and engineers.</p> <p>Doug\u2019s main architecture goals at Uplight are observability, deployability, and security. Part of the observability narrative included talking about OpenTelemetry and showing folks how it all works. To do that, Doug has created a number of short internal Loom videos, inspired by Microsoft\u2019s Channel 9. The Loom videos have been a very effective means of sharing information about OpenTelemetry (both theory and code snippets) very quickly across the organization. They have been extremely well-received. Video topics have included structured logging, metrics, traces, and integrating distributed tracing with webhook platforms.</p> <p>Internal hackathons have also proven to be a very effective means of promoting OpenTelemetry, and getting folks to use it.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#how-have-developers-found-the-experience-of-integrating-the-otel-sdks-into-the-application-code","title":"How have developers found the experience of integrating the OTel SDKs into the application code?","text":"<p>One of Doug\u2019s goals with OpenTelemetry was to create a pleasant developer experience around implementing the language SDKs. There was a lot of internal debate on whether or not shared libraries would help lower the barrier to entry for implementing the OTel SDK. It was ultimately decided to allow teams to choose their own path: some teams are implementing Uplight shared libraries, others are leveraging code snippets from a reference architecture created by Doug, and others are using the SDK directly.</p> <p>Doug\u2019s main takeaway is for folks to just start using OpenTelemetry right away, get to know it, and not worry about creating shared libraries.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#manual-or-auto-instrumentation","title":"Manual or auto-instrumentation?","text":"<p>Folks at Uplight have used a combination of manual and auto-instrumentation. Doug\u2019s main advice is to do the minimum you need to get instrumentation up and running, do the minimum required to get traces and logs emitted and correlated, and then refine as needed.</p> <p>The SDKs give you everything you need. How much you decided to optimize on top of that is up to you. Doug\u2019s advice is to do the minimum you need to get started</p>"},{"location":"blog/2023/end-user-q-and-a-02/#how-do-you-deploy-your-otel-collectors","title":"How do you deploy your OTel Collectors?","text":"<p>Uplight currently has a few different Collector configurations:</p> <ul> <li>Collectors running standalone as some   sidecars</li> <li>For larger Kubernetes clusters, there\u2019s a   Collector running in each cluster</li> <li>Developers running their own Collectors   locally with Docker</li> </ul> <p>Doug\u2019s ultimate goal is for any deployment in any environment to be able to easily send telemetry to an OTel Collector gateway.</p> <p>Collectors at Uplight are typically run and maintained by the infrastructure team, unless individual teams decide to take ownership of their own Collectors. Those who do take ownership of their own Collectors have had a positive experience thus far. Uplight may revisit whether or not development teams should own their own Collectors at a later date, but for now, giving developers a quick path to standing up the Collector is more important to help further OpenTelemetry adoption.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#feedback","title":"Feedback","text":""},{"location":"blog/2023/end-user-q-and-a-02/#community-engagement","title":"Community Engagement","text":"<p>Doug has had a very positive experience with OpenTelemetry so far. He has been happy to see that the OTel community is very active on the CNCF Community Slack, and recommends for anyone new to OpenTelemetry to just join some OTel Channels (e.g. #otel-collector, #otel-logs, #otel-python) and just see what people are talking about. The conversations happening in the various channels have helped inform his decisions at Uplight.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#contribution","title":"Contribution","text":"<p>Doug has made some contributions to the Python SDK; however, it took a little bit of time to understand the logistics of contributing. He was initially unsure about how to get engaged, who to talk to in Slack, and how to nudge folks to request a review of his PRs. Anything that can be done to make it super easy and obvious for people to contribute would be super helpful.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#communication","title":"Communication","text":"<p>Doug has found it challenging to determine where to go for certain types of conversations. Is it GitHub issues, or Slack? Where do you go if you\u2019re someone new who wants to make a contribution? Where do you go if you\u2019re new to OTel and are seeing a problem? How do you ensure that the conversations are not being duplicated?</p>"},{"location":"blog/2023/end-user-q-and-a-02/#simple-reference-implementations","title":"Simple Reference Implementations","text":"<p>Doug would like to see really simple reference implementations to help folks who are starting OTel from scratch. For example, they\u2019re running a simple \u201cHello World\u201d program to send data to the Collector, and nothing is showing up, and need some guidance around this. How do we help folks who aren\u2019t super familiar with Docker and aren\u2019t super familiar with OpenTelemetry? Can we have some super simple reference implementations to hold folks\u2019 hands as they get started? For example, for a Ruby developer, clone X repo, run <code>docker compose up</code>1, and everything should be up and running. That way, they can focus on learning OpenTelemetry, rather than mess around with Docker networking and other distracting things.</p> <p>I shared with Doug that we have the OTel Demo App (and #otel-community-demo channel on Slack), which provides an OTel-example-in-a-box. I also shared the #otel-config-file Slack channel, which aims to simplify OTel bootstrapping</p> <p>Doug would like to see a more targeted, language-specific example in a box. For example, a FastAPI example with 2 Python services talking to each other, to demonstrate context propagation, going through the Collector, which sends traces to Jaeger.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#whats-next","title":"What's next?","text":"<p>If you\u2019d like to see my conversation with Doug in full, you can check out the video here.</p> <p>If anyone would like to continue the conversation with Doug, please reach out to him in the #otel-user-research Slack channel!</p> <p>Also, be sure to check out more of Doug's OTel adventures at this month's OTel in Practice series, on March 27th, 09:00 PT/11:00 ET.</p>"},{"location":"blog/2023/end-user-q-and-a-02/#final-thoughts","title":"Final Thoughts","text":"<p>OpenTelemetry is all about community, and we wouldn\u2019t be where we are without our contributors, maintainers, and users. Hearing stories of how OpenTelemetry is being implemented in real life is only part of the picture. We value user feedback, and encourage all of our users to share your experiences with us, so that we can continue to improve OpenTelemetry. \u2763\ufe0f</p> <p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End Users Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Sign up for one of our   monthly interview/feedback sessions</li> <li>Join the   OpenTelemetry group on LinkedIn</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/2023/end-user-q-and-a-03/","title":"End-User Q&A Series: Using OTel at Farfetch","text":"<p>With contributions from Rynn Mancuso (Honeycomb) and Reese Lee (New Relic).</p> <p>On Thursday, May 25th, 2023, the OpenTelemetry (OTel) End User Working Group hosted its third End User Q&amp;A session of 2023. We had a bit of a gap due to KubeCon Europe, but now we\u2019re back! This series is a monthly casual discussion with a team using OpenTelemetry in production. The goal is to learn more about their environment, their successes, and the challenges that they face, and to share it with the community, so that together, we can help make OpenTelemetry awesome!</p> <p>This month, I spoke with Iris Dyrmishi, Platform Engineer at Farfetch.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#overview","title":"Overview","text":"<p>Iris is a huge fan of observability and OpenTelemetry, and her love of these two topics is incredibly infectious.</p> <p>In this session, Iris shared:</p> <ul> <li>Farfetch\u2019s journey to OpenTelemetry</li> <li>How metrics and traces are instrumented</li> <li>OpenTelemetry Collector deployment and configuration</li> </ul>"},{"location":"blog/2023/end-user-q-and-a-03/#qa","title":"Q&amp;A","text":""},{"location":"blog/2023/end-user-q-and-a-03/#tell-us-about-your-role","title":"Tell us about your role?","text":"<p>Iris is part of a central team that provides tools for all the engineering teams across Farfetch to monitor their services, including traces, metrics, logs, and alerting. The team is responsible for maintaining Observability tooling, managing deployments related to Observability tooling, and educating teams on instrumenting code using OpenTelemetry.</p> <p>Iris first started her career as a software engineer, focusing on back-end development. She eventually moved to a DevOps Engineering role, and it was in this role that she was introduced to cloud monitoring through products such as Amazon CloudWatch and Azure App Insights. The more she learned about monitoring, the more it became a passion for her.</p> <p>She then moved into another role where she was introduced to OpenTelemetry, Prometheus, and Grafana, and got to dabble a little more in the world of Observability. This role became an excellent stepping stone for her current role at Farfetch, which she has been doing for a little over a year now.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-did-you-hear-about-opentelemetry","title":"How did you hear about OpenTelemetry?","text":"<p>Iris first heard about OpenTelemetry on LinkedIn. The company she was working at at the time, which was not using traces, had started exploring the possibility of using them and was looking into tracing solutions. After reading about OpenTelemetry, Iris created a small Proof-of-Concept (POC) for her manager. While nothing had moved past the POC at that role, when Iris joined Farfetch and OpenTelemetry came up again, she jumped at the chance to work with it.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#what-is-the-architecture-at-farfetch-like-how-has-opentelemetry-helped","title":"What is the architecture at Farfetch like? How has OpenTelemetry helped?","text":"<p>Farfetch currently has 2000 engineers, with a complex and varied architecture which includes cloud-native, Kubernetes, and virtual machines running on three different cloud providers. There is a lot of information coming from everywhere, with a lack of standardization on how to collect this information. For example, Prometheus is used mostly as a standard for collecting metrics; however, in some cases, engineers found that Prometheus did not suit their needs. With the introduction of OpenTelemetry, Farfetch was able to standardize the collection of both metrics and traces, and enabled them to collect telemetry signals from services where signal collection had not previously been possible.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#can-you-describe-the-build-and-deployment-process-at-farfetch","title":"Can you describe the build and deployment process at Farfetch?","text":"<p>Farfetch uses Jenkins for CI/CD, and there is a separate team that manages this.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#what-observability-tooling-do-you-use","title":"What Observability tooling do you use?","text":"<p>Iris\u2019 team uses mostly open source tooling, alongside some in-house tooling created by her team. On the open source tooling front:</p> <ul> <li>Grafana is used for dashboards</li> <li>OpenTelemetry is used for emitting traces, and   Grafana Tempo is used as a tracing back-end</li> <li>Jaeger is still used in some cases for emitting   traces and as a tracing back-end, because some teams have not yet completely   moved to OpenTelemetry for instrumenting traces   (via Jaeger\u2019s implementation of the OpenTracing API).</li> <li>Prometheus Thanos (highly-available   Prometheus) is used for metrics collection and storage</li> <li>OpenTelemetry is also being used to collect metrics</li> </ul>"},{"location":"blog/2023/end-user-q-and-a-03/#tell-us-about-farfetchs-opentelemetry-journey","title":"Tell us about Farfetch\u2019s OpenTelemetry journey","text":"<p>Farfetch is a very Observability-driven organization, so when senior leadership floated the idea of bringing OpenTelemetry into the organization, it got overwhelming support across the organization. The biggest challenge faced around OpenTelemetry was around timing for its implementation; however, once work on OpenTelemetry started, everyone embraced it.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-did-you-and-your-team-enable-observability-through-opentelemetry","title":"How did you and your team enable Observability through OpenTelemetry?","text":"<p>By the time Iris joined Farfetch, most of the big struggles and challenges around Observability had passed. When Observability was first introduced within the organization, it was very new and unknown to many engineers there, and as with all new things, there is a learning curve.</p> <p>When Iris and her team took on the task of enabling OpenTelemetry across the organization, Observability as a concept had already been embraced. Their biggest challenge in bringing OpenTelemetry to Farfetch was making sure that engineers did not experience major disruptions to their work, while still benefiting from having OpenTelemetry in place. It helped that OpenTelemetry is compatible with many of the tools in their existing Observability stack, including Jaeger and Prometheus.</p> <p>Due to the enthusiasm, drive, and push that Iris and one of her co-workers, an architect at Farfetch, made for OpenTelemetry, Iris was proud to share that they are now using OpenTelemetry in production.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-long-did-it-take-your-team-to-get-opentelemetry-in-production","title":"How long did it take your team to get OpenTelemetry in production?","text":"<p>Iris and her team planned to start using OpenTelemetry in January 2023. This included initial investigation and information-gathering. By mid-March, they had their first pieces in production.</p> <p>They are not fully there yet:</p> <ul> <li>There is still a lot of reliance on Prometheus and Jaeger for generating   metrics and traces, respectively</li> <li>Not all applications have been instrumented with OpenTelemetry</li> </ul> <p>In spite of that, Iris and her team are leveraging the power of the OpenTelemetry Collector to gather and send metrics and traces to various Observability back-ends. Since she and her team started using OpenTelemetery, they started instrumenting more traces. In fact, with their current setup, Iris has happily reported that they went from processing 1,000 spans per second, to processing 40,000 spans per second!</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-are-you-collecting-your-traces-right-now","title":"How are you collecting your traces right now?","text":"<p>Traces are being collected through a combination of manual and auto instrumentation.</p> <p>Some applications are being manually instrumented through OpenTelemetry, and others are still instrumented using the [legacy OpenTracing using shims.</p> <p>The OpenTelemetry Operator is being implemented to auto-instrument Java and .NET code. Among other things, the OTel Operator supports injecting and configuring auto-instrumentation in .NET, Java, Python, and Node.js. Iris hopes that Go auto-instrumentation will be available in the near-future. To track progress of auto-instrumentation in Go, see OpenTelemetry Go Automatic Instrumentation.</p> <p>Although this will be a lengthy and time-consuming process, the team\u2019s goal is to have all applications instrumented using OpenTelemetry.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#what-kind-of-support-does-your-team-provide-for-manual-instrumentation","title":"What kind of support does your team provide for manual instrumentation?","text":"<p>By design, Iris and her team don\u2019t instrument other teams\u2019 code. Instead, they provide documentation and guidelines on manual instrumentation, and refer teams to the OpenTelemetry docs where applicable. They also have sessions with engineers to show them best practices around instrumenting their own code. It\u2019s a team sport!</p>"},{"location":"blog/2023/end-user-q-and-a-03/#can-you-share-your-experience-around-using-the-otel-operator","title":"Can you share your experience around using the OTel Operator?","text":"<p>The OTel Operator is only partially used in production, and is currently not available for everyone. Iris and her team really love the OTel Operator; however, it did take a bit of getting used to. Iris and her team found that there is a tight coupling between cert-manager and the OTel Operator. They were not able to use our own custom certificates, and they did not support cert-manager in their clusters, so they found it hard to use the Operator in our clusters. They solved this by submitting a PR -- opentelemetry-helm-charts PR #760!</p> <p>One of the things she loves about OpenTelemetry was that, when she was trying to troubleshoot an issue whereby Prometheus was not sending metrics to the Collector, and was therefore not able to create alerts from it. Then a colleague suggested using OpenTelemetry to troubleshoot OpenTelemetry.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#have-you-or-anyone-on-your-team-or-at-farfetch-started-playing-with-otel-logging","title":"Have you or anyone on your team or at Farfetch started playing with OTel Logging?","text":"<p>Iris has played around a bit with OTel logging, mostly consuming logs from a Kafka topic. This experiment has not included log correlation, but it is something that Iris would like to explore further.</p> <p>Since logs are not yet stable, Iris doesn\u2019t expect logging to go into production at Farfetch just yet. Farfetch has a huge volume of logs (more than traces), so they don\u2019t want to start converting to OTel logging until things are more stable.</p> <p>Note: some parts of OTel logs are stable. For details, see Specification Status Summary.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-are-you-collecting-the-metrics-signal","title":"How are you collecting the metrics signal?","text":"<p>Auto-instrumentation emits some OTLP metrics; however, the majority of metrics still come from Prometheus.</p> <p>The team currently uses the Prometheus Receiver to scrape metrics from Consul. Specifically, they use Consul to get the targets and the ports where to scrape them. The Receiver\u2019s scrape configs are the same as in Prometheus, so it was relatively easy to move from Prometheus to the Prometheus Receiver (lift and shift).</p> <p>They also plan to collect OTLP metrics from Kubernetes. This is facilitated by the Prometheus Receiver\u2019s support for the OTel Operator\u2019s Target Allocator.</p> <p>Prometheus is also still currently used for metrics collection in other areas, and will probably remain this way, especially when collecting metrics from virtual machines.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-many-kubenetes-clusters-are-you-observing","title":"How many Kubenetes clusters are you observing?","text":"<p>There are 100 Kubernetes clusters being observed, and thousands of virtual machines. Iris and her team are responsible for managing the OTel Operator across all of these clusters, and are therefore also trained in Kubernetes, so that they can maintain their stack on the clusters.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#have-you-dabbled-in-any-of-the-otel-experimental-features-in-kubernetes","title":"Have you dabbled in any of the OTel experimental features in Kubernetes?","text":"<p>This question is referring to the ability for Kubernetes components to emit OTLP traces which can then be consumed by the OTel Collector. For more info, see Traces For Kubernetes System Components. This feature is currently in beta, and was first introduced in Kubernetes 1.25.</p> <p>Iris and team have not played around with this beta feature.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#how-do-you-deploy-your-otel-collectors","title":"How do you deploy your OTel Collectors?","text":"<p>Because there are so many Kubernetes clusters, having a single OTel Collector would be a bottleneck in terms of load and single point of failure. The team currently has one OpenTelemetry Collector agent per Kubernetes cluster. The end goal is to replace those agents with the OTel Operator instead, which allows you to deploy and configure the OTel Collector and inject and configure auto-instrumentation.</p> <p>Everything is then sent to a central OTel Collector (i.e. an OTel Collector gateway) per data center, where data masking (using the transform processor, or redaction processor), data sampling (e.g. tail sampling processor or probabilistic sample processor), and other things happen. It then sends traces to Grafana Tempo.</p> <p>The central OTel Collector resides on another Kubernetes cluster that belongs solely to the Farfetch Observability team, which runs the Collector and other applications that belong to the team.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#what-happens-if-the-central-collector-fails","title":"What happens if the central Collector fails?","text":"<p>The team has fallback clusters, so that if a central Collector fails, the fallback cluster will be used in its place. The satellite clusters are configured to send data to the central Collector on the fallback cluster, so if the central cluster fails, the fallback cluster can be brought up without disruption to OTel data flow.</p> <p>Having autoscaling policies in place to ensure that the Collectors have enough memory and CPU to handle data loads also helps to keep the system highly available.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#what-were-some-of-the-challenges-you-experienced-in-deploying-the-otel-collector","title":"What were some of the challenges you experienced in deploying the OTel Collector?","text":"<p>The biggest challenge was getting to know the Collector and how to use it effectively. Farfetch relies heavily on auto-scaling, so one of the first things that the team did was to enable auto-scaling for the Collectors, and tweak settings to make sure that it could handle large amounts of data.</p> <p>The team also leaned heavily on OTel Helm charts, and on the OTel Community for additional support.</p> <p>Are you currently using any processors on the OTel Collector? \\ The team is currently experimenting with processors, namely for data masking (transform processor, or redaction processor), especially as they move to using OTel Logs, which will contain sensitive data that they won\u2019t want to transmit to their Observability back-end. They currently, however, are only using the batch processor.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#are-you-aware-of-any-teams-using-span-events","title":"Are you aware of any teams using span events?","text":"<p>A span event provides additional point-in-time information in a trace. It\u2019s basically a structured log within a span.</p> <p>Not at the moment, but it is something that they would like to explore. When the Observability team first started, there was little interest in tracing. As they started implementing OpenTelemetry and tracing, they have moved to make traces first-class citizens, and now it is piquing the interest of engineers, as they begin to see the relevance of traces.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#have-you-encountered-anyone-who-was-resistant-to-opentelemetry","title":"Have you encountered anyone who was resistant to OpenTelemetry?","text":"<p>Farfetch is a very Observability-driven culture, and the Observability team hasn\u2019t really encountered anyone who is against Observability or OpenTelemetry. Some engineers might not care either way, but they are not opposed to it, either.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#have-you-or-your-team-made-any-contributions-to-opentelemetry","title":"Have you or your team made any contributions to OpenTelemetry?","text":"<p>The team, led by the architect, has made a contribution recently to the OTel Operator around certificates. The OTel Operator relied on cert-manager for certificates, rather than custom certificates. They initially put in a feature request, but then decided to develop the feature themselves, and filed a pull request.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#audience-questions","title":"Audience Questions","text":""},{"location":"blog/2023/end-user-q-and-a-03/#how-much-memory-and-cpu","title":"How much memory and CPU?","text":"<p>When their Collector was processing around 30,000 spans per second, there were 4 instances of the Collector, using around 8GB memory.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#are-you-doing-any-correlation-between-metrics-data-trace-data-and-log-data","title":"Are you doing any correlation between metrics data, trace data, and log data?","text":"<p>This is something that is currently being explored. The team is exploring traces/metrics correlation (exemplars) through OpenTelemetry; however, they found that this correlation is accomplished more easily through their tracing back-end, Tempo.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#are-you-concerned-about-the-amount-of-data-that-you-end-up-producing-transporting-and-collecting-how-do-you-ensure-data-quality","title":"Are you concerned about the amount of data that you end up producing, transporting, and collecting? How do you ensure data quality?","text":"<p>This is not a concern, since the volume of data never changed, and the team knows that they can handle these large volumes. The team is simply changing how the data is being produced, transported, and collected. Iris also recognizes that the amount of trace data is gradually increasing; however, the data increase is gradual, so that the team can prepare itself to handle larger data volumes.</p> <p>The team is working very hard to ensure that they are getting quality data. This is especially true for metrics, where they are cleaning up metrics data to make sure that they are processing meaningful data. If a team decided to drastically increase the volume of metrics it emits, the Observability team is consulted beforehand, to ensure that the increase makes sense.</p> <p>Since trace volumes were initially a low lower, they did not need to concern themselves with trace sampling. Now that trace volume is increasing, they are keeping a close eye on things.</p> <p>The team is also focusing its attention on data quality and volume of logs, which means researching log processors to see which ones suit their needs. Ultimately, they will publish a set of guidelines for development teams to follow, and evangelize practices within the company.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#feedback","title":"Feedback","text":"<p>Iris and her team have had a very positive experience with OpenTelemetry and the OpenTelemetry community.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#documentation","title":"Documentation","text":"<p>Iris shared that the docs at times are not as clear as they could be, requiring some extra digging on the part of the engineer, to understand how a certain component works or is supposed to be configured. For example, she had a hard time finding documentation on Consul SD configuration for OpenTelemetry. That being said, Iris is hoping to contribute back to docs to help improve them.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#turnaround-time-on-prs","title":"Turnaround time on PRs","text":"<p>Iris and her team were pleasantly surprised by the quick turnaround time on getting their OTel Operator PR approved and merged.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#additional-resources","title":"Additional Resources","text":"<p>My conversation with Iris, in full, is available on YouTube.</p> <p>If anyone would like to continue the conversation with Iris, reach out to her in the #otel-user-research Slack channel!</p> <p>She will also be presenting at OTel in Practice on June 8th.</p>"},{"location":"blog/2023/end-user-q-and-a-03/#final-thoughts","title":"Final Thoughts","text":"<p>OpenTelemetry is all about community, and we wouldn\u2019t be where we are without our contributors, maintainers, and users. Hearing stories of how OpenTelemetry is being implemented in real life is only part of the picture. We value user feedback, and encourage all of our users to share your experiences with us, so that we can continue to improve OpenTelemetry. \u2763\ufe0f</p> <p>If you have a story to share about how you use OpenTelemetry at your organization, we\u2019d love to hear from you! Ways to share:</p> <ul> <li>Join the #otel-endusers channel on the   CNCF Community Slack</li> <li>Join our monthly   End Users Discussion Group calls</li> <li>Join our OTel in Practice sessions</li> <li>Sign up for one of our   monthly interview/feedback sessions</li> <li>Join the   OpenTelemetry group on LinkedIn</li> <li>Share your stories on the   OpenTelemetry blog</li> </ul> <p>Be sure to follow OpenTelemetry on Mastodon and Twitter, and share your stories using the #OpenTelemetry hashtag!</p>"},{"location":"blog/2023/exponential-histograms/","title":"Exponential Histograms","text":"<p>Previously, in [Why Histograms?][] and [Histograms vs Summaries][], I went over the basics of histograms and summaries, explaining the tradeoffs, benefits, and limitations of each. Because they're easy to understand and demonstrate, those posts focused on so-called explicit bucket histograms. The exponential bucket histogram, also referred to as native histogram in Prometheus, is a low-cost, efficient alternative to explicit bucket histograms. In this post, I go through what they are, how they work, and the problems they solve that explicit bucket histograms struggle with.</p>"},{"location":"blog/2023/exponential-histograms/#types-of-histograms","title":"Types of histograms","text":"<p>For the purposes of this blog post, there are two major types of histograms: explicit bucket histograms and exponential bucket histograms. In previous posts, I've focused on what OpenTelemetry calls explicit bucket histograms and Prometheus simply refers to as histograms. As the name implies, an explicit bucket histogram has each bucket configured explicitly by either the user or some default list of buckets. Exponential histograms work by calculating bucket boundaries using an exponential growth function. This means each consecutive bucket is larger than the previous bucket and ensures a constant relative error for every bucket.</p>"},{"location":"blog/2023/exponential-histograms/#exponential-histograms","title":"Exponential histograms","text":"<p>In OpenTelemetry exponential histograms, buckets are calculated automatically from an integer scale factor, with larger scale factors offering smaller buckets and greater precision. It is important to select a scale factor that is appropriate for the distribution of values you are collecting in order to minimize error, maximize efficiency, and ensure the values being collected fit in a reasonable number of buckets. In the next few sections, I'll go over the scale and error calculations in detail.</p>"},{"location":"blog/2023/exponential-histograms/#scale-factor","title":"Scale factor","text":"<p>The most important and most fundamental part of an exponential histogram is also one of the trickiest to understand, the scale factor. From the scale factor, bucket boundaries, and by extension resolution, range, and error rates, are derived. The first step is to calculate the histogram base.</p> <p>The base is a constant derived directly from the scale using the equation <code>2 ^ (2 ^ -scale)</code>. For example, given a scale of 3, the base can be calculated as <code>2^(2^-3) ~= 1.090508</code>. Because the calculation depends on the power of the negative scale, as the scale grows, the base shrinks and vice versa. As will be shown later, this is the fundamental reason that a greater scale factor results in smaller buckets and a higher resolution histogram.</p>"},{"location":"blog/2023/exponential-histograms/#bucket-calculation","title":"Bucket calculation","text":"<p>Given a scale factor and its resulting base, we can calculate every possible bucket in the histogram. From the base, the upper bound of each bucket at index <code>i</code> is defined to be <code>base ^ (i + 1)</code>, with the first bucket lower boundary of 1. Because of this, the upper boundary of the first bucket at index 0 is also exactly the base. For now, we will only consider nonnegative indices, but negative indexed buckets are also possible and define all buckets between 0 and 1. Keeping with our example using a scale of 3 and resulting base of 1.090508, the third bucket at index 2 has an upper bound of <code>1.090508^(2+1) = 1.29684</code>. The following table shows upper bounds for the first 10 buckets of a few different scale factors:</p> index scale -1 scale 0 scale 1 scale 3 -1 1 1 1 1 0 4 2 1.4142 1.0905 1 16 4 2 1.1892 2 64 8 2.8284 1.2968 3 256 16 4 1.4142 4 1024 32 5.6569 1.5422 5 4096 64 8 1.6818 6 16384 128 11.3137 1.8340 7 65536 256 16 2 8 262144 512 22.6274 2.1810 9 1048576 1024 32 2.3784 <p>I've bolded some of the values here to show an important property of exponential histograms called perfect subsetting.</p>"},{"location":"blog/2023/exponential-histograms/#perfect-subsetting","title":"Perfect subsetting","text":"<p>In the chart above, some of the bucket boundaries are shared between histograms with differing scale factors. In fact, each time the scale factor increases by 1, exactly 1 boundary is inserted between each existing boundary. This feature is called perfect subsetting because each set of boundaries for a given scale factor is a perfect subset of the boundaries for any histogram with a greater scale factor.</p> <p>Because of this, histograms with differing scale factors can be normalized to whichever has the lesser scale factor by combining neighboring buckets. This means that histograms with different scale factors can still be combined into a single histogram with exactly the precision of the least precise histogram being combined. For example, histogram A with scale 3 and histogram B with scale 2 can be combined into a single histogram C with scale 2 by first summing each pair of neighboring buckets in A to form histogram A' with scale 2. Then, each bucket in A' is summed with the corresponding bucket of the same index in B to make C.</p>"},{"location":"blog/2023/exponential-histograms/#relative-error","title":"Relative Error","text":"<p>A histogram does not store exact values for each point, but represents each point as a bucket consisting of a range of possible points. This can be thought of as being similar to lossy compression. In the same way the it is impossible to recover an exact source image from a compressed JPEG, it is impossible to recover the exact input data set from a histogram. The difference between the input data and the estimated reconstruction of the data is the error of the histogram. It is important to understand histogram errors because it affects \u03c6-quantile estimation and may affect how you define your SLOs.</p> <p>The relative error for a histogram is defined as half the bucket width divided by the bucket midpoint. Because the relative error is the same across all buckets, we can use the first bucket with the upper bound of the base to make the math easy. An example is shown below using a scale of 3.</p> <pre><code>scale = 3\n# For base calculation, see above\nbase  = 1.090508\n\nrelative error = (bucketWidth / 2) / bucketMidpoint\n               = ((upper - lower) / 2) / ((upper + lower) / 2)\n               = ((base - 1) / 2) / ((base + 1) / 2)\n               = (base - 1) / (base + 1)\n               = (1.090508 - 1) / (1.090508 + 1)\n               = 0.04329\n               = 4.329%\n</code></pre> <p>For more information regarding histogram errors, see OTEP 149 and the specification for exponential histogram aggregations.</p>"},{"location":"blog/2023/exponential-histograms/#choosing-a-scale","title":"Choosing a scale","text":"<p>Because increasing the scale factor increases the resolution and decreases the relative error, it may be tempting to choose a large scale factor. After all, why would you want to introduce error? The answer is that there is a positive relationship between the scale factor and the number of buckets required to represent values within a specified range. For example, with 160 buckets (the OpenTelemetry default), histogram A with a scale factor of 3 can represent values between 1 and about 1 million; histogram B with a scale of 4 the same number of buckets would only be able to represent values between about 1 and about 1000, albeit at half the relative error. To represent the same range of values as A with B, twice as many buckets are required; in this case 320.</p> <p>This brings me to the first most important point of choosing a scale, data contrast. Data contrast is how you describe the difference in scale between the smallest possible value x and the largest possible value y in your dataset and is calculated as the constant multiple c such that <code>y = c * x</code>. For example, if your data is between 1 and 1000 milliseconds, your data contrast is 1000. If your data is between 1 kilobyte and 1 terabyte, your data contrast is 1,000,000,000. Data contrast, scale, and the number of buckets are all interlinked such that if you have 2, you can calculate the third.</p> <p>Fortunately, if you are using OpenTelemetry, scale choice is largely done for you. In OpenTelemetry, you configure a maximum scale (default 20) and a maximum size (default 160), or number of buckets, in the histogram. The histogram is initially assumed have the maximum scale. As additional data points are added, the histogram will rescale itself down such that the data points always fit within your maximum number of buckets. The default of 160 buckets was chosen by the OpenTelemetry authors to be able to cover typical web requests between 1ms and 10s with less than 5% relative error. If your data has less contrast, your error will be even less.</p>"},{"location":"blog/2023/exponential-histograms/#negative-or-zero-values","title":"Negative or zero values","text":"<p>For the bulk of this post we have ignored zero and negative values, but negative buckets work much the same way, growing larger as the buckets get further from zero. All of the math and explanation above applies in the same way to negative values, but they should be substituted for their absolute values, and upper bounds for buckets are lower bounds (or upper absolute value bounds). Zero values, or values with an absolute value less than a configurable threshold, go into a special zero bucket. When merging histograms with differing zero thresholds, the larger threshold is taken and any buckets with absolute value upper bounds within the zero threshold are added to the zero bucket and discarded.</p>"},{"location":"blog/2023/exponential-histograms/#opentelemetry-and-prometheus","title":"OpenTelemetry and Prometheus","text":"<p>Compatibility between OpenTelemetry and Prometheus is probably a topic large enough for its own post. For now I will just say that for all practical purposes, OpenTelemetry exponential histograms are 1:1 compatible with Prometheus native histograms. Scale calculations, bucket boundaries, error rates, zero buckets, etc are all the same. For more information, I recommend you watch this talk given by Ruslan Vovalov and Ganesh Vernekar: Using OpenTelemetry\u2019s Exponential Histograms in Prometheus</p> <p>A version of this article was [originally posted][] to the author's blog.</p> <p>[Why Histograms?]: {{% relref \"why-histograms\" %}} [Histograms vs Summaries]: {{% relref \"histograms-vs-summaries\" %}}</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2023/http-conventions-stability/","title":"Final push to HTTP semantic convention stability","text":"<p>The OpenTelemetry community is beginning the final push to declare HTTP tracing and metrics semantic conventions stable!</p> <p>Following the recently proposed Semantic Convention Process, the HTTP semantic convention stability working group will meet three times a week for the next six weeks (starting January 30) to work through the remaining list of issues. This group will submit spec PRs for any changes that need to be made prior to declaring the HTTP semantic conventions stable.</p> <p>Once this is done, the community will have four weeks to review and provide feedback on the final set of PRs submitted by the working group.</p> <p>And finally, the working group and spec approvers will have two weeks to clean up and merge the final spec PRs, and mark the HTTP semantic conventions as stable.</p> <p>If you are interested in participating in the working group, please join the meetings starting Monday, January 30 at 3pm Pacific Time, and continuing for six weeks on Mondays, Wednesdays and Fridays:</p> <ul> <li>Mon 3-3:30pm Pacific Time</li> <li>Wed 3-3:30pm Pacific Time</li> <li>Fri 9:30-10am Pacific Time</li> </ul> <p>See the OpenTelemetry calendar for Zoom link details.</p>"},{"location":"blog/2023/kubecon-eu/","title":"Join us for OpenTelemetry Talks and Activities at KubeCon EU 2023","text":"<p>The OpenTelemetry project maintainers, members of the governance committee, and technical committee are excited to be at KubeCon EU in Amsterdam from April 18 - 21, 2023!</p> <p>Read on to learn about all the things related OpenTelemetry during KubeCon.</p>"},{"location":"blog/2023/kubecon-eu/#kubecon-talks-and-maintainer-sessions","title":"KubeCon Talks and Maintainer Sessions","text":"<ul> <li>Jaeger: The Future with OpenTelemetry and Metrics   by Pavol Loffay, Red Hat &amp; Jonah Kowall, Aiven Wednesday, April 19 \u2022   11:55 - 12:30</li> <li>Using OpenTelemetry for Application Security, with a Real Life Example   by Ron Vider, Oxeye Wednesday, April 19 \u2022 11:55 - 12:30</li> <li>Understand Systems with OpenTelemetry: A Hybrid Telemetry Data Backend   by Ran Xu, Huawei &amp; Xiaochun Yang, Northeastern University Wednesday,   April 19 \u2022 14:30 - 15:05</li> <li>OTel Me About Metrics: A Metrics 101 Crash Course   by Reese Lee, New Relic Wednesday, April 19 \u2022 17:25 - 18:00</li> <li>OpenTelemetry: Using Unified Semantics to Drive Insights + Project Update   by Morgan McLean, Splunk, Alolita Sharma, Apple, Daniel Dyla, Dynatrace, &amp; Ted   Young, Lightstep Thursday, April 20 \u2022 16:30 - 17:05</li> <li>Connected Observability Pipelines in the OpenTelemetry Collector   by Daniel Jaglowski, observIQ Friday, April 21 \u2022 11:55 - 12:30</li> <li>Tutorial: Exploring the Power of OpenTelemetry on Kubernetes   by Pavol Loffay, Benedikt Bongartz &amp; Yuri Oliveira Sa, Red Hat, Severin   Neumann, Cisco &amp; Kristina Pathak, LightStep Friday, April 21 \u2022 16:00 -   17:30</li> </ul>"},{"location":"blog/2023/kubecon-eu/#co-located-events","title":"Co-located Events","text":"<p>Come network with OpenTelemetry maintainers and core contributors during the OpenTelemetry project meeting, on Tuesday April 18, 2023 from 16:00 - 17:00. You can attend with a standard in-person pass.</p> <p>Observability Day fosters collaboration, discussion, and knowledge sharing of cloud-native observability projects. This event will be held on April 18, 2023 from 9:00 - 17:00. There will be several sessions on OpenTelemetry as well.</p> <p> IMPORTANT access note: You need an in-person all-access pass for on-site access to Observability Day. For details, see KubeCon registration. If you have a virtual ticket, you will be able to follow Observability Day through a live stream.</p>"},{"location":"blog/2023/kubecon-eu/#opentelemetry-project-booth","title":"OpenTelemetry Project Booth","text":"<p>Drop by and say Hi! at the OpenTelemetry project booth in the KubeCon EU Project Pavilion. If you\u2019re lucky, you may even pick up some OpenTelemetry swag!</p> <p>You will find us in the Solutions Showcase in Hall 5, Kiosk Number 20.</p> <p>Pavilion hours are as follows:</p> <ul> <li>Wednesday, April 19: 10:30 \u2013 21:00 (includes KubeCrawl + CloudNativeFest from   18:00 \u2013 21:00)</li> <li>Thursday, April 20: 10:30 \u2013 17:30</li> <li>Friday, April 21: 10:30 \u2013 14:30</li> </ul> <p>You can help us improve the project by sharing your thoughts and feedback about your OpenTelemetry adoption, implementation, and usage! We also invite you to fill out our community survey. We will create action items from your comments as appropriate. Check #otel-user-research in CNCF's Slack instance for survey results and action item updates to come after KubeCon EU.</p> <p>Come join us to listen, learn, and get involved in OpenTelemetry.</p> <p>See you in Amsterdam!</p>"},{"location":"blog/2023/lambda-release/","title":"OpenTelemetry Updates Lambda Support","text":"<p>The Functions-as-a-Service (FaaS) SIG is incredibly excited to announce that the release of OpenTelemetry Lambda layers, and associated documentation on how to monitor Amazon Web Services (AWS) Lambdas.</p>"},{"location":"blog/2023/lambda-release/#otel-faas-repackaged","title":"OTel FaaS repackaged","text":"<p>If you've been monitoring Lambdas using OTel for a while now, you may be slightly confused by this announcement. You might think something like: OTel has had a repo for Lambda layers and they've been available on AWS for years.</p> <p>You're totally correct. Rest assured, we're not reinventing the wheel. However, there are some pre-existing problems that may impact users:</p> <ul> <li>The OTel Lambda layers were only released as part of the   AWS Distribution for OTel (ADOT), and the   community had limited control over releases which meant a delay getting new   features and fixes delivered.</li> <li>The layers available on AWS combined the Collector and auto-instrumentation   capabilities into a single package, which contributed to performance   degradations and limited user choice.</li> <li>There wasn't official OTel guidance on how to monitor Lambdas and no single   source of truth for OTel users to reference.</li> </ul> <p>The FaaS SIG has addressed the above-mentioned shortcomings:</p> <ul> <li>We have written new Github Actions to release the Lambda layers ourselves,   thus empowering the community to make its own release decisions.</li> <li>Separated the Collector and instrumentation layers to give users options when   instrumenting their Lambdas. We now offer a standalone Lambda layer for the   Collector alongside auto-instrumentation layers for JavaScript, Java, and   Python.</li> <li>Added official community Lambda documentation to the OTel website under the   new FaaS section.</li> </ul>"},{"location":"blog/2023/lambda-release/#what-next","title":"What next","text":"<p>Moving forward, the FaaS SIG plans to: enhance the documentation, add auto-instrumentation for other Cloud vendors like Azure and GCP (tentative), enhancing the existing Lambda assets, and improving OpenTelemetry performance for Function specific scenarios.</p>"},{"location":"blog/2023/lambda-release/#get-involved","title":"Get Involved","text":"<p>Interested in learning more, or if you'd like to help: join us in a SIG meeting (every Tuesday at 12 pm PST), or join us on Slack at #otel-faas.</p>"},{"location":"blog/2023/new-apac-meetings/","title":"New APAC Collector-SIG meetings","text":"<p>As the collector community grows worldwide, having the ability to meet with each other is a challenge. To help more APAC maintainers and contributors connect, we have created two new meetings times:</p> <ul> <li>1st Wednesday is EU-APAC friendly</li> <li>3rd Wednesday is NA-APAC friendly</li> </ul>"},{"location":"blog/2023/new-apac-meetings/#meeting-times","title":"Meeting times","text":"UTC\u221208:00 (PST) UTC -05:00 (EST) UTC +01:00 (CET) UTC +08:00 (China) UTC +10:00 (Sydney) EU-APAC 00:00 03:00 09:00 16:00 19:00 NA-APAC 15:00 18:00 00:00 07:00 10:00 <p>To stay up to date with these times, subscribe to the community calendar.</p> <p>We look forward to seeing more of you join the Collector community at these new meetings!</p>"},{"location":"blog/2023/otel-in-focus-01/","title":"OpenTelemetry in Focus, January 2023","text":"<p>Welcome to the first edition of OpenTelemetry In Focus! This blog is intended to be an overview of important releases, roadmap updates, and community news. This series will be focusing on our core components, such as the specification, data format, tools, and most popular API/SDKs.</p> <p>Are you a maintainer with something you\u2019d like featured here? Get in touch with me via email, or on the CNCF Slack, #otel-comms channel.</p>"},{"location":"blog/2023/otel-in-focus-01/#releases-and-updates","title":"Releases and Updates","text":"<p>New year, new code! The following repositories have released new versions this month. For more details on what\u2019s in each release, be sure to check out the full release notes.</p> <ul> <li>Specification v.1.17.0   has been released! This includes deprecation notices for the Jaeger exporter,   histogram data model stability, changes to semantic conventions, and several   other changes.</li> <li>Go v1.12.0/v0.35.0   celebrates an important release of updated semantic conventions and metric   instruments, along with a handful of bug fixes and other important changes.</li> <li>JavaScript has   released v1.4.0 of the API, v.1.9.0 of core, and v0.35.0 of experimental   packages! These releases include important bug fixes in tracing around clock   drift, as well as other deprecations and enhancements.</li> <li>Java v1.22.0   includes several fixes and enhancements for exporters, as well as other   ease-of-use and correctness issues. In addition,   Java Agent v1.22.1   has been released to align with the core API and SDK, in addition to new   instrumentations for Spring Web MVC, JMS 3.0 (Jakarta), and Spring JMS 6.0.</li> <li>Operator v0.68.0   brings with it a new OpAMP Bridge service,and a fix to allow for deployment to   OpenShift clusters, along with other bug fixes.</li> <li>Collector v1.0.0 (RC4)   and   Collector Contrib v0.70.0   have been released with a significant amount of changes, including support for   connectors in the Collector Builder.</li> <li>Demo v1.3.0   has been released with support for metric exemplars, enhanced resource   detection, and updates to OpenTelemetry API and SDKs.</li> </ul>"},{"location":"blog/2023/otel-in-focus-01/#project-updates","title":"Project Updates","text":"<p>Over the past few months, through community discussions both in-person and online, a new public roadmap has been created and published! This roadmap isn\u2019t meant to be a set-in-stone list of priorities, but more of a guide to our priorities and prioritization.</p> <p>Interested in AWS Lambda, or other Functions-as-a-Service workloads, and how to emit OpenTelemetry data from them? Our FAAS Working Group has restarted in order to work on this problem. Join a meeting, or check out their notes, for more information.</p> <p>The End User Working Group has published a summary of their discussions for the month. If you\u2019re a user of OpenTelemetry, these meetings are a great place to get connected with your peers and discuss how you\u2019re using the project.</p>"},{"location":"blog/2023/otel-in-focus-01/#news-and-upcoming-events","title":"News and Upcoming Events","text":"<p>We\u2019re proud to support Observability Day Europe as part of KubeCon EU 2023. If you\u2019re planning to be in Amsterdam for KubeCon, be sure to come a day early and meet up with OpenTelemetry contributors and maintainers!</p>"},{"location":"blog/2023/otel-in-focus-02/","title":"OpenTelemetry in Focus, February 2023","text":"<p>Welcome to this month\u2019s edition of OpenTelemetry in Focus! It might be cold and snowy in much of the Northern Hemisphere, but that hasn\u2019t frozen our progress. Read on for an overview of new releases, announcements, and other important updates.</p> <p>Are you a maintainer with something you\u2019d like featured here? Get in touch with me via email, or on the CNCF Slack #otel-comms channel.</p>"},{"location":"blog/2023/otel-in-focus-02/#releases-and-updates","title":"Releases and Updates","text":"<p>Here are the latest updates from our core repositories.</p>"},{"location":"blog/2023/otel-in-focus-02/#specification","title":"Specification","text":"<p>v1.18 has been released, with a batch of semantic convention updates and clarifications on mapping and converting between Prometheus and OpenTelemetry Metrics.</p>"},{"location":"blog/2023/otel-in-focus-02/#collector-and-contrib","title":"Collector and contrib","text":"<p>v0.72 have been released with several major changes to be aware of:</p> <ul> <li>The minimum supported Golang version is now 1.19</li> <li>The host metrics receiver has removed deprecated metrics for process memory.</li> <li>The promtail receiver has been removed from collector-contrib.</li> <li>The Jaeger exporters are now deprecated, to be removed in a future release.</li> <li>Connectors   have been added! These are components that act as exporters and receivers,   allowing you to route data through pipelines. Please see the component docs   for more information.</li> <li>Many bug fixes and enhancements.</li> </ul>"},{"location":"blog/2023/otel-in-focus-02/#go","title":"Go","text":"<p>v1.14 has been released. This is the last release to support Go 1.18; 1.19 will be required in the future. Semantic conventions have been updated, resulting in changes to constant and function names. Finally, there\u2019s a variety of bug fixes and other small changes.</p>"},{"location":"blog/2023/otel-in-focus-02/#java","title":"Java","text":"<p>v1.23 has been released, bringing with it stable base2 exponential histogram aggregations and significant metrics refactoring. Semantic convention updates, improvements to SDK shutdown, and several enhancements to the SDK extensions are also in this release. Java Instrumentation has been updated as well, most notably changing HTTP span names to reflect updated semantic conventions.</p>"},{"location":"blog/2023/otel-in-focus-02/#php","title":"PHP","text":"<p>v1 beta was announced at the end of January. The PHP SIG is looking forward to your feedback. In addition, the Communications SIG is planning a release of new documentation for PHP soon.</p>"},{"location":"blog/2023/otel-in-focus-02/#python","title":"Python","text":"<p>v1.16 has been released with deprecations to Jaeger exporters, several performance improvements and bug fixes, and changes to Prometheus export.</p>"},{"location":"blog/2023/otel-in-focus-02/#net","title":".NET","text":"<p>v1.4 removes several deprecated extension methods.</p> <p>As always, this is just a snapshot of important changes and improvements across the core projects. Make sure you thoroughly read the release notes when upgrading your OpenTelemetry dependencies.</p>"},{"location":"blog/2023/otel-in-focus-02/#project-updates","title":"Project Updates","text":"<p>The Outreachy project is looking for participants. This is an annual program that connects new open source contributors with small, self-contained projects that they can work on. There are also opportunities to volunteer to mentor these contributors. Read the blog for more information!</p> <p>The Collector SIG will be starting new APAC-friendly meetings to support contributors and maintainers worldwide.</p> <p>Our End-User Working Group has written up a Q&amp;A about using OpenTelemetry with GraphQL.</p>"},{"location":"blog/2023/otel-in-focus-02/#news-and-upcoming-events","title":"News and Upcoming Events","text":"<p>OpenTelemetry maintainers and contributors will be in attendance at Observability Day Europe on April 18th, 2023, as part of KubeCon/CloudNativeCon Europe 2023.</p>"},{"location":"blog/2023/otel-in-focus-03/","title":"OpenTelemetry in Focus, March 2023","text":"<p>Welcome to this month\u2019s edition of OpenTelemetry in Focus! It's been another busy month in the OpenTelemetry community, with some big announcements and new releases from our core repositories. I've also put together an overview of some blog, website, and project highlights - give it a look, and tell me what you think.</p> <p>Are you a maintainer with something you\u2019d like featured here? Get in touch with me via email, or on the CNCF Slack #otel-comms channel.</p>"},{"location":"blog/2023/otel-in-focus-03/#releases-and-updates","title":"Releases and Updates","text":"<p>Here are the latest updates from our core repositories.</p>"},{"location":"blog/2023/otel-in-focus-03/#specification","title":"Specification","text":"<p>Version 1.19 has been released with a number of important udates.</p> <ul> <li>OTLP/JSON has been declared stable.</li> <li>To clarify its purpose, the Logs API has been renamed to the Logs Bridge API.</li> <li>Semantic convention updates.</li> </ul>"},{"location":"blog/2023/otel-in-focus-03/#collector-and-contrib","title":"Collector and contrib","text":"<p>Version 0.74/v1.0-rc8 has been released for the collector, resulting in a new operator version as well. Highlights include:</p> <ul> <li>Connectors are enabled by default.</li> <li>The <code>spanmetricsprocessor</code> has been deprecated in favor of the   <code>spanmetricsconnector</code>. Other changes have been made to the behavior of this   component.</li> <li>A new receiver for CloudFlare logs has been added.</li> <li>Many bugfixes and enhancements.</li> </ul>"},{"location":"blog/2023/otel-in-focus-03/#go","title":"Go","text":"<p>Version v1.15.0-rc.2 has been released. Version 1.15 will ship with Metrics v1 support, and its associated stability guarantees. Other highlights of the release candidate include:</p> <ul> <li>Support for global meter providers.</li> <li>Exemplar support added for metric data.</li> <li>Several optimizations, bugfixes, and removals/deprecations.</li> </ul>"},{"location":"blog/2023/otel-in-focus-03/#java","title":"Java","text":"<p>Version 1.24.0 of the Java SDK has been released, featuring several optimizations and bugfixes to the metrics SDK.</p> <p>In addition, the Java Instrumentation package has been updated to 1.24 as well, featuring several new instrumentations and fixes:</p> <ul> <li>Apache Pulsar and Jodd-Http can now be instrumented automatically via the   agent.</li> <li>Ktor and Spring Webflux libraries can be instrumented using the library.</li> <li>Improvements to the RxJava2, Cassandra, Spring Boot, and other instrumentation   packages.</li> </ul>"},{"location":"blog/2023/otel-in-focus-03/#python","title":"Python","text":"<p>Version 1.17 has been released with a handful of fixes and improvements, most notably support for exponential histograms!</p>"},{"location":"blog/2023/otel-in-focus-03/#project-updates","title":"Project Updates","text":"<p>The proposal to merge the Elastic Common Schema (ECS) into OpenTelemetry has been passed! This is a big step towards reducing competing standards and aligning the open source observability ecosystem around a common data model.</p> <p>A proposal to donate OpenTelemetry Instrumentation for Android has been made. You can follow along with the discussion in the linked issue -- exciting to see more options for client observability in OpenTelemetry!</p> <p>We're on a mission to reduce the number of unanswered OpenTelemetry questions on Stack Overflow. Be sure to check out the Stack Overflow Watch in the Monthly Highlights to learn how you can help, and get some cool swag in the process.</p> <p>The Logs Bridge Specification is in the final stretch before merge. If you'd like to help proofread, or have any comments, now's the time to get involved!</p>"},{"location":"blog/2023/otel-in-focus-03/#news-and-upcoming-events","title":"News and Upcoming Events","text":"<p>The schedule for KubeCon EU is up, and there's a lot of OpenTelemetry to go around! We'll also be at Observability Day EU -- which will be live-streamed, including project updates and a panel discussion featuring several OpenTelemetry maintainers. Will you be there in-person? Find me (I'm the guy with the hat) and say hi -- I'd love to meet you (and I'll have some stickers to give away). We'll also have a project booth, so swing by -- and stay tuned for another blog detailing our full involvement at KubeCon EU.</p>"},{"location":"blog/2023/otel-in-focus-04/","title":"OpenTelemetry in Focus, April 2023","text":"<p>Welcome to this month\u2019s edition of OpenTelemetry in Focus! It's been another busy month in the OpenTelemetry community, with some big announcements and new releases from our core repositories. I'll also be sharing some highlights from OpenTelemetry at KubeCon EU, which was a blast. Can't wait for Chicago this fall!</p> <p>Are you a maintainer with something you\u2019d like featured here? Get in touch with me via email, or on the CNCF Slack #otel-comms channel.</p>"},{"location":"blog/2023/otel-in-focus-04/#releases-and-updates","title":"Releases and Updates","text":"<p>Here are the latest updates from some of our core repositories.</p>"},{"location":"blog/2023/otel-in-focus-04/#specification","title":"Specification","text":"<p>Version 1.20 has been released, and it's a big one!</p> <p>First, OpenTelemetry Protocol has been declared stable! Second, we've started a process to converge the Elastic Common Schema with OpenTelemetry Semantic Conventions. What does this mean? At a high level, you can expect to see that semantic conventions will split out of the specification as we proceed towards aligning our standards. Please be on the look out for more information.</p> <p>Other changes include:</p> <ul> <li>Changes to span and metric SDK details.</li> <li>Clean up the log bridge API.</li> <li>Key stability work for existing Semantic Conventions.</li> <li>Breaking change to <code>http.server.active_requests</code> metric; The   <code>http.status_code</code> attribute is no longer present.</li> </ul>"},{"location":"blog/2023/otel-in-focus-04/#collector-and-contrib","title":"Collector and contrib","text":"<p>Version 0.76.1/v1.0-rcv0011 has been released for the collector. The operator has been updated to v0.75.0, adding support for feature gates in the operator.</p> <p>This release includes several bug fixes and improvements to connectors, along with a breaking change to the <code>confmap</code> component.</p>"},{"location":"blog/2023/otel-in-focus-04/#go","title":"Go","text":"<p>Version v1.15.0 has been released! This marks the official release of OpenTelemetry Metrics v1 in Go. Please check out the full release notes, as there are several important changes and renamings, especially if you're using metrics.</p>"},{"location":"blog/2023/otel-in-focus-04/#java","title":"Java","text":"<p>Version 1.25.0 of the Java SDK has been released, with several bugfixes and improvements. Please note that this includes a change to exponential bucket histograms, please see the release notes for details if you rely on automatic configuration of histograms.</p> <p>In addition, the Java Instrumentation package has been updated to 1.25.1 as well. Highlights include:</p> <ul> <li>New instrumentation added for R2DBC, JFR streaming metrics, and ZIO 2.0</li> <li>Passwords no longer emitted from db.user when using JDBC instrumentation.</li> <li>Apache HTTP Client library now emits client metrics as well.</li> <li>Alignment with semantic conventions.</li> </ul> <p>There's much more -- be sure to check out the release notes!</p>"},{"location":"blog/2023/otel-in-focus-04/#project-updates","title":"Project Updates","text":"<p>KubeCon EU saw over ten thousand cloud-native developers gather in Amsterdam, and a lot of you stopped by the OpenTelemetry booth to say hi! Hopefully some of you got your hands on our limited-edition KubeCon stickers... if not, well, there'll be more limited edition stickers. Just not for KubeCon, because it's come and gone.</p> <p>There was a lot of great feedback that we're excited to tackle as a project over the coming months, including:</p> <ul> <li>Improving discoverability of components for the collector.</li> <li>Increasing responsiveness to PR's and issues.</li> <li>Finishing up the Logging Bridge API and getting logs to stability.</li> </ul> <p>There were also a lot of great talks from the Observability community at KubeCon, including at Observability Day Europe. Go check it out if you have some time, there's some really interesting real-world examples in there of how people are using OpenTelemetry!</p>"},{"location":"blog/2023/otel-in-focus-04/#news-and-upcoming-events","title":"News and Upcoming Events","text":"<p>OpenCensus is being sunset in July 2023. Once this has concluded, our initial goal of OpenTelemetry as a single replacement for OpenTracing and OpenCensus will have been realized!</p>"},{"location":"blog/2023/otel-in-focus-05/","title":"OpenTelemetry in Focus, May 2023","text":"<p>Welcome back to OpenTelemetry in Focus for May, 2023! The sun is shining, the sky is blue, and it's time to run down the latest updates from the OpenTelemetry project!</p> <p>Are you a maintainer with something you\u2019d like featured here? Get in touch with me via email, or on the CNCF Slack #otel-comms channel.</p>"},{"location":"blog/2023/otel-in-focus-05/#releases-and-updates","title":"Releases and Updates","text":"<p>Here are the latest updates from some of our core repositories.</p>"},{"location":"blog/2023/otel-in-focus-05/#specification","title":"Specification","text":"<p>Version 1.21 has been released with a variety of important changes, including:</p> <ul> <li>Log Bridge API and SDK have been marked stable.</li> <li>Add groundwork for file-based configuration of OpenTelemetry.</li> <li>OpenCensus compatibility specification marked stable.</li> </ul>"},{"location":"blog/2023/otel-in-focus-05/#collector","title":"Collector","text":"<p>Version 0.78.0 has been released, along with 0.77. These releases address several important core issues, including:</p> <ul> <li>Batch processor can now batch by attribute keys.</li> <li>Initial support for internal OpenTelemetry SDK usage.</li> <li>Default queue size for exporters reduced from 5000 to 1000.</li> <li>Feature gate added to disable internal metrics with high cardinality.</li> </ul> <p>In addition, collector-contrib has been updated with several changes and enhancements. The Operator now supports Golang &amp; Apache HTTP server auto-instrumentation in addition to Python, Java, Node.JS, and .NET.</p>"},{"location":"blog/2023/otel-in-focus-05/#go","title":"Go","text":"<p>Version 1.16.0/0.39.0 marks the stable release of the OpenTelemetry Metric API in Go.</p>"},{"location":"blog/2023/otel-in-focus-05/#java","title":"Java","text":"<p>Version 1.26 is the Release Candidate for the Log Bridge. This release enables log appenders to bridge logs from existing log frameworks, allowing users to configure the Log SDK and dictate how logs are processed and exported. In addition, opentelemetry-opentracing-shim is now stable, as well as other bug fixes and improvements.</p> <p>Java Instrumentation includes instrumentation support for vertx-sql-client, as well as several bug fixes.</p>"},{"location":"blog/2023/otel-in-focus-05/#javascript","title":"Javascript","text":"<p>Version 1.13 has been released, adding support for gRPC log export. In addition, a couple bugs have been fixed.</p>"},{"location":"blog/2023/otel-in-focus-05/#python","title":"Python","text":"<p>Version 1.18 adds a new feature that allows histogram aggregation to be set using an environment variable, as well as various bug fixes related to resource detection, exporting, and suppressing instrumentation.</p> <ul> <li>Add ability to select histogram aggregation with an environment variable</li> <li>Move protobuf encoding to its own package</li> <li>Add experimental feature to detect resource detectors in auto instrumentation</li> <li>Fix exporting of ExponentialBucketHistogramAggregation from   opentelemetry.sdk.metrics.view</li> <li>Fix headers types mismatch for OTLP Exporters</li> </ul>"},{"location":"blog/2023/otel-in-focus-05/#net","title":".NET","text":"<p>Version 1.5.0-rc1 includes many bug fixes across a variety of packages.</p>"},{"location":"blog/2023/otel-in-focus-05/#project-and-community-updates","title":"Project and Community Updates","text":""},{"location":"blog/2023/otel-in-focus-05/#youtube-and-meeting-recordings","title":"YouTube and Meeting Recordings","text":"<p>Recently, you may have noticed that the OpenTelemetry YouTube channel stopped publishing meeting recordings. In the future, you will be able to access recordings, transcripts, and chat history for meetings through the Zoom cloud. Please see this issue for more information.</p> <p>We'll be publishing more curated content on the OpenTelemetry channel starting in June, including interviews with end-users and more. Please keep an eye on the OpenTelemetry Blog for updates.</p>"},{"location":"blog/2023/otel-in-focus-05/#from-the-blog","title":"From the blog...","text":"<p>OpenTelemetry Lambda Layers are now available. Congratulations to the Functions-as-a-Service SIG on the release!</p> <p>A new blog series discussing Histograms vs. Summaries and Exponential Histograms has gone up on the blog, giving an overview of this important topic.</p>"},{"location":"blog/2023/otel-in-focus-05/#news-and-upcoming-events","title":"News and Upcoming Events","text":"<p>OpenTelemetry in Practice is coming up on June 8th at 10:00 PT/13:00 ET/19:00 CET featuring Iris Dyrmishi of Farfetch. Please see the #otel-comms channel on the CNCF Slack for more info.</p> <p>Observability Day is coming to KubeCon North America in Chicago! Keep an eye on the KubeCon page for more information. A call for proposals is expected to be available in early June.</p>"},{"location":"blog/2023/outreachy-may-cohort/","title":"Call for participation - Outreachy May 2023","text":"<p>It's almost time for the next Outreachy cohort and I (Juraci Paix\u00e3o Kr\u00f6hling) want to get YOU involved, even if you are not a maintainer.</p> <ol> <li>Perhaps you are NOT a maintainer, but there's a feature you dream on having    implemented? Let me know! I'm looking for project ideas for Outreachy interns    to work on. I'll try to find a mentor for your idea. Given this is all open    source, you'll have a chance to follow the development closely.</li> <li>Are you a maintainer and there's something you want to get done for your    project? Even if you prefer not to be a mentor this time, I'd appreciate to    receive project ideas from you. I'll try to find a mentor to work on it.</li> <li>I hear you want to be a mentor? That's awesome! Outreachy is a great    opportunity to improve your mentoring skills and to get someone to work on    that feature you always wanted to get done but never really got around to    actually do it. Typically, the outcome of the internship is great in many    levels, being an interesting topic for conferences such as KubeCon.</li> </ol> <p>What's a great idea, you ask? Small to medium-sized self-contained tasks, suitable for new contributors. Your intern will likely be a person who's new to our area (observability) and might not be an experienced programmer yet. That said, they will have around 3 months to complete the task, which is typically more than enough! In the past, people have been working on adding auto-instrumentation support for Python threading module, creating component generators for OpenTelemetry Collector, benchmarking the client SDKs, writing user-facing documentation, experimenting with data visualization for distributed tracing and more.</p> <p>Here's where you can get more information about Outreachy and our participation on previous cohorts:</p> <ul> <li>Outreachy</li> <li>CNCF OpenTelemetry: Past community participation in Outreachy</li> </ul> <p>The easiest way to get in touch with us if you have a project idea or want to be a mentor is via CNCF Slack, #outreachy.</p>"},{"location":"blog/2023/php-beta-release/","title":"Opentelemetry PHP Beta Release","text":"<p>The OpenTelemetry PHP SIG is very excited to announce the release of v1.0.0beta1 of OpenTelemetry PHP. This is the culmination of over 3 years of work done by the OpenTelemetry PHP team.</p> <p>We are actively soliciting feedback from the development community for this library. Try the beta release, instrument your PHP app with it, and open an issue if you\u2019d like to see a bug squashed or a new feature added.</p> <p>There are many ways you can get started with our project:</p> <ul> <li>There are examples in the repo to get   you started.</li> <li>The getting started guide can   help you to instrument a sample PHP file.</li> <li>The quote service, is a demo application built   in PHP to showcase the library.</li> </ul> <p>Questions? Feel free to reach out to us in the CNCF #otel-php Slack channel, or come to our SIG meeting, which you can find on the OTel public calendar.</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/","title":"Submitting Your First Conference Talk","text":"<p>Submitting a conference talk in the tech industry can be a thrilling and nerve-wracking experience, especially if it\u2019s your first time. The thought of presenting your ideas to a room full of experts and industry professionals can be intimidating, but also an opportunity to showcase your skills, gain recognition, and network with others in your field.</p> <p>On Wednesday, February 1st, 2023, the OpenTelemetry End User Working Group ran an Observability Abstract Workshop. The goal was to help folks who are new to speaking, and are interested in submitting an observability panel or talk. The workshop featured advice and expertise from OpenTelemetry community members Reese Lee, Daniel Kim, Rynn Mancuso, Juraci Paix\u00e3o Kr\u00f6hling, and Adriana Villela.</p> <p>What follows is a summary of the workshop's main takeaways. Whether you\u2019re a seasoned speaker or just starting out, this guide will provide you with tips to help you make the most of your conference talk submission and increase your chances of being selected to speak.</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/#tip-1-just-do-it","title":"Tip #1: Just do it","text":"<p>Don\u2019t let perfection be the enemy of good. The best way to start giving talks is to just start submitting and see what happens. You don\u2019t need to craft the perfect proposal (although tailoring it for the event and target audience will certainly help!) and you don\u2019t need to be an industry-leading subject matter expert.</p> <p>Don\u2019t let any excuse stop you. So many conferences and events are desperate for anybody who simply has the willingness to speak and a little something to share. You may be surprised how happy people are to hear real world experience from their peers.</p> <p>But if you\u2019re still unsure, you may want to consider\u2026</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/#tip-2-start-at-a-meetup-or-user-group","title":"Tip #2: Start at a Meetup or User Group","text":"<p>If you\u2019re not sure about your public speaking and want to start in a low-pressure environment, I would definitely recommend pitching any topics to a local meetup or user group. You can even treat your next team meeting as an opportunity to speak, paying attention how you present your thoughts.</p> <p>As a former meetup organizer, I can tell you that they are constantly looking for willing speakers.</p> <p>Meetups are also a great place to workshop a talk or topic that you are planning to present for larger audiences at a conference.</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/#tip-3-you-dont-have-to-be-an-expert","title":"Tip #3: You don\u2019t have to be an expert","text":"<p>A lot of people that I talk to feel that they need to be an expert on a topic in order to give a talk about it. This couldn\u2019t be further from the truth. While conferences and audiences love to highlight deep subject matter experts, the insight of beginners can be just as valuable.</p> <p>A common tactic for conference talks is to submit a topic that you are interested in learning more about. If your talk is accepted, it gives you an excuse to learn that topic deeply \u2014 and your fresh perspective can make the topic more accessible to other beginners.</p> <p>This tactic is sometimes referred to as \u201cConference Driven Development\u201d \ud83d\ude02</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/#tip-4-you-dont-have-to-be-original","title":"Tip #4: You don\u2019t have to be original","text":"<p>Choosing a topic can be difficult. There is a strong temptation to only submit original topics that the world has never seen before. Resist this urge. Your topics don\u2019t have to be unique or novel to be valuable.</p> <p>In fact, \u201cA beginners guide to X\u201d is probably going to have much broader appeal than \u201cHow we combined seven really specific and niche technologies to solve this one problem\u201d \u2014 although both of those topics could be interesting!</p> <p>If you\u2019re stumped for deeper ideas, consider:</p> <ul> <li>Sharing a learning journey (see Tip #3)</li> <li>Sharing a real world case study about how you used a specific technology to   solve a problem</li> <li>Diving deep on a specific topic or technology</li> <li>Doing a bake-off or round-up of comparable tools</li> </ul> <p>If your topic is touching some Open Source project - you can always ask for the feedback from the expert in the community. They may suggest an interesting angle for your talk. You can even try to find a co-speaker. Don't be shy asking for help and form great connections in the community.</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/#where-to-submit-your-talk","title":"Where to submit your talk","text":"<p>I am thrilled to see the resurgence in conferences that is currently underway. There is no shortage of venues in need of up-and-coming speakers.</p> <p>As a starting point, I would recommend looking at smaller community-organized conferences like DevOpsDays and Code Camps. Often these conferences are hosted by a local meetup group, which makes it very easy to get connected with the organizers and ask them exactly what kind of talks they are looking for.</p> <p>Don\u2019t be afraid to submit the same talk to multiple conferences (unless the conferences disallow this, but most don\u2019t). Here are some websites I use to find conferences:</p> <ul> <li>GitHub - scraly/developers-conferences-agenda</li> <li>SeeCFP</li> <li>Sessionize</li> <li>The Linux Foundation</li> </ul>"},{"location":"blog/2023/submitting-your-first-conference-talk/#writing-your-abstract","title":"Writing your abstract","text":"<p>Some conferences just require a few sentences or bullet points about your talk, while others may require a few pages of information including a detailed abstract and bio. In either case, remember to think about the abstract from the (potential) audience\u2019s point of view.</p> <p>It\u2019s important to cover what technologies you will discuss, of course, but you also want to make sure you do a proper introduction to the use case for people who may not know the technology.</p> <p>One of the most valuable talks I ever attended was about a topic I needed (debugging strategies) in a language I had never used at that point (.NET).</p> <p>So really, what you want to tell your audience in your abstract is: what will they learn from attending your talk?</p>"},{"location":"blog/2023/submitting-your-first-conference-talk/#making-the-most-of-your-conference-experience","title":"Making the most of your conference experience","text":"<p>Making the most of a conference could be a topic for an entirely new blog post, but I want to share my top three most important tips:</p> <ol> <li>Wear comfortable shoes</li> <li>Leave room for serendipity (the hallway track)</li> <li>Collect stats, make notes, and record feedback to motivate you to do it again</li> </ol> <p>The first point should be obvious. Most of us are used to spending 10-12 hours a day on our butts. Shifting that weight to our feet for a week can be a lot.</p> <p>The second point is less obvious. At my first conference I felt that I was missing out any time I wasn\u2019t in a session. Now I know better. While the talks are amazing for revving my mental engine, the \u201cHallway Track\u201d is where the best conversations and connections happen.</p> <p>Third is important - any data that may help you remember your experience or be used to brag or convince your company to sponsor your next speaking engagement, are very valuable. You have done a lot of work, be proud of it. The only way to take advantage of this is if you leave some wiggle room in your schedule and aren\u2019t afraid to take breaks when you need them.</p>"},{"location":"blog/2023/sunsetting-opencensus/","title":"Sunsetting OpenCensus","text":"<p>In 2019, we announced that OpenTracing and OpenCensus would be merging to form the OpenTelemetry project. From the start, we considered OpenTelemetry to be the next major version of both OpenTracing and OpenCensus.</p> <p>We are excited to announce that OpenTelemetry has reached feature parity with OpenCensus in C++, .NET, Go, Java, JavaScript, PHP and Python. Stable releases of both the Tracing and Metrics SDKs are available in most of these languages with Go and PHP soon to follow. This means that OpenTelemetry can collect and export telemetry data with the same level of functionality as OpenCensus. Beyond that, OpenTelemetry offers a richer ecosystem of instrumentation libraries and exporters, and an active open source community.</p> <p>As a result, we will be archiving all OpenCensus GitHub repositories (with the exception of census-instrumentation/opencensus-python1) on July 31st, 2023. We are excited to see the long term plan for OpenTelemetry coming to fruition, and encourage all users of OpenCensus to migrate to OpenTelemetry.</p>"},{"location":"blog/2023/sunsetting-opencensus/#how-to-migrate-to-opentelemetry","title":"How to Migrate to OpenTelemetry","text":"<p>One of the key goals of the OpenTelemetry project is to provide backward compatibility with OpenCensus and a migration story for existing users.</p> <p>To help ease the migration path, we provide backward compatibility bridges for the following languages2:</p> <ul> <li>Go</li> <li>Java</li> <li>JavaScript</li> <li>Python</li> </ul> <p>Installing these bridges allows OpenCensus and OpenTelemetry instrumentation to smoothly interoperate, with all of your telemetry flowing out of OpenTelemetry exporters. This lets OpenCensus users incrementally transition all of their instrumentation from OpenCensus to OpenTelemetry, and finally remove OpenCensus libraries from their applications3.</p> <p>While OpenTelemetry was never intended to be a strict superset of OpenCensus, most of the APIs and data models are compatible. Migration should be considered a \"major version bump\" and you may notice some changes in your telemetry.</p> <p>More details on what to expect and some suggested workflows for migration are outlined in the OpenCensus Compatibility specification.</p>"},{"location":"blog/2023/sunsetting-opencensus/#what-to-expect-after-july-31-2023","title":"What to Expect After July 31, 2023","text":"<p>After July 31st, 2023, the OpenCensus project will no longer be maintained. This means that there will be no new features added to the project, and any security vulnerabilities that are found will not be patched.</p> <p>However, the OpenCensus repositories will remain archived on GitHub. This means users will still be able to download the OpenCensus code and use it in their projects. Existing releases of OpenCensus will remain available in public package repositories like NPM and PyPI. We encourage all OpenCensus users to begin planning their project's migration to OpenTelemetry now.</p> <p>One exception to this is the census-instrumentation/opencensus-python repo1.</p> <ol> <li> <p>A number of projects within the <code>opencensus-python</code> repository are still being used as recommended production solutions. These projects will continue to be maintained. For details regarding maintenance timeline, next steps for migration, and general support questions, reach out to repo maintainers.\u00a0\u21a9\u21a9</p> </li> <li> <p>Python and JavaScript shim packages will be released soon.\u00a0\u21a9</p> </li> <li> <p>These shims implement the stable OpenCensus Compatibility specification and will be supported for at least one year following OpenTelemetry's long term support guidelines.\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/2023/demo-birthday/","title":"The OpenTelemetry Demo Turns 1(.4)","text":"<p>It's hard to believe as we prepare our 1.4.0 release but the OpenTelemetry demo is turning 1 year old and it's been 6 months since we declared general availability with our 1.0.0 release.</p>"},{"location":"blog/2023/demo-birthday/#project-milestones","title":"Project Milestones","text":"<p>The demo has achieved remarkable milestones in its first year, with more than 70 contributors, 20 official vendor forks, 780 Github stars, and 180K Docker pulls. The project team has been hard at work adding new capabilities and improving on existing ones with more than 460 merged PRs, 5 re-written services in new languages, and 7 brand new components / services.</p> <p>Time flies when you're stabilizing semantic conventions. But what's actually changed between our 1.0.0 and 1.4.0 releases? Quite a lot actually.</p>"},{"location":"blog/2023/demo-birthday/#the-highlights","title":"The Highlights","text":"<ul> <li>2x build time improvements despite adding additional services</li> <li>Support added for arm64 architectures (M1 and M2 Macs)</li> <li>Async support using Kafka and the new Fraud Detection (Kotlin) / Accounting   (Go) services</li> <li>Kubernetes manifest to enable Kubernetes deployment without using requiring   Helm</li> <li>More out of the box dashboards like our   Collector Data Flow Dashboard</li> <li>A myriad of frontend bug fixes</li> <li>Our first   Connector   in the Collector to demonstrate how telemetry pipelines can be linked</li> <li>New OTel SDKs like the Java logging SDK and JavaScript / Go Metric SDK</li> <li>New manual metric instruments in the Ad, Currency, Product Catalog services</li> <li>PHP no-code change auto-instrumentation</li> <li>Browser and compute resource detectors that enrich our data with   infrastructure information</li> <li>More feature flag scenarios like generating a   failure for every 10th Ad shown</li> <li>General stability improvements to fix service restarts</li> </ul> <p>For detailed changes, check out our in depth release notes or changelog.</p>"},{"location":"blog/2023/demo-birthday/#get-involved","title":"Get Involved","text":"<p>Our contributors are essential to all of this and the project team can't thank them enough. New development is constantly ongoing as we add new capabilities and the community's tools evolve. If you'd like to help, check out our contributing guidance or join our Slack channel.</p>"},{"location":"blog/2023/histograms-vs-summaries/","title":"Histograms vs Summaries","text":"<p>In many ways, histograms and summaries appear quite similar. They both roll up many data points into a data structure for efficient processing, transmission, and storage. They can also both be used to track arbitrary quantiles such as the median or p99 of your data. So how do they differ? Let's dive in.</p>"},{"location":"blog/2023/histograms-vs-summaries/#histograms","title":"Histograms","text":"<p>Since I just published a post about histograms and when they are useful, I will only provide a quick summary here. A histogram is a data structure which describes the distribution of a set of data points. For example, one may collect all response times to an HTTP endpoint and describe them as a histogram with 10 bins ranging from 0 to 1000 milliseconds. Each bin counts the number of requests that fall within its range.</p> <p></p> <p>From this we can estimate \u03c6-quantiles like the 90th percentile. We know there are 1260 requests, so the 1134th-ranked (<code>1260 * .90</code>) request represents the 90th percentile. We can then calculate that the request would fall in the 8th bucket (<code>300 &lt;= x &lt; 500</code>) by summing the bucket counts until we exceed that rank. Finally, using relative rank within the bucket of 24 (<code>1134 - 1110</code>), we can estimate the p90 value to be 360ms (<code>300 + ((24 / 80) * (500 - 300))</code>) using linear interpolation. It is important to know that this is an estimation and could be off by as much as 60ms (<code>360 - 300</code>), a relative error of 17% (<code>60 / 360</code>). This error can be mitigated by configuring more and smaller buckets around your SLO values, but never eliminated.</p> <p>One important property of histograms is that they are aggregatable, meaning that as long as the bucket boundaries line up, an arbitrary number of histograms can be combined into a single histogram with no loss of data or precision. This means that an arbitrary number of hosts can report histogram data structures to a server, which can aggregate and compute quantiles from all of them as if they were reported by a single host. By collecting histograms from 1 or more hosts over a long period of time, developers can gain a strong understanding of how their data is distributed and how that distribution changes over time.</p>"},{"location":"blog/2023/histograms-vs-summaries/#summaries","title":"Summaries","text":"<p>Summaries work in almost the opposite manner. When a summary is configured it is given a \u03c6-quantile to track, an acceptable error range, and a decay rate. For example, a summary may track p99 \u00b1 0.5% with a decay rate of 5 minutes. The math is more complex so it won't be discussed here, but one important distinction is that the value is calculated on the client before it is sent to the server. The most important consequence of this is that summaries from multiple clients cannot be aggregated. Another disadvantage is that if you cannot query arbitrary \u03c6-quantiles, only those which you have configured and collected in advance.</p> <p>Given these disadvantages, summaries do have some advantages. First, they trade off a small performance penalty on the client for a significant reduction in transmission, storage, and server processing cost. In our histogram example above, the distribution is represented as 12 separate timeseries: 1 counter for each bucket + 1 bucket for out of range values + a total sum of all values. That is for a single, relatively modest, histogram with no attributes to multiply cardinality. By comparison, the summary is only a single timeseries for the precomputed <code>p99</code> value. Second, they have very low and configurable relative error rates. In the histogram example above, we had a potential relative error of 17% where our summary is guaranteed to be within \u00b1 0.5% accuracy.</p>"},{"location":"blog/2023/histograms-vs-summaries/#so-which-should-you-choose","title":"So which should you choose?","text":"<p>The disappointing answer is \"it depends,\" and there is no one-size-fits-all solution. If you need to aggregate data from many sources, then histograms may be the right choice. If you are collecting a large number of separate metrics with very strict SLOs, or your Prometheus server is particularly resource constrained, then maybe summaries are the right choice for you. Maybe your ideal solution is a hybrid with some histograms for flexible querying and some summaries for high-accuracy, low-cost alerting. Only you can know the ins and outs of your own system and design an observability solution around it that is accurate and flexible and fits your particular needs. The key is knowing the strengths and limitations of the available tools so you can make informed decisions.</p>"},{"location":"blog/2023/histograms-vs-summaries/#bonus-round-nativeexponential-histograms","title":"Bonus round: native/exponential histograms","text":"<p>I'm planning a longer post on this so I'll keep this short, but many of the key disadvantages of histograms are mitigated by exponential histograms, called native histograms in Prometheus. They are available in Prometheus as an experimental feature since v2.40.0, and stable in the OpenTelemetry specification as of v1.17.0. Exponential histograms come with several advantages:</p> <ul> <li>Very efficient data collection and transmission</li> <li>A constant number of timeseries created (and fewer of them) per histogram</li> <li>Very low relative error rates</li> <li>Automatic bucket boundaries, making them simpler to configure and use</li> </ul> <p>These advantages are accomplished by defining bucket boundaries according to a scale factor, intelligently resizing buckets as your distribution evolves, instead of the traditional method of defining explicit buckets. If you're not happy with the state of your current histograms and summaries, I encourage you to give exponential histograms a try. As of this writing there are no official Prometheus docs on native histograms, but if you stay tuned I plan to add a thorough explanation of them in the coming days.</p> <p>Until then, here are some talks I found helpful:</p> <ul> <li>PromCon EU 2022 - Native Histograms in Prometheus - Ganesh Vernekar</li> <li>KubeCon EU 2023 - Prometheus Native Histograms in Production - Bj\u00f6rn Rabenstein, Grafana Labs</li> <li>Using OpenTelemetry\u2019s Exponential Histograms in Prometheus - Ruslan Kovalov &amp; Ganesh Vernekar</li> </ul> <p>A version of this article was [originally posted][] to the author's blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"blog/2023/jmx-metric-insight/","title":"Gaining JMX Metric Insights with the OpenTelemetry Java Agent","text":"<p>JMX (Java Management Extensions) is a technology that provides a way to manage and monitor Java-based applications. Detailed information about the performance and resource usage of the application can be derived from JMX metrics. This data can help you identify trends or potential issues with the application and take action to address them before they become serious problems. If there are any problems, we can diagnose them with the help of metrics collected, and fine-tune the system for optimal performance.</p> <p>With the addition of the JMX Metric Insight module into the OpenTelemetry Javaagent, we don't need to deploy a separate service just to collect JMX metrics for monitoring our application. The agent can now natively collect and export metrics exposed by application servers through local MBeans available within the instrumented application. The required MBeans and corresponding metrics can be described using a YAML configuration file. The individual metric configurations allow precise metric selection and identification. JMX Metric Insight comes with a number of predefined configurations containing curated sets of JMX metrics for popular application servers or frameworks, such as:</p> <ul> <li>ActiveMQ</li> <li>Hadoop</li> <li>Jetty</li> <li>Kafka Broker</li> <li>Tomcat</li> <li>Wildfly</li> </ul> <p>You can also provide your own metric definitions, through one or more YAML files. The YAML file syntax documentation is available here.</p>"},{"location":"blog/2023/jmx-metric-insight/#observe-kafka-broker-metrics","title":"Observe Kafka Broker metrics","text":"<p>Let's observe the health of our Kafka Broker by exporting the predefined set of metrics using the JMX Metric Insight module and export it to Prometheus.</p> <p>Kafka can be installed on macOS using Homebrew with the following steps:</p> <pre><code>brew install kafka\n</code></pre> <p>To start Zookeeper:</p> <pre><code>zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties\n</code></pre>"},{"location":"blog/2023/jmx-metric-insight/#attach-the-opentelemetry-java-instrumentation-agent","title":"Attach the OpenTelemetry java instrumentation agent","text":"<p>Before starting the kafka broker, attach the OpenTelemetry java instrumentation agent to Kafka Broker by providing options in the KAFKA_OPTS environment variable. You can download the latest release of the agent from here.</p> <pre><code>export KAFKA_OPTS=\"-Dapplication.name=my-kafka-app\n-Dotel.metrics.exporter=prometheus\n-Dotel.exporter.prometheus.port=9464\n-Dotel.service.name=my-kafka-broker\n-Dotel.jmx.target.system=kafka-broker\n-javaagent:/path/to/opentelemetry-javaagent.jar\"\n</code></pre> <p>Now we can start the Kafka Broker:</p> <pre><code>kafka-server-start /usr/local/etc/kafka/server.properties\n</code></pre> <p>The Kafka broker should be up and running now. To test the installation, we can create a topic and use the Kafka console producer and console consumer. Create Kafka Topic:</p> <pre><code>kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic my-test-topic\n</code></pre> <p>Start Kafka console producer to produce messages to the topic we created:</p> <pre><code>$ kafka-console-producer --broker-list localhost:9092 --topic test\n&gt;First message\n&gt;Second message\n</code></pre> <p>Now we will start the Kafka console consumer which will consume messages from the topic from the beginning:</p> <pre><code>$ kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning\nFirst message\nSecond message\n</code></pre> <p>If we are able to see the two messages received by the consumer, that verifies that our Kafka installation is working as expected.</p>"},{"location":"blog/2023/jmx-metric-insight/#export-metrics-to-prometheus","title":"Export metrics to Prometheus","text":"<p>The metrics can be exported by any of the supported metric exporters, to a backend of your choice. The full list of exporters and their configuration options can be found here. For instance, you can export the metrics to an OTel collector using the OTLP exporter, perform some processing and then consume the metrics on a backend of your choice. In this example for the sake of simplicity, we are directly exporting the metrics to Prometheus.</p> <p>We will visualise the metrics on a Grafana dashboard using Prometheus as the data source. In this demo, we\u2019ll deploy Prometheus on Docker. We can create a <code>prometheus.yml</code> file containing this minimal configuration:</p> <pre><code>global:\nscrape_interval: 10s\nevaluation_interval: 10s\nscrape_configs:\n- job_name: my-kafka-broker\nscrape_interval: 5s\nstatic_configs:\n- targets: [host.docker.internal:9464]\n</code></pre> <p>Then run the command below to deploy Prometheus on Docker:</p> <pre><code>docker run -d \\\n-p 9090:9090 \\\n-v path/to/prometheus.yml:/etc/prometheus/prometheus.yml \\\nprom/prometheus\n</code></pre> <p>The Prometheus container should be running now. You can now navigate to http://localhost:9090 and explore the Prometheus dashboard. Here we are viewing the metric <code>kafka_request_count_total</code> on Prometheus.</p> <p></p> <p>More installation options for Prometheus can be found here.</p>"},{"location":"blog/2023/jmx-metric-insight/#view-the-metrics-on-a-grafana-dashboard","title":"View the metrics on a Grafana Dashboard","text":"<p>Now, we are going to visualise the Prometheus metrics in a Grafana dashboard. To do that, first, pull the Grafana docker image using the following command:</p> <pre><code>docker run -d -p 3000:3000 grafana/grafana\n</code></pre> <p>You can now navigate to http://localhost:3000 and explore the Grafana home page. Click on Add Data Source and select Prometheus. Add the HTTP URL, default is http://localhost:9090. After that we can create new Dashboards, with multiple options of visualisations to choose from (Graph, Singlestat, Gauge, Table, Text, etc). We can then create new panels and add any metric we would like to observe. Here is an example dashboard consisting of 6 panels, we are observing a metric in each panel. We can observe the health of our Kafka Broker in real time on this dashboard.</p> <p></p>"},{"location":"blog/2023/jmx-metric-insight/#jmx-metric-insight-in-the-otel-demo-application","title":"JMX Metric Insight in the OTel demo application","text":"<p>You can also explore the official OpenTelemetry Astronomy shop demo application. The message queue service which connects the checkout service with the accounting and fraud detection services is based on Kafka and utilises the JMX Metric Insight module to export Kafka broker metrics out of the box. You can head to the documentation.</p> <p></p> <p></p>"},{"location":"blog/2023/jmx-metric-insight/#further-capabilities-of-the-module","title":"Further Capabilities of the module","text":"<p>In this example, we have only observed a few metrics from the predefined set available for Kafka Broker. Not all metrics exposed by Kafka are part of the set, so if your requirement is a metric not covered in this predefined set, fret not! The module provides you with the option to create your custom metric definition yaml files, so you can observe any metric exposed as an MBean attribute. To get a peek into the structure of the yaml file, We can take a look at a segment of the kafka-broker.yaml:</p> <pre><code>---\nrules:\n- bean: kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec\nmapping:\nCount:\nmetric: kafka.message.count\ntype: counter\ndesc: The number of messages received by the broker\nunit: '{messages}'\n</code></pre> <p>Each file can consist of multiple rules. Each rule can identify a set of one or more MBeans, by the object name. In this example <code>kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec</code> identifies a unique MBean. We are interested in the attribute <code>Count</code> of this MBean, which is specified under <code>mapping</code>. The metric reported will have the name <code>kafka.message.count</code>, instrument type will be <code>counter</code> which indicates the metric is a monotonic sum. It's unit will be <code>{messages}</code>. We have also provided a description of the metric. This yaml segment is simple, to try out more configuration options, you can head to the documentation to understand and try out all the features of the module.</p> <p>Lastly, if you feel some metrics are important to be in the predefined sets of metrics, or in general if you have any idea for enhancement of the module, feel free to contribute to the repository.</p>"},{"location":"blog/2023/k8s-runtime-observability/","title":"Creating a Kubernetes Cluster with Runtime Observability","text":"<p>With contributions from Sebastian Choren, Adnan Rahi\u0107 and Ken Hamric.</p> <p>Kubernetes is an open source system widely used in the cloud native landscape to provide ways to deploy and scale containerized applications in the cloud. Its ability to observe logs and metrics is well-known and documented, but its observability regarding application traces is new.</p> <p>Here is a brief synopsis of the recent activity in the Kubernetes ecosystem:</p> <ul> <li>The first discussions started in December 2018 with a first PR on   implementing instrumentation.</li> <li>A KEP (Kubernetes Enhancement Proposal) was created in January 2020 and later   scoped to API Server   (KEP 647 - API Server Tracing),   while a new KEP for Kubelet was proposed in July 2021   (KEP 2831 Kubelet Tracing).</li> <li>etcd (Kubernetes uses it as an internal   datastore) started to discuss tracing in November 2020   (here) and had a   first version merged in   May 2021.</li> <li>containerd and   CRI-O, two Container Runtime Interfaces for   Kubernetes, started to implement tracing in 2021   (April 2021 for CRI-O and   August 2021 for containerd).</li> <li>API Server tracing was released as   alpha in v1.22   (Aug. 2021) and   beta in v1.27   (Apr. 2023).</li> <li>Kubelet tracing was released as   alpha in v1.25   (Aug. 2022) and   beta in v1.27   (Apr. 2023).</li> </ul> <p>In investigating the current state of tracing with Kubernetes, we found very few articles documenting how to enable it, like this article on Kubernetes blog about <code>kubelet</code> observability. We decided to document our findings and provide step-by-step instructions to set Kubernetes up locally and inspect traces.</p> <p>You\u2019ll learn how to use this instrumentation with Kubernetes to start observing traces on its API (kube-apiserver), node agent (kubelet), and container runtime (containerd) by setting up a local observability environment and later doing a local install of Kubernetes with tracing enabled.</p> <p>First, install the following tools on your local machine:</p> <ul> <li>Docker: a container environment that allows us to   run containerized environments</li> <li>k3d: a wrapper to run k3s (a lightweight   Kubernetes distribution) with Docker</li> <li>kubectl: a Kubernetes CLI to   interact with clusters</li> </ul>"},{"location":"blog/2023/k8s-runtime-observability/#setting-up-an-observability-stack-to-monitor-traces","title":"Setting up an Observability Stack to Monitor Traces","text":"<p>To set up the observability stack, you\u2019ll run the OpenTelemetry (OTel) Collector, a tool that receives telemetry data from different apps and sends it to a tracing backend. As a tracing backend, you\u2019ll use Jaeger, an open source tool that collects traces and lets you query them.</p> <p>On your machine, create a directory called <code>kubetracing</code> and create a file called otel-collector.yaml, copy the contents of the following snippet, and save it in a folder of your preference.</p> <p>This file will configure the OpenTelemetry Collector to receive traces in OpenTelemetry format and export them to Jaeger.</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nprocessors:\nprobabilistic_sampler:\nhash_seed: 22\nsampling_percentage: 100\nbatch:\ntimeout: 100ms\nexporters:\nlogging:\nlogLevel: debug\notlp/jaeger:\nendpoint: jaeger:4317\ntls:\ninsecure: true\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [probabilistic_sampler, batch]\nexporters: [otlp/jaeger, logging]\n</code></pre> <p>After that, in the same folder, create a docker-compose.yaml file that will have two containers, one for Jaeger and another for the OpenTelemetry Collector.</p> <pre><code>services:\njaeger:\nhealthcheck:\ntest:\n- CMD\n- wget\n- --spider\n- localhost:16686\ntimeout: 3s\ninterval: 1s\nretries: 60\nimage: jaegertracing/all-in-one:latest\nrestart: unless-stopped\nenvironment:\n- COLLECTOR_OTLP_ENABLED=true\nports:\n- 16686:16686\notel-collector:\ncommand:\n- --config\n- /otel-local-config.yaml\ndepends_on:\njaeger:\ncondition: service_started\nimage: otel/opentelemetry-collector:0.54.0\nports:\n- 4317:4317\nvolumes:\n- ./otel-collector.yaml:/otel-local-config.yaml\n</code></pre> <p>Now, start the observability environment by running the following command in the <code>kubetracing</code> folder:</p> <pre><code>docker compose up\n</code></pre> <p>This will start both Jaeger and the OpenTelemetry Collector, enabling them to receive traces from other apps.</p>"},{"location":"blog/2023/k8s-runtime-observability/#creating-a-kubernetes-cluster-with-runtime-observability","title":"Creating a Kubernetes Cluster with Runtime Observability","text":"<p>With the observability environment set up, create the configuration files to enable OpenTelemetry tracing in <code>kube-apiserver</code>, <code>kubelet</code>, and <code>containerd</code>.</p> <p>Inside the <code>kubetracing</code> folder, create a subfolder called <code>config</code> that will have the following two files.</p> <p>First, the apiserver-tracing.yaml, which contains the tracing configuration used by <code>kube-apiserver</code> to export traces containing execution data of the Kubernetes API. In this configuration, set the API to send 100% of the traces with the <code>samplingRatePerMillion</code> config. Set the endpoint as <code>host.k3d.internal:4317</code> to allow the cluster created by <code>k3d/k3s</code> to call another API on your machine. In this case, the OpenTelemetry Collector deployed via <code>docker compose</code> on port <code>4317</code>.</p> <pre><code>apiVersion: apiserver.config.k8s.io/v1beta1\nkind: TracingConfiguration\nendpoint: host.k3d.internal:4317\nsamplingRatePerMillion: 1000000 # 100%\n</code></pre> <p>The second file is kubelet-tracing.yaml, which provides additional configuration for <code>kubelet</code>. Here you\u2019ll enable the feature flag <code>KubeletTracing</code> (a beta feature in Kubernetes 1.27, the current version when this article was written) and set the same tracing settings that were set on <code>kube-apiserver</code>.</p> <pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nfeatureGates:\nKubeletTracing: true\ntracing:\nendpoint: host.k3d.internal:4317\nsamplingRatePerMillion: 1000000 # 100%\n</code></pre> <p>Returning to the <code>kubetracing</code> folder, create the last file, config.toml.tmpl, which is a template file used by <code>k3s</code> to configure <code>containerd</code>. This file is similar to the default configuration that <code>k3s</code> uses, with two more sections at the end of the file that configures <code>containerd</code> to send traces.</p> <pre><code>version = 2\n\n[plugins.\"io.containerd.internal.v1.opt\"]\n  path = \"{{ .NodeConfig.Containerd.Opt }}\"\n[plugins.\"io.containerd.grpc.v1.cri\"]\n  stream_server_address = \"127.0.0.1\"\n  stream_server_port = \"10010\"\n  enable_selinux = {{ .NodeConfig.SELinux }}\n  enable_unprivileged_ports = {{ .EnableUnprivileged }}\n  enable_unprivileged_icmp = {{ .EnableUnprivileged }}\n\n{{- if .DisableCgroup}}\n  disable_cgroup = true\n{{end}}\n{{- if .IsRunningInUserNS }}\n  disable_apparmor = true\n  restrict_oom_score_adj = true\n{{end}}\n\n{{- if .NodeConfig.AgentConfig.PauseImage }}\n  sandbox_image = \"{{ .NodeConfig.AgentConfig.PauseImage }}\"\n{{end}}\n\n{{- if .NodeConfig.AgentConfig.Snapshotter }}\n[plugins.\"io.containerd.grpc.v1.cri\".containerd]\n  snapshotter = \"{{ .NodeConfig.AgentConfig.Snapshotter }}\"\n  disable_snapshot_annotations = {{ if eq .NodeConfig.AgentConfig.Snapshotter \"stargz\" }}false{{else}}true{{end}}\n{{ if eq .NodeConfig.AgentConfig.Snapshotter \"stargz\" }}\n{{ if .NodeConfig.AgentConfig.ImageServiceSocket }}\n[plugins.\"io.containerd.snapshotter.v1.stargz\"]\ncri_keychain_image_service_path = \"{{ .NodeConfig.AgentConfig.ImageServiceSocket }}\"\n[plugins.\"io.containerd.snapshotter.v1.stargz\".cri_keychain]\nenable_keychain = true\n{{end}}\n{{ if .PrivateRegistryConfig }}\n{{ if .PrivateRegistryConfig.Mirrors }}\n[plugins.\"io.containerd.snapshotter.v1.stargz\".registry.mirrors]{{end}}\n{{range $k, $v := .PrivateRegistryConfig.Mirrors }}\n[plugins.\"io.containerd.snapshotter.v1.stargz\".registry.mirrors.\"{{$k}}\"]\n  endpoint = [{{range $i, $j := $v.Endpoints}}{{if $i}}, {{end}}{{printf \"%q\" .}}{{end}}]\n{{if $v.Rewrites}}\n  [plugins.\"io.containerd.snapshotter.v1.stargz\".registry.mirrors.\"{{$k}}\".rewrite]\n{{range $pattern, $replace := $v.Rewrites}}\n    \"{{$pattern}}\" = \"{{$replace}}\"\n{{end}}\n{{end}}\n{{end}}\n{{range $k, $v := .PrivateRegistryConfig.Configs }}\n{{ if $v.Auth }}\n[plugins.\"io.containerd.snapshotter.v1.stargz\".registry.configs.\"{{$k}}\".auth]\n  {{ if $v.Auth.Username }}username = {{ printf \"%q\" $v.Auth.Username }}{{end}}\n  {{ if $v.Auth.Password }}password = {{ printf \"%q\" $v.Auth.Password }}{{end}}\n  {{ if $v.Auth.Auth }}auth = {{ printf \"%q\" $v.Auth.Auth }}{{end}}\n  {{ if $v.Auth.IdentityToken }}identitytoken = {{ printf \"%q\" $v.Auth.IdentityToken }}{{end}}\n{{end}}\n{{ if $v.TLS }}\n[plugins.\"io.containerd.snapshotter.v1.stargz\".registry.configs.\"{{$k}}\".tls]\n  {{ if $v.TLS.CAFile }}ca_file = \"{{ $v.TLS.CAFile }}\"{{end}}\n  {{ if $v.TLS.CertFile }}cert_file = \"{{ $v.TLS.CertFile }}\"{{end}}\n  {{ if $v.TLS.KeyFile }}key_file = \"{{ $v.TLS.KeyFile }}\"{{end}}\n  {{ if $v.TLS.InsecureSkipVerify }}insecure_skip_verify = true{{end}}\n{{end}}\n{{end}}\n{{end}}\n{{end}}\n{{end}}\n\n{{- if not .NodeConfig.NoFlannel }}\n[plugins.\"io.containerd.grpc.v1.cri\".cni]\n  bin_dir = \"{{ .NodeConfig.AgentConfig.CNIBinDir }}\"\n  conf_dir = \"{{ .NodeConfig.AgentConfig.CNIConfDir }}\"\n{{end}}\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n  runtime_type = \"io.containerd.runc.v2\"\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n  SystemdCgroup = {{ .SystemdCgroup }}\n\n{{ if .PrivateRegistryConfig }}\n{{ if .PrivateRegistryConfig.Mirrors }}\n[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]{{end}}\n{{range $k, $v := .PrivateRegistryConfig.Mirrors }}\n[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"{{$k}}\"]\n  endpoint = [{{range $i, $j := $v.Endpoints}}{{if $i}}, {{end}}{{printf \"%q\" .}}{{end}}]\n{{if $v.Rewrites}}\n  [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"{{$k}}\".rewrite]\n{{range $pattern, $replace := $v.Rewrites}}\n    \"{{$pattern}}\" = \"{{$replace}}\"\n{{end}}\n{{end}}\n{{end}}\n\n{{range $k, $v := .PrivateRegistryConfig.Configs }}\n{{ if $v.Auth }}\n[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"{{$k}}\".auth]\n  {{ if $v.Auth.Username }}username = {{ printf \"%q\" $v.Auth.Username }}{{end}}\n  {{ if $v.Auth.Password }}password = {{ printf \"%q\" $v.Auth.Password }}{{end}}\n  {{ if $v.Auth.Auth }}auth = {{ printf \"%q\" $v.Auth.Auth }}{{end}}\n  {{ if $v.Auth.IdentityToken }}identitytoken = {{ printf \"%q\" $v.Auth.IdentityToken }}{{end}}\n{{end}}\n{{ if $v.TLS }}\n[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"{{$k}}\".tls]\n  {{ if $v.TLS.CAFile }}ca_file = \"{{ $v.TLS.CAFile }}\"{{end}}\n  {{ if $v.TLS.CertFile }}cert_file = \"{{ $v.TLS.CertFile }}\"{{end}}\n  {{ if $v.TLS.KeyFile }}key_file = \"{{ $v.TLS.KeyFile }}\"{{end}}\n  {{ if $v.TLS.InsecureSkipVerify }}insecure_skip_verify = true{{end}}\n{{end}}\n{{end}}\n{{end}}\n\n{{range $k, $v := .ExtraRuntimes}}\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.\"{{$k}}\"]\n  runtime_type = \"{{$v.RuntimeType}}\"\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.\"{{$k}}\".options]\n  BinaryName = \"{{$v.BinaryName}}\"\n{{end}}\n\n[plugins.\"io.containerd.tracing.processor.v1.otlp\"]\n  endpoint = \"host.k3d.internal:4317\"\n  protocol = \"grpc\"\n  insecure = true\n\n[plugins.\"io.containerd.internal.v1.tracing\"]\n  sampling_ratio = 1.0\n  service_name = \"containerd\"\n</code></pre> <p>After creating these files, open a terminal inside the <code>kubetracing</code> folder and run <code>k3d</code> to create a cluster. Before running this command, replace the <code>[CURRENT_PATH]</code> placeholder for the entire path of the <code>kubetracing</code> folder. You can retrieve it by running the <code>echo $PWD</code> command in the terminal in that folder.</p> <pre><code>k3d cluster create tracingcluster \\\n--image=rancher/k3s:v1.27.1-k3s1 \\\n--volume '[CURRENT_PATH]/config.toml.tmpl:/var/lib/rancher/k3s/agent/etc/containerd/config.toml.tmpl@server:*' \\\n--volume '[CURRENT_PATH]/config:/etc/kube-tracing@server:*' \\\n--k3s-arg '--kube-apiserver-arg=tracing-config-file=/etc/kube-tracing/apiserver-tracing.yaml@server:*' \\\n--k3s-arg '--kube-apiserver-arg=feature-gates=APIServerTracing=true@server:*' \\\n--k3s-arg '--kubelet-arg=config=/etc/kube-tracing/kubelet-tracing.yaml@server:*'\n</code></pre> <p>This command will create a Kubernetes cluster with version <code>v1.17.1</code>, and set up in three docker containers on your machine. If you run the command <code>kubectl cluster-info</code> now, you will see this output:</p> <pre><code>Kubernetes control plane is running at https://0.0.0.0:60503\nCoreDNS is running at https://0.0.0.0:60503/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\nMetrics-server is running at https://0.0.0.0:60503/api/v1/namespaces/kube-system/services/https:metrics-server:https/proxy\n</code></pre> <p>Going back to the logs of the observability environment, you should see some spans of internal Kubernetes operations being published in OpenTelemetry Collector, like this:</p> <pre><code>Span #90\n    Trace ID       : 03a7bf9008d54f02bcd4f14aa5438202\n    Parent ID      :\n    ID             : d7a10873192f7066\n    Name           : KubernetesAPI\n    Kind           : SPAN_KIND_SERVER\n    Start time     : 2023-05-18 01:51:44.954563708 +0000 UTC\n    End time       : 2023-05-18 01:51:44.957555323 +0000 UTC\n    Status code    : STATUS_CODE_UNSET\n    Status message :\nAttributes:\n     -&gt; net.transport: STRING(ip_tcp)\n     -&gt; net.peer.ip: STRING(127.0.0.1)\n     -&gt; net.peer.port: INT(54678)\n     -&gt; net.host.ip: STRING(127.0.0.1)\n     -&gt; net.host.port: INT(6443)\n     -&gt; http.target: STRING(/api/v1/namespaces/kube-system/pods/helm-install-traefik-crd-8w4wd)\n     -&gt; http.server_name: STRING(KubernetesAPI)\n     -&gt; http.user_agent: STRING(k3s/v1.27.1+k3s1 (linux/amd64) kubernetes/bc5b42c)\n     -&gt; http.scheme: STRING(https)\n     -&gt; http.host: STRING(127.0.0.1:6443)\n     -&gt; http.flavor: STRING(2)\n     -&gt; http.method: STRING(GET)\n     -&gt; http.wrote_bytes: INT(4724)\n     -&gt; http.status_code: INT(200)\n</code></pre>"},{"location":"blog/2023/k8s-runtime-observability/#testing-the-cluster-runtime","title":"Testing the Cluster Runtime","text":"<p>With the Observability environment and the Kubernetes cluster set up, you can now trigger commands against Kubernetes and see traces of these actions in Jaeger.</p> <p>Open the browser, and navigate to the Jaeger UI located at http://localhost:16686/search. You\u2019ll see that the <code>apiserver</code>, <code>containerd</code>, and <code>kubelet</code> services are publishing traces:</p> <p></p> <p>Choose <code>apiserver</code> and click on \"Find Traces\u201d. Here you see traces from the Kubernetes control plane:</p> <p></p> <p>Let\u2019s run a sample command against Kubernetes with <code>kubectl</code>, like running an echo:</p> <pre><code>$ kubectl run -it --rm --restart=Never --image=alpine echo-command -- echo hi\n\n# Output\n# If you don't see a command prompt, try pressing enter.\n# warning: couldn't attach to pod/echo-command, falling back to streaming logs: unable to upgrade connection: container echo-command not found in pod echo-command_default\n# Hi\n# pod \"echo-command\" deleted\n</code></pre> <p>And now, open Jaeger again, choose the <code>kubelet</code> service, operation <code>syncPod</code>, and add the tag <code>k8s.pod=default/echo-command</code>, you should be able to see spans related to this pod:</p> <p></p> <p>Expanding one trace, you\u2019ll see the operations that created this pod:</p> <p></p>"},{"location":"blog/2023/k8s-runtime-observability/#conclusion","title":"Conclusion","text":"<p>Even in beta, both traces for kubelet and apiserver can help a developer understand what\u2019s happening under the hood in Kubernetes and start debugging issues.</p> <p>This will be helpful for developers that create custom tasks, like Kubernetes Operators that update internal resources to add more functionalities to Kubernetes.</p> <p>As a team focused on building an open source tool in the observability space, the opportunity to help the overall OpenTelemetry community was important to us. That\u2019s why we were researching finding new ways of collecting traces from the core Kubernetes engine. With the current level of observability being exposed by Kubernetes we wanted to publish our findings in order to help others interested in seeing the current state of distributed tracing in the Kubernetes engine. Daniel Dias and Sebastian Choren are working on Tracetest, an open-source tool that allows you to develop and test your distributed system with OpenTelemetry. It works with any OTel compatible system and enables trace\u2013based tests to be created. Check it out at https://github.com/kubeshop/tracetest.</p> <p>The example sources used in this article, and setup instructions are available from the Tracetest repo.</p>"},{"location":"blog/2023/k8s-runtime-observability/#references","title":"References","text":"<ul> <li>Traces For Kubernetes System Components</li> <li>Tracing on ContainerD</li> <li>Kubernetes: Tools for Monitoring Resources</li> <li>Getting Started with OTel Collector</li> <li>Boosting Kubernetes container runtime observability with OpenTelemetry</li> </ul>"},{"location":"blog/2023/php-auto-instrumentation/","title":"OpenTelemetry PHP Auto-Instrumentation","text":"<p>Automatic Instrumentation is a process of adding tracing capabilities into user application without modifying its source code. There are several techniques to do that, but all of them more or less work in the same way by injecting additional code into original one during compile time, link time, run-time or by extending the operating system in case of eBPF. This blog post presents method used by OpenTelemetry PHP auto-instrumentation.</p>"},{"location":"blog/2023/php-auto-instrumentation/#prerequisites","title":"Prerequisites","text":"<p>To use the PHP auto-instrumentation, you'll need three things:</p> <ul> <li>PHP 8.0 or higher. The PHP auto-instrumentation uses the Observability API   introduced in PHP 8.0.</li> <li>Composer</li> <li>A C Compiler must be available on your machine</li> </ul>"},{"location":"blog/2023/php-auto-instrumentation/#background-on-the-php-80-observability-api","title":"Background on the PHP 8.0 Observability API","text":"<p>Observability API allows you to register and execute additional code (function) before and after an original one without introducing additional performance penalties in other areas. Before PHP 8.0, the most common technique for adding tracing capabilities was altering the <code>zend_execute_ex</code> function (a monkey patching kind technique). However, this can lead to performance problems, stack overflows at runtime, and a general application overhead that may not be desirable. Another approach considered in the past was plugging into the AST and modifying it during compilation time, but there are not known production ready traces that use this technique.</p>"},{"location":"blog/2023/php-auto-instrumentation/#observability-api-from-auto-instrumentation-perspective","title":"Observability API from auto-instrumentation perspective","text":"<p>At the moment of this writing, observability API is used by c extension and exposes one function with the following interface:</p> <pre><code>function hook(\n    ?string $class,\n    string $function,\n    ?\\Closure $pre = null,\n    ?\\Closure $post = null,\n): bool {}\n</code></pre> <p>This function can be used from user application in order to add additional functionality executed before and after the observed function. The below code snippet shows how to instrument dummy <code>helloworld</code> function:</p> <pre><code>function helloWorld() {\n  echo 'helloWorld';\n}\n\\OpenTelemetry\\Instrumentation\\hook(null, 'helloWorld',\n    static function (?string $class, array $params, ?string $classname, string $functionname, ?string $filename, ?int $lineno)\n    {\n      echo 'before';\n    },\n    static function (mixed $object, array $params, mixed $return, ?Throwable $exception)\n    {\n      echo 'after';\n    }\n);\n</code></pre> <p>In the same way, we have implemented tracing support for some of the most important <code>interfaces/libraries/frameworks</code> that are parts of Contrib repo. Each <code>auto-instrumentation</code> package uses above <code>hook</code> function in order to register and provide tracing functionality. One missing thing, not mentioned yet is an <code>API</code> <code>SDK</code> used to create traces and other necessary components. This is the responsibility of the opentelemetry-php main repo which is foundation for everything.</p> <p></p>"},{"location":"blog/2023/php-auto-instrumentation/#how-to-use-it","title":"How to use it","text":"<p>All components necessary for auto-instrumentation can be installed manually, however we invested time to lower the barrier to entry and have created an installer that can do that for you. This section will show how auto-instrument a simple PHP <code>laravel</code> application created from scratch.</p> <p>The first step is to create a demo application. Here we use the popular laravel framework:</p> <pre><code>composer create-project laravel/laravel example-app\n</code></pre> <p>Next, install opentelemetry-instrumentation-installer.</p> <pre><code>cd example-app\ncomposer require open-telemetry/opentelemetry-instrumentation-installer\n</code></pre> <p>OpenTelemetry instrumentation installer works in two modes:</p> <ul> <li>basic (installs everything with most recent version)</li> <li>advanced (gives control to the user)</li> </ul> <p>After installation, run <code>install-otel-instrumentation</code> with either <code>basic</code> or <code>advanced</code> switch as below.</p> <pre><code>./vendor/bin/install-otel-instrumentation basic\n</code></pre> <p>The final step is to run your application with <code>run-with-otel-instrumentation</code>:</p> <pre><code>./vendor/bin/run-with-otel-instrumentation php -S localhost:8080 -t public public/index.php\n</code></pre> <p>The run-with-otel-instrumentation isn't magic: everything it does can be done by hand by setting environment variables and running your application normally. It is a convenience tool for rapidly testing out OpenTelemetry against an application with a working default configuration.</p> <pre><code>./vendor/bin/run-with-otel-instrumentation php -S localhost:8080 -t public public/index.php\n</code></pre> <p>Now, as a result of triggering request to http://localhost:8080 you should see following result in Jaeger</p> <p></p>"},{"location":"blog/2023/php-auto-instrumentation/#current-status-and-next-steps","title":"Current status and next steps","text":"<p>We have all necessary components in place:</p> <ul> <li>APIs and SDK as a foundation and implementation of opentelemetry   specification.</li> <li>C extension as a foundation for auto-instrumentation.</li> <li>Auto Instrumentation support (WIP) for most important and popular libraries   and frameworks.</li> <li>Development tools that can help lower barrier for users and developers   interested in instrumenting arbitrary code.</li> <li>Documentation</li> </ul> <p>One of our goals is to increase awareness of this work and involve more people that will help us improve it, extend coverage and fix bugs.</p> <p>Please try it out and give us feedback. If you encounter any problems, you can open an issue. Questions? Feel free to reach out to us in the CNCF #otel-php Slack channel, or come to our SIG meeting, which you can find on the OTel public calendar.</p>"},{"location":"blog/2023/why-histograms/","title":"Why Histograms?","text":"<p>A histogram is a multi-value counter that summarizes the distribution of data points. For example, a histogram may have 3 counters which count the occurrences of negative, positive, and zero values respectively. Given a series of numbers, <code>3</code>, <code>-9</code>, <code>7</code>, <code>6</code>, <code>0</code>, and <code>-1</code>, the histogram would count <code>2</code> negative, <code>1</code> zero, and <code>3</code> positive values. A single histogram data point is most commonly represented as a bar chart.</p> <p></p> <p>The above example has only 3 possible output values, but it is common to have many more in a single histogram. A real-world application typically exports a histogram every minute that summarizes a metric for the previous minute. By using histograms this way, you can study how the distribution of your data changes over time.</p>"},{"location":"blog/2023/why-histograms/#what-are-histograms-for","title":"What are histograms for?","text":"<p>There are many uses for histograms, but their power comes from the ability to efficiently answer queries about the distribution of your data. These queries most commonly come in some form like \"what was the median response time in the last minute?\" These are known as \u03c6-quantiles, and often are abbreviated in a shorthand like <code>p50</code> for the 50th percentile or 0.5-quantile, also known as the median. More generally, the \u03c6-quantile is the observation value that ranks at number \u03c6*N among the N observations.</p>"},{"location":"blog/2023/why-histograms/#why-are-histograms-useful","title":"Why are Histograms useful?","text":"<p>A common use-case for histograms in observability is defining service level objectives (SLOs). One example of such an SLO might be \"&gt;=99% of all queries should respond in less than 30ms,\" or \"90% of all page loads should become interactive within 100ms of first paint.\"</p> <p>In the following chart, you can see the <code>p50</code>, <code>p90</code>, and <code>p99</code> response times plotted for some requests over some time. From the data, you can see that 50% of requests are served in around 20-30ms or less, 90% of requests are served in under about 80ms, and 99% of requests are served in under around 90ms. You can very quickly see that at least 50% of your users are receiving very fast response times, but almost all of your users are experiencing response times under 90ms.</p> <p></p>"},{"location":"blog/2023/why-histograms/#other-metric-types","title":"Other metric types","text":"<p>What if you're already defining SLOs based on other metrics? You may have considered defining the SLOs to be based on gauges or counters. This approach can work, but it requires defining your SLOs before understanding your data distribution and requires non-trivial implementation at collection time. It is also inflexible; if you decide to change your SLO from 90% of requests to 99% of requests, you have to make and release code changes, then wait for the old data to age out and the new metric to collect enough data to make useful queries. Because histograms model data as a distribution from start to finish, they enable you to simply change your queries and get answers on the data you've already collected. Particularly with exponential histograms, arbitrary distribution queries can be made with very low relative error rates and minimal resource consumption on both the client and the analysis backend.</p> <p>The inflexibility of not using histograms for SLOs also impacts your ability to gauge impact when your SLO is violated. For example, imagine you are collecting a gauge that calculates the <code>p99</code> of some metric and you define an SLO based on it. When your SLO is violated and an alert is triggered, how do you know it is really only affecting 1% of queries, 10%, or 50%? A histogram allows you to answer that question by querying the percentiles you're interested in.</p> <p>Another option is to collect each quantile you're interested in as a gauge. Some systems, like Prometheus, support this natively using a metric type sometimes called a summary. Summaries can work, but they suffer the same inflexibility as gauges and counters, requiring you to decide ahead of time which quantiles to collect. They also cannot be aggregated, meaning that a <code>p90</code> cannot be accurately calculated from two separate hosts each reporting their own <code>p90</code>.</p>"},{"location":"blog/2023/why-histograms/#other-data-sources-and-metric-types","title":"Other data sources and metric types","text":"<p>You may ask, \"why would I report a separate metric rather than calculating it from my existing log and trace data?\" While it is true that for some use cases, like response times, this may be possible, it is not necessarily possible for all use cases. Even when quantiles can be calculated from existing data, you may run into other problems. You need to be sure your observability backend is able to query and analyze a large amount of existing data on-line or index and analyze it at ingestion time. If you are sampling your logs and traces or employing a data retention policy that ages data out, you need to be sure those things are not affecting derived metrics, or that they are properly re-weighted, or you risk not being able to accurately asses your SLOs. Depending on your sampling strategy, it may not even be possible. Using histograms is a way to avoid these subtle problems if they apply to you.</p> <p>A version of this article was [originally posted][] to the author's blog.</p> <p>[originally posted]: {{% param canonical_url %}}</p>"},{"location":"community/_index/","title":"Community","text":"<p>{{% community-lists %}}</p>"},{"location":"community/_index/#participate-in-end-user-groups","title":"Participate in End User Groups","text":"<p>Interested in connecting with other end-users and providing feedback to OpenTelemetry maintainers? Check out the End User Resources to learn more.</p>"},{"location":"community/_index/#special-interest-groups","title":"Special Interest Groups","text":"<p>We organize the community into Special Interest Groups (SIGs) in order to improve our workflow and more easily manage a community project. Read more from our community repo.</p>"},{"location":"community/_index/#ecosystem","title":"Ecosystem","text":"<p>Looking for components, examples, integrations and more? See Ecosystem.</p>"},{"location":"community/marketing-guidelines/","title":"OpenTelemetry Marketing Guidelines for Contributing Organizations","text":"<p>OpenTelemetry (aka OTel) is a collaboration among end-users, adjacent OSS projects, and vendors who ultimately sell products and services built upon OTel data or components. Like many standards-oriented projects, the vendors that partner on OTel also compete in the marketplace, and for this reason it\u2019s important to establish some ground rules and expectations for how contributing organizations communicate and message about OTel.</p> <p>In fact, OTel\u2019s success depends on both the reality and the perception of sincere collaboration between the many parties (and vendors) involved. There\u2019s a lot of superb technical work happening within OTel, and we want to make sure it\u2019s not overshadowed by an opportunistic marketing department here or there!</p> <p>This document is divided into two sections:</p> <ul> <li>Goals and Guidelines: What are we trying to achieve? What is our guidance?</li> <li>Concerns and consequences: How do we determine that a guideline has been   violated? And what do we do about it?</li> </ul>"},{"location":"community/marketing-guidelines/#goals-and-guidelines","title":"Goals and Guidelines","text":"<p>There are three high-level focus areas for these goals and guidelines.</p>"},{"location":"community/marketing-guidelines/#i-opentelemetry-is-a-joint-effort","title":"I: OpenTelemetry is a joint effort","text":"<ul> <li>Do\u2019s:</li> <li>Use project collateral such as logo and name in line with the Linux     Foundation\u2019s branding and     trademark usage guidelines</li> <li>Emphasize that OTel would not be possible without collaboration from many     contributors who happen to work for competing vendors and providers</li> <li>Cite names of the other contributors and vendors involved with OTel efforts</li> <li>Emphasize our common goals as a community to improve end user/developer     experiences and empower them</li> <li>Don\u2019ts:</li> <li>Imply that a single provider is responsible for OTel itself, and/or one of     its various component parts</li> <li>Diminish the contributions of another organization or of another individual</li> </ul>"},{"location":"community/marketing-guidelines/#ii-its-not-a-competition","title":"II: It\u2019s not a competition","text":"<ul> <li>Do\u2019s:</li> <li>Emphasize that all contributions are valuable, and that they come in many     shapes and sizes, including:</li> <li>Contributions to the core project code or to language- or framework-specific     SDKs</li> <li>Creating and sharing educational resources (videos, workshops, articles), or     shared resources that can be used for educational purposes (e.g. a sample     app using specific language/framework)</li> <li>Community-building activities such as organizing an event or meetup group</li> <li>Publicly recognize and thank other organizations for their contributions to     OTel</li> <li>Don\u2019ts:</li> <li>Directly compare the volume or value of different contributors to OTel     (E.g., via CNCF devstats)</li> <li>Imply that infrequent or minor contributors to OTel are necessarily     second-class citizens, and/or that their own OTel compatibility should be     questioned as a result (in fact, there\u2019s no reason that any provider needs     to contribute to OTel in order to support it)</li> </ul>"},{"location":"community/marketing-guidelines/#iii-promote-awareness-of-otel-interoperability-and-modularization","title":"III: Promote awareness of OTel interoperability and modularization","text":"<ul> <li>Do\u2019s:</li> <li>\u201cShout from the rooftops\u201d about OTel compatibility \u2013 the more that end-users     understand what they can do with OTel data, the better</li> <li>Emphasize the vendor-neutrality and portability of any OTel integration</li> <li>Don\u2019ts:</li> <li>Imply that an end-user isn\u2019t \u201cUsing OTel\u201d unless they\u2019re using some specific     set of components within OTel (OTel is a \u201cwide\u201d project with many decoupled     components)</li> <li>Publicly denigrate the OTel support of another provider, particularly     without objective evidence</li> </ul>"},{"location":"community/marketing-guidelines/#concerns-and-consequences","title":"Concerns and Consequences","text":"<p>Inevitably there will be instances where vendors (or at least their Marketing departments) run afoul of these guidelines. To date, this hasn\u2019t happened frequently, so we don\u2019t want to create an over-complicated process to handle concerns.</p> <p>Here is how we handle such circumstances:</p> <ol> <li>Whomever notices the relevant public (marketing) content should write an    email to cncf-opentelemetry-governance@lists.cncf.io and include an    explanation of why the content is problematic, ideally referencing the    relevant guidelines above.</li> <li>The OTel Governance Committee (GC) will discuss the case during its next    (weekly) meeting, or asynchronously via email if possible. The OTel GC    guarantees a response via email within two weeks of the initial report.</li> <li>If the GC agrees that there\u2019s a problem, a corrective action will be    recommended to the author of the content in question, and the GC will request    that the organization that published the content train relevant employees on    the content in this document as a further preventative measure.</li> </ol> <p>If a pattern develops with a particular vendor, the GC will meet to discuss more significant consequences \u2013 for instance, removing that vendor\u2019s name from OTel-maintained lists of compatible providers, or simply publicly documenting the pattern of poor community behavior.</p>"},{"location":"community/end-user/_index/","title":"End-user Resources","text":"<p>The OpenTelemetry End User Working Group has heard feedback from users who desire a vendor-agnostic space to discuss adopting OpenTelemetry, so we provide multiple ways for you to connect with other users of the project and share best practices:</p> <ul> <li>A synchronous monthly discussion group</li> <li>A private slack channel</li> <li>Talks about OTel in practice</li> <li>Direct interview/feedback sessions</li> </ul> <p>These forums will bring together operations and development engineers from different organizations to discuss challenges and solutions to achieving ubiquitous observability. Share successes and failures, discover best practices, and meet others who are also on a journey to implement observability powered by OpenTelemetry.</p>"},{"location":"community/end-user/_index/#topics","title":"Topics","text":"<p>This group is what its members make it -- whatever is of interest to the group is fair game!</p> <p>But here are some of the kinds of things we expect will be on the table:</p> <ul> <li>Refactoring with telemetry</li> <li>What is company X doing with OpenTelemetry?</li> <li>Correlating multiple observability signals</li> <li>Maintaining and scaling OpenTelemetry deployments</li> <li>Writing custom instrumentation</li> </ul>"},{"location":"community/end-user/_index/#questions","title":"Questions","text":"<p>Is this group only for OpenTelemetry end users?</p> <p>No! Anyone is welcome to join and discuss their journey to observability. This group is hosted by the OpenTelemetry Community End-User Working Group, so we expect most participants will be from organizations that are evaluating or using OpenTelemetry.</p> <p>I have questions about this, who can I reach out to?</p> <p>You can find members of the End User Working Group in #otel-user-research.</p>"},{"location":"community/end-user/discussion-group/","title":"Monthly Discussion Group","text":"<p>Interested in learning how other end users are implementing OpenTelemetry in their organizations? Come talk shop with other OpenTelemetry end users! This is a vendor-neutral space to discuss best practices, ask questions, and meet other observability-minded folks.</p> <p>Feedback that is shared and collected in these sessions will be routed back to the relevant project maintainers to help drive prioritization of improvements and changes to the project.</p> <p>New for 2023!</p> <ul> <li>Sessions are now available for all regions!</li> <li>You can now find summaries of past discussions every month! Search the blog   for \"End-User Discussions\".</li> <li>A project maintainer and/or a Governance Committee member will be in   attendance at each session to provide additional context, insight, and plans   to user questions and feedback.</li> <li>The Chatham House Rule will no longer be applied, and sessions will be   recorded. This will help make the feedback more discoverable by the   community.</li> </ul> <p>Upcoming sessions</p> <p>Here are upcoming sessions, or you can view them on the OpenTelemetry calendar:</p> <ul> <li>EMEA (Europe, Middle East, and Africa): every third Tuesday of the month   at 11AM CET (GMT +1), join   here</li> <li>March 21</li> <li>April 18</li> <li>May 16</li> <li>APAC (Asia Pacific): every third Wednesday of the month at 11AM India ST   (GMT +5.5), register here to get the Zoom link</li> <li>March 15</li> <li>April 19</li> <li>May 17</li> <li>AMER (Americas): every third Thursday of the month at 9AM PST (GMT -8),   join   here</li> <li>March 16</li> <li>April 20</li> <li>May 18</li> </ul> <p>Past topics/questions have included:</p> <ul> <li>Best practices on monitoring collectors in production</li> <li>Using OTel in CI/CD pipelines</li> <li>What\u2019s holding you back from adopting more OpenTelemetry?</li> <li>Auto vs manual instrumentation use cases</li> <li>How to secure a publicly exposed OTel Collector?</li> </ul> <p>We use a Lean Coffee format where discussion topics are generated and democratically selected by the group at the start of the meeting. Topics are rigorously time-boxed by a facilitator.</p>"},{"location":"community/end-user/interviews-feedback/","title":"Interviews or Feedback Sessions","text":"<p>One of the core functions of the OpenTelemetry End User Working Group is to improve the project by gathering feedback from end users and sharing them with the appropriate SIGs to help drive prioritization of improvements and changes to the project.</p> <p>Direct interview or feedback sessions between an organization and the OpenTelemetry Community is one such resource. In these hour-long sessions, we learn about the organization's OTel adoption and implementation, with particular interest in the following:</p> <ul> <li>Special use cases</li> <li>Challenges with implementation -- what went well? What needs improvement?   These can be anything, from instrumentation to documentation.</li> <li>Challenges with adoption within the organization -- how can the Community help   you drive adoption with your teams?</li> </ul> <p>We will then take the feedback you shared and turn them into actionable tasks for the relevant SIGs, as well as provide context and insight for you during the session as appropriate.</p> <p>We schedule these sessions once a month, usually during one of the EUWG's meetings (alternating Thursdays at 10AM Pacific Time), but can set up a different time if that does not work for you. The sessions are typically attended by a few project maintainers and/or Governance Committee members, as well as some curious general members of the Community.</p> <p>Things to keep in mind:</p> <ul> <li>These sessions are recorded. However, if your organization has compliance   concerns, we can delete them once we've summarized the notes and feedback.</li> <li>We will write up a summary post for the OpenTelemetry blog. Our goal with   these is to drive awareness and adoption of the software, and to chronicle   interesting use cases. These can be anonymized if your org has compliance   concerns.</li> <li>These are open to the public, so other users may come and ask you questions.</li> </ul> <p>To schedule a session, reach out to us in CNCF Community Slack:</p> <ul> <li>In the   #otel-user-research   channel</li> <li>Via direct message: ping   Reese Lee,   Adriana Villela, or   Rynn Mancuso</li> </ul>"},{"location":"community/end-user/otel-in-practice/","title":"OpenTelemetry In Practice","text":"<p>We\u2019re aiming to:</p> <ul> <li>Address practical problems that commonly stop development teams from   succeeding with OpenTelemetry</li> <li>Build stronger connections with developers focused on specific languages</li> <li>Improve the experience of implementing OpenTelemetry in production</li> </ul> <p>Each OpenTelemetry in Practice session will include a half hour of lightning talks and a half hour of open conversation about the topic. We are looking for people to join the OpenTelemetry in Practice team and people to give talks at future events. So if you\u2019re interested in shaping these conversations, reach out in the #otel-user-research channel of the CNCF Slack.</p> <p>Join the OpenTelemetry in Practice Meetup Group to get invited to our next talk!</p>"},{"location":"community/end-user/slack-channel/","title":"Slack Channel","text":"<ul> <li>Confirm your agreement with channel Code of Conduct and reach out to Reese   Lee, Rynn Mancuso, or Adriana Villela on CNCF slack for an invite to   <code>#otel-endusers</code>.</li> <li>Troubleshooting or tactical SDK specific questions are still best directed to   individual SIG channels or the   #opentelemetry channel.</li> <li>Vendor specific questions are still best directed to vendor channels, or if it   doesn\u2019t exist   #otel-vendor</li> </ul>"},{"location":"docs/_index/","title":"\u6587\u6863","text":"<p>OpenTelemetry\uff0c\u4e5f\u88ab\u7b80\u79f0\u4e3aOTel\uff0c\u662f\u4e00\u4e2a\u4f9b\u5e94\u5546\u4e2d\u7acb\u7684\u5f00\u6e90\u53ef\u89c2\u5bdf\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u3001\u751f\u6210\u3001\u6536\u96c6\u548c\u5bfc\u51fa\u9065\u6d4b\u6570\u636e\uff0c\u5982\u8ddf\u8e2a\u3001\u5ea6\u91cf\u3001\u65e5\u5fd7\u3002 \u4f5c\u4e3a\u4e00\u4e2a\u884c\u4e1a\u6807\u51c6\uff0c\u5b83\u88ab\u8bb8\u591a\u4f9b\u5e94\u5546\u672c\u5730\u652f\u6301\u3002</p> <p></p>"},{"location":"docs/contribution-guidelines/","title":"Contribution guidelines","text":"<p>OpenTelemetry is an open source project, and we gladly accept new contributions and contributors. Please see the CONTRIBUTING.md file in each SIG repository for information on getting started.</p>"},{"location":"docs/contribution-guidelines/#contributing-to-the-opentelemetry-documentation","title":"Contributing to the OpenTelemetry Documentation","text":"<p>Individual SIGs may maintain documentation above and beyond what is offered here, but we strive for accurate general guidance on using the project from our main website.</p> <p>The per-language API, SDK, and \"Getting Started\" documentation is hosted in each language's GitHub repository. For more information, see the Mirrored Documentation section of the website repository's CONTRIBUTING.md file.</p>"},{"location":"docs/contribution-guidelines/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>Contributors to this and other OpenTelemetry projects require acceptance of our CLA, managed by EasyCLA.</p>"},{"location":"docs/contribution-guidelines/#code-reviews","title":"Code reviews","text":"<p>All submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose. Consult GitHub Help for more information on using pull requests.</p>"},{"location":"docs/contribution-guidelines/#getting-started","title":"Getting started","text":"<p>See README.md for current information.</p>"},{"location":"docs/contribution-guidelines/#code-of-conduct","title":"Code of conduct","text":"<p>OpenTelemetry follows the CNCF Code of Conduct.</p>"},{"location":"docs/what-is-opentelemetry/","title":"\u4ec0\u4e48\u662fOpenTelemetry?","text":"<p>\u5fae\u670d\u52a1\u67b6\u6784\u4f7f\u5f00\u53d1\u4eba\u5458\u80fd\u591f\u66f4\u5feb\u3001\u66f4\u72ec\u7acb\u5730\u6784\u5efa\u548c\u53d1\u5e03\u8f6f\u4ef6\uff0c\u56e0\u4e3a\u4ed6\u4eec\u4e0d\u518d\u53d7\u5236\u4e8e\u4e0e\u5355\u7247\u67b6\u6784\u76f8\u5173\u7684\u590d\u6742\u53d1\u5e03\u8fc7\u7a0b\u3002</p> <p>\u968f\u7740\u8fd9\u4e9b\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6269\u5c55\uff0c\u5f00\u53d1\u4eba\u5458\u8d8a\u6765\u8d8a\u96be\u4ee5\u770b\u5230\u4ed6\u4eec\u81ea\u5df1\u7684\u670d\u52a1\u5982\u4f55\u4f9d\u8d56\u6216\u5f71\u54cd\u5176\u4ed6\u670d\u52a1\uff0c\u7279\u522b\u662f\u5728\u90e8\u7f72\u4e4b\u540e\u6216\u4e2d\u65ad\u671f\u95f4\uff0c\u901f\u5ea6\u548c\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002</p> <p>\u53ef\u89c2\u5bdf\u6027\u4f7f\u5f00\u53d1\u4eba\u5458\u548c\u64cd\u4f5c\u4eba\u5458\u90fd\u53ef\u4ee5\u83b7\u5f97\u5bf9\u5176\u7cfb\u7edf\u7684\u53ef\u89c1\u6027\u3002</p>"},{"location":"docs/what-is-opentelemetry/#_1","title":"\u90a3\u53c8\u600e\u6837?","text":"<p>\u4e3a\u4e86\u4f7f\u7cfb\u7edf\u53ef\u89c2\u5bdf\uff0c\u5fc5\u987b\u5bf9\u5176\u8fdb\u884c\u68c0\u6d4b\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u4ee3\u7801\u5fc5\u987b\u53d1\u51fatrace\u3001metrics\u548clogs\u3002 \u7136\u540e\u5fc5\u987b\u5c06\u68c0\u6d4b\u7684\u6570\u636e\u53d1\u9001\u5230\u53ef\u89c2\u5bdf\u6027\u540e\u7aef\u3002 \u73b0\u5728\u6709\u5f88\u591a\u53ef\u89c2\u5bdf\u6027\u540e\u7aef\uff0c\u4ece\u81ea\u6258\u7ba1\u7684\u5f00\u6e90\u5de5\u5177(\u4f8b\u5982Jaeger\u548cZipkin)\u5230\u5546\u4e1aSaaS\u4ea7\u54c1\u3002</p> <p>\u5728\u8fc7\u53bb\uff0c\u68c0\u6d4b\u4ee3\u7801\u7684\u65b9\u5f0f\u5404\u4e0d\u76f8\u540c\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u53ef\u89c2\u5bdf\u7684\u540e\u7aef\u90fd\u6709\u81ea\u5df1\u7684\u68c0\u6d4b\u5e93\u548c\u4ee3\u7406\uff0c\u7528\u4e8e\u5411\u5de5\u5177\u53d1\u9001\u6570\u636e\u3002</p> <p>\u8fd9\u610f\u5473\u7740\u6ca1\u6709\u6807\u51c6\u7684\u6570\u636e\u683c\u5f0f\u6765\u5c06\u6570\u636e\u53d1\u9001\u5230\u53ef\u89c2\u5bdf\u6027\u540e\u7aef\u3002 \u6b64\u5916\uff0c\u5982\u679c\u4e00\u5bb6\u516c\u53f8\u9009\u62e9\u5207\u6362Observability\u540e\u7aef\uff0c\u8fd9\u610f\u5473\u7740\u4ed6\u4eec\u5fc5\u987b\u91cd\u65b0\u7f16\u5199\u4ee3\u7801\u5e76\u914d\u7f6e\u65b0\u7684\u4ee3\u7406\uff0c\u4ee5\u4fbf\u80fd\u591f\u5411\u6240\u9009\u62e9\u7684\u65b0\u5de5\u5177\u53d1\u9001\u9065\u6d4b\u6570\u636e\u3002</p> <p>\u7531\u4e8e\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u6700\u7ec8\u7684\u7ed3\u679c\u662f\u7f3a\u4e4f\u6570\u636e\u53ef\u79fb\u690d\u6027\uff0c\u5e76\u4e14\u589e\u52a0\u4e86\u7528\u6237\u7ef4\u62a4\u4eea\u5668\u5e93\u7684\u8d1f\u62c5\u3002</p> <p>\u8ba4\u8bc6\u5230\u6807\u51c6\u5316\u7684\u9700\u8981\uff0c\u4e91\u793e\u533a\u805a\u96c6\u5728\u4e00\u8d77\uff0c\u4e24\u4e2a\u5f00\u6e90\u9879\u76ee\u8bde\u751f\u4e86:OpenTracing(\u4e00\u4e2acloud Native Computing Foundation (CNCF)\u9879\u76ee)\u548cOpenCensus(\u4e00\u4e2aGoogle opensource\u793e\u533a\u9879\u76ee)\u3002</p> <p>OpenTracing \u63d0\u4f9b\u4e86\u4e00\u4e2a\u5382\u5546\u4e2d\u7acb\u7684API\uff0c\u7528\u4e8e\u5c06\u9065\u6d4b\u6570\u636e\u53d1\u9001\u5230\u53ef\u89c2\u5bdf\u7684\u540e\u7aef;\u7136\u800c\uff0c\u5b83\u4f9d\u8d56\u4e8e\u5f00\u53d1\u4eba\u5458\u5b9e\u73b0\u4ed6\u4eec\u81ea\u5df1\u7684\u5e93\u6765\u6ee1\u8db3\u89c4\u8303\u3002</p> <p>OpenCensus \u63d0\u4f9b\u4e86\u4e00\u7ec4\u7279\u5b9a\u4e8e\u8bed\u8a00\u7684\u5e93\uff0c\u5f00\u53d1\u4eba\u5458\u53ef\u4ee5\u4f7f\u7528\u5b83\u4eec\u6765\u68c0\u6d4b\u4ed6\u4eec\u7684\u4ee3\u7801\u5e76\u5c06\u5176\u53d1\u9001\u5230\u4ed6\u4eec\u652f\u6301\u7684\u4efb\u4f55\u4e00\u4e2a\u540e\u7aef\u3002</p>"},{"location":"docs/what-is-opentelemetry/#opentelemetry","title":"\u4f60\u597d,OpenTelemetry !","text":"<p>\u4e3a\u4e86\u5b9e\u73b0\u5355\u4e00\u6807\u51c6\uff0cOpenCensus\u548cOpenTracing\u4e8e2019\u5e745\u6708\u5408\u5e76\u4e3aOpenTelemetry(\u7b80\u79f0OTel)\u3002 \u4f5c\u4e3aCNCF\u7684\u5b75\u5316\u9879\u76ee\uff0cOpenTelemetry\u517c\u6536\u5e76\u4e3e\u3002</p> <p>OTel\u7684\u76ee\u6807\u662f\u63d0\u4f9b\u4e00\u5957\u6807\u51c6\u5316\u7684\u3001\u4e0e\u4f9b\u5e94\u5546\u65e0\u5173\u7684sdk\u3001api\u548c\u5de5\u5177(/docs/collector)\uff0c\u7528\u4e8e\u6444\u53d6\u3001\u8f6c\u6362\u548c\u53d1\u9001\u6570\u636e\u5230\u53ef\u89c2\u5bdf\u6027\u540e\u7aef(\u5373\u5f00\u6e90\u6216\u5546\u4e1a\u4f9b\u5e94\u5546)\u3002</p>"},{"location":"docs/what-is-opentelemetry/#opentelemetry_1","title":"OpenTelemetry\u80fd\u4e3a\u6211\u505a\u4ec0\u4e48?","text":"<p>OTel\u62e5\u6709\u5e7f\u6cdb\u7684\u884c\u4e1a\u652f\u6301\u548c\u4e91\u63d0\u4f9b\u5546\u3001\u5382\u5546\u548c\u7ec8\u7aef\u7528\u6237\u7684\u91c7\u7528\u3002\u5b83\u4e3a\u60a8\u63d0\u4f9b:</p> <ul> <li>\u4e00\u4e2a\u5355\u4e00\u7684\u3001\u4e0e\u5382\u5546\u65e0\u5173\u7684\u68c0\u6d4b\u5e93\u6bcf\u79cd\u8bed\u8a00\uff0c\u652f\u6301\u81ea\u52a8\u548c\u624b\u52a8\u68c0\u6d4b\u3002</li> <li>\u4e00\u4e2a\u72ec\u7acb\u4e8e\u4f9b\u5e94\u5546\u7684\u6536\u96c6\u5668\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u53ef\u4ee5\u4ee5\u591a\u79cd\u65b9\u5f0f\u90e8\u7f72\u3002</li> <li>\u751f\u6210\u3001\u53d1\u51fa\u3001\u6536\u96c6\u3001\u5904\u7406\u548c\u5bfc\u51fa\u9065\u6d4b\u6570\u636e\u7684\u7aef\u5230\u7aef\u5b9e\u73b0\u3002</li> <li>\u5b8c\u5168\u63a7\u5236\u60a8\u7684\u6570\u636e\uff0c\u5e76\u80fd\u591f\u901a\u8fc7\u914d\u7f6e\u5c06\u6570\u636e\u5e76\u884c\u53d1\u9001\u5230\u591a\u4e2a\u76ee\u7684\u5730\u3002</li> <li>\u5f00\u653e\u6807\u51c6\u8bed\u4e49\u7ea6\u5b9a\uff0c\u786e\u4fdd\u4e0e\u4f9b\u5e94\u5546\u65e0\u5173\u7684\u6570\u636e\u6536\u96c6</li> <li>\u80fd\u591f\u5e76\u884c\u652f\u6301\u591a\u79cd\u4e0a\u4e0b\u6587\u4f20\u64ad\u683c\u5f0f\uff0c\u4ee5\u5e2e\u52a9\u968f\u7740\u6807\u51c6\u7684\u53d1\u5c55\u800c\u8fc1\u79fb\u3002</li> <li>\u65e0\u8bba\u4f60\u5728\u53ef\u89c2\u5bdf\u6027\u4e4b\u65c5\u7684\u54ea\u4e2a\u4f4d\u7f6e\uff0c\u90fd\u662f\u4e00\u6761\u524d\u8fdb\u7684\u9053\u8def\u3002</li> </ul> <p>\u901a\u8fc7\u5bf9\u5404\u79cd\u5f00\u6e90\u548c\u5546\u4e1a\u534f\u8bae\uff0c\u683c\u5f0f\u548c\u4e0a\u4e0b\u6587\u4f20\u64ad\u673a\u5236\u7684\u652f\u6301\uff0c\u4ee5\u53ca\u4e3aOpenTracing\u548cOpenCensus\u9879\u76ee\u63d0\u4f9bshims\uff0c\u91c7\u7528OpenTelemetry\u5f88\u5bb9\u6613\u3002</p>"},{"location":"docs/what-is-opentelemetry/#opentelemetry_2","title":"OpenTelemetry\u4e0d\u662f\u4ec0\u4e48","text":"<p>OpenTelemetry\u4e0d\u50cfJaeger\u6216Prometheus\u90a3\u6837\u662f\u4e00\u4e2a\u53ef\u89c2\u5bdf\u7684\u540e\u7aef\u3002 \u76f8\u53cd\uff0c\u5b83\u652f\u6301\u5c06\u6570\u636e\u5bfc\u51fa\u5230\u5404\u79cd\u5f00\u6e90\u548c\u5546\u4e1a\u540e\u7aef\u3002 \u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u63d2\u62d4\u7684\u67b6\u6784\uff0c\u56e0\u6b64\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u6dfb\u52a0\u5176\u4ed6\u6280\u672f\u534f\u8bae\u548c\u683c\u5f0f\u3002</p>"},{"location":"docs/what-is-opentelemetry/#_2","title":"\u4e0b\u4e00\u4e2a\u4ec0\u4e48?","text":"<ul> <li>\u5165\u95e8 \u2014\u8df3\u8fdb\u53bb\u5427!</li> <li>\u4e86\u89e3OpenTelemetry\u6982\u5ff5.</li> </ul>"},{"location":"docs/acknowledgements/_index/","title":"Acknowledgements","text":"<p>We would like to acknowledge the following sources for some of the content on this site:</p> <ol> <li>APM is Dying and That's Okay - Lightstep</li> <li>Alexandria Pigram via    Honeycomb for tracing content in    Traces</li> <li>What is OpenTelemetry - Dynatrace</li> <li>Understanding OpenTracing, OpenCensus, and OpenMetrics - BMC</li> <li>Ask Miss O11y: Baggage in OTel - Honeycomb</li> </ol>"},{"location":"docs/collector/_index/","title":"\u6536\u96c6\u5668","text":""},{"location":"docs/collector/_index/#_1","title":"\u4ecb\u7ecd","text":"<p>The OpenTelemetry Collector offers a vendor-agnostic implementation of how to receive, process and export telemetry data. It removes the need to run, operate, and maintain multiple agents/collectors. This works with improved scalability and supports open source observability data formats (e.g. Jaeger, Prometheus, Fluent Bit, etc.) sending to one or more open source or commercial back-ends. The local Collector agent is the default location to which instrumentation libraries export their telemetry data.</p>"},{"location":"docs/collector/_index/#_2","title":"\u76ee\u6807","text":"<ul> <li>Usability: \u5408\u7406\u7684\u9ed8\u8ba4\u914d\u7f6e\uff0c\u652f\u6301\u6d41\u884c\u7684\u534f\u8bae\uff0c\u5f00\u7bb1\u5373\u7528\u7684\u8fd0\u884c\u548c\u6536\u96c6\u3002</li> <li>Performance: Highly stable and performant under varying loads and   configurations.</li> <li>Observability: An exemplar of an observable service.</li> <li>Extensibility: Customizable without touching the core code.</li> <li>Unification: Single codebase, deployable as an agent or collector with   support for traces, metrics, and logs (future).</li> </ul>"},{"location":"docs/collector/_index/#_3","title":"\u4f55\u65f6\u4f7f\u7528\u6536\u96c6\u5668","text":"<p>\u5bf9\u4e8e\u5927\u591a\u6570\u7279\u5b9a\u4e8e\u8bed\u8a00\u7684\u5de5\u5177\u5e93\uff0c\u60a8\u90fd\u6709\u9488\u5bf9\u6d41\u884c\u540e\u7aef\u548cOTLP\u7684\u5bfc\u51fa\u5668\u3002\u4f60\u53ef\u80fd\u4f1a\u60f3\uff0c</p> <p>\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u4f7f\u7528\u6536\u96c6\u5668\u53d1\u9001\u6570\u636e\uff0c\u800c\u4e0d\u662f\u8ba9\u6bcf\u4e2a\u670d\u52a1\u76f4\u63a5\u53d1\u9001\u5230\u540e\u7aef?</p> <p>\u5bf9\u4e8e\u5c1d\u8bd5\u548c\u5f00\u59cb\u4f7f\u7528OpenTelemetry\uff0c\u5c06\u6570\u636e\u76f4\u63a5\u53d1\u9001\u5230\u540e\u7aef\u662f\u5feb\u901f\u83b7\u53d6\u4ef7\u503c\u7684\u597d\u65b9\u6cd5\u3002 \u6b64\u5916\uff0c\u5728\u5f00\u53d1\u6216\u5c0f\u89c4\u6a21\u73af\u5883\u4e2d\uff0c\u60a8\u53ef\u4ee5\u5728\u6ca1\u6709\u6536\u96c6\u5668\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u4e0d\u9519\u7684\u7ed3\u679c\u3002</p> <p>\u4f46\u662f\uff0c\u901a\u5e38\u6211\u4eec\u5efa\u8bae\u5728\u670d\u52a1\u65c1\u8fb9\u4f7f\u7528\u6536\u96c6\u5668\uff0c\u56e0\u4e3a\u5b83\u5141\u8bb8\u60a8\u7684\u670d\u52a1\u5feb\u901f\u5378\u8f7d\u6570\u636e\uff0c\u5e76\u4e14\u6536\u96c6\u5668\u53ef\u4ee5\u5904\u7406 \u989d\u5916\u7684\u5904\u7406\uff0c\u5982\u91cd\u8bd5\uff0c\u6279\u5904\u7406\uff0c\u52a0\u5bc6\uff0c\u751a\u81f3\u654f\u611f\u6570\u636e\u8fc7\u6ee4\u3002</p> <p>\u8bbe\u7f6e\u6536\u96c6\u5668\u4e5f\u6bd4\u60a8\u60f3\u8c61\u7684\u8981\u5bb9\u6613:\u6bcf\u79cd\u8bed\u8a00\u7684\u9ed8\u8ba4OTLP\u5bfc\u51fa\u5668\u90fd\u5047\u5b9a\u6709\u4e00\u4e2a\u672c\u5730\u6536\u96c6\u5668\u7aef\u70b9\uff0c\u56e0\u6b64\u60a8\u542f\u52a8\u6536\u96c6\u5668\u5e76\u5f00\u59cb\u8fdb\u884c\u9065\u6d4b\u3002</p>"},{"location":"docs/collector/_index/#_4","title":"\u72b6\u6001\u548c\u53d1\u5e03","text":"<p>The collector status is: mixed, since core collector components currently have mixed stability levels.</p> <p>Collector components differ in their maturity levels. An effort is underway to ensure that every component has its stability documented. To track the progress of this effort, see <code>opentelemetry-collector-contrib</code> issue #10116.</p> <p>{{% latest_release \"collector-releases\" /%}}</p>"},{"location":"docs/collector/configuration/","title":"\u914d\u7f6e","text":"<p>Familiarity with the following pages is assumed:</p> <ul> <li>Data Collection concepts in order to   understand the repositories applicable to the OpenTelemetry Collector.</li> <li>Security guidance</li> </ul>"},{"location":"docs/collector/configuration/#basics","title":"Basics","text":"<p>The Collector consists of four components that access telemetry data:</p> <ul> <li> Receivers</li> <li> Processors</li> <li> Exporters</li> <li> Connectors</li> </ul> <p>These components once configured must be enabled via pipelines within the service section.</p> <p>Secondarily, there are extensions, which provide capabilities that can be added to the Collector, but which do not require direct access to telemetry data and are not part of pipelines. They are also enabled within the service section.</p> <p>An example configuration would look like:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nprocessors:\nbatch:\nexporters:\notlp:\nendpoint: otelcol:4317\nextensions:\nhealth_check:\npprof:\nzpages:\nservice:\nextensions: [health_check, pprof, zpages]\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp]\nmetrics:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp]\nlogs:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp]\n</code></pre> <p>Note that receivers, processors, exporters and/or pipelines are defined via component identifiers in <code>type[/name]</code> format (e.g. <code>otlp</code> or <code>otlp/2</code>). Components of a given type can be defined more than once as long as the identifiers are unique. For example:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nhttp:\notlp/2:\nprotocols:\ngrpc:\nendpoint: 0.0.0.0:55690\nprocessors:\nbatch:\nbatch/test:\nexporters:\notlp:\nendpoint: otelcol:4317\notlp/2:\nendpoint: otelcol2:4317\nextensions:\nhealth_check:\npprof:\nzpages:\nservice:\nextensions: [health_check, pprof, zpages]\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp]\ntraces/2:\nreceivers: [otlp/2]\nprocessors: [batch/test]\nexporters: [otlp/2]\nmetrics:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp]\nlogs:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlp]\n</code></pre> <p>The configuration can also include other files, causing the Collector to merge the two files in a single in-memory representation of the YAML configuration:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nexporters: ${file:exporters.yaml}\nservice:\nextensions: []\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: []\nexporters: [otlp]\n</code></pre> <p>With the <code>exporters.yaml</code> file being:</p> <pre><code>otlp:\nendpoint: otelcol.observability.svc.cluster.local:443\n</code></pre> <p>The final result in memory will be:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nexporters:\notlp:\nendpoint: otelcol.observability.svc.cluster.local:443\nservice:\nextensions: []\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: []\nexporters: [otlp]\n</code></pre>"},{"location":"docs/collector/configuration/#receivers","title":"Receivers","text":"<p>A receiver, which can be push or pull based, is how data gets into the Collector. Receivers may support one or more data sources.</p> <p>The <code>receivers:</code> section is how receivers are configured. Many receivers come with default settings so simply specifying the name of the receiver is enough to configure it (for example, <code>zipkin:</code>). If configuration is required or a user wants to change the default configuration then such configuration must be defined in this section. Configuration parameters specified for which the receiver provides a default configuration are overridden.</p> <p>Configuring a receiver does not enable it. Receivers are enabled via pipelines within the service section.</p> <p>One or more receivers must be configured. By default, no receivers are configured. A basic example of receivers is provided below.</p> <p>For detailed receiver configuration, please see the receiver README.md.</p> <pre><code>receivers:\n# Data sources: logs\nfluentforward:\nendpoint: 0.0.0.0:8006\n# Data sources: metrics\nhostmetrics:\nscrapers:\ncpu:\ndisk:\nfilesystem:\nload:\nmemory:\nnetwork:\nprocess:\nprocesses:\npaging:\n# Data sources: traces\njaeger:\nprotocols:\ngrpc:\nthrift_binary:\nthrift_compact:\nthrift_http:\n# Data sources: traces\nkafka:\nprotocol_version: 2.0.0\n# Data sources: traces, metrics\nopencensus:\n# Data sources: traces, metrics, logs\notlp:\nprotocols:\ngrpc:\nhttp:\n# Data sources: metrics\nprometheus:\nconfig:\nscrape_configs:\n- job_name: otel-collector\nscrape_interval: 5s\nstatic_configs:\n- targets: [localhost:8888]\n# Data sources: traces\nzipkin:\n</code></pre>"},{"location":"docs/collector/configuration/#processors","title":"Processors","text":"<p>Processors are run on data between being received and being exported. Processors are optional though some are recommended.</p> <p>The <code>processors:</code> section is how processors are configured. Processors may come with default settings, but many require configuration. Any configuration for a processor must be done in this section. Configuration parameters specified for which the processor provides a default configuration are overridden.</p> <p>Configuring a processor does not enable it. Processors are enabled via pipelines within the service section.</p> <p>A basic example of the default processors is provided below. The full list of processors can be found by combining the list found here and here.</p> <p>For detailed processor configuration, please see the processor README.md.</p> <pre><code>processors:\n# Data sources: traces\nattributes:\nactions:\n- key: environment\nvalue: production\naction: insert\n- key: db.statement\naction: delete\n- key: email\naction: hash\n# Data sources: traces, metrics, logs\nbatch:\n# Data sources: metrics\nfilter:\nmetrics:\ninclude:\nmatch_type: regexp\nmetric_names:\n- prefix/.*\n- prefix_.*\n# Data sources: traces, metrics, logs\nmemory_limiter:\ncheck_interval: 5s\nlimit_mib: 4000\nspike_limit_mib: 500\n# Data sources: traces\nresource:\nattributes:\n- key: cloud.zone\nvalue: zone-1\naction: upsert\n- key: k8s.cluster.name\nfrom_attribute: k8s-cluster\naction: insert\n- key: redundant-attribute\naction: delete\n# Data sources: traces\nprobabilistic_sampler:\nhash_seed: 22\nsampling_percentage: 15\n# Data sources: traces\nspan:\nname:\nto_attributes:\nrules:\n- ^\\/api\\/v1\\/document\\/(?P&lt;documentId&gt;.*)\\/update$\nfrom_attributes: [db.svc, operation]\nseparator: '::'\n</code></pre>"},{"location":"docs/collector/configuration/#exporters","title":"Exporters","text":"<p>An exporter, which can be push or pull based, is how you send data to one or more backends/destinations. Exporters may support one or more data sources.</p> <p>The <code>exporters:</code> section is how exporters are configured. Exporters may come with default settings, but many require configuration to specify at least the destination and security settings. Any configuration for an exporter must be done in this section. Configuration parameters specified for which the exporter provides a default configuration are overridden.</p> <p>Configuring an exporter does not enable it. Exporters are enabled via pipelines within the service section.</p> <p>One or more exporters must be configured. By default, no exporters are configured. A basic example of exporters is provided below. Certain exporter configurations require x.509 certificates to be created in order to be secure, as described in setting up certificates.</p> <p>For detailed exporter configuration, see the exporter README.md.</p> <pre><code>exporters:\n# Data sources: traces, metrics, logs\nfile:\npath: ./filename.json\n# Data sources: traces\njaeger:\nendpoint: jaeger-all-in-one:14250\ntls:\ncert_file: cert.pem\nkey_file: cert-key.pem\n# Data sources: traces\nkafka:\nprotocol_version: 2.0.0\n# Data sources: traces, metrics, logs\nlogging:\nloglevel: debug\n# Data sources: traces, metrics\nopencensus:\nendpoint: otelcol2:55678\n# Data sources: traces, metrics, logs\notlp:\nendpoint: otelcol2:4317\ntls:\ncert_file: cert.pem\nkey_file: cert-key.pem\n# Data sources: traces, metrics\notlphttp:\nendpoint: https://example.com:4318\n# Data sources: metrics\nprometheus:\nendpoint: prometheus:8889\nnamespace: default\n# Data sources: metrics\nprometheusremotewrite:\nendpoint: http://some.url:9411/api/prom/push\n# For official Prometheus (e.g. running via Docker)\n# endpoint: 'http://prometheus:9090/api/v1/write'\n# tls:\n#   insecure: true\n# Data sources: traces\nzipkin:\nendpoint: http://localhost:9411/api/v2/spans\n</code></pre>"},{"location":"docs/collector/configuration/#connectors","title":"Connectors","text":"<p>A connector is both an exporter and receiver. As the name suggests a Connector connects two pipelines: It consumes data as an exporter at the end of one pipeline and emits data as a receiver at the start of another pipeline. It may consume and emit data of the same data type, or of different data types. A connector may generate and emit data to summarize the consumed data, or it may simply replicate or route data.</p> <p>The <code>connectors:</code> section is how connectors are configured.</p> <p>Configuring a connectors does not enable it. Connectors are enabled via pipelines within the service section.</p> <p>One or more connectors may be configured. By default, no connectors are configured. A basic example of connectors is provided below.</p> <p>For detailed connector configuration, please see the connector README.md.</p> <pre><code>connectors:\nforward:\ncount:\nspanevents:\nmy.prod.event.count:\ndescription: The number of span events from my prod environment.\nconditions:\n- 'attributes[\"env\"] == \"prod\"'\n- 'name == \"prodevent\"'\nspanmetrics:\nhistogram:\nexplicit:\nbuckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]\ndimensions:\n- name: http.method\ndefault: GET\n- name: http.status_code\ndimensions_cache_size: 1000\naggregation_temporality: 'AGGREGATION_TEMPORALITY_CUMULATIVE'\nservicegraph:\nlatency_histogram_buckets: [1, 2, 3, 4, 5]\ndimensions:\n- dimension-1\n- dimension-2\nstore:\nttl: 1s\nmax_items: 10\n</code></pre>"},{"location":"docs/collector/configuration/#extensions","title":"Extensions","text":"<p>Extensions are available primarily for tasks that do not involve processing telemetry data. Examples of extensions include health monitoring, service discovery, and data forwarding. Extensions are optional.</p> <p>The <code>extensions:</code> section is how extensions are configured. Many extensions come with default settings so simply specifying the name of the extension is enough to configure it (for example, <code>health_check:</code>). If configuration is required or a user wants to change the default configuration then such configuration must be defined in this section. Configuration parameters specified for which the extension provides a default configuration are overridden.</p> <p>Configuring an extension does not enable it. Extensions are enabled within the service section.</p> <p>By default, no extensions are configured. A basic example of extensions is provided below.</p> <p>For detailed extension configuration, please see the extension README.md.</p> <pre><code>extensions:\nhealth_check:\npprof:\nzpages:\nmemory_ballast:\nsize_mib: 512\n</code></pre>"},{"location":"docs/collector/configuration/#service","title":"Service","text":"<p>The service section is used to configure what components are enabled in the Collector based on the configuration found in the receivers, processors, exporters, and extensions sections. If a component is configured, but not defined within the service section then it is not enabled. The service section consists of three sub-sections:</p> <ul> <li>extensions</li> <li>pipelines</li> <li>telemetry</li> </ul> <p>Extensions consist of a list of all extensions to enable. For example:</p> <pre><code>service:\nextensions: [health_check, pprof, zpages]\n</code></pre> <p>Pipelines can be of the following types:</p> <ul> <li>traces: collects and processes trace data.</li> <li>metrics: collects and processes metric data.</li> <li>logs: collects and processes log data.</li> </ul> <p>A pipeline consists of a set of receivers, processors and exporters. Each receiver/processor/exporter must be defined in the configuration outside of the service section to be included in a pipeline.</p> <p>Note: Each receiver/processor/exporter can be used in more than one pipeline. For processor(s) referenced in multiple pipelines, each pipeline will get a separate instance of that processor(s). This is in contrast to receiver(s)/exporter(s) referenced in multiple pipelines, where only one instance of a receiver/exporter is used for all pipelines. Also note that the order of processors dictates the order in which data is processed.</p> <p>The following is an example pipeline configuration:</p> <pre><code>service:\npipelines:\nmetrics:\nreceivers: [opencensus, prometheus]\nexporters: [opencensus, prometheus]\ntraces:\nreceivers: [opencensus, jaeger]\nprocessors: [batch]\nexporters: [opencensus, zipkin]\n</code></pre> <p>Telemetry is where the telemetry for the collector itself can be configured. It has two subsections: <code>logs</code> and <code>metrics</code>.</p> <p>The <code>logs</code> subsection allows configuration of the logs generated by the collector. By default the collector will write its logs to stderr with a log level of <code>INFO</code>. You can also add static key-value pairs to all logs using the <code>initial_fields</code> section. View the full list of <code>logs</code> options here.</p> <p>The <code>metrics</code> subsection allows configuration of the metrics generated by the collector. By default the collector will generate basic metrics about itself and expose them for scraping at <code>localhost:8888/metrics</code> View the full list of <code>metrics</code> options here.</p> <p>The following is an example telemetry configuration:</p> <pre><code>service:\ntelemetry:\nlogs:\nlevel: debug\ninitial_fields:\nservice: my-instance\nmetrics:\nlevel: detailed\naddress: 0.0.0.0:8888\n</code></pre>"},{"location":"docs/collector/configuration/#other-information","title":"Other Information","text":""},{"location":"docs/collector/configuration/#configuration-environment-variables","title":"Configuration Environment Variables","text":"<p>The use and expansion of environment variables is supported in the Collector configuration. For example to use the values stored on the <code>DB_KEY</code> and <code>OPERATION</code> environment variables you can write the following:</p> <pre><code>processors:\nattributes/example:\nactions:\n- key: ${env:DB_KEY}\naction: ${env:OPERATION}\n</code></pre> <p>Use <code>$$</code> to indicate a literal <code>$</code>. For example, representing <code>$DataVisualization</code> would look like the following:</p> <pre><code>exporters:\nprometheus:\nendpoint: prometheus:8889\nnamespace: $$DataVisualization\n</code></pre>"},{"location":"docs/collector/configuration/#proxy-support","title":"Proxy Support","text":"<p>Exporters that leverage the <code>net/http</code> package (all do today) respect the following proxy environment variables:</p> <ul> <li>HTTP_PROXY</li> <li>HTTPS_PROXY</li> <li>NO_PROXY</li> </ul> <p>If set at Collector start time then exporters, regardless of protocol, will or will not proxy traffic as defined by these environment variables.</p>"},{"location":"docs/collector/configuration/#authentication","title":"Authentication","text":"<p>Most receivers exposing an HTTP or gRPC port are able to be protected using the collector's authentication mechanism, and most exporters using HTTP or gRPC clients are able to add authentication data to the outgoing requests.</p> <p>The authentication mechanism in the collector uses the extensions mechanism, allowing for custom authenticators to be plugged into collector distributions. If you are interested in developing a custom authenticator, check out the \"Building a custom authenticator\" document.</p> <p>Each authentication extension has two possible usages: as client authenticator for exporters, adding auth data to outgoing requests, and as server authenticator for receivers, authenticating incoming connections. Refer to the authentication extension for a list of its capabilities, but in general, an authentication extension would only implement one of those traits. For a list of known authenticators, use the Registry available in this website.</p> <p>To add a server authenticator to a receiver in your collector, make sure to:</p> <ol> <li>add the authenticator extension and its configuration under <code>.extensions</code></li> <li>add a reference to the authenticator to <code>.services.extensions</code>, so that it's    loaded by the collector</li> <li>add a reference to the authenticator under    <code>.receivers.&lt;your-receiver&gt;.&lt;http-or-grpc-config&gt;.auth</code></li> </ol> <p>Here's an example that uses the OIDC authenticator on the receiver side, making this suitable for a remote collector that receives data from an OpenTelemetry Collector acting as agent:</p> <pre><code>extensions:\noidc:\nissuer_url: http://localhost:8080/auth/realms/opentelemetry\naudience: collector\nreceivers:\notlp/auth:\nprotocols:\ngrpc:\nauth:\nauthenticator: oidc\nprocessors:\nexporters:\nlogging:\nservice:\nextensions:\n- oidc\npipelines:\ntraces:\nreceivers:\n- otlp/auth\nprocessors: []\nexporters:\n- logging\n</code></pre> <p>On the agent side, this is an example that makes the OTLP exporter obtain OIDC tokens, adding them to every RPC made to a remote collector:</p> <pre><code>extensions:\noauth2client:\nclient_id: agent\nclient_secret: some-secret\ntoken_url: http://localhost:8080/auth/realms/opentelemetry/protocol/openid-connect/token\nreceivers:\notlp:\nprotocols:\ngrpc:\nendpoint: localhost:4317\nprocessors:\nexporters:\notlp/auth:\nendpoint: remote-collector:4317\nauth:\nauthenticator: oauth2client\nservice:\nextensions:\n- oauth2client\npipelines:\ntraces:\nreceivers:\n- otlp\nprocessors: []\nexporters:\n- otlp/auth\n</code></pre>"},{"location":"docs/collector/configuration/#setting-up-certificates","title":"Setting up certificates","text":"<p>For a production setup, we strongly recommend using TLS certificates, either for secure communication or mTLS for mutual authentication. See the below steps to generate self-signed certificates used in this example. You might want to use your current cert provisioning procedures to procure a certificate for production usage.</p> <p>Install cfssl, and create the following <code>csr.json</code> file:</p> <pre><code>{\n\"hosts\": [\"localhost\", \"127.0.0.1\"],\n\"key\": {\n\"algo\": \"rsa\",\n\"size\": 2048\n},\n\"names\": [\n{\n\"O\": \"OpenTelemetry Example\"\n}\n]\n}\n</code></pre> <p>Now, run the following commands:</p> <pre><code>cfssl genkey -initca csr.json | cfssljson -bare ca\ncfssl gencert -ca ca.pem -ca-key ca-key.pem csr.json | cfssljson -bare cert\n</code></pre> <p>This will create two certificates; first, an \"OpenTelemetry Example\" Certificate Authority (CA) in <code>ca.pem</code> and the associated key in <code>ca-key.pem</code>, and second a client certificate in <code>cert.pem</code> (signed by the OpenTelemetry Example CA) and the associated key in <code>cert-key.pem</code>.</p>"},{"location":"docs/collector/custom-auth/","title":"\u6784\u5efa\u81ea\u5b9a\u4e49\u8eab\u4efd\u9a8c\u8bc1\u5668","text":"<p>The OpenTelemetry Collector allows receivers and exporters to be connected to authenticators, providing a way to both authenticate incoming connections at the receiver's side, as well as adding authentication data to outgoing requests at the exporter's side.</p> <p>This mechanism is implemented on top of the <code>extensions</code> framework and this document will guide you on implementing your own authenticators. If you are looking for documentation on how to use an existing authenticator, refer to the Getting Started page and to your authenticator's documentation. You can find a list of existing authenticators in this website's registry.</p> <p>Use this guide for general directions on how to build a custom authenticator and refer to the up-to-date API Reference Guide for the actual semantics of each type and function.</p> <p>If at anytime you need assistance, join the #opentelemetry-collector room at the CNCF Slack workspace.</p>"},{"location":"docs/collector/custom-auth/#architecture","title":"Architecture","text":"<p>Authenticators are regular extensions that also satisfy one or more interfaces related to the authentication mechanism:</p> <ul> <li>go.opentelemetry.io/collector/config/configauth/ServerAuthenticator</li> <li>go.opentelemetry.io/collector/config/configauth/GRPCClientAuthenticator</li> <li>go.opentelemetry.io/collector/config/configauth/HTTPClientAuthenticator</li> </ul> <p>Server authenticators are used with receivers, and are able to intercept HTTP and gRPC requests, while client authenticators are used with exporters, able to add authentication data to HTTP and gRPC requests. It is possible for authenticators to implement both interfaces at the same time, allowing a single instance of the extension to be used both for the incoming and outgoing requests. Note that users might still want to have different authenticators for the incoming and outgoing requests, so, don't make your authenticator required to be used at both ends.</p> <p>Once an authenticator extension is available in the collector distribution, it can be referenced in the configuration file as a regular extension:</p> <pre><code>extensions:\noidc:\nreceivers:\nprocessors:\nexporters:\nservice:\nextensions:\n- oidc\npipelines:\ntraces:\nreceivers: []\nprocessors: []\nexporters: []\n</code></pre> <p>However, an authenticator will need to be referenced by a consuming component to be effective. The following example shows the same extension as above, now being used by a receiver named <code>otlp/auth</code>:</p> <pre><code>extensions:\noidc:\nreceivers:\notlp/auth:\nprotocols:\ngrpc:\nauth:\nauthenticator: oidc\nprocessors:\nexporters:\nservice:\nextensions:\n- oidc\npipelines:\ntraces:\nreceivers:\n- otlp/auth\nprocessors: []\nexporters: []\n</code></pre> <p>When multiple instances of a given authenticator are needed, they can have different names:</p> <pre><code>extensions:\noidc/some-provider:\noidc/another-provider:\nreceivers:\notlp/auth:\nprotocols:\ngrpc:\nauth:\nauthenticator: oidc/some-provider\nprocessors:\nexporters:\nservice:\nextensions:\n- oidc/some-provider\n- oidc/another-provider\npipelines:\ntraces:\nreceivers:\n- otlp/auth\nprocessors: []\nexporters: []\n</code></pre>"},{"location":"docs/collector/custom-auth/#server-authenticators","title":"Server authenticators","text":"<p>A server authenticator is essentially an extension with an <code>Authenticate</code> function, receiving the payload headers as parameter. If the authenticator is able to authenticate the incoming connection, it should return a <code>nil</code> error, or the concrete error if it can't. As an extension, the authenticator should make sure to initialize all the resources it needs during the <code>Start</code> phase, and is expected to clean them up upon <code>Shutdown</code>.</p> <p>The <code>Authenticate</code> call is part of the hot path for incoming requests and will block the pipeline, so make sure to properly handle any blocking operations you need to make. Concretely, respect the deadline set by the context, in case one is provided. Also make sure to add enough observability to your extension, especially in the form of metrics and traces, so that users can get setup a notification system in case error rates go up beyond a certain level and can debug specific failures.</p>"},{"location":"docs/collector/custom-auth/#client-authenticators","title":"Client authenticators","text":"<p>A client authenticator is one that implements one or more of the following interfaces:</p> <ul> <li>go.opentelemetry.io/collector/config/configauth/GRPCClientAuthenticator</li> <li>go.opentelemetry.io/collector/config/configauth/HTTPClientAuthenticator</li> </ul> <p>Similar to server authenticators, they are essentially extensions with extra functions, each receiving an object that gives the authenticator an opportunity to inject the authentication data into. For instance, the HTTP client authenticator provides an <code>http.RoundTripper</code>, while the gRPC client authenticator can produce a <code>credentials.PerRPCCredentials</code>.</p>"},{"location":"docs/collector/custom-auth/#adding-your-custom-authenticator-to-a-distribution","title":"Adding your custom authenticator to a distribution","text":"<p>Custom authenticators have to be part of the same binary as the main collector. When building your own authenticator, you'll likely have to build a custom distribution as well, or provide means for your users to consume your extension as part of their own distributions. Fortunately, building a custom distribution can be done using the OpenTelemetry Collector Builder utility.</p>"},{"location":"docs/collector/custom-collector/","title":"\u6784\u5efa\u81ea\u5b9a\u4e49\u6536\u96c6\u5668","text":"<p>If you are planning to build and debug custom collector receivers, processors, extensions, or exporters, you are going to need your own Collector instance. That will allow you to launch and debug your OpenTelemetry Collector components directly within your favorite Golang IDE.</p> <p>The other interesting aspect of approaching the component development this way is that you can use all the debugging features from your IDE (stack traces are great teachers!) to understand how the Collector itself interacts with your component code.</p> <p>The OpenTelemetry Community developed a tool called OpenTelemetry Collector builder (or <code>ocb</code> for short) to assist people in assembling their own distribution, making it easy to build a distribution that includes their custom components along with components that are publicly available.</p> <p>As part of the process the <code>builder</code> will generate the Collector's source code, which you can use to help build and debug your own custom components, so let's get started.</p>"},{"location":"docs/collector/custom-collector/#step-1-install-the-builder","title":"Step 1 - Install the builder","text":"<p>The <code>ocb</code> binary is available as a downloadable asset from OpenTelemetry Collector releases. You will find the list of assets at the bottom of the page. Assets are named based on OS and chipset, so download the one that fits your configuration.</p> <p>The binary has a pretty long name, so you can simply rename it to <code>ocb</code>; and if you are running Linux or macOS, you will also need to provide execution permissions for the binary.</p> <p>Open your terminal and type the following commands to accomplish both operations:</p> <pre><code>mv ocb_{{% param collectorVersion %}}_darwin_amd64 ocb\nchmod 777 ocb\n</code></pre> <p>To make sure the <code>ocb</code> is ready to be used, go to your terminal and type <code>./ocb help</code>, and once you hit enter you should have the output of the <code>help</code> command showing up in your console.</p>"},{"location":"docs/collector/custom-collector/#step-2-create-a-builder-manifest-file","title":"Step 2 - Create a builder manifest file","text":"<p>The builder's <code>manifest</code> file is a <code>yaml</code> where you pass information about the code generation and compile process combined with the components that you would like to add to your Collector's distribution.</p> <p>The <code>manifest</code> starts with a map named <code>dist</code> which contains tags to help you configure the code generation and compile process. In fact, all the tags for <code>dist</code> are the equivalent of the <code>ocb</code> command line <code>flags</code>.</p> <p>Here are the tags for the <code>dist</code> map:</p> Tag Description Optional Default Value module: The module name for the new distribution, following Go mod conventions. Optional, but recommended. Yes <code>go.opentelemetry.io/collector/cmd/builder</code> name: The binary name for your distribution Yes <code>otelcol-custom</code> description: A long name for the application. Yes <code>Custom OpenTelemetry Collector distribution</code> otelcol_version: The OpenTelemetry Collector version to use as base for the distribution. Yes <code>{{% param collectorVersion %}}</code> output_path: The path to write the output (sources and binary). Yes <code>/var/folders/86/s7l1czb16g124tng0d7wyrtw0000gn/T/otelcol-distribution3618633831</code> version: The version for your custom OpenTelemetry Collector. Yes <code>1.0.0</code> go: Which Go binary to use to compile the generated sources. Yes go from the PATH <p>As you can see on the table above, all the <code>dist</code> tags are optional, so you will be adding custom values for them depending if your intentions to make your custom Collector distribution available for consumption by other users or if you are simply leveraging the <code>ocb</code> to bootstrap your component development and testing environment.</p> <p>For this tutorial, you will be creating a Collector's distribution to support the development and testing of components.</p> <p>Go ahead and create a manifest file named <code>builder-config.yaml</code> with the following content:</p> <p>builder-config.yaml</p> <pre><code>dist:\nname: otelcol-dev\ndescription: Basic OTel Collector distribution for Developers\noutput_path: ./otelcol-dev\n</code></pre> <p>Now you need to add the modules representing the components you want to be incorporated in this custom Collector distribution. Take a look at the ocb configuration documentation to understand the different modules and how to add the components.</p> <p>We will be adding the following components to our development and testing collector distribution:</p> <ul> <li>Exporters: Jaeger and Logging</li> <li>Receivers: OTLP</li> <li>Processors: Batch</li> </ul> <p>Here is what my <code>builder-config.yaml</code> manifest file looks after adding the modules for the components above:</p> <pre><code>dist:\nname: otelcol-dev\ndescription: Basic OTel Collector distribution for Developers\noutput_path: ./otelcol-dev\notelcol_version: {{% param collectorVersion %}}\nexporters:\n- gomod:\ngo.opentelemetry.io/collector/exporter/loggingexporter v{{% param collectorVersion %}}\n- gomod:\ngithub.com/open-telemetry/opentelemetry-collector-contrib/exporter/jaegerexporter\nv{{% param collectorVersion %}}\nprocessors:\n- gomod:\ngo.opentelemetry.io/collector/processor/batchprocessor v{{% param collectorVersion %}}\nreceivers:\n- gomod:\ngo.opentelemetry.io/collector/receiver/otlpreceiver v{{% param collectorVersion %}}\n</code></pre>"},{"location":"docs/collector/custom-collector/#step-3-generating-the-code-and-building-your-collectors-distribution","title":"Step 3 - Generating the Code and Building your Collector's distribution.","text":"<p>All you need now is to let the <code>ocb</code> do it's job, so go to your terminal and type the following command:</p> <pre><code>./ocb --config builder-config.yaml\n</code></pre> <p>If everything went well, here is what the output of the command should look like:</p> <pre><code>2022-06-13T14:25:03.037-0500    INFO    internal/command.go:85  OpenTelemetry Collector distribution builder    {\"version\": \"{{% param collectorVersion %}}\", \"date\": \"2023-01-03T15:05:37Z\"}\n2022-06-13T14:25:03.039-0500    INFO    internal/command.go:108 Using config file   {\"path\": \"builder-config.yaml\"}\n2022-06-13T14:25:03.040-0500    INFO    builder/config.go:99    Using go    {\"go-executable\": \"/usr/local/go/bin/go\"}\n2022-06-13T14:25:03.041-0500    INFO    builder/main.go:76  Sources created {\"path\": \"./otelcol-dev\"}\n2022-06-13T14:25:03.445-0500    INFO    builder/main.go:108 Getting go modules\n2022-06-13T14:25:04.675-0500    INFO    builder/main.go:87  Compiling\n2022-06-13T14:25:17.259-0500    INFO    builder/main.go:94  Compiled    {\"binary\": \"./otelcol-dev/otelcol-dev\"}\n</code></pre> <p>As defined in the <code>dist</code> section of your config file, you now have a folder named <code>otelcol-dev</code> containing all the source code and the binary for your Collector's distribution.</p> <p>You can now use the generated code to bootstrap your component development projects and easily build and distribute your own collector distribution with your components.</p>"},{"location":"docs/collector/distributions/","title":"\u5206\u5e03","text":"<p>The OpenTelemetry project currently offers pre-built distributions of the collector. The components included in the distributions can be found by in the <code>manifest.yaml</code> of each distribution.</p> <p>{{% latest_release \"collector-releases\" /%}}</p>"},{"location":"docs/collector/distributions/#custom-distributions","title":"Custom Distributions","text":"<p>For various reasons the existing distributions provided by the OpenTelemetry project may not meet your needs. Whether you want a smaller version, or have the need to implement custom functionality like custom authenticators, receivers, processors, or exporters. The tool used to build distributions ocb (OpenTelemetry Collector Builder) is available to build your own distributions.</p>"},{"location":"docs/collector/getting-started/","title":"\u5165\u95e8","text":"<p>If you aren't familiar with the deployment models, components, and repositories applicable to the OpenTelemetry Collector, first review the Data Collection and Deployment Methods page.</p>"},{"location":"docs/collector/getting-started/#demo","title":"Demo","text":"<p>Deploys a load generator, agent and gateway as well as Jaeger, Zipkin and Prometheus back-ends. More information can be found on the demo README.md.</p> <pre><code>git clone git@github.com:open-telemetry/opentelemetry-collector-contrib.git --depth 1; \\\ncd opentelemetry-collector-contrib/examples/demo; \\\ndocker compose up -d\n</code></pre> <p>{{% alert title=\"Note\" color=\"info\" %}} {{% _param notes.docker-compose-v2 %}} {{% /alert %}}</p>"},{"location":"docs/collector/getting-started/#docker","title":"Docker","text":"<p>Pull a docker image and run the collector in a container. Replace <code>{{% param collectorVersion %}}</code> with the version of the Collector you wish to run.</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab DockerHub &gt;}} docker pull otel/opentelemetry-collector-contrib:{{% param collectorVersion %}} docker run otel/opentelemetry-collector-contrib:{{% param collectorVersion %}} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ghcr.io &gt;}} docker pull ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:{{% param collectorVersion %}} docker run ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:{{% param collectorVersion %}} {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p> <p>To load your custom configuration <code>config.yaml</code> from your current working directory, mount that file as a volume:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab DockerHub &gt;}} docker run -v $(pwd)/config.yaml:/etc/otelcol-contrib/config.yaml otel/opentelemetry-collector-contrib:{{% param collectorVersion %}} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ghcr.io &gt;}} docker run -v $(pwd)/config.yaml:/etc/otelcol-contrib/config.yaml ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:{{% param collectorVersion %}} {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/collector/getting-started/#docker-compose","title":"Docker Compose","text":"<p>You can add OpenTelemetry collector to your existing <code>docker-compose.yaml</code> like the following:</p> <pre><code>otel-collector:\nimage: otel/opentelemetry-collector-contrib\ncommand: [--config=/etc/otel-collector-config.yaml]\nvolumes:\n- ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\nports:\n- 1888:1888 # pprof extension\n- 8888:8888 # Prometheus metrics exposed by the collector\n- 8889:8889 # Prometheus exporter metrics\n- 13133:13133 # health_check extension\n- 4317:4317 # OTLP gRPC receiver\n- 4318:4318 # OTLP http receiver\n- 55679:55679 # zpages extension\n</code></pre>"},{"location":"docs/collector/getting-started/#kubernetes","title":"Kubernetes","text":"<p>Deploys an agent as a daemonset and a single gateway instance.</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/examples/k8s/otel-config.yaml\n</code></pre> <p>The example above is meant to serve as a starting point, to be extended and customized before actual production usage. For production-ready customization and installation, see OpenTelemetry Helm Charts.</p> <p>The OpenTelemetry Operator can also be used to provision and maintain an OpenTelemetry Collector instance, with features such as automatic upgrade handling, <code>Service</code> configuration based on the OpenTelemetry configuration, automatic sidecar injection into deployments, among others.</p>"},{"location":"docs/collector/getting-started/#nomad","title":"Nomad","text":"<p>Reference job files to deploy the Collector as an agent, gateway and in the full demo can be found at Getting Started with OpenTelemetry on HashiCorp Nomad.</p>"},{"location":"docs/collector/getting-started/#linux-packaging","title":"Linux Packaging","text":"<p>Every Collector release includes APK, DEB and RPM packaging for Linux amd64/arm64/i386 systems. The packaging includes a default configuration that can be found at <code>/etc/otelcol/config.yaml</code> post-installation.</p> <p>Note: <code>systemd</code> is required for automatic service configuration.</p>"},{"location":"docs/collector/getting-started/#apk-installation","title":"APK Installation","text":"<p>To get started on alpine systems run the following replacing <code>v{{% param collectorVersion %}}</code> with the version of the Collector you wish to run.</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab AMD64 &gt;}} apk update apk add wget shadow wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_amd64.apk apk add --allow-untrusted otelcol}_linux_amd64.apk {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ARM64 &gt;}} apk update apk add wget shadow wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_arm64.apk apk add --allow-untrusted otelcol}_linux_arm64.apk {{&lt; /tab &gt;}}</p> <p>{{&lt; tab i386 &gt;}} apk update apk add wget shadow wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_386.apk apk add --allow-untrusted otelcol}_linux_386.apk {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/collector/getting-started/#deb-installation","title":"DEB Installation","text":"<p>To get started on Debian systems run the following replacing <code>v{{% param collectorVersion %}}</code> with the version of the Collector you wish to run and <code>amd64</code> with the appropriate architecture.</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab AMD64 &gt;}} sudo apt-get update sudo apt-get -y install wget systemctl wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_amd64.deb sudo dpkg -i otelcol}_linux_amd64.deb {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ARM64 &gt;}} sudo apt-get update sudo apt-get -y install wget systemctl wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_arm64.deb sudo dpkg -i otelcol}_linux_arm64.deb {{&lt; /tab &gt;}}</p> <p>{{&lt; tab i386 &gt;}} sudo apt-get update sudo apt-get -y install wget systemctl wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_386.deb sudo dpkg -i otelcol}_linux_386.deb {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/collector/getting-started/#rpm-installation","title":"RPM Installation","text":"<p>To get started on Red Hat systems run the following replacing <code>v{{% param collectorVersion %}}</code> with the version of the Collector you wish to run and <code>x86_64</code> with the appropriate architecture.</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab AMD64 &gt;}} sudo yum update sudo yum -y install wget systemctl wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_amd64.rpm sudo rpm -ivh otelcol}_linux_amd64.rpm {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ARM64 &gt;}} sudo yum update sudo yum -y install wget systemctl wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_arm64.rpm sudo rpm -ivh otelcol}_linux_arm64.rpm {{&lt; /tab &gt;}}</p> <p>{{&lt; tab i386 &gt;}} sudo yum update sudo yum -y install wget systemctl wget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_386.rpm sudo rpm -ivh otelcol}_linux_386.rpm {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/collector/getting-started/#manual-installation","title":"Manual Installation","text":"<p>Linux releases are available for various architectures. It's possible to download the archive containing the binary and install it on your machine manually:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab AMD64 &gt;}} curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_amd64.tar.gz tar -xvf otelcol}_linux_amd64.tar.gz {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ARM64 &gt;}} curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_arm64.tar.gz tar -xvf otelcol}_linux_arm64.tar.gz {{&lt; /tab &gt;}}</p> <p>{{&lt; tab i386 &gt;}} curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_386.tar.gz tar -xvf otelcol}_linux_386.tar.gz {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ppc64le &gt;}} curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}linux_ppc64le.tar.gz tar -xvf otelcol}_linux_ppc64le.tar.gz {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/collector/getting-started/#automatic-service-configuration","title":"Automatic Service Configuration","text":"<p>By default, the <code>otelcol</code> systemd service will be started with the <code>--config=/etc/otelcol/config.yaml</code> option after installation. To customize these options, modify the <code>OTELCOL_OPTIONS</code> variable in the <code>/etc/otelcol/otelcol.conf</code> systemd environment file with the appropriate command-line options (run <code>/usr/bin/otelcol --help</code> to see all available options). Additional environment variables can also be passed to the <code>otelcol</code> service by adding them to this file.</p> <p>If either the Collector configuration file or <code>/etc/otelcol/otelcol.conf</code> are modified, restart the <code>otelcol</code> service to apply the changes by running:</p> <pre><code>sudo systemctl restart otelcol\n</code></pre> <p>To check the output from the <code>otelcol</code> service, run:</p> <pre><code>sudo journalctl -u otelcol\n</code></pre>"},{"location":"docs/collector/getting-started/#macos-packaging","title":"MacOS Packaging","text":"<p>MacOS releases are available for Intel- &amp; ARM-based systems. They are packaged as gzipped tarballs (<code>.tar.gz</code>) and will need to be unpacked with a tool that supports this compression format:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}} {{&lt; tab Intel &gt;}} curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}darwin_amd64.tar.gz tar -xvf otelcol}_darwin_amd64.tar.gz {{&lt; /tab &gt;}}</p> <p>{{&lt; tab ARM &gt;}} curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v}/otelcol_{{% param collectorVersion %}}darwin_arm64.tar.gz tar -xvf otelcol}_darwin_arm64.tar.gz {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p> <p>Every Collector release includes an <code>otelcol</code> executable that you can run after unpacking.</p>"},{"location":"docs/collector/getting-started/#windows-packaging","title":"Windows Packaging","text":"<p>Windows releases are packaged as gzipped tarballs (<code>.tar.gz</code>) and will need to be unpacked with a tool that supports this compression format.</p> <p>Every Collector release includes an <code>otelcol.exe</code> executable that you can run after unpacking.</p>"},{"location":"docs/collector/getting-started/#local","title":"Local","text":"<p>Builds the latest version of the collector based on the local operating system, runs the binary with all receivers enabled and exports all the data it receives locally to a file. Data is sent to the container and the container scrapes its own Prometheus metrics. The following example uses two terminal windows to better illustrate the collector. In the first terminal window run the following:</p> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-collector.git\ncd opentelemetry-collector\nmake install-tools\nmake otelcorecol\n./bin/otelcorecol_* --config ./examples/local/otel-config.yaml\n</code></pre> <p>In a second terminal window, you can test the newly built collector by doing the following:</p> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-collector-contrib.git\ncd opentelemetry-collector-contrib/examples/demo/server\ngo build -o main main.go; ./main &amp; pid1=\"$!\"\ncd ../client\ngo build -o main main.go; ./main\n</code></pre> <p>To stop the client, use type Ctrl-C. To stop the server, use the <code>kill $pid1</code> command. To stop the collector, type Ctrl-C in its terminal window as well.</p> <p>Note: The commands shown above demonstrate the process in a bash shell. These commands may vary slightly for other shells.</p>"},{"location":"docs/collector/management/","title":"\u7ba1\u7406","text":"<p>This document describes how you can manage your OpenTelemetry collector deployment at scale.</p> <p>To get the most out of this page you should know how to install and configure the collector. These topics are covered elsewhere:</p> <ul> <li>Getting Started to understand how to install   the OpenTelemetry collector.</li> <li>Configuration for how to configure the   OpenTelemetry collector, setting up telemetry pipelines.</li> </ul>"},{"location":"docs/collector/management/#basics","title":"Basics","text":"<p>Telemetry collection at scale requires a structured approach to manage agents. Typical agent management tasks include:</p> <ol> <li>Querying the agent information and configuration. The agent information can    include its version, operating system related information, or capabilities.    The configuration of the agent refers to its telemetry collection setup, for    example, the OpenTelemetry collector    configuration.</li> <li>Upgrading/downgrading agents and management of agent-specific packages,    including the base agent functionality and plugins.</li> <li>Applying new configurations to agents. This might be required because of    changes in the environment or due to policy changes.</li> <li>Health and performance monitoring of the agents, typically CPU and memory    usage and also agent-specific metrics, for example, the rate of processing or    backpressure-related information.</li> <li>Connection management between a control plane and the agent such as handling    of TLS certificates (revocation and rotation).</li> </ol> <p>Not every use case requires support for all of the above agent management tasks. In the context of OpenTelemetry task 4. Health and performance monitoring is ideally done using OpenTelemetry.</p>"},{"location":"docs/collector/management/#opamp","title":"OpAMP","text":"<p>Observability vendors and cloud providers offer proprietary solutions for agent management. In the open source observability space, there is an emerging standard that you can use for agent management: Open Agent Management Protocol (OpAMP).</p> <p>The OpAMP specification defines how to manage a fleet of telemetry data agents. These agents can be OpenTelemetry collectors, Fluent Bit or other agents in any arbitrary combination.</p> <p>Note The term \"agent\" is used here as a catch-all term for OpenTelemetry components that respond to OpAMP, this could be the collector but also SDK components.</p> <p>OpAMP is a client/server protocol that supports communication over HTTP and over WebSockets:</p> <ul> <li>The OpAMP server is part of the control plane and acts as the   orchestrator, managing a fleet of telemetry agents.</li> <li>The OpAMP client is part of the data plane. The client side of OpAMP can   be implemented in-process, for example, as the case in OpAMP support in the   OpenTelemetry collector. The client side of OpAMP   could alternatively be implemented out-of-process. For this latter option, you   can use a supervisor that takes care of the OpAMP specific communication with   the OpAMP server and at the same time controls the telemetry agent, for   example to apply a configuration or to upgrade it. Note that the   supervisor/telemetry communication is not part of OpAMP.</li> </ul> <p>Let's have a look at a concrete setup:</p> <p></p> <ol> <li>The OpenTelemetry collector, configured with pipeline(s) to:</li> <li>(A) receive signals from downstream sources</li> <li>(B) export signals to upstream destinations, potentially including      telemetry about the collector itself (represented by the OpAMP <code>own_xxx</code>      connection settings).</li> <li>The bi-directional OpAMP control flow between the control plane implementing    the server-side OpAMP part and the collector (or a supervisor controlling the    collector) implementing OpAMP client-side.</li> </ol> <p>You can try out a simple OpAMP setup yourself by using the OpAMP protocol implementation in Go. For the following walkthrough you will need to have Go in version 1.19 or above available.</p> <p>We will set up a simple OpAMP control plane consisting of an example OpAMP server and let an OpenTelemetry collector connect to it via an example OpAMP supervisor.</p> <p>First, clone the <code>open-telemetry/opamp-go</code> repo:</p> <pre><code>git clone https://github.com/open-telemetry/opamp-go.git\n</code></pre> <p>Next, we need an OpenTelemetry collector binary that the OpAMP supervisor can manage. For that, install the OpenTelemetry Collector Contrib distro. The path to the collector binary (where you installed it into) is referred to as <code>$OTEL_COLLECTOR_BINARY</code> in the following.</p> <p>In the <code>./opamp-go/internal/examples/server</code> directory, launch the OpAMP server:</p> <pre><code>$ go run .\n2023/02/08 13:31:32.004501 [MAIN] OpAMP Server starting...\n2023/02/08 13:31:32.004815 [MAIN] OpAMP Server running...\n</code></pre> <p>In the <code>./opamp-go/internal/examples/supervisor</code> directory create a file named <code>supervisor.yaml</code> with the following content (telling the supervisor where to find the server and what OpenTelemetry collector binary to manage):</p> <pre><code>server:\nendpoint: ws://127.0.0.1:4320/v1/opamp\nagent:\nexecutable: $OTEL_COLLECTOR_BINARY\n</code></pre> <p>Note Make sure to replace <code>$OTEL_COLLECTOR_BINARY</code> with the actual file path. For example, in Linux or macOS, if you installed the collector in <code>/usr/local/bin/</code> then you would replace <code>$OTEL_COLLECTOR_BINARY</code> with <code>/usr/local/bin/otelcol</code>.</p> <p>Next, create a collector configuration as follows (save it in a file called <code>effective.yaml</code> in the <code>./opamp-go/internal/examples/supervisor</code> directory):</p> <pre><code>receivers:\nprometheus/own_metrics:\nconfig:\nscrape_configs:\n- job_name: otel-collector\nscrape_interval: 10s\nstatic_configs:\n- targets: [0.0.0.0:8888]\nhostmetrics:\ncollection_interval: 10s\nscrapers:\nload:\nfilesystem:\nmemory:\nnetwork:\nexporters:\nlogging:\nverbosity: detailed\nservice:\npipelines:\nmetrics:\nreceivers: [hostmetrics, prometheus/own_metrics]\nexporters: [logging]\n</code></pre> <p>Now it's time to launch the supervisor (which in turn will launch your OpenTelemetry collector):</p> <pre><code>$ go run .\n2023/02/08 13:32:54 Supervisor starting, id=01GRRKNBJE06AFVGQT5ZYC0GEK, type=io.opentelemetry.collector, version=1.0.0.\n2023/02/08 13:32:54 Starting OpAMP client...\n2023/02/08 13:32:54 OpAMP Client started.\n2023/02/08 13:32:54 Starting agent /usr/local/bin/otelcol\n2023/02/08 13:32:54 Connected to the server.\n2023/02/08 13:32:54 Received remote config from server, hash=e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.\n2023/02/08 13:32:54 Agent process started, PID=13553\n2023/02/08 13:32:54 Effective config changed.\n2023/02/08 13:32:54 Enabling own metrics pipeline in the config&lt;F11&gt;\n2023/02/08 13:32:54 Effective config changed.\n2023/02/08 13:32:54 Config is changed. Signal to restart the agent.\n2023/02/08 13:32:54 Agent is not healthy: Get \"http://localhost:13133\": dial tcp [::1]:13133: connect: connection refused\n2023/02/08 13:32:54 Stopping the agent to apply new config.\n2023/02/08 13:32:54 Stopping agent process, PID=13553\n2023/02/08 13:32:54 Agent process PID=13553 successfully stopped.\n2023/02/08 13:32:54 Starting agent /usr/local/bin/otelcol\n2023/02/08 13:32:54 Agent process started, PID=13554\n2023/02/08 13:32:54 Agent is not healthy: Get \"http://localhost:13133\": dial tcp [::1]:13133: connect: connection refused\n2023/02/08 13:32:55 Agent is not healthy: health check on http://localhost:13133 returned 503\n2023/02/08 13:32:55 Agent is not healthy: health check on http://localhost:13133 returned 503\n2023/02/08 13:32:56 Agent is not healthy: health check on http://localhost:13133 returned 503\n2023/02/08 13:32:57 Agent is healthy.\n</code></pre> <p>If everything worked out you should now be able to go to http://localhost:4321/ and access the OpAMP server UI where you should see your collector listed, managed by the supervisor:</p> <p></p> <p>You can also query the collector for the metrics exported (note the label values):</p> <pre><code>$ curl localhost:8888/metrics\n...\n# HELP otelcol_receiver_accepted_metric_points Number of metric points successfully pushed into the pipeline.\n# TYPE otelcol_receiver_accepted_metric_points counter\notelcol_receiver_accepted_metric_points{receiver=\"prometheus/own_metrics\",service_instance_id=\"01GRRKNBJE06AFVGQT5ZYC0GEK\",service_name=\"io.opentelemetry.collector\",service_version=\"1.0.0\",transport=\"http\"} 322\n# HELP otelcol_receiver_refused_metric_points Number of metric points that could not be pushed into the pipeline.\n# TYPE otelcol_receiver_refused_metric_points counter\notelcol_receiver_refused_metric_points{receiver=\"prometheus/own_metrics\",service_instance_id=\"01GRRKNBJE06AFVGQT5ZYC0GEK\",service_name=\"io.opentelemetry.collector\",service_version=\"1.0.0\",transport=\"http\"} 0\n</code></pre>"},{"location":"docs/collector/management/#other-information","title":"Other information","text":"<ul> <li>Blog post Using OpenTelemetry OpAMP to modify service telemetry on the   go</li> <li>YouTube videos:</li> <li>Lightning Talk: Managing OpenTelemetry Through the OpAMP     Protocol</li> <li>What is OpAMP &amp; What is BindPlane</li> </ul>"},{"location":"docs/collector/scaling/","title":"\u6269\u5bb9\u91c7\u96c6\u5668","text":"<p>When planning your observability pipeline with the OpenTelemetry Collector, you should consider ways to scale the pipeline as your telemetry collection increases.</p> <p>The following sections will guide you through the planning phase discussing which components to scale, how to determine when it\u2019s time to scale up, and how to execute the plan.</p>"},{"location":"docs/collector/scaling/#what-to-scale","title":"What to Scale","text":"<p>While the OpenTelemetry Collector handles all telemetry signal types in a single binary, the reality is that each type may have different scaling needs and might require different scaling strategies. Start by looking at your workload to determine which signal type is expected to have the biggest share of the load and which formats are expected to be received by the Collector. For instance, scaling a scraping cluster differs significantly from scaling log receivers. Think also about how elastic the workload is: do you have peaks at specific times of the day, or is the load similar across all 24 hours? Once you gather that information, you will understand what needs to be scaled.</p> <p>For example, suppose you have hundreds of Prometheus endpoints to be scraped, a terabyte of logs coming from fluentd instances every minute, and some application metrics and traces arriving in OTLP format from your newest microservices. In that scenario, you\u2019ll want an architecture that can scale each signal individually: scaling the Prometheus receivers requires coordination among the scrapers to decide which scraper goes to which endpoint. In contrast, we can horizontally scale the stateless log receivers on demand. Having the OTLP receiver for metrics and traces in a third cluster of Collectors would allow us to isolate failures and iterate faster without fear of restarting a busy pipeline. Given that the OTLP receiver enables the ingestion of all telemetry types, we can keep the application metrics and traces on the same instance, scaling them horizontally when needed.</p>"},{"location":"docs/collector/scaling/#when-to-scale","title":"When to Scale","text":"<p>Once again, we should understand our workload to decide when it\u2019s time to scale up or down, but a few metrics emitted by the Collector can give you good hints on when to take action.</p> <p>One helpful hint the Collector can give you when the memory_limiter processor is part of the pipeline is the metric <code>otelcol_processor_refused_spans</code> . This processor allows you to restrict the amount of memory the Collector can use. While the Collector may consume a bit more than the maximum amount configured in this processor, new data will eventually be blocked from passing through the pipeline by the memory_limiter, which will record the fact in this metric. The same metric exists for all other telemetry data types. If data is being refused from entering the pipeline too often, you\u2019ll probably want to scale up your Collector cluster. You can scale down once the memory consumption across the nodes is significantly lower than the limit set in this processor.</p> <p>Another set of metrics to keep in sight are the ones related to the queue sizes for exporters: <code>otelcol_exporter_queue_capacity</code> and <code>otelcol_exporter_queue_size</code>. The Collector will queue data in memory while waiting for a worker to become available to send the data. If there aren\u2019t enough workers or the backend is too slow, data starts piling up in the queue. Once the queue has hit its capacity (<code>otelcol_exporter_queue_size</code> &gt; <code>otelcol_exporter_queue_capacity</code>) it rejects data (<code>otelcol_exporter_enqueue_failed_spans</code>). Adding more workers will often make the Collector export more data, which might not necessarily be what you want (see When NOT to scale).</p> <p>It\u2019s also worth getting familiar with the components that you intend to use, as different components might produce other metrics. For instance, the load-balancing exporter will record timing information about the export operations, exposing this as part of the histogram <code>otelcol_loadbalancer_backend_latency</code>. You can extract this information to determine whether all backends are taking a similar amount of time to process requests: single backends being slow might indicate problems external to the Collector.</p> <p>For receivers doing scraping, such as the Prometheus receiver, the scraping should be scaled, or sharded, once the time it takes to finish scraping all targets often becomes critically close to the scrape interval. When that happens, it\u2019s time to add more scrapers, usually new instances of the Collector.</p>"},{"location":"docs/collector/scaling/#when-not-to-scale","title":"When NOT to scale","text":"<p>Perhaps as important as knowing when to scale is to understand which signs indicate that a scaling operation won\u2019t bring any benefits. One example is when a telemetry database can\u2019t keep up with the load: adding Collectors to the cluster won\u2019t help without scaling up the database. Similarly, when the network connection between the Collector and the backend is saturated, adding more Collectors might cause a harmful side effect.</p> <p>Again, one way to catch this situation is by looking at the metrics <code>otelcol_exporter_queue_size</code> and <code>otelcol_exporter_queue_capacity</code>. If you keep having the queue size close to the queue capacity, it\u2019s a sign that exporting data is slower than receiving data. You can try to increase the queue size, which will cause the Collector to consume more memory, but it will also give some room for the backend to breathe without permanently dropping telemetry data. But if you keep increasing the queue capacity and the queue size keeps rising at the same proportion, it\u2019s indicative that you might want to look outside of the Collector. It\u2019s also important to note that adding more workers here would not be helpful: you\u2019ll only be putting more pressure on a system already suffering from a high load.</p> <p>Another sign that the backend might be having problems is an increase in the <code>otelcol_exporter_send_failed_spans</code> metric: this indicates that sending data to the backend failed permanently. Scaling up the Collector will likely only worsen the situation when this is consistently happening.</p>"},{"location":"docs/collector/scaling/#how-to-scale","title":"How to Scale","text":"<p>At this point, we know which parts of our pipeline needs scaling. Regarding scaling, we have three types of components: stateless, scrapers, and stateful.</p> <p>Most Collector components are stateless. Even if they hold some state in memory, it isn\u2019t relevant for scaling purposes.</p> <p>Scrapers, like the Prometheus receiver, are configured to obtain telemetry data from external locations. The receiver will then scrape target by target, putting data into the pipeline.</p> <p>Components like the tail sampling processor cannot be easily scaled, as they keep some relevant state in memory for their business. Those components require some careful consideration before being scaled up.</p>"},{"location":"docs/collector/scaling/#scaling-stateless-collectors","title":"Scaling Stateless Collectors","text":"<p>The good news is that most of the time, scaling the Collector is easy, as it\u2019s just a matter of adding new replicas and using an off-the-shelf load balancer. When gRPC is used to receive the data, we recommend using a load-balancer that understands gRPC. Otherwise, clients will always hit the same backing Collector.</p> <p>You should still consider splitting your collection pipeline with reliability in mind. For instance, when your workloads run on Kubernetes, you might want to use DaemonSets to have a Collector on the same physical node as your workloads and a remote central Collector responsible for pre-processing the data before sending the data to the storage. When the number of nodes is low and the number of pods is high, Sidecars might make more sense, as you\u2019ll get a better load balancing for the gRPC connections among Collector layers without needing a gRPC-specific load balancer. Using a Sidecar also makes sense to avoid bringing down a crucial component for all pods in a node when one DaemonSet pod fails.</p> <p>The sidecar pattern consists in adding a container into the workload pod. The OpenTelemetry Operator can automatically add that for you. To accomplish that, you\u2019ll need an OpenTelemetry Collector CR and you\u2019ll need to annotate your PodSpec or Pod telling the operator to inject a sidecar:</p> <pre><code>---\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\nname: sidecar-for-my-workload\nspec:\nmode: sidecar\nconfig: |\nreceivers:\notlp:\nprotocols:\ngrpc:\nprocessors:\nexporters:\nlogging:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: []\nexporters: [logging]\n---\napiVersion: v1\nkind: Pod\nmetadata:\nname: my-microservice\nannotations:\nsidecar.opentelemetry.io/inject: 'true'\nspec:\ncontainers:\n- name: my-microservice\nimage: my-org/my-microservice:v0.0.0\nports:\n- containerPort: 8080\nprotocol: TCP\n</code></pre> <p>In case you prefer to bypass the operator and add a sidecar manually, here\u2019s an example:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: my-microservice\nspec:\ncontainers:\n- name: my-microservice\nimage: my-org/my-microservice:v0.0.0\nports:\n- containerPort: 8080\nprotocol: TCP\n- name: sidecar\nimage: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector:0.69.0\nports:\n- containerPort: 8888\nname: metrics\nprotocol: TCP\n- containerPort: 4317\nname: otlp-grpc\nprotocol: TCP\nargs:\n- --config=/conf/collector.yaml\nvolumeMounts:\n- mountPath: /conf\nname: sidecar-conf\nvolumes:\n- name: sidecar-conf\nconfigMap:\nname: sidecar-for-my-workload\nitems:\n- key: collector.yaml\npath: collector.yaml\n</code></pre>"},{"location":"docs/collector/scaling/#scaling-the-scrapers","title":"Scaling the Scrapers","text":"<p>Some receivers are actively obtaining telemetry data to place in the pipeline, like the hostmetrics and prometheus receivers. While getting host metrics isn\u2019t something we\u2019d typically scale up, we might need to split the job of scraping thousands of endpoints for the Prometheus receiver. And we can\u2019t simply add more instances with the same configuration, as each Collector would try to scrape the same endpoints as every other Collector in the cluster, causing even more problems, like out-of-order samples.</p> <p>The solution is to shard the endpoints by Collector instances so that if we add another replica of the Collector, each one will act on a different set of endpoints.</p> <p>One way of doing that is by having one configuration file for each Collector so that each Collector would discover only the relevant endpoints for that Collector. For instance, each Collector could be responsible for one Kubernetes namespace or specific labels on the workloads.</p> <p>Another way of scaling the Prometheus receiver is to use the Target Allocator: it\u2019s an extra binary that can be deployed as part of the OpenTelemetry Operator and will split the share of Prometheus jobs for a given configuration across the cluster of Collectors using a consistent hashing algorithm. You can use a Custom Resource (CR) like the following to make use of the Target Allocator:</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\nname: collector-with-ta\nspec:\nmode: statefulset\ntargetAllocator:\nenabled: true\nconfig: |\nreceivers:\nprometheus:\nconfig:\nscrape_configs:\n- job_name: 'otel-collector'\nscrape_interval: 10s\nstatic_configs:\n- targets: [ '0.0.0.0:8888' ]\nexporters:\nlogging:\nservice:\npipelines:\ntraces:\nreceivers: [prometheus]\nprocessors: []\nexporters: [logging]\n</code></pre> <p>After the reconciliation, the OpenTelemetry Operator will convert the Collector\u2019s configuration into the following:</p> <pre><code>   exporters:\nlogging: null\nreceivers:\nprometheus:\nconfig:\nglobal:\nscrape_interval: 1m\nscrape_timeout: 10s\nevaluation_interval: 1m\nscrape_configs:\n- job_name: otel-collector\nhonor_timestamps: true\nscrape_interval: 10s\nscrape_timeout: 10s\nmetrics_path: /metrics\nscheme: http\nfollow_redirects: true\nhttp_sd_configs:\n- follow_redirects: false\nurl: http://collector-with-ta-targetallocator:80/jobs/otel-collector/targets?collector_id=$POD_NAME\nservice:\npipelines:\ntraces:\nexporters:\n- logging\nprocessors: []\nreceivers:\n- prometheus\n</code></pre> <p>Note how the Operator added a <code>global</code> section and a <code>new http_sd_configs</code> to the <code>otel-collector</code> scrape config, pointing to a Target Allocator instance it provisioned. Now, to scale the collectors, change the \u201creplicas\u201d attribute of the CR and the Target Allocator will distribute the load accordingly by providing a custom <code>http_sd_config</code> per collector instance (pod).</p>"},{"location":"docs/collector/scaling/#scaling-stateful-collectors","title":"Scaling Stateful Collectors","text":"<p>Certain components might hold data in memory, yielding different results when scaled up. It is the case for the tail-sampling processor, which holds spans in memory for a given period, evaluating the sampling decision only when the trace is considered complete. Scaling a Collector cluster by adding more replicas means that different collectors will receive spans for a given trace, causing each collector to evaluate whether that trace should be sampled, potentially coming to different answers. This behavior results in traces missing spans, misrepresenting what happened in that transaction.</p> <p>A similar situation happens when using the span-to-metrics processor to generate service metrics. When different collectors receive data related to the same service, aggregations based on the service name will be inaccurate.</p> <p>To overcome this, you can deploy a layer of Collectors containing the load-balancing exporter in front of your Collectors doing the tail-sampling or the span-to-metrics processing. The load-balancing exporter will hash the trace ID or the service name consistently and determine which collector backend should receive spans for that trace. You can configure the load-balancing exporter to use the list of hosts behind a given DNS A entry, such as a Kubernetes headless service. When the deployment backing that service is scaled up or down, the load-balancing exporter will eventually see the updated list of hosts. Alternatively, you can specify a list of static hosts to be used by the load-balancing exporter. You can scale up the layer of Collectors configured with the load-balancing exporter by increasing the number of replicas. Note that each Collector will potentially run the DNS query at different times, causing a difference in the cluster view for a few moments. We recommend lowering the interval value so that the cluster view is different only for a short period in highly-elastic environments.</p> <p>Here\u2019s an example configuration using a DNS A record (Kubernetes service otelcol on the observability namespace) as the input for the backend information:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nprocessors:\nexporters:\nloadbalancing:\nprotocol:\notlp:\nresolver:\ndns:\nhostname: otelcol.observability.svc.cluster.local\nservice:\npipelines:\ntraces:\nreceivers:\n- otlp\nprocessors: []\nexporters:\n- loadbalancing\n</code></pre>"},{"location":"docs/collector/trace-receiver/","title":"\u5efa\u7acb\u8ddf\u8e2a\u63a5\u6536\u5668","text":"<p>If you are reading this tutorial, you probably already have an idea of the OpenTelemetry concepts behind distributed tracing, but if you don't you can quickly read through it here.</p> <p>Here is the definition of those concepts according to OpenTelemetry:</p> <p>Traces track the progression of a single request, called a trace, as it is handled by services that make up an application. The request may be initiated by a user or an application. Distributed tracing is a form of tracing that traverses process, network and security boundaries.</p> <p>Although the definition seems very application centric, you can leverage the OpenTelemetry trace model as a way to represent a request and quickly understand its duration and the details about every step involved in completing it.</p> <p>Assuming you already have a system generating some kind of tracing telemetry, the OpenTelemetry Collector is the doorway to help you make it available into the OTel world.</p> <p>Within the Collector, a trace receiver has the role to receive and convert your request telemetry from its original format into the OTel trace model, so the information can be properly processed through the Collector's pipelines.</p> <p>In order to implement a traces receiver you will need the following:</p> <ul> <li> <p>A <code>Config</code> implementation to enable the trace receiver to gather and validate   its configurations within the Collector's config.yaml.</p> </li> <li> <p>A <code>receiver.Factory</code> implementation so the Collector can properly instantiate   the trace receiver component.</p> </li> <li> <p>A <code>TracesReceiver</code> implementation that is responsible to collect the   telemetry, convert it to the internal trace representation, and hand the   information to the next consumer in the pipeline.</p> </li> </ul> <p>In this tutorial we will create a sample trace receiver called <code>tailtracer</code> that simulates a pull operation and generates traces as an outcome of that operation. The next sections will guide you through the process of implementing the steps above in order to create the receiver, so let's get started.</p>"},{"location":"docs/collector/trace-receiver/#setting-up-your-receiver-development-and-testing-environment","title":"Setting up your receiver development and testing environment","text":"<p>First use the Building a Custom Collector tutorial to create a Collector instance named <code>otelcol-dev</code>; all you need is to copy the <code>builder-config.yaml</code> described on Step 2 and make the following changes:</p> <pre><code>dist:\nname: otelcol-dev # the binary name. Optional.\noutput_path: ./otelcol-dev # the path to write the output (sources and binary). Optional.\n</code></pre> <p>As an outcome you should now have a <code>otelcol-dev</code> folder with your Collector's development instance ready to go.</p> <p>In order to properly test your trace receiver, you will need a distributed tracing backend so the Collector can send the telemetry to it. We will be using Jaeger, if you don't have a <code>Jaeger</code> instance running, you can easily start one using Docker with the following command:</p> <pre><code>docker run -d --name jaeger \\\n-p 16686:16686 \\\n-p 14268:14268 \\\n-p 14250:14250 \\\njaegertracing/all-in-one:1.29\n</code></pre> <p>Now, create a <code>config.yaml</code> file so you can set up your Collector's components.</p> <pre><code>cd otelcol-dev\ntouch config.yaml\n</code></pre> <p>For now, you just need a basic traces pipeline with the <code>otlp</code> receiver, the <code>jaeger</code> and <code>logging</code> exporters, here is what your <code>config.yaml</code> file should look like:</p> <p>config.yaml</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nprocessors:\nexporters:\nlogging:\nverbosity: detailed\njaeger:\nendpoint: localhost:14250\ntls:\ninsecure: true\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: []\nexporters: [jaeger, logging]\ntelemetry:\nlogs:\nlevel: debug\n</code></pre> <p>Notice that I am only using the <code>insecure</code> flag in my <code>jaeger</code> receiver config to make my local development setup easier; you should not use this flag when running your collector in production.</p> <p>In order to verify that your initial pipeline is properly set up, you should have the following output after running your <code>otelcol-dev</code> command:</p> <pre><code>$ ./otelcol-dev --config config.yaml\n2022-06-21T13:02:09.253-0500    info    builder/exporters_builder.go:255        Exporter was built.     {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-06-21T13:02:09.254-0500    info    builder/exporters_builder.go:255        Exporter was built.     {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-06-21T13:02:09.254-0500    info    builder/pipelines_builder.go:224        Pipeline was built.     {\"kind\": \"pipeline\", \"name\": \"traces\"}\n2022-06-21T13:02:09.254-0500    info    builder/receivers_builder.go:225        Receiver was built.     {\"kind\": \"receiver\", \"name\": \"otlp\", \"datatype\": \"traces\"}\n2022-06-21T13:02:09.254-0500    info    service/telemetry.go:102        Setting up own telemetry...\n2022-06-21T13:02:09.255-0500    info    service/telemetry.go:141        Serving Prometheus metrics      {\"address\": \":8888\", \"level\": \"basic\"}\n2022-06-21T13:02:09.255-0500    info    service/service.go:93   Starting extensions...\n2022-06-21T13:02:09.255-0500    info    service/service.go:98   Starting exporters...\n2022-06-21T13:02:09.255-0500    info    builder/exporters_builder.go:40 Exporter is starting... {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-06-21T13:02:09.258-0500    info    builder/exporters_builder.go:48 Exporter started.       {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-06-21T13:02:09.258-0500    info    jaegerexporter@v0.53.0/exporter.go:186  State of the connection with the Jaeger Collector backend       {\"kind\": \"exporter\", \"name\": \"jaeger\", \"state\": \"IDLE\"}\n2022-06-21T13:02:09.258-0500    info    builder/exporters_builder.go:40 Exporter is starting... {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-06-21T13:02:09.258-0500    info    builder/exporters_builder.go:48 Exporter started.       {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-06-21T13:02:09.258-0500    info    service/service.go:103  Starting processors...\n2022-06-21T13:02:09.258-0500    info    builder/pipelines_builder.go:54 Pipeline is starting... {\"kind\": \"pipeline\", \"name\": \"traces\"}\n2022-06-21T13:02:09.258-0500    info    builder/pipelines_builder.go:65 Pipeline is started.    {\"kind\": \"pipeline\", \"name\": \"traces\"}\n2022-06-21T13:02:09.258-0500    info    service/service.go:108  Starting receivers...\n2022-06-21T13:02:09.258-0500    info    builder/receivers_builder.go:67 Receiver is starting... {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-06-21T13:02:09.258-0500    info    otlpreceiver/otlp.go:70 Starting GRPC server on endpoint localhost:55690        {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-06-21T13:02:09.261-0500    info    builder/receivers_builder.go:72 Receiver started.       {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-06-21T13:02:09.262-0500    info    service/collector.go:226        Starting otelcol-dev... {\"Version\": \"1.0.0\", \"NumCPU\": 12}\n2022-06-21T13:02:09.262-0500    info    service/collector.go:134        Everything is ready. Begin running and processing data.\n2022-06-21T13:02:10.258-0500    info    jaegerexporter@v0.53.0/exporter.go:186  State of the connection with the Jaeger Collector backend       {\"kind\": \"exporter\", \"name\": \"jaeger\", \"state\": \"READY\"}\n</code></pre> <p>Make sure you see the last line, that will confirm that the Jaeger exporter has successfully established a connection to your local Jaeger instance. Now that we have our environment ready, let's start writing your receiver's code.</p> <p>Now, create another folder called <code>tailtracer</code> so we can have a place to host all of our receiver code.</p> <pre><code>mkdir tailtracer\n</code></pre> <p>Every Collector's component should be created as a Go module, so you will need to properly initialize the <code>tailtracer</code> module. In my case here is what the command looked like:</p> <pre><code>cd tailtracer\ngo mod init github.com/rquedas/otel4devs/collector/receiver/trace-receiver/tailtracer\n</code></pre>"},{"location":"docs/collector/trace-receiver/#reading-and-validating-your-receiver-settings","title":"Reading and Validating your Receiver Settings","text":"<p>In order to be instantiated and participate in pipelines the Collector needs to identify your receiver and properly load its settings from within its configuration file.</p> <p>The <code>tailtracer</code> receiver will have the following settings:</p> <ul> <li><code>interval</code>: a string representing the time interval (in minutes) between   telemetry pull operations</li> <li><code>number_of_traces</code>: the number of mock traces generated for each interval</li> </ul> <p>Here is what the <code>tailtracer</code> receiver settings will look like:</p> <pre><code>receivers:\ntailtracer: # this line represents the ID of your receiver\ninterval: 1m\nnumber_of_traces: 1\n</code></pre> <p>Under the <code>tailtracer</code> folder, create a file named <code>config.go</code> where you will write all the code to support your receiver settings.</p> <pre><code>cd tailtracer\ntouch config.go\n</code></pre> <p>To implement the configuration aspects of a receiver you need create a <code>Config</code> struct. Add the following code to your <code>config.go</code> file:</p> <pre><code>package tailtracer\ntype Config struct{\n}\n</code></pre> <p>In order to be able to give your receiver access to its settings the <code>Config</code> struct must have a field for each of the receiver's settings.</p> <p>Here is what your <code>config.go</code> file should look like after you implemented the requirements above.</p> <p>config.go</p> <pre><code>package tailtracer\n// Config represents the receiver config settings within the collector's config.yaml\ntype Config struct {\nInterval    string `mapstructure:\"interval\"`\nNumberOfTraces int `mapstructure:\"number_of_traces\"`\n}\n</code></pre> <p>Now that you have access to the settings, you can provide any kind of validation needed for those values by implementing the <code>Validate</code> method according to the optional ConfigValidator interface.</p> <p>In this case, the <code>interval</code> value will be optional (we will look at generating default values later) but when defined should be at least 1 minute (1m) and the <code>number_of_traces</code> will be a required value. Here is what the config.go looks like after implementing the <code>Validate</code> method.</p> <p>config.go</p> <pre><code>package tailtracer\nimport (\n\"fmt\"\n\"time\"\n)\n// Config represents the receiver config settings within the collector's config.yaml\ntype Config struct {\nInterval       string `mapstructure:\"interval\"`\nNumberOfTraces int    `mapstructure:\"number_of_traces\"`\n}\n// Validate checks if the receiver configuration is valid\nfunc (cfg *Config) Validate() error {\ninterval, _ := time.ParseDuration(cfg.Interval)\nif interval.Minutes() &lt; 1 {\nreturn fmt.Errorf(\"when defined, the interval has to be set to at least 1 minute (1m)\")\n}\nif cfg.NumberOfTraces &lt; 1 {\nreturn fmt.Errorf(\"number_of_traces must be greater or equal to 1\")\n}\nreturn nil\n}\n</code></pre> <p>If you want to take a closer look at the structs and interfaces involved in the configuration aspects of a component, take a look at the component/config.go file inside the Collector's GitHub project.</p>"},{"location":"docs/collector/trace-receiver/#check-your-work","title":"Check your work","text":"<ul> <li>I added the <code>Interval</code> and the <code>NumberOfTraces</code> fields so I can properly   have access to their values from the config.yaml.</li> </ul>"},{"location":"docs/collector/trace-receiver/#check-your-work_1","title":"Check your work","text":"<ul> <li>I imported the <code>fmt</code> package, so I can properly format print my error   messages.</li> <li>I added the <code>Validate</code> method to my Config struct where I am checking if the   <code>interval</code> setting value is at least 1 minute (1m) and if the   <code>number_of_traces</code> setting value is greater or equal to 1. If that is not   true the Collector will generate an error during its startup process and   display the message accordingly.</li> </ul>"},{"location":"docs/collector/trace-receiver/#enabling-the-collector-to-instantiate-your-receiver","title":"Enabling the Collector to instantiate your receiver","text":"<p>At the beginning of this tutorial, you created your <code>otelcol-dev</code> instance, which is bootstrapped with the following components:</p> <ul> <li>Receivers: OTLP Receiver</li> <li>Processors: Batch Processor</li> <li>Exporters: Logging and Jaeger Exporters</li> </ul> <p>Go ahead and open the <code>components.go</code> file under the <code>otelcol-dev</code> folder, and let's take a look at the <code>components()</code> function.</p> <pre><code>func components() (otelcol.Factories, error) {\nvar err error\nfactories := otelcol.Factories{}\nfactories.Extensions, err = extension.MakeFactoryMap(\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nfactories.Receivers, err = receiver.MakeFactoryMap(\notlpreceiver.NewFactory(),\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nfactories.Exporters, err = exporter.MakeFactoryMap(\nloggingexporter.NewFactory(),\njaegerexporter.NewFactory(),\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nfactories.Processors, err = processor.MakeFactoryMap(\nbatchprocessor.NewFactory(),\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nreturn factories, nil\n}\n</code></pre> <p>As you can see, the <code>components()</code> function is responsible to provide the Collector the factories for all its components which is represented by a variable called <code>factories</code> of type <code>otelcol.Factories</code> (here is the declaration of the otelcol.Factories struct), which will then be used to instantiate the components that are configured and consumed by the Collector's pipelines.</p> <p>Notice that <code>factories.Receivers</code> is the field holding a map to all the receiver factories (instances of <code>receiver.Factory</code>), and it currently has the <code>otlpreceiver</code> factory only which is instantiated through the <code>otlpreceiver.NewFactory()</code> function call.</p> <p>The <code>tailtracer</code> receiver has to provide a <code>receiver.Factory</code> implementation, and although you will find a <code>receiver.Factory</code> interface (you can find its definition in the receiver/receiver.go file within the Collector's project ), the right way to provide the implementation is by using the functions available within the <code>go.opentelemetry.io/collector/receiver</code> package.</p>"},{"location":"docs/collector/trace-receiver/#implementing-your-receiverfactory","title":"Implementing your receiver.Factory","text":"<p>Start by creating a file named factory.go within the <code>tailtracer</code> folder.</p> <pre><code>cd tailtracer\ntouch factory.go\n</code></pre> <p>Now let's follow the convention and add a function named <code>NewFactory()</code> that will be responsible to instantiate the <code>tailtracer</code> factory. Go ahead the add the following code to your <code>factory.go</code> file:</p> <pre><code>package tailtracer\nimport (\n\"go.opentelemetry.io/collector/receiver\"\n)\n// NewFactory creates a factory for tailtracer receiver.\nfunc NewFactory() receiver.Factory {\n}\n</code></pre> <p>In order to instantiate your <code>tailtracer</code> receiver factory, you will use the following function from the <code>receiver</code> package:</p> <pre><code>func NewFactory(cfgType component.Type, createDefaultConfig component.CreateDefaultConfigFunc, options ...FactoryOption) Factory\n</code></pre> <p>The <code>receiver.NewFactory()</code> instantiates and returns a <code>receiver.Factory</code> and it requires the following parameters:</p> <ul> <li> <p><code>component.Type</code>: a unique string identifier for your receiver across all   Collector's components.</p> </li> <li> <p><code>component.CreateDefaultConfigFunc</code>: a reference to a function that returns   the component.Config instance for your receiver.</p> </li> <li> <p><code>...FactoryOption</code>: the slice of <code>receiver.FactoryOption</code>s that will determine   what type of signal your receiver is capable of processing.</p> </li> </ul> <p>Let's now implement the code to support all the parameters required by <code>receiver.NewFactory()</code>.</p>"},{"location":"docs/collector/trace-receiver/#identifying-and-providing-default-settings-for-the-receiver","title":"Identifying and Providing default settings for the receiver","text":"<p>Previously, we said that the <code>interval</code> setting for our <code>tailtracer</code> receiver would be optional, in that case you will need to provide a default value for it so it can be used as part of the default settings.</p> <p>Go ahead and add the following code to your <code>factory.go</code> file:</p> <pre><code>const (\ntypeStr = \"tailtracer\"\ndefaultInterval = 1 * time.Minute\n)\n</code></pre> <p>As for default settings, you just need to add a function that returns a <code>component.Config</code> holding the default configurations for the <code>tailtracer</code> receiver.</p> <p>To accomplish that, go ahead and add the following code to your <code>factory.go</code> file:</p> <pre><code>func createDefaultConfig() component.Config {\nreturn &amp;Config{\nInterval: string(defaultInterval),\n}\n}\n</code></pre> <p>After these two changes you will notice a few imports are missing, so here is what your <code>factory.go</code> file should look like with the proper imports:</p> <p>factory.go</p> <pre><code>package tailtracer\nimport (\n\"time\"\n\"go.opentelemetry.io/collector/component\"\n\"go.opentelemetry.io/collector/receiver\"\n)\nconst (\ntypeStr = \"tailtracer\"\ndefaultInterval = 1 * time.Minute\n)\nfunc createDefaultConfig() component.Config {\nreturn &amp;Config{\nInterval: string(defaultInterval),\n}\n}\n// NewFactory creates a factory for tailtracer receiver.\nfunc NewFactory() receiver.Factory {\nreturn nil\n}\n</code></pre>"},{"location":"docs/collector/trace-receiver/#check-your-work_2","title":"Check your work","text":"<ul> <li>Importing the <code>time</code> package in order to support the time.Duration type for   the defaultInterval</li> <li>Importing the <code>go.opentelemetry.io/collector/component</code> package, which is   where <code>component.Config</code> is declared.</li> <li>Importing the <code>go.opentelemetry.io/collector/receiver</code> package, which is   where <code>receiver.Factory</code> is declared.</li> <li>Added a <code>time.Duration</code> constant called <code>defaultInterval</code> to represent the   default value for our receiver's <code>Interval</code> setting. We will be setting the   default value for 1 minute hence the assignment of <code>1 * time.Minute</code> as its   value.</li> <li>Added a function called <code>createDefaultConfig</code> which is responsible to return   a component.Config implementation, which in this case is going to be an   instance of our <code>tailtracer.Config</code> struct.</li> <li>The <code>tailtracer.Config.Interval</code> field was initialized with the   <code>defaultInterval</code> constant.</li> </ul>"},{"location":"docs/collector/trace-receiver/#enabling-the-factory-to-describe-the-receiver-as-capable-of-processing-traces","title":"Enabling the factory to describe the receiver as capable of processing traces","text":"<p>The same receiver component can process traces, metrics, and logs. The receiver's factory is responsible for describing those capabilities.</p> <p>Given that traces are the subject of the tutorial, that's the only signal we will enable the <code>tailtracer</code> receiver to work with. The <code>receiver</code> package provides the following function and type to help the factory describe the trace processing capabilities:</p> <pre><code>func WithTraces(createTracesReceiver CreateTracesFunc, sl component.StabilityLevel) FactoryOption\n</code></pre> <p>The <code>receiver.WithTraces()</code> instantiates and returns a <code>receiver.FactoryOption</code> and it requires the following parameters:</p> <ul> <li><code>createTracesReceiver</code>: A reference to a function that matches the   <code>receiver.CreateTracesFunc</code> type</li> </ul> <p>The <code>receiver.CreateTracesFunc</code> type is a pointer to a function that is responsible to instantiate and return a <code>receiver.Traces</code> instance and it requires the following parameters:</p> <ul> <li><code>context.Context</code>: the reference to the Collector's <code>context.Context</code> so your   trace receiver can properly manage its execution context.</li> <li><code>receiver.CreateSettings</code>: the reference to some of the Collector's settings   under which your receiver is created.</li> <li><code>component.Config</code>: the reference for the receiver config settings passed by   the Collector to the factory so it can properly read its settings from the   Collector config.</li> <li><code>consumer.Traces</code>: the reference to the next <code>consumer.Traces</code> in the   pipeline, which is where received traces will go. This is either a processor   or an exporter.</li> </ul> <p>Start by adding the bootstrap code to properly implement the <code>receiver.CreateTracesFunc</code> function pointer. Go ahead and add the following code to your <code>factory.go</code> file:</p> <pre><code>func createTracesReceiver(_ context.Context, params receiver.CreateSettings, baseCfg component.Config, consumer consumer.Traces) (receiver.Traces, error) {\nreturn nil, nil\n}\n</code></pre> <p>You now have all the necessary components to successfully instantiate your receiver factory using the <code>receiver.NewFactory</code> function. Go ahead and and update your <code>NewFactory()</code> function in your <code>factory.go</code> file as follow:</p> <pre><code>// NewFactory creates a factory for tailtracer receiver.\nfunc NewFactory() receiver.Factory {\nreturn receiver.NewFactory(\ntypeStr,\ncreateDefaultConfig,\nreceiver.WithTraces(createTracesReceiver, component.StabilityLevelAlpha))\n}\n</code></pre> <p>After these two changes you will notice a few imports are missing, so here is what your <code>factory.go</code> file should look like with the proper imports:</p> <p>factory.go</p> <pre><code>package tailtracer\nimport (\n\"context\"\n\"time\"\n\"go.opentelemetry.io/collector/component\"\n\"go.opentelemetry.io/collector/consumer\"\n\"go.opentelemetry.io/collector/receiver\"\n)\nconst (\ntypeStr = \"tailtracer\"\ndefaultInterval = 1 * time.Minute\n)\nfunc createDefaultConfig() component.Config {\nreturn &amp;Config{\nInterval: string(defaultInterval),\n}\n}\nfunc createTracesReceiver(_ context.Context, params receiver.CreateSettings, baseCfg component.Config, consumer consumer.Traces) (receiver.Traces, error) {\nreturn nil, nil\n}\n// NewFactory creates a factory for tailtracer receiver.\nfunc NewFactory() receiver.Factory {\nreturn receiver.NewFactory(\ntypeStr,\ncreateDefaultConfig,\nreceiver.WithTraces(createTracesReceiver, component.StabilityLevelAlpha))\n}\n</code></pre> <p>At this point, you have the <code>tailtracer</code> factory and config code needed for the Collector to validate the <code>tailtracer</code> receiver settings if they are defined within the <code>config.yaml</code>. You just need to add it to the Collector's initialization process.</p>"},{"location":"docs/collector/trace-receiver/#check-your-work_3","title":"Check your work","text":"<ul> <li>Importing the <code>context</code> package in order to support the <code>context.Context</code>   type referenced in the <code>createTracesReceiver</code> function</li> <li>Importing the <code>go.opentelemetry.io/collector/consumer</code> package in order to   support the <code>consumer.Traces</code> type referenced in the <code>createTracesReceiver</code>   function</li> <li>Updated the <code>NewFactory()</code> function so it returns the <code>receiver.Factory</code>   generated by the <code>receiver.NewFactory()</code> call with the required parameters.   The generated receiver factory will be capable of processing traces through   the call to   <code>receiver.WithTraces(createTracesReceiver, component.StabilityLevelAlpha)</code></li> </ul>"},{"location":"docs/collector/trace-receiver/#adding-the-receiver-factory-to-the-collectors-initialization","title":"Adding the receiver factory to the Collector's initialization","text":"<p>As explained before, all the Collector components are instantiated by the <code>components()</code> function within the <code>components.go</code> file.</p> <p>The <code>tailtracer</code> receiver factory instance has to be added to the <code>factories</code> map so the Collector can load it properly as part of its initialization process.</p> <p>Here is what the <code>components.go</code> file looks like after making the changes to support that:</p> <p>components.go</p> <pre><code>// Code generated by \"go.opentelemetry.io/collector/cmd/builder\". DO NOT EDIT.\npackage main\nimport (\n\"go.opentelemetry.io/collector/exporter\"\n\"go.opentelemetry.io/collector/extension\"\n\"go.opentelemetry.io/collector/otelcol\"\n\"go.opentelemetry.io/collector/processor\"\n\"go.opentelemetry.io/collector/receiver\"\nloggingexporter \"go.opentelemetry.io/collector/exporter/loggingexporter\"\njaegerexporter \"github.com/open-telemetry/opentelemetry-collector-contrib/exporter/jaegerexporter\"\nbatchprocessor \"go.opentelemetry.io/collector/processor/batchprocessor\"\notlpreceiver \"go.opentelemetry.io/collector/receiver/otlpreceiver\"\ntailtracer \"github.com/rquedas/otel4devs/collector/receiver/trace-receiver/tailtracer\"\n)\nfunc components() (otelcol.Factories, error) {\nvar err error\nfactories := otelcol.Factories{}\nfactories.Extensions, err = extension.MakeFactoryMap(\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nfactories.Receivers, err = receiver.MakeFactoryMap(\notlpreceiver.NewFactory(),\ntailtracer.NewFactory(),\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nfactories.Exporters, err = exporter.MakeFactoryMap(\nloggingexporter.NewFactory(),\njaegerexporter.NewFactory(),\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nfactories.Processors, err = processor.MakeFactoryMap(\nbatchprocessor.NewFactory(),\n)\nif err != nil {\nreturn otelcol.Factories{}, err\n}\nreturn factories, nil\n}\n</code></pre> <p>We added the <code>tailtracer</code> receiver settings to the <code>config.yaml</code> previously, so here is what the beginning of the output for running your Collector with <code>otelcol-dev</code> command should look like after building it with the current codebase:</p> <pre><code>$ ./otelcol-dev --config config.yaml\n2022-02-24T12:17:41.454-0600    info    service/collector.go:190        Applying configuration...\n2022-02-24T12:17:41.454-0600    info    builder/exporters_builder.go:254        Exporter was built.     {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-02-24T12:17:41.454-0600    info    builder/exporters_builder.go:254        Exporter was built.     {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-02-24T12:17:41.454-0600    info    builder/pipelines_builder.go:222        Pipeline was built.     {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-02-24T12:17:41.454-0600    info    builder/receivers_builder.go:111        Ignoring receiver as it is not used by any pipeline      {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-02-24T12:17:41.454-0600    info    builder/receivers_builder.go:224        Receiver was built.     {\"kind\": \"receiver\", \"name\": \"otlp\", \"datatype\": \"traces\"}\n2022-02-24T12:17:41.454-0600    info    service/service.go:86   Starting extensions...\n2022-02-24T12:17:41.454-0600    info    service/service.go:91   Starting exporters...\n</code></pre> <p>Look for the log line for \"builder/receivers_builder.go:111\" (it's the 4th line from the bottom at the snippet showed here), you can see that the Collector found the settings for the <code>tailtracer</code> receiver, validated them (the current settings are all correct), but ignores the receiver given that it's not used in any pipeline.</p> <p>Let's check if the <code>tailtracer</code> factory is validating the receiver settings correctly, the <code>interval</code> setting isn't required, so if you remove it from the <code>config.yaml</code> and run the command again you should get the same output.</p> <p>Now, let's test one of the <code>tailtracer</code> settings validation rules. Remove the <code>number_of_traces</code> setting from the <code>config.yaml</code>, and here is what the output for running the Collector will look like:</p> <pre><code>$ ./otelcol-dev --config config.yaml\nError: invalid configuration: receiver \"tailtracer\" has invalid configuration: number_of_traces must be at least 1\n2022/02/24 13:00:20 collector server run finished with error: invalid configuration: receiver \"tailtracer\" has invalid configuration: number_of_traces must be at least 1\n</code></pre> <p>The <code>tailtracer</code> receiver factory and config requirements are done and the Collector is properly loading your component. You can now move to the core of your receiver, the implementation of the component itself.</p>"},{"location":"docs/collector/trace-receiver/#check-your-work_4","title":"Check your work","text":"<ul> <li>Importing the   <code>github.com/rquedas/otel4devs/collector/receiver/trace-receiver/tailtracer</code>   module which is where the receiver types and function are.</li> <li>Added a call to <code>tailtracer.NewFactory()</code> as a parameter of the   <code>receiver.MakeFactoryMap()</code> call so your <code>tailtracer</code> receiver factory is   properly added to the <code>factories</code> map.</li> </ul>"},{"location":"docs/collector/trace-receiver/#implementing-the-trace-receiver-component","title":"Implementing the trace receiver component","text":"<p>In the previous section, I mentioned the fact that a receiver can process any of the OpenTelemetry signals, and the Collector's API is designed to help you accomplish that.</p> <p>All the receiver APIs responsible to enable the signals are currently declared in the receiver/receiver.go file within the OTel Collector's project in GitHub, open the file and take a minute to browse through all the interfaces declared in it.</p> <p>Notice that <code>receiver.Traces</code> (and its siblings <code>receiver.Metrics</code> and <code>receiver.Logs</code>) at this point in time, doesn't describe any specific methods other than the ones it \"inherits\" from <code>component.Component</code>.</p> <p>It might feel weird, but remember, the Collector's API was meant to be extensible, and the components and their signals might evolve in different ways, so the role of those interfaces exist to help support that.</p> <p>So, to create a <code>receiver.Traces</code>, you just need to implement the following methods described by <code>component.Component</code> interface:</p> <pre><code>Start(ctx context.Context, host Host) error\nShutdown(ctx context.Context) error\n</code></pre> <p>Both methods actually act as event handlers used by the Collector to communicate with its components as part of their lifecycle.</p> <p>The <code>Start()</code> represents a signal of the Collector telling the component to start its processing. As part of the event, the Collector will pass the following information:</p> <ul> <li><code>context.Context</code>: Most of the time, a receiver will be processing a   long-running operation, so the recommendation is to ignore this context and   actually create a new one from context.Background().</li> <li><code>Host</code>: The host is meant to enable the receiver to communicate with the   Collector's host once it's up and running.</li> </ul> <p>The <code>Shutdown()</code> represents a signal of the Collector telling the component that the service is getting shutdown and as such the component should stop its processing and make all the necessary cleanup work required:</p> <ul> <li><code>context.Context</code>: the context passed by the Collector as part of the shutdown   operation.</li> </ul> <p>You will start the implementation by creating a new file called <code>trace-receiver.go</code> within your project's <code>tailtracer</code> folder and add the declaration to a type type called <code>tailtracerReceiver</code> as follow:</p> <pre><code>type tailtracerReceiver struct{\n}\n</code></pre> <p>Now that you have the <code>tailtracerReceiver</code> type you can implement the Start() and Shutdown() methods so the receiver type can be compliant with the <code>receiver.Traces</code> interface.</p> <p>Here is what the <code>tailtracer/trace-receiver.go</code> file should look like with the methods implementation:</p> <p>trace-receiver.go</p> <pre><code>package tailtracer\nimport (\n\"context\"\n\"go.opentelemetry.io/collector/component\"\n)\ntype tailtracerReceiver struct {\n}\nfunc (tailtracerRcvr *tailtracerReceiver) Start(ctx context.Context, host component.Host) error {\nreturn nil\n}\nfunc (tailtracerRcvr *tailtracerReceiver) Shutdown(ctx context.Context) error {\nreturn nil\n}\n</code></pre> <p>The <code>Start()</code> method is passing 2 references (<code>context.Context</code> and <code>component.Host</code>) that your receiver might need to keep so they can be used as part of its processing operations.</p> <p>The <code>context.Context</code> reference should be used for creating a new context to support you receiver processing operations, and in that case you will need to decide the best way to handle context cancellation so you can finalize it properly as part of the component's shutdown within the <code>Shutdown()</code> method.</p> <p>The <code>component.Host</code> can be useful during the whole lifecycle of the receiver so you should keep that reference within your <code>tailtracerReceiver</code> type.</p> <p>Here is what the <code>tailtracerReceiver</code> type declaration will look like after you include the fields for keeping the references suggested above:</p> <pre><code>type tailtracerReceiver struct {\nhost component.Host\ncancel context.CancelFunc\n}\n</code></pre> <p>Now you need to update the <code>Start()</code> methods so the receiver can properly initialize its own processing context and have the cancellation function kept in the <code>cancel</code> field and also initialize its <code>host</code> field value. You will also update the <code>Stop()</code> method in order to finalize the context by calling the <code>cancel</code> function.</p> <p>Here is what the <code>trace-receiver.go</code> file look like after making the changes above:</p> <p>trace-receiver.go</p> <pre><code>package tailtracer\nimport (\n\"context\"\n\"go.opentelemetry.io/collector/component\"\n)\ntype tailtracerReceiver struct {\nhost component.Host\ncancel context.CancelFunc\n}\nfunc (tailtracerRcvr *tailtracerReceiver) Start(ctx context.Context, host component.Host) error {\ntailtracerRcvr.host = host\nctx = context.Background()\nctx, tailtracerRcvr.cancel = context.WithCancel(ctx)\nreturn nil\n}\nfunc (tailtracerRcvr *tailtracerReceiver) Shutdown(ctx context.Context) error {\ntailtracerRcvr.cancel()\nreturn nil\n}\n</code></pre>"},{"location":"docs/collector/trace-receiver/#check-your-work_5","title":"Check your work","text":"<ul> <li>Importing the <code>context</code> package which is where the <code>Context</code> type and   functions are declared</li> <li>Importing the <code>go.opentelemetry.io/collector/component</code> package which is   where the <code>Host</code> type is declared</li> <li>Added a bootstrap implementation of the   <code>Start(ctx context.Context, host component.Host)</code> method to comply with the   <code>receiver.Traces</code> interface.</li> <li>Added a bootstrap implementation of the <code>Shutdown(ctx context.Context)</code>   method to comply with the <code>receiver.Traces</code> interface.</li> </ul>"},{"location":"docs/collector/trace-receiver/#check-your-work_6","title":"Check your work","text":"<ul> <li>Updated the <code>Start()</code> method by adding the initialization to the <code>host</code>   field with the <code>component.Host</code> reference passed by the Collector and the   <code>cancel</code> function field with the cancellation based on a new context created   with <code>context.Background()</code> (according the Collector's API documentation   suggestions).</li> <li>Updated the <code>Stop()</code> method by adding a call to the <code>cancel()</code> context   cancellation function.</li> </ul>"},{"location":"docs/collector/trace-receiver/#keeping-information-passed-by-the-receivers-factory","title":"Keeping information passed by the receiver's factory","text":"<p>Now that you have implemented the <code>receiver.Traces</code> interface methods, your <code>tailtracer</code> receiver component is ready to be instantiated and returned by its factory.</p> <p>Open the <code>tailtracer/factory.go</code> file and navigate to the <code>createTracesReceiver()</code> function. Notice that the factory will pass references as part of the <code>createTracesReceiver()</code> function parameters that your receiver actually requires to work properly like its configuration settings (<code>component.Config</code>), the next <code>Consumer</code> in the pipeline that will consume the generated traces (<code>consumer.Traces</code>) and the Collector's logger so the <code>tailtracer</code> receiver can add meaningful events to it (<code>receiver.CreateSettings</code>).</p> <p>Given that all this information will be only be made available to the receiver at the moment its instantiated by the factory, The <code>tailtracerReceiver</code> type will need fields to keep that information and use it within other stages of its lifecycle.</p> <p>Here is what the <code>trace-receiver.go</code> file looks like with the updated <code>tailtracerReceiver</code> type declaration:</p> <p>trace-receiver.go</p> <pre><code>package tailtracer\nimport (\n\"context\"\n\"time\"\n\"go.opentelemetry.io/collector/component\"\n\"go.opentelemetry.io/collector/consumer\"\n\"go.uber.org/zap\"\n)\ntype tailtracerReceiver struct {\nhost         component.Host\ncancel       context.CancelFunc\nlogger       *zap.Logger\nnextConsumer consumer.Traces\nconfig       *Config\n}\nfunc (tailtracerRcvr *tailtracerReceiver) Start(ctx context.Context, host component.Host) error {\ntailtracerRcvr.host = host\nctx = context.Background()\nctx, tailtracerRcvr.cancel = context.WithCancel(ctx)\ninterval, _ := time.ParseDuration(tailtracerRcvr.config.Interval)\ngo func() {\nticker := time.NewTicker(interval)\ndefer ticker.Stop()\nfor {\nselect {\ncase &lt;-ticker.C:\ntailtracerRcvr.logger.Info(\"I should start processing traces now!\")\ncase &lt;-ctx.Done():\nreturn\n}\n}\n}()\nreturn nil\n}\nfunc (tailtracerRcvr *tailtracerReceiver) Shutdown(ctx context.Context) error {\ntailtracerRcvr.cancel()\nreturn nil\n}\n</code></pre> <p>The <code>tailtracerReceiver</code> type is now ready to be instantiated and keep all meaningful information passed by its factory.</p> <p>Open the <code>tailtracer/factory.go</code> file and navigate to the <code>createTracesReceiver()</code> function.</p> <p>The receiver is only instantiated if it's declared as a component within a pipeline and the factory is responsible to make sure the next consumer (either a processor or exporter) in the pipeline is valid otherwise it should generate an error.</p> <p>The Collector's API provides some standard error types to help the factory handle pipeline configurations. Your receiver factory should throw a <code>component.ErrNilNextConsumer</code> in case the next consumer has an issue and is passed as nil.</p> <p>The <code>createTracesReceiver()</code> function will need a guard clause to make that validation.</p> <p>You will also need variables to properly initialize the <code>config</code> and the <code>logger</code> fields of the <code>tailtracerReceiver</code> instance.</p> <p>Here is what the <code>factory.go</code> file looks like with the updated <code>createTracesReceiver()</code> function:</p> <p>factory.go</p> <pre><code>package tailtracer\nimport (\n\"context\"\n\"time\"\n\"go.opentelemetry.io/collector/component\"\n\"go.opentelemetry.io/collector/consumer\"\n\"go.opentelemetry.io/collector/receiver\"\n)\nconst (\ntypeStr = \"tailtracer\"\ndefaultInterval = 1 * time.Minute\n)\nfunc createDefaultConfig() component.Config {\nreturn &amp;Config{\nInterval: string(defaultInterval),\n}\n}\nfunc createTracesReceiver(_ context.Context, params receiver.CreateSettings, baseCfg component.Config, consumer consumer.Traces) (receiver.Traces, error) {\nif consumer == nil {\nreturn nil, component.ErrNilNextConsumer\n}\nlogger := params.Logger\ntailtracerCfg := baseCfg.(*Config)\ntraceRcvr := &amp;tailtracerReceiver{\nlogger:       logger,\nnextConsumer: consumer,\nconfig:       tailtracerCfg,\n}\nreturn traceRcvr, nil\n}\n// NewFactory creates a factory for tailtracer receiver.\nfunc NewFactory() receiver.Factory {\nreturn receiver.NewFactory(\ntypeStr,\ncreateDefaultConfig,\nreceiver.WithTraces(createTracesReceiver, component.StabilityLevelAlpha))\n}\n</code></pre> <p>With the factory fully implemented and instantiating the trace receiver component you are ready to test the receiver as part of a pipeline. Go ahead and add the <code>tailtracer</code> receiver to your <code>traces</code> pipeline in the <code>config.yaml</code> as follow:</p> <pre><code>service:\npipelines:\ntraces:\nreceivers: [otlp, tailtracer]\nprocessors: []\nexporters: [jaeger, logging]\n</code></pre> <p>Here is what the output for running your Collector with <code>otelcol-dev</code> command should look like after you updated the <code>traces</code> pipeline:</p> <pre><code>$ ./otelcol-dev --config config.yaml\n2022-03-03T11:19:50.779-0600    info    service/collector.go:190        Applying configuration...\n2022-03-03T11:19:50.780-0600    info    builder/exporters_builder.go:254        Exporter was built.     {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-03-03T11:19:50.780-0600    info    builder/exporters_builder.go:254        Exporter was built.     {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-03-03T11:19:50.780-0600    info    builder/pipelines_builder.go:222        Pipeline was built.     {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-03T11:19:50.780-0600    info    builder/receivers_builder.go:224        Receiver was built.     {\"kind\": \"receiver\", \"name\": \"otlp\", \"datatype\": \"traces\"}\n2022-03-03T11:19:50.780-0600    info    builder/receivers_builder.go:224        Receiver was built.     {\"kind\": \"receiver\", \"name\": \"tailtracer\", \"datatype\": \"traces\"}\n2022-03-03T11:19:50.780-0600    info    service/service.go:86   Starting extensions...\n2022-03-03T11:19:50.780-0600    info    service/service.go:91   Starting exporters...\n2022-03-03T11:19:50.780-0600    info    builder/exporters_builder.go:40 Exporter is starting... {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-03-03T11:19:50.781-0600    info    builder/exporters_builder.go:48 Exporter started.       {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-03-03T11:19:50.781-0600    info    jaegerexporter@v0.41.0/exporter.go:186  State of the connection with the Jaeger Collector backend       {\"kind\": \"exporter\", \"name\": \"jaeger\", \"state\": \"IDLE\"}\n2022-03-03T11:19:50.781-0600    info    builder/exporters_builder.go:40 Exporter is starting... {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-03-03T11:19:50.781-0600    info    builder/exporters_builder.go:48 Exporter started.       {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-03-03T11:19:50.781-0600    info    service/service.go:96   Starting processors...\n2022-03-03T11:19:50.781-0600    info    builder/pipelines_builder.go:54 Pipeline is starting... {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-03T11:19:50.781-0600    info    builder/pipelines_builder.go:65 Pipeline is started.    {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-03T11:19:50.781-0600    info    service/service.go:101  Starting receivers...\n2022-03-03T11:19:50.781-0600    info    builder/receivers_builder.go:68 Receiver is starting... {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-03-03T11:19:50.781-0600    info    otlpreceiver/otlp.go:69 Starting GRPC server on endpoint localhost:55680        {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-03-03T11:19:50.783-0600    info    builder/receivers_builder.go:73 Receiver started.       {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-03-03T11:19:50.783-0600    info    builder/receivers_builder.go:68 Receiver is starting... {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-03T11:19:50.783-0600    info    builder/receivers_builder.go:73 Receiver started.       {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-03T11:19:50.783-0600    info    service/telemetry.go:92 Setting up own telemetry...\n2022-03-03T11:19:50.788-0600    info    service/telemetry.go:116        Serving Prometheus metrics      {\"address\": \":8888\", \"level\": \"basic\", \"service.instance.id\": \"0ca4907c-6fda-4fe1-b0e9-b73d789354a4\", \"service.version\": \"latest\"}\n2022-03-03T11:19:50.788-0600    info    service/collector.go:239        Starting otelcol-dev... {\"Version\": \"1.0.0\", \"NumCPU\": 12}\n2022-03-03T11:19:50.788-0600    info    service/collector.go:135        Everything is ready. Begin running and processing data.\n2022-03-21T15:19:51.717-0500    info    jaegerexporter@v0.46.0/exporter.go:186  State of the connection with the Jaeger Collector backend   {\"kind\": \"exporter\", \"name\": \"jaeger\", \"state\": \"READY\"}\n2022-03-03T11:20:51.783-0600    info    tailtracer/trace-receiver.go:23  I should start processing traces now!   {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n</code></pre> <p>Look for the log line for \"builder/receivers_builder.go:68 Receiver is starting... {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\", you can see that the Collector found the settings for the <code>tailtracer</code> receiver within the <code>traces</code> pipeline and is now instantiating it and starting it given that 1 minute after the Collector has started, you can see the info line we added to the <code>ticker</code> function within the <code>Start()</code> method.</p> <p>Now, go ahead and press Ctrl + C in your Collector's terminal so you want watch the shutdown process happening. Here is what the output should look like:</p> <pre><code>^C2022-03-03T11:20:14.652-0600  info    service/collector.go:166        Received signal from OS {\"signal\": \"interrupt\"}\n2022-03-03T11:20:14.652-0600    info    service/collector.go:255        Starting shutdown...\n2022-03-03T11:20:14.652-0600    info    service/service.go:121  Stopping receivers...\n2022-03-03T11:20:14.653-0600    info    tailtracer/trace-receiver.go:29  I am done and ready to shutdown!        {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-03T11:20:14.653-0600    info    service/service.go:126  Stopping processors...\n2022-03-03T11:20:14.653-0600    info    builder/pipelines_builder.go:73 Pipeline is shutting down...    {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-03T11:20:14.653-0600    info    builder/pipelines_builder.go:77 Pipeline is shutdown.   {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-03T11:20:14.653-0600    info    service/service.go:131  Stopping exporters...\n2022-03-03T11:20:14.653-0600    info    service/service.go:136  Stopping extensions...\n2022-03-03T11:20:14.653-0600    info    service/collector.go:273        Shutdown complete.\n</code></pre> <p>As you can see there is an info log line for the <code>tailtracer</code> receiver which means the component is responding correctly to the <code>Shutdown()</code> event. In the next section you will learn more about the OpenTelemetry Trace data model so the <code>tailtracer</code> receiver can finally generate traces!</p>"},{"location":"docs/collector/trace-receiver/#check-your-work_7","title":"Check your work","text":"<ul> <li>Importing the <code>go.opentelemetry.io/collector/consumer</code> which is where the   pipeline's consumer types and interfaces are declared.</li> <li>Importing the <code>go.uber.org/zap</code> package, which is what the Collector uses   for its logging capabilities.</li> <li>Added a <code>zap.Logger</code> field named <code>logger</code> so we can have access to the   Collector's logger reference from within the receiver.</li> <li>Added a <code>consumer.Traces</code> field named <code>nextConsumer</code> so we can push the   traces generated by the <code>tailtracer</code> receiver to the next consumer declared   in the Collector's pipeline.</li> <li>Added a <code>Config</code> field named <code>config</code> so we can have access to receiver's   configuration settings defined within the Collector's config.</li> <li>Added a variable named <code>interval</code> that will be initialized as a   <code>time.Duration</code> based on the value of the <code>interval</code> settings of the   <code>tailtracer</code> receiver defined within the Collector's config.</li> <li>Added a <code>go func()</code> to implement the <code>ticker</code> mechanism so our receiver can   generate traces every time the <code>ticker</code> reaches the amount of time specified   by the <code>interval</code> variable and used the <code>tailtracerRcvr.logger</code> field to   generate a info message every time the receiver supposed to be generating   traces.</li> </ul>"},{"location":"docs/collector/trace-receiver/#check-your-work_8","title":"Check your work","text":"<ul> <li>Added a guard clause that verifies if the consumer is properly instantiated   and if not returns the <code>component.ErrNilNextConsumer</code>error.</li> <li>Added a variable called <code>logger</code> and initialized it with the Collector's   logger that is available as a field named <code>Logger</code> within the   <code>receiver.CreateSettings</code> reference.</li> <li>Added a variable called <code>tailtracerCfg</code> and initialized it by casting the   <code>component.Config</code> reference to the <code>tailtracer</code> receiver <code>Config</code>.</li> <li>Added a variable called <code>traceRcvr</code> and initialized it with the   <code>tailtracerReceiver</code> instance using the factory information stored within   the variables.</li> <li>Updated the return statement to now include the <code>traceRcvr</code> instance.</li> </ul>"},{"location":"docs/collector/trace-receiver/#the-collectors-trace-data-model","title":"The Collector's Trace Data Model","text":"<p>You might be familiar with OpenTelemetry traces by using the SDKs and instrumenting an application so you can see and evaluate your traces within a distributed tracing backend like Jaeger.</p> <p>Here is what a trace looks like in Jaeger:</p> <p></p> <p>Granted, this is a Jaeger trace, but it was generated by a trace pipeline within the Collector, therefore you can use it to learn a few things about the OTel trace data model :</p> <ul> <li>A trace is made of one or multiple spans structured within a hierarchy to   represent dependencies.</li> <li>The spans can represent operations within a service and/or across services.</li> </ul> <p>Creating a trace within the trace receiver will be slightly different than the way you would do it with the SDKs, so let's start reviewing the high level concepts.</p>"},{"location":"docs/collector/trace-receiver/#working-with-resources","title":"Working with Resources","text":"<p>In the OTel world, all telemetry is generated by a <code>Resource</code>, here is the definition according to the OTel spec:</p> <p>A <code>Resource</code> is an immutable representation of the entity producing telemetry as Attributes. For example, a process producing telemetry that is running in a container on Kubernetes has a Pod name, it is in a namespace and possibly is part of a Deployment which also has a name. All three of these attributes can be included in the <code>Resource</code>.</p> <p>Traces are most commonly used to represent a service request (the Services entity described by Jaeger's model), which are normally implemented as processes running in a compute unit, but OTel's API approach to describe a <code>Resource</code> through attributes is flexible enough to represent any entity that you may require like ATMs, IoT sensors, the sky is the limit.</p> <p>So it's safe to say that for a trace to exist, a <code>Resource</code> will have to start it.</p> <p>In this tutorial we will simulate a system that has telemetry that demonstrate ATMs located in 2 different states (eg: Illinois and California) accessing the Account's backend system to execute balance, deposit and withdraw operations, therefore we will have to implement code to create the <code>Resource</code> types representing the ATM and the backend system.</p> <p>Go ahead and create a file named <code>model.go</code> inside the <code>tailtracer</code> folder</p> <pre><code>cd tailtracer\ntouch model.go\n</code></pre> <p>Now, within the <code>model.go</code> file, add the definition for the <code>Atm</code> and the <code>BackendSystem</code> types as follow:</p> <p>model.go</p> <pre><code>package tailtracer\ntype Atm struct{\nID           int64\nVersion      string\nName         string\nStateID      string\nSerialNumber string\nISPNetwork   string\n}\ntype BackendSystem struct{\nVersion       string\nProcessName   string\nOSType        string\nOSVersion     string\nCloudProvider string\nCloudRegion   string\nServiceName   string\nEndpoint      string\n}\n</code></pre> <p>These types are meant to represent the entities as they are within the system being observed and they contain information that would be quite meaningful to be added to the traces as part of the <code>Resource</code> definition. You will add some helper functions to generate the instances of those types.</p> <p>Here is what the <code>model.go</code> file will look with the helper functions:</p> <p>model.go</p> <pre><code>package tailtracer\nimport (\n\"math/rand\"\n\"time\"\n)\ntype Atm struct{\nID           int64\nVersion      string\nName         string\nStateID      string\nSerialNumber string\nISPNetwork   string\n}\ntype BackendSystem struct{\nVersion       string\nProcessName   string\nOSType        string\nOSVersion     string\nCloudProvider string\nCloudRegion   string\nEndpoint      string\n}\nfunc generateAtm() Atm{\ni := getRandomNumber(1, 2)\nvar newAtm Atm\nswitch i {\ncase 1:\nnewAtm = Atm{\nID: 111,\nName: \"ATM-111-IL\",\nSerialNumber: \"atmxph-2022-111\",\nVersion: \"v1.0\",\nISPNetwork: \"comcast-chicago\",\nStateID: \"IL\",\n}\ncase 2:\nnewAtm = Atm{\nID: 222,\nName: \"ATM-222-CA\",\nSerialNumber: \"atmxph-2022-222\",\nVersion: \"v1.0\",\nISPNetwork: \"comcast-sanfrancisco\",\nStateID: \"CA\",\n}\n}\nreturn newAtm\n}\nfunc generateBackendSystem() BackendSystem{\ni := getRandomNumber(1, 3)\nnewBackend := BackendSystem{\nProcessName: \"accounts\",\nVersion: \"v2.5\",\nOSType: \"lnx\",\nOSVersion: \"4.16.10-300.fc28.x86_64\",\nCloudProvider: \"amzn\",\nCloudRegion: \"us-east-2\",\n}\nswitch i {\ncase 1:\nnewBackend.Endpoint = \"api/v2.5/balance\"\ncase 2:\nnewBackend.Endpoint = \"api/v2.5/deposit\"\ncase 3:\nnewBackend.Endpoint = \"api/v2.5/withdrawn\"\n}\nreturn newBackend\n}\nfunc getRandomNumber(min int, max int) int {\nrand.Seed(time.Now().UnixNano())\ni := (rand.Intn(max - min + 1) + min)\nreturn i\n}\n</code></pre> <p>Now that you have the functions to generate object instances representing the entities generating telemetry, you are ready to represent those entities in the OTel Collector world.</p> <p>The Collector's API provides a package named <code>ptrace</code> (nested under the <code>pdata</code> package) with all the types, interfaces and helper functions required to work with traces within the Collector's pipeline components.</p> <p>Open the <code>tailtracer/model.go</code> file and add <code>go.opentelemetry.io/collector/pdata/ptrace</code> to the <code>import</code> clause so you can have access to the <code>ptrace</code> package capabilities.</p> <p>Before you can define a <code>Resource</code>, you need to create a <code>ptrace.Traces</code> that will be responsible to propagate the traces through the Collector's pipeline and you can use the helper function <code>ptrace.NewTraces()</code> to instantiate it. You will also need to create instances of the <code>Atm</code> and <code>BackendSystem</code> types so you can have data to represent the telemetry sources involved in your trace.</p> <p>Open the <code>tailtracer/model.go</code> file and add the following function to it:</p> <pre><code>func generateTraces(numberOfTraces int) ptrace.Traces{\ntraces := ptrace.NewTraces()\nfor i := 0; i &lt;= numberOfTraces; i++{\nnewAtm := generateAtm()\nnewBackendSystem := generateBackendSystem()\n}\nreturn traces\n}\n</code></pre> <p>By now you have heard and read enough about how traces are made up of Spans. You have probably also written some instrumentation code using the SDK's functions and types available to create them, but what you probably didn't know, is that within the Collector's API, that there are other types of \"spans\" involved in creating a trace.</p> <p>You will start with a type called <code>ptrace.ResourceSpans</code> which represents the resource and all the operations that it either originated or received while participating in a trace. You can find its definition within the /pdata/internal/data/protogen/trace/v1/trace.pb.go.</p> <p><code>ptrace.Traces</code> has a method named <code>ResourceSpans()</code> which returns an instance of a helper type called <code>ptrace.ResourceSpansSlice</code>. The <code>ptrace.ResourceSpansSlice</code> type has methods to help you handle the array of <code>ptrace.ResourceSpans</code> that will contain as many items as the number of <code>Resource</code> entities participating in the request represented by the trace.</p> <p><code>ptrace.ResourceSpansSlice</code> has a method named <code>AppendEmpty()</code> that adds a new <code>ptrace.ResourceSpan</code> to the array and return its reference.</p> <p>Once you have an instance of a <code>ptrace.ResourceSpan</code> you will use a method named <code>Resource()</code> which will return the instance of the <code>pcommon.Resource</code> associated with the <code>ResourceSpan</code>.</p> <p>Update the <code>generateTrace()</code> function with the following changes:</p> <ul> <li>add a variable named <code>resourceSpan</code> to represent the <code>ResourceSpan</code></li> <li>add a variable named <code>atmResource</code> to represent the <code>pcommon.Resource</code>   associated with the <code>ResourceSpan</code>.</li> <li>Use the methods mentioned above to initialize both variables respectively.</li> </ul> <p>Here is what the function should look like after you implemented these changes:</p> <pre><code>func generateTraces(numberOfTraces int) ptrace.Traces{\ntraces := ptrace.NewTraces()\nfor i := 0; i &lt;= numberOfTraces; i++{\nnewAtm := generateAtm()\nnewBackendSystem := generateBackendSystem()\nresourceSpan := traces.ResourceSpans().AppendEmpty()\natmResource := resourceSpan.Resource()\n}\nreturn traces\n}\n</code></pre>"},{"location":"docs/collector/trace-receiver/#check-your-work_9","title":"Check your work","text":"<ul> <li>Imported the <code>math/rand</code> and <code>time</code> packages to support the implementation   of the <code>generateRandomNumber</code> function</li> <li>Added the <code>generateAtm</code> function that instantiates an <code>Atm</code> type and   randomly assign either Illinois or California as values for <code>StateID</code> and   the equivalent value for <code>ISPNetwork</code></li> <li>Added the <code>generateBackendSystem</code> function that instantiates a   <code>BackendSystem</code>type and randomly assign service endpoint values for the   <code>Endpoint</code> field</li> <li>Added the <code>generateRandomNumber</code> function to help generating random numbers   between a desired range.</li> </ul>"},{"location":"docs/collector/trace-receiver/#check-your-work_10","title":"Check your work","text":"<ul> <li>Added the <code>resourceSpan</code> variable and initialized it with the <code>ResourceSpan</code>   reference returned by the <code>traces.ResourceSpans().AppendEmpty()</code> call</li> <li>Added the <code>atmResource</code> variable and initialized it with the   <code>pcommon.Resource</code> reference returned by the <code>resourceSpan.Resource()</code> call</li> </ul>"},{"location":"docs/collector/trace-receiver/#describing-resources-through-attributes","title":"Describing Resources through attributes","text":"<p>The Collector's API provides a package named <code>pcommon</code> (nested under the <code>pdata</code> package) with all the types and helper functions required to describe a <code>Resource</code>.</p> <p>In the Collector's world, a <code>Resource</code> is described by attributes in a key/value pair format represented by the <code>pcommon.Map</code> type.</p> <p>You can check the definition of the <code>pcommon.Map</code> type and the related helper functions to create attribute values using the supported formats in the /pdata/pcommon/common.go file within the Otel Collector's GitHub project.</p> <p>Key/value pairs provide a lot of flexibility to help model your <code>Resource</code> data, so the OTel specification has some guidelines in place to help organize and minimize the conflicts across all the different types of telemetry generation entities that it may need to represent.</p> <p>These guidelines are known as Resource Semantic Conventions and are documented in the OTel specification.</p> <p>When creating your own attributes to represent your own telemetry generation entities, you should follow the guideline provided by the specification:</p> <p>Attributes are grouped logically by the type of the concept that they described. Attributes in the same group have a common prefix that ends with a dot. For example all attributes that describe Kubernetes properties start with <code>k8s.</code></p> <p>Let's start by opening the <code>tailtracer/model.go</code> and adding <code>go.opentelemetry.io/collector/pdata/pcommon</code> to the <code>import</code> clause so you can have access to the <code>pcommon</code> package capabilities.</p> <p>Now go ahead and add a function to read the field values from an <code>Atm</code> instance and write them as attributes (grouped by the prefix \"atm.\") into a <code>pcommon.Resource</code> instance. Here is what the function looks like:</p> <pre><code>func fillResourceWithAtm(resource *pcommon.Resource, atm Atm){\natmAttrs := resource.Attributes()\natmAttrs.PutInt(\"atm.id\", atm.ID)\natmAttrs.PutStr(\"atm.stateid\", atm.StateID)\natmAttrs.PutStr(\"atm.ispnetwork\", atm.ISPNetwork)\natmAttrs.PutStr(\"atm.serialnumber\", atm.SerialNumber)\n}\n</code></pre> <p>The resource semantic conventions also have prescriptive attribute names and well-known values to represent telemetry generation entities that are common and applicable across different domains like compute unit, environment and others.</p> <p>So, when you look at the <code>BackendSystem</code> entity, it has fields representing OS related information and Cloud related information, and we will use the attribute names and values prescribed by the resource semantic convention to represent that information on its <code>Resource</code>.</p> <p>All the resource semantic convention attribute names and well known-values are kept within the /semconv/v1.9.0/generated_resource.go file within the Collector's GitHub project.</p> <p>Let's create a function to read the field values from an <code>BackendSystem</code> instance and write them as attributes into a <code>pcommon.Resource</code> instance. Open the <code>tailtracer/model.go</code> file and add the following function:</p> <pre><code>func fillResourceWithBackendSystem(resource *pcommon.Resource, backend BackendSystem){\nbackendAttrs := resource.Attributes()\nvar osType, cloudProvider string\nswitch {\ncase backend.CloudProvider == \"amzn\":\ncloudProvider = conventions.AttributeCloudProviderAWS\ncase backend.OSType == \"mcrsft\":\ncloudProvider = conventions.AttributeCloudProviderAzure\ncase backend.OSType == \"gogl\":\ncloudProvider = conventions.AttributeCloudProviderGCP\n}\nbackendAttrs.PutStr(conventions.AttributeCloudProvider, cloudProvider)\nbackendAttrs.PutStr(conventions.AttributeCloudRegion, backend.CloudRegion)\nswitch {\ncase backend.OSType == \"lnx\":\nosType = conventions.AttributeOSTypeLinux\ncase backend.OSType == \"wndws\":\nosType = conventions.AttributeOSTypeWindows\ncase backend.OSType == \"slrs\":\nosType = conventions.AttributeOSTypeSolaris\n}\nbackendAttrs.PutStr(conventions.AttributeOSType, osType)\nbackendAttrs.PutStr(conventions.AttributeOSVersion, backend.OSVersion)\n}\n</code></pre> <p>Notice that I didn't add an attribute named \"atm.name\" or \"backendsystem.name\" to the <code>pcommon.Resource</code> representing the <code>Atm</code> and <code>BackendSystem</code> entity names, that's because most (not to say all) distributed tracing backend systems that are compatible with the OTel trace specification, interpret the <code>pcommon.Resource</code> described in a trace as a <code>Service</code>, therefore they expect the <code>pcommon.Resource</code> to carry a required attribute named <code>service.name</code> as prescribed by the resource semantic convention.</p> <p>We will also use non-required attribute named <code>service.version</code> to represent the version information for both <code>Atm</code> and <code>BackendSystem</code> entities.</p> <p>Here is what the <code>tailtracer/model.go</code> file looks like after adding the code for properly assign the \"service.\" group attributes:</p> <p>model.go</p> <pre><code>package tailtracer\nimport (\n\"math/rand\"\n\"time\"\n\"go.opentelemetry.io/collector/pdata/pcommon\"\n\"go.opentelemetry.io/collector/pdata/ptrace\"\nconventions \"go.opentelemetry.io/collector/semconv/v1.9.0\"\"\n)\ntype Atm struct {\n    ID           int64\n    Version      string\n    Name         string\n    StateID      string\n    SerialNumber string\n    ISPNetwork   string\n}\ntype BackendSystem struct {\n    Version       string\n    ProcessName   string\n    OSType        string\n    OSVersion     string\n    CloudProvider string\n    CloudRegion   string\n    Endpoint      string\n}\nfunc generateAtm() Atm {\n    i := getRandomNumber(1, 2)\n    var newAtm Atm\n    switch i {\n        case 1:\n            newAtm = Atm{\n                ID:           111,\n                Name:         \"ATM-111-IL\",\n                SerialNumber: \"atmxph-2022-111\",\n                Version:      \"v1.0\",\n                ISPNetwork:   \"comcast-chicago\",\n                StateID:      \"IL\",\n            }\n        case 2:\n            newAtm = Atm{\n                ID:           222,\n                Name:         \"ATM-222-CA\",\n                SerialNumber: \"atmxph-2022-222\",\n                Version:      \"v1.0\",\n                ISPNetwork:   \"comcast-sanfrancisco\",\n                StateID:      \"CA\",\n            }\n    }\n    return newAtm\n}\nfunc generateBackendSystem() BackendSystem {\n    i := getRandomNumber(1, 3)\n    newBackend := BackendSystem{\n        ProcessName:   \"accounts\",\n        Version:       \"v2.5\",\n        OSType:        \"lnx\",\n        OSVersion:     \"4.16.10-300.fc28.x86_64\",\n        CloudProvider: \"amzn\",\n        CloudRegion:   \"us-east-2\",\n    }\n    switch i {\n        case 1:\n            newBackend.Endpoint = \"api/v2.5/balance\"\n        case 2:\n            newBackend.Endpoint = \"api/v2.5/deposit\"\n        case 3:\n            newBackend.Endpoint = \"api/v2.5/withdrawn\"\n    }\n    return newBackend\n}\nfunc getRandomNumber(min int, max int) int {\n    rand.Seed(time.Now().UnixNano())\n    i := (rand.Intn(max-min+1) + min)\n    return i\n}\nfunc generateTraces(numberOfTraces int) ptrace.Traces {\n    traces := ptrace.NewTraces()\n    for i := 0; i &lt;= numberOfTraces; i++ {\n        newAtm := generateAtm()\n        newBackendSystem := generateBackendSystem()\n        resourceSpan := traces.ResourceSpans().AppendEmpty()\n        atmResource := resourceSpan.Resource()\n        fillResourceWithAtm(&amp;atmResource, newAtm)\n        resourceSpan = traces.ResourceSpans().AppendEmpty()\n        backendResource := resourceSpan.Resource()\n        fillResourceWithBackendSystem(&amp;backendResource, newBackendSystem)\n    }\n    return traces\n}\nfunc fillResourceWithAtm(resource *pcommon.Resource, atm Atm) {\n    atmAttrs := resource.Attributes()\n    atmAttrs.PutInt(\"atm.id\", atm.ID)\n    atmAttrs.PutStr(\"atm.stateid\", atm.StateID)\n    atmAttrs.PutStr(\"atm.ispnetwork\", atm.ISPNetwork)\n    atmAttrs.PutStr(\"atm.serialnumber\", atm.SerialNumber)\n    atmAttrs.PutStr(conventions.AttributeServiceName, atm.Name)\n    atmAttrs.PutStr(conventions.AttributeServiceVersion, atm.Version)\n}\nfunc fillResourceWithBackendSystem(resource *pcommon.Resource, backend BackendSystem) {\n    backendAttrs := resource.Attributes()\n    var osType, cloudProvider string\n    switch {\n        case backend.CloudProvider == \"amzn\":\n            cloudProvider = conventions.AttributeCloudProviderAWS\n        case backend.OSType == \"mcrsft\":\n            cloudProvider = conventions.AttributeCloudProviderAzure\n        case backend.OSType == \"gogl\":\n            cloudProvider = conventions.AttributeCloudProviderGCP\n    }\n    backendAttrs.PutStr(conventions.AttributeCloudProvider, cloudProvider)\n    backendAttrs.PutStr(conventions.AttributeCloudRegion, backend.CloudRegion)\n    switch {\n        case backend.OSType == \"lnx\":\n            osType = conventions.AttributeOSTypeLinux\n        case backend.OSType == \"wndws\":\n            osType = conventions.AttributeOSTypeWindows\n        case backend.OSType == \"slrs\":\nosType = conventions.AttributeOSTypeSolaris\n}\nbackendAttrs.PutStr(conventions.AttributeOSType, osType)\nbackendAttrs.PutStr(conventions.AttributeOSVersion, backend.OSVersion)\nbackendAttrs.PutStr(conventions.AttributeServiceName, backend.ProcessName)\nbackendAttrs.PutStr(conventions.AttributeServiceVersion, backend.Version)\n}\n</code></pre>"},{"location":"docs/collector/trace-receiver/#check-your-work_11","title":"Check your work","text":"<ul> <li>Declared a variable called <code>atmAttrs</code> and initialized it with the   <code>pcommon.Map</code> reference returned by the <code>resource.Attributes()</code> call</li> <li>Used the <code>PutInt()</code> and <code>PutStr()</code> methods from <code>pcommon.Map</code> to add int and   string attributes based on the equivalent <code>Atm</code> field types. Notice that   because those attributes are very specific and only represent the <code>Atm</code>   entity, they are all grouped within the \"atm.\" prefix.</li> </ul>"},{"location":"docs/collector/trace-receiver/#check-your-work_12","title":"Check your work","text":"<ul> <li>Imported the <code>go.opentelemetry.io/collector/semconv/v1.9.0</code> package as   <code>conventions</code>, in order to have access to all resource semantic conventions   attribute names and values.</li> <li>Updated the <code>fillResourceWithAtm()</code> function by adding lines to properly   assign the \"service.name\" and \"service.version\" attributes to the   <code>pcommon.Resource</code> representing the <code>Atm</code> entity</li> <li>Updated the <code>fillResourceWithBackendSystem()</code> function by adding lines to   properly assign the \"service.name\" and \"service.version\" attributes to the   <code>pcommon.Resource</code> representing the <code>BackendSystem</code> entity</li> <li>Updated the <code>generateTraces</code> function by adding lines to properly   instantiate a <code>pcommon.Resource</code> and fill in the attribute information for   both <code>Atm</code> and <code>BackendSystem</code> entities using the <code>fillResourceWithAtm()</code>   and <code>fillResourceWithBackendSystem()</code> functions</li> </ul>"},{"location":"docs/collector/trace-receiver/#representing-operations-with-spans","title":"Representing operations with spans","text":"<p>You now have a <code>ResourceSpan</code> instance with their respective <code>Resource</code> properly filled with attributes to represent the <code>Atm</code> and <code>BackendSystem</code> entities, you are ready to represent the operations that each <code>Resource</code> execute as part of a trace within the <code>ResourceSpan</code>.</p> <p>In the OTel world, in order for a system to generate telemetry, it needs to be instrumented either manually or automatically through an instrumentation library.</p> <p>The instrumentation libraries are responsible to set the scope (also known as the instrumentation scope) in which the operations participating on a trace happened and then describe those operations as spans within the context of the trace.</p> <p><code>pdata.ResourceSpans</code> has a method named <code>ScopeSpans()</code> which returns an instance of a helper type called <code>ptrace.ScopeSpansSlice</code>. The <code>ptrace.ScopeSpansSlice</code> type has methods to help you handle the array of <code>ptrace.ScopeSpans</code> that will contain as many items as the number of <code>ptrace.ScopeSpan</code> representing the different instrumentation scopes and the spans it generated within the context of a trace.</p> <p><code>ptrace.ScopeSpansSlice</code> has a method named <code>AppendEmpty()</code> that adds a new <code>ptrace.ScopeSpans</code> to the array and return its reference.</p> <p>Let's create a function to instantiate a <code>ptrace.ScopeSpans</code> representing for the ATM system's instrumentation scope and its spans. Open the <code>tailtracer/model.go</code> file and add the following function:</p> <pre><code> func appendAtmSystemInstrScopeSpans(resourceSpans *ptrace.ResourceSpans) (ptrace.ScopeSpans){\nscopeSpans := resourceSpans.ScopeSpans().AppendEmpty()\nreturn scopeSpans\n}\n</code></pre> <p>The <code>ptrace.ScopeSpans</code> has a method named <code>Scope()</code> that returns a reference for the <code>pcommon.InstrumentationScope</code> instance representing the instrumentation scope that generated the spans.</p> <p><code>pcommon.InstrumentationScope</code> has the following methods to describe an instrumentation scope:</p> <ul> <li> <p><code>SetName(v string)</code> sets the name for the instrumentation library</p> </li> <li> <p><code>SetVersion(v string)</code> sets the version for the instrumentation library</p> </li> <li> <p><code>Name() string</code> returns the name associated with the instrumentation library</p> </li> <li> <p><code>Version() string</code> returns the version associated with the instrumentation   library</p> </li> </ul> <p>Let's update the <code>appendAtmSystemInstrScopeSpans</code> function so we can set the name and version of the instrumentation scope for the new <code>ptrace.ScopeSpans</code>. Here is what <code>appendAtmSystemInstrScopeSpans</code> looks like after the update:</p> <pre><code> func appendAtmSystemInstrScopeSpans(resourceSpans *ptrace.ResourceSpans) (ptrace.ScopeSpans){\nscopeSpans := resourceSpans.ScopeSpans().AppendEmpty()\nscopeSpans.Scope().SetName(\"atm-system\")\nscopeSpans.Scope().SetVersion(\"v1.0\")\nreturn scopeSpans\n}\n</code></pre> <p>You can now update the <code>generateTraces</code> function and add variables to represent the instrumentation scope used by both <code>Atm</code> and <code>BackendSystem</code> entities by initializing them with the <code>appendAtmSystemInstrScopeSpans()</code>. Here is what <code>generateTraces()</code> looks like after the update:</p> <pre><code>func generateTraces(numberOfTraces int) ptrace.Traces{\ntraces := ptraces.NewTraces()\nfor i := 0; i &lt;= numberOfTraces; i++{\nnewAtm := generateAtm()\nnewBackendSystem := generateBackendSystem()\nresourceSpan := traces.ResourceSpans().AppendEmpty()\natmResource := resourceSpan.Resource()\nfillResourceWithAtm(&amp;atmResource, newAtm)\natmInstScope := appendAtmSystemInstrScopeSpans(&amp;resourceSpan)\nresourceSpan = traces.ResourceSpans().AppendEmpty()\nbackendResource := resourceSpan.Resource()\nfillResourceWithBackendSystem(&amp;backendResource, newBackendSystem)\nbackendInstScope := appendAtmSystemInstrScopeSpans(&amp;resourceSpan)\n}\nreturn traces\n}\n</code></pre> <p>At this point, you have everything needed to represent the telemetry generation entities in your system and the instrumentation scope that is responsible to identify operations and generate the traces for the system. The next step is to finally create the spans representing the operations that the given instrumentation scope generated as part of a trace.</p> <p><code>ptrace.ScopeSpans</code> has a method named <code>Spans()</code> which returns an instance of a helper type called <code>ptrace.SpanSlice</code>. The <code>ptrace.SpanSlice</code> type has methods to help you handle the array of <code>ptrace.Span</code> that will contain as many items as the number of operations the instrumentation scope was able to identify and describe as part of the trace.</p> <p><code>ptrace.SpanSlice</code> has a method named <code>AppendEmpty()</code> that adds a new <code>ptrace.Span</code> to the array and return its reference.</p> <p><code>ptrace.Span</code> has the following methods to describe an operation:</p> <ul> <li> <p><code>SetTraceID(v pcommon.TraceID)</code> sets the <code>pcommon.TraceID</code> uniquely   identifying the trace which this span is associated with</p> </li> <li> <p><code>SetSpanID(v pcommon.SpanID)</code> sets the <code>pcommon.SpanID</code> uniquely identifying   this span within the context of the trace it is associated with</p> </li> <li> <p><code>SetParentSpanID(v pcommon.SpanID)</code> sets <code>pcommon.SpanID</code> for the parent   span/operation in case the operation represented by this span is executed as   part of the parent (nested)</p> </li> <li> <p><code>SetName(v string)</code> sets the name of the operation for the span</p> </li> <li> <p><code>SetKind(v ptrace.SpanKind)</code> sets <code>ptrace.SpanKind</code> defining what kind of   operation the span represents.</p> </li> <li> <p><code>SetStartTimestamp(v pcommon.Timestamp)</code> sets the <code>pcommon.Timestamp</code>   representing the date and time when the operation represented by the span has   started</p> </li> <li> <p><code>SetEndTimestamp(v pcommon.Timestamp)</code> sets the <code>pcommon.Timestamp</code>   representing the date and time when the operation represented by the span has   ended</p> </li> </ul> <p>As you can see per the methods above, a <code>ptrace.Span</code> is uniquely identified by 2 required IDs; their own unique ID represented by the <code>pcommon.SpanID</code> type and the ID of the trace they are associated with represented by a <code>pcommon.TraceID</code> type.</p> <p>The <code>pcommon.TraceID</code> has to carry a globally unique ID represented through a 16 byte array and should follow the W3C Trace Context specification while the <code>pcommon.SpanID</code> is a unique ID within the context of the trace they are associated with and it's represented through a 8 byte array.</p> <p>The <code>pcommon</code> package provides the following types to generate the span's IDs:</p> <ul> <li> <p><code>type TraceID [16]byte</code></p> </li> <li> <p><code>type SpanID [8]byte</code></p> </li> </ul> <p>For this tutorial, you will be creating the IDs using functions from <code>github.com/google/uuid</code> package for the <code>pcommon.TraceID</code> and functions from the <code>crypto/rand</code> package to randomly generate the <code>pcommon.SpanID</code>. Open the <code>tailtracer/model.go</code> file and add both packages to the <code>import</code> statement; after that, add the following functions to help generate both IDs:</p> <pre><code>func NewTraceID() pcommon.TraceID {\nreturn pcommon.TraceID(uuid.New())\n}\nfunc NewSpanID() pcommon.SpanID {\nvar rngSeed int64\n_ = binary.Read(crand.Reader, binary.LittleEndian, &amp;rngSeed)\nrandSource := rand.New(rand.NewSource(rngSeed))\nvar sid [8]byte\nrandSource.Read(sid[:])\nspanID := pcommon.SpanID(sid)\nreturn spanID\n}\n</code></pre> <p>Now that you have a way to properly identify the spans, you can start creating them to represent the operations within and across the entities in your system.</p> <p>As part of the <code>generateBackendSystem()</code> function, we have randomly assigned the operations that the <code>BackEndSystem</code> entity can provide as services to the system. We will now open the <code>tailtracer/model.go</code> file and a function called <code>appendTraceSpans()</code> that will be responsible to create a trace and append spans representing the <code>BackendSystem</code> operations. Here is what the initial implementation for the <code>appendTraceSpans()</code> function looks like:</p> <pre><code>func appendTraceSpans(backend *BackendSystem, backendScopeSpans *ptrace.ScopeSpans, atmScopeSpans *ptrace.ScopeSpans) {\ntraceId := NewTraceID()\nbackendSpanId := NewSpanID()\nbackendDuration, _ := time.ParseDuration(\"1s\")\nbackendSpanStartTime := time.Now()\nbackendSpanFinishTime := backendSpanStartTime.Add(backendDuration)\nbackendSpan := backendScopeSpans.Spans().AppendEmpty()\nbackendSpan.SetTraceID(traceId)\nbackendSpan.SetSpanID(backendSpanId)\nbackendSpan.SetName(backend.Endpoint)\nbackendSpan.SetKind(ptrace.SpanKindServer)\nbackendSpan.SetStartTimestamp(pcommon.NewTimestampFromTime(backendSpanStartTime))\nbackendSpan.SetEndTimestamp(pcommon.NewTimestampFromTime(backendSpanFinishTime))\n}\n</code></pre> <p>You probably noticed that there are 2 references to <code>ptrace.ScopeSpans</code> as parameters in the <code>appendTraceSpans()</code> function, but we only used one of them. Don't worry about it for now, we will get back to it later.</p> <p>You will now update the <code>generateTraces()</code> function so it can actually generate the trace by calling the <code>appendTraceSpans()</code> function. Here is what the updated <code>generateTraces()</code> function looks like:</p> <pre><code>func generateTraces(numberOfTraces int) ptrace.Traces {\ntraces := ptrace.NewTraces()\nfor i := 0; i &lt;= numberOfTraces; i++ {\nnewAtm := generateAtm()\nnewBackendSystem := generateBackendSystem()\nresourceSpan := traces.ResourceSpans().AppendEmpty()\natmResource := resourceSpan.Resource()\nfillResourceWithAtm(&amp;atmResource, newAtm)\natmInstScope := appendAtmSystemInstrScopeSpans(&amp;resourceSpan)\nresourceSpan = traces.ResourceSpans().AppendEmpty()\nbackendResource := resourceSpan.Resource()\nfillResourceWithBackendSystem(&amp;backendResource, newBackendSystem)\nbackendInstScope := appendAtmSystemInstrScopeSpans(&amp;resourceSpan)\nappendTraceSpans(&amp;newBackendSystem, &amp;backendInstScope, &amp;atmInstScope)\n}\nreturn traces\n}\n</code></pre> <p>You now have the <code>BackendSystem</code> entity and its operations represented in spans within a proper trace context! All you need to do is to push the generated trace through the pipeline so the next consumer (either a processor or an exporter) can receive and process it.</p> <p><code>consumer.Traces</code> has a method called <code>ConsumeTraces()</code> which is responsible to push the generated traces to the next consumer in the pipeline. All you need to do now is to update the <code>Start()</code> method within the <code>tailtracerReceiver</code> type and add the code to use it.</p> <p>Open the <code>tailtracer/trace-receiver.go</code> file and update the <code>Start()</code> method as follow:</p> <pre><code>func (tailtracerRcvr *tailtracerReceiver) Start(ctx context.Context, host component.Host) error {\ntailtracerRcvr.host = host\nctx = context.Background()\nctx, tailtracerRcvr.cancel = context.WithCancel(ctx)\ninterval, _ := time.ParseDuration(tailtracerRcvr.config.Interval)\ngo func() {\nticker := time.NewTicker(interval)\ndefer ticker.Stop()\nfor {\nselect {\ncase &lt;-ticker.C:\ntailtracerRcvr.logger.Info(\"I should start processing traces now!\")\ntailtracerRcvr.nextConsumer.ConsumeTraces(ctx, generateTraces(tailtracerRcvr.config.NumberOfTraces))\ncase &lt;-ctx.Done():\nreturn\n}\n}\n}()\nreturn nil\n}\n</code></pre> <p>If you run your <code>otelcol-dev</code>, here is what the output should look like after 2 minutes running:</p> <pre><code>Starting: /Users/rquedas/go/bin/dlv dap --check-go-version=false --listen=127.0.0.1:54625 --log-dest=3 from /Users/rquedas/Documents/vscode-workspace/otel4devs/collector/receiver/trace-receiver/otelcol-dev\nDAP server listening at: 127.0.0.1:54625\n2022-03-21T15:44:22.737-0500    info    builder/exporters_builder.go:255    Exporter was built. {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-03-21T15:44:22.737-0500    info    builder/exporters_builder.go:255    Exporter was built. {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-03-21T15:44:22.737-0500    info    builder/pipelines_builder.go:223    Pipeline was built. {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-21T15:44:22.738-0500    info    builder/receivers_builder.go:226    Receiver was built. {\"kind\": \"receiver\", \"name\": \"otlp\", \"datatype\": \"traces\"}\n2022-03-21T15:44:22.738-0500    info    builder/receivers_builder.go:226    Receiver was built. {\"kind\": \"receiver\", \"name\": \"tailtracer\", \"datatype\": \"traces\"}\n2022-03-21T15:44:22.738-0500    info    service/service.go:82   Starting extensions...\n2022-03-21T15:44:22.738-0500    info    service/service.go:87   Starting exporters...\n2022-03-21T15:44:22.738-0500    info    builder/exporters_builder.go:40 Exporter is starting... {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-03-21T15:44:22.738-0500    info    builder/exporters_builder.go:48 Exporter started.   {\"kind\": \"exporter\", \"name\": \"logging\"}\n2022-03-21T15:44:22.738-0500    info    builder/exporters_builder.go:40 Exporter is starting... {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-03-21T15:44:22.738-0500    info    builder/exporters_builder.go:48 Exporter started.   {\"kind\": \"exporter\", \"name\": \"jaeger\"}\n2022-03-21T15:44:22.738-0500    info    service/service.go:92   Starting processors...\n2022-03-21T15:44:22.738-0500    info    jaegerexporter@v0.46.0/exporter.go:186  State of the connection with the Jaeger Collector backend   {\"kind\": \"exporter\", \"name\": \"jaeger\", \"state\": \"IDLE\"}\n2022-03-21T15:44:22.738-0500    info    builder/pipelines_builder.go:54 Pipeline is starting... {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-21T15:44:22.738-0500    info    builder/pipelines_builder.go:65 Pipeline is started.    {\"name\": \"pipeline\", \"name\": \"traces\"}\n2022-03-21T15:44:22.738-0500    info    service/service.go:97   Starting receivers...\n2022-03-21T15:44:22.738-0500    info    builder/receivers_builder.go:68 Receiver is starting... {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-03-21T15:44:22.738-0500    info    otlpreceiver/otlp.go:69 Starting GRPC server on endpoint localhost:55680    {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-03-21T15:44:22.741-0500    info    builder/receivers_builder.go:73 Receiver started.   {\"kind\": \"receiver\", \"name\": \"otlp\"}\n2022-03-21T15:44:22.741-0500    info    builder/receivers_builder.go:68 Receiver is starting... {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-21T15:44:22.741-0500    info    builder/receivers_builder.go:73 Receiver started.   {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-21T15:44:22.741-0500    info    service/telemetry.go:109    Setting up own telemetry...\n2022-03-21T15:44:22.741-0500    info    service/telemetry.go:129    Serving Prometheus metrics  {\"address\": \":8888\", \"level\": \"basic\", \"service.instance.id\": \"4b134d3e-2822-4360-b2c6-7030bea0beec\", \"service.version\": \"latest\"}\n2022-03-21T15:44:22.742-0500    info    service/collector.go:248    Starting otelcol-dev... {\"Version\": \"1.0.0\", \"NumCPU\": 12}\n2022-03-21T15:44:22.742-0500    info    service/collector.go:144    Everything is ready. Begin running and processing data.\n2022-03-21T15:44:23.739-0500    info    jaegerexporter@v0.46.0/exporter.go:186  State of the connection with the Jaeger Collector backend   {\"kind\": \"exporter\", \"name\": \"jaeger\", \"state\": \"READY\"}\n2022-03-21T15:45:22.743-0500    info    tailtracer/trace-receiver.go:33 I should start processing traces now!   {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-21T15:45:22.743-0500    INFO    loggingexporter/logging_exporter.go:40  TracesExporter  {\"#spans\": 1}\n2022-03-21T15:45:22.743-0500    DEBUG   loggingexporter/logging_exporter.go:49  ResourceSpans #0\nResource SchemaURL:\nResource labels:\n     -&gt; atm.id: INT(222)\n     -&gt; atm.stateid: STRING(CA)\n     -&gt; atm.ispnetwork: STRING(comcast-sanfrancisco)\n     -&gt; atm.serialnumber: STRING(atmxph-2022-222)\n     -&gt; service.name: STRING(ATM-222-CA)\n     -&gt; service.version: STRING(v1.0)\nScopeSpans #0\nScopeSpans SchemaURL:\nInstrumentationScope atm-system v1.0\nResourceSpans #1\nResource SchemaURL:\nResource labels:\n     -&gt; cloud.provider: STRING(aws)\n     -&gt; cloud.region: STRING(us-east-2)\n     -&gt; os.type: STRING(linux)\n     -&gt; os.version: STRING(4.16.10-300.fc28.x86_64)\n     -&gt; service.name: STRING(accounts)\n     -&gt; service.version: STRING(v2.5)\nScopeSpans #0\nScopeSpans SchemaURL:\nInstrumentationScope atm-system v1.0\nSpan #0\n    Trace ID       : 5cce8a774d4546c2a5cbdeb607ec74c9\n    Parent ID      :\n    ID             : bb25c05c7fb13084\n    Name           : api/v2.5/balance\n    Kind           : SPAN_KIND_SERVER\n    Start time     : 2022-03-21 20:45:22.743385 +0000 UTC\n    End time       : 2022-03-21 20:45:23.743385 +0000 UTC\n    Status code    : STATUS_CODE_OK\n    Status message :\n2022-03-21T15:46:22.743-0500    info    tailtracer/trace-receiver.go:33 I should start processing traces now!   {\"kind\": \"receiver\", \"name\": \"tailtracer\"}\n2022-03-21T15:46:22.744-0500    INFO    loggingexporter/logging_exporter.go:40  TracesExporter  {\"#spans\": 1}\n2022-03-21T15:46:22.744-0500    DEBUG   loggingexporter/logging_exporter.go:49  ResourceSpans #0\nResource SchemaURL:\nResource labels:\n     -&gt; atm.id: INT(111)\n     -&gt; atm.stateid: STRING(IL)\n     -&gt; atm.ispnetwork: STRING(comcast-chicago)\n     -&gt; atm.serialnumber: STRING(atmxph-2022-111)\n     -&gt; service.name: STRING(ATM-111-IL)\n     -&gt; service.version: STRING(v1.0)\nScopeSpans #0\nScopeSpans SchemaURL:\nInstrumentationScope atm-system v1.0\nResourceSpans #1\nResource SchemaURL:\nResource labels:\n     -&gt; cloud.provider: STRING(aws)\n     -&gt; cloud.region: STRING(us-east-2)\n     -&gt; os.type: STRING(linux)\n     -&gt; os.version: STRING(4.16.10-300.fc28.x86_64)\n     -&gt; service.name: STRING(accounts)\n     -&gt; service.version: STRING(v2.5)\nScopeSpans #0\nScopeSpans SchemaURL:\nInstrumentationScope atm-system v1.0\nSpan #0\n    Trace ID       : 8a6ca822db0847f48facfebbb08bbb9e\n    Parent ID      :\n    ID             : 7cf668c1273ecee5\n    Name           : api/v2.5/withdrawn\n    Kind           : SPAN_KIND_SERVER\n    Start time     : 2022-03-21 20:46:22.74404 +0000 UTC\n    End time       : 2022-03-21 20:46:23.74404 +0000 UTC\n    Status code    : STATUS_CODE_OK\n    Status message :\n</code></pre> <p>Here is what the generated trace looks like in Jaeger: </p> <p>What you currently see in Jaeger is the representation of a service that is receiving a request from an external entity that isn't instrumented by an OTel SDK, therefore it can't be identified as the origin/start of the trace. In order for a <code>ptrace.Span</code> to understand it is representing an operation that was execute as a result of another operation originated either within or outside (nested/child) of the <code>Resource</code> within the same trace context you will need to:</p> <ul> <li>Set the same trace context as the caller operation by calling the   <code>SetTraceID()</code> method and passing the <code>pcommon.TraceID</code> of the parent/caller   <code>ptrace.Span</code> as a parameter.</li> <li>Define who is the caller operation within the context of the trace by calling   <code>SetParentId()</code> method and passing the <code>pcommon.SpanID</code> of the parent/caller   <code>ptrace.Span</code> as a parameter.</li> </ul> <p>You will now create a <code>ptrace.Span</code> representing the <code>Atm</code> entity operations and set it as the parent for <code>BackendSystem</code> span. Open the <code>tailtracer/model.go</code> file and update the <code>appendTraceSpans()</code> function as follow:</p> <pre><code>func appendTraceSpans(backend *BackendSystem, backendScopeSpans *ptrace.ScopeSpans, atmScopeSpans *ptrace.ScopeSpans) {\ntraceId := NewTraceID()\nvar atmOperationName string\nswitch {\ncase strings.Contains(backend.Endpoint, \"balance\"):\natmOperationName = \"Check Balance\"\ncase strings.Contains(backend.Endpoint, \"deposit\"):\natmOperationName = \"Make Deposit\"\ncase strings.Contains(backend.Endpoint, \"withdraw\"):\natmOperationName = \"Fast Cash\"\n}\natmSpanId := NewSpanID()\natmSpanStartTime := time.Now()\natmDuration, _ := time.ParseDuration(\"4s\")\natmSpanFinishTime := atmSpanStartTime.Add(atmDuration)\natmSpan := atmScopeSpans.Spans().AppendEmpty()\natmSpan.SetTraceID(traceId)\natmSpan.SetSpanID(atmSpanId)\natmSpan.SetName(atmOperationName)\natmSpan.SetKind(ptrace.SpanKindClient)\natmSpan.Status().SetCode(ptrace.StatusCodeOk)\natmSpan.SetStartTimestamp(pcommon.NewTimestampFromTime(atmSpanStartTime))\natmSpan.SetEndTimestamp(pcommon.NewTimestampFromTime(atmSpanFinishTime))\nbackendSpanId := NewSpanID()\nbackendDuration, _ := time.ParseDuration(\"2s\")\nbackendSpanStartTime := atmSpanStartTime.Add(backendDuration)\nbackendSpan := backendScopeSpans.Spans().AppendEmpty()\nbackendSpan.SetTraceID(atmSpan.TraceID())\nbackendSpan.SetSpanID(backendSpanId)\nbackendSpan.SetParentSpanID(atmSpan.SpanID())\nbackendSpan.SetName(backend.Endpoint)\nbackendSpan.SetKind(ptrace.SpanKindServer)\nbackendSpan.Status().SetCode(ptrace.StatusCodeOk)\nbackendSpan.SetStartTimestamp(pcommon.NewTimestampFromTime(backendSpanStartTime))\nbackendSpan.SetEndTimestamp(atmSpan.EndTimestamp())\n}\n</code></pre> <p>Go ahead and run your <code>otelcol-dev</code> again and after 2 minutes running, you should start seeing traces in Jaeger like the following: </p> <p>We now have services representing both the <code>Atm</code> and the <code>BackendSystem</code> telemetry generation entities in our system and can fully understand how both entities are being used and contributing to the performance of an operation executed by an user.</p> <p>Here is the detailed view of one of those traces in Jaeger: </p> <p>That's it! You have now reached the end of this tutorial and successfully implemented a trace receiver, congratulations!</p>"},{"location":"docs/collector/trace-receiver/#check-your-work_13","title":"Check your work","text":"<ul> <li>Added <code>traceId</code> and <code>backendSpanId</code> variables to respectively represent the   trace and the span id and initialized them with the helper functions created   previously</li> <li>Added <code>backendSpanStartTime</code> and <code>backendSpanFinishTime</code> to represent the   start and the end time of the operation. For the tutorial, any   <code>BackendSystem</code> operation will take 1 second.</li> <li>Added a variable called <code>backendSpan</code> which will hold the instance of the   <code>ptrace.Span</code> representing this operation.</li> <li>Setting the <code>Name</code> of the span with the <code>Endpoint</code> field value from the   <code>BackendSystem</code> instance</li> <li>Setting the <code>Kind</code> of the span as <code>ptrace.SpanKindServer</code>. Take a look at   SpanKind section within the trace   specification to understand how to properly define SpanKind.</li> <li>Used all the methods mentioned before to fill the <code>ptrace.Span</code> with the   proper values to represent the <code>BackendSystem</code> operation</li> </ul>"},{"location":"docs/collector/trace-receiver/#check-your-work_14","title":"Check your work","text":"<ul> <li>Added a line under the <code>case &lt;=ticker.C</code> condition calling the   <code>tailtracerRcvr.nextConsumer.ConsumeTraces()</code> method passing the new context   created within the <code>Start()</code> method (<code>ctx</code>) and a call to the   <code>generateTraces</code> function so the generated traces can be pushed to the next   consumer in the pipeline</li> </ul>"},{"location":"docs/collector/transforming-telemetry/","title":"\u6539\u53d8\u9065\u6d4b","text":"<p>The OpenTelemetry Collector is a convenient place to transform data before sending it to a vendor or other systems. This is frequently done for data quality, governance, cost, and security reasons.</p> <p>Processors available from the the Collector Contrib repository support dozens of different transformations on metric, span and log data. The following sections provide some basic examples on getting started with a few frequently-used processors.</p> <p>The configuration of processors, particularly advanced transformations, may have a significant impact on collector performance.</p>"},{"location":"docs/collector/transforming-telemetry/#basic-filtering","title":"Basic filtering","text":"<p>Processor: filter processor</p> <p>The filter processor allows users to filter telemetry based on <code>include</code> or <code>exclude</code> rules. Include rules are used for defining \"allow lists\" where anything that does not match include rules is dropped from the collector. Exclude rules are used for defining \"deny lists\" where telemetry that matches rules is dropped from the collector.</p> <p>For example, to only allow span data from services app1, app2, and app3 and drop data from all other services:</p> <pre><code>processors:\nfilter/allowlist:\nspans:\ninclude:\nmatch_type: strict\nservices:\n- app1\n- app2\n- app3\n</code></pre> <p>To only block spans from a service called development while allowing all other spans, an exclude rule is used:</p> <pre><code>processors:\nfilter/denylist:\nspans:\nexclude:\nmatch_type: strict\nservices:\n- development\n</code></pre> <p>The filter processor docs have more examples, including filtering on logs and metrics.</p>"},{"location":"docs/collector/transforming-telemetry/#adding-or-deleting-attributes","title":"Adding or Deleting Attributes","text":"<p>Processor: attributes processor or resource processor</p> <p>The attributes processor can be used to update, insert, delete, or replace existing attributes on metrics or traces. For example, here\u2019s a configuration that adds an attribute called account_id to all spans:</p> <pre><code>processors:\nattributes/accountid:\nactions:\n- key: account_id\nvalue: 2245\naction: insert\n</code></pre> <p>The resource processor has an identical configuration, but applies only to resource attributes. Use the resource processor to modify infrastructure metadata related to telemetry. For example, this inserts the Kubernetes cluster name:</p> <pre><code>processors:\nresource/k8s:\nattributes:\n- key: k8s.cluster.name\nfrom_attribute: k8s-cluster\naction: insert\n</code></pre>"},{"location":"docs/collector/transforming-telemetry/#renaming-metrics-or-metric-labels","title":"Renaming Metrics or Metric Labels","text":"<p>Processor: metrics transform processor</p> <p>The metrics transform processor shares some functionality with the attributes processor, but also supports renaming and other metric-specific functionality.</p> <pre><code>processors:\nmetricstransform/rename:\ntransforms:\ninclude: system.cpu.usage\naction: update\nnew_name: system.cpu.usage_time\n</code></pre> <p>The metrics transform processor also supports regular expressions to apply transform rules to multiple metric names or metric labels at the same time. This example renames cluster_name to cluster-name for all metrics:</p> <pre><code>processors:\nmetricstransform/clustername:\ntransforms:\n- include: ^.*$\nmatch_type: regexp\naction: update\noperations:\n- action: update_label\nlabel: cluster_name\nnew_label: cluster-name\n</code></pre>"},{"location":"docs/collector/transforming-telemetry/#enriching-telemetry-with-resource-attributes","title":"Enriching Telemetry with Resource Attributes","text":"<p>Processor: resource detection processor and k8sattributes processor</p> <p>These processors can be used for enriching telemetry with relevant infrastructure metadata to help teams quickly identify when underlying infrastructure is impacting service health or performance.</p> <p>The resource detection processor adds relevant cloud or host-level information to telemetry:</p> <pre><code>processors:\nresourcedetection/system:\n# Modify the list of detectors to match the cloud environment\ndetectors: [env, system, gcp, ec2, azure]\ntimeout: 2s\noverride: false\n</code></pre> <p>Similarly, the K8s processor enriches telemetry with relevant Kubernetes metadata like pod name, node name, or workload name. The collector pod must be configured to have read access to certain Kubernetes RBAC APIs, which is documented here. To use the default options, it can be configured with an empty block:</p> <pre><code>processors:\nk8sattributes/default:\n</code></pre>"},{"location":"docs/collector/transforming-telemetry/#advanced-transformations","title":"Advanced Transformations","text":"<p>More advanced attribute transformations are also available in the transform processor. The transform processor allows end-users to specify transformations on metrics, logs, and traces using the OpenTelemetry Transformation Language.</p>"},{"location":"docs/collector/troubleshooting/","title":"\u6545\u969c\u6392\u9664","text":"<p>This page describes some options when troubleshooting the health or performance of the OpenTelemetry Collector. The Collector provides a variety of metrics, logs, and extensions for debugging issues.</p>"},{"location":"docs/collector/troubleshooting/#sending-test-data","title":"Sending test data","text":"<p>For certain types of issues, particularly verifying configuration and debugging network issues, it can be helpful to send a small amount of data to a collector configured to output to local logs. For details, see Local exporters.</p>"},{"location":"docs/collector/troubleshooting/#checklist-for-debugging-complex-pipelines","title":"Checklist for debugging complex pipelines","text":"<p>It can be difficult to isolate problems when telemetry flows through multiple collectors and networks. For each \"hop\" of telemetry data through a collector or other component in your telemetry pipeline, it\u2019s important to verify the following:</p> <ul> <li>Are there error messages in the logs of the collector?</li> <li>How is the telemetry being ingested into this component?</li> <li>How is the telemetry being modified (i.e. sampling, redacting) by this   component?</li> <li>How is the telemetry being exported from this component?</li> <li>What format is the telemetry in?</li> <li>How is the next hop configured?</li> <li>Are there any network policies that prevent data from getting in or out?</li> </ul>"},{"location":"docs/collector/troubleshooting/#more","title":"More","text":"<p>For detailed recommendations, including common problems, see Troubleshooting from the Collector repo.</p>"},{"location":"docs/collector/deployment/_index/","title":"\u90e8\u7f72","text":"<p>The OpenTelemetry collector consists of a single binary which you can use in different ways, for different use cases. This section describes deployment patterns, their use cases along with pros and cons and best practices for collector configurations for cross-environment and multi-backend deployments.</p>"},{"location":"docs/collector/deployment/_index/#resources","title":"Resources","text":"<ul> <li>KubeCon NA 2021 Talk on OpenTelemetry Collector Deployment   Patterns</li> <li>Deployment Patterns accompanying the talk</li> </ul>"},{"location":"docs/collector/deployment/agent/","title":"\u4ee3\u7406","text":"<p>The agent collector deployment pattern consists of applications \u2014 instrumented with an OpenTelemetry SDK using OpenTelemetry protocol (OTLP) \u2014 or other collectors (using the OTLP exporter) that send telemetry signals to a collector instance running with the application or on the same host as the application (such as a sidecar or a daemonset).</p> <p>Each client-side SDK or downstream collector is configured with a collector location:</p> <p></p> <ol> <li>In the app, the SDK is configured to send OTLP data to a collector.</li> <li>The collector is configured to send telemetry data to one or more backends.</li> </ol>"},{"location":"docs/collector/deployment/agent/#example","title":"Example","text":"<p>A concrete example of the agent collector deployment pattern could look as follows: you manually instrument, say, a Java application to export metrics using the OpenTelemetry Java SDK. In the context of the app, you would set the <code>OTEL_METRICS_EXPORTER</code> to <code>otlp</code> (which is the default value) and configure the OTLP exporter with the address of your collector, for example (in Bash or <code>zsh</code> shell):</p> <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://collector.example.com:4318\n</code></pre> <p>The collector serving at <code>collector.example.com:4318</code> would then be configured like so:</p> <p>{{&lt; tabpane lang=yaml persistLang=false &gt;}} {{&lt; tab Traces &gt;}} receivers:   otlp: # the OTLP receiver the app is sending traces to     protocols:       grpc:</p> <p>processors:   batch:</p> <p>exporters:   jaeger: # the Jaeger exporter, to ingest traces to backend     endpoint: \"https://jaeger.example.com:14250\"     tls:       insecure: true</p> <p>service:   pipelines:     traces/dev:       receivers: otlp       processors: [batch]       exporters: [jaeger] {{&lt; /tab &gt;}} {{&lt; tab Metrics &gt;}} receivers:   otlp: # the OTLP receiver the app is sending metrics to     protocols:       grpc:</p> <p>processors:   batch:</p> <p>exporters:   prometheusremotewrite: # the PRW exporter, to ingest metrics to backend     endpoint: \"https://prw.example.com/v1/api/remote_write\"</p> <p>service:   pipelines:     metrics/prod:       receivers: otlp       processors: [batch]       exporters: [prometheusremotewrite]</p> <p>{{&lt; /tab &gt;}} {{&lt; tab Logs &gt;}} receivers:   otlp: # the OTLP receiver the app is sending logs to     protocols:       grpc:</p> <p>processors:   batch:</p> <p>exporters:   file: # the File Exporter, to ingest logs to local file     path: \"./app42_example.log\"     rotation:</p> <p>service:   pipelines:     logs/dev:       receivers: otlp       processors: [batch]       exporters: [file] {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>If you want to try it out for yourself, you can have a look at the end-to-end Java or Python examples.</p>"},{"location":"docs/collector/deployment/agent/#tradeoffs","title":"Tradeoffs","text":"<p>Pros:</p> <ul> <li>Simple to get started</li> <li>Clear 1:1 mapping between application and collector</li> </ul> <p>Cons:</p> <ul> <li>Scalability (human and load-wise)</li> <li>Inflexible</li> </ul>"},{"location":"docs/collector/deployment/gateway/","title":"\u7f51\u5173","text":"<p>The gateway collector deployment pattern consists of applications (or other collectors) sending telemetry signals to a single OTLP endpoint provided by one or more collector instances running as a standalone service (for example, a deployment in Kubernetes), typically per cluster, per data center or per region.</p> <p>In the general case you can use an out-of-the-box load balancer to distribute the load amongst the collectors:</p> <p></p> <p>For use cases where the processing of the telemetry data processing has to happen in a specific collector, you would use a two-tiered setup with a collector that has a pipeline configured with the Trace ID/Service-name aware load-balancing exporter in the first tier and the collectors handling the scale out in the second tier. For example, you will need to use the load-balancing exporter when using the Tail Sampling processor so that all spans for a given trace reach the same collector instance where the tail sampling policy is applied.</p> <p>Let's have a look at such a case where we are using the load-balancing exporter:</p> <p></p> <ol> <li>In the app, the SDK is configured to send OTLP data to a central location.</li> <li>A collector configured using the load-balancing exporter that distributes    signals to a group of collectors.</li> <li>The collectors are configured to send telemetry data to one or more backends.</li> </ol> <p>{{% alert title=\"Note\" color=\"info\" %}} Currently, the load-balancing exporter only supports pipelines of the <code>traces</code> type. {{% /alert %}}</p>"},{"location":"docs/collector/deployment/gateway/#example","title":"Example","text":"<p>For a concrete example of the centralized collector deployment pattern we first need to have a closer look at the load-balancing exporter. It has two main configuration fields:</p> <ul> <li>The <code>resolver</code>, which determines where to find the downstream collectors (or:   backends). If you use the <code>static</code> sub-key here, you will have to manually   enumerate the collector URLs. The other supported resolver is the DNS resolver   which will periodically check for updates and resolve IP addresses. For this   resolver type, the <code>hostname</code> sub-key specifies the hostname to query in order   to obtain the list of IP addresses.</li> <li>With the <code>routing_key</code> field you tell the load-balancing exporter to route   spans to specific downstream collectors. If you set this field to <code>traceID</code>   (default) then the Load-balancing exporter exports spans based on their   <code>traceID</code>. Otherwise, if you use <code>service</code> as the value for <code>routing_key</code>, it   exports spans based on their service name which is useful when using   connectors like the Span Metrics connector, so all   spans of a service will be send to the same downstream collector for metric   collection, guaranteeting accurate aggregations.</li> </ul> <p>The first-tier collector servicing the OTLP endpoint would be configured as shown below:</p> <p>{{&lt; tabpane lang=yaml persistLang=false &gt;}} {{&lt; tab Static &gt;}} receivers:   otlp:     protocols:       grpc:</p> <p>exporters:   loadbalancing:     protocol:       otlp:         insecure: true     resolver:       static:         hostnames:           - collector-1.example.com:4317           - collector-2.example.com:5317           - collector-3.example.com</p> <p>service:   pipelines:     traces:       receivers: [otlp]       exporters: [loadbalancing] {{&lt; /tab &gt;}} {{&lt; tab DNS &gt;}} receivers:   otlp:     protocols:       grpc:</p> <p>exporters:   loadbalancing:     protocol:       otlp:         insecure: true     resolver:       dns:         hostname: collectors.example.com</p> <p>service:   pipelines:     traces:       receivers: [otlp]       exporters: [loadbalancing] {{&lt; /tab &gt;}} {{&lt; tab \"DNS with service\" &gt;}} receivers:   otlp:     protocols:       grpc:</p> <p>exporters:   loadbalancing:     routing_key: \"service\"     protocol:       otlp:         insecure: true     resolver:       dns:         hostname: collectors.example.com         port: 5317</p> <p>service:   pipelines:     traces:       receivers: [otlp]       exporters: [loadbalancing] {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>The load-balancing exporter emits metrics including <code>otelcol_loadbalancer_num_backends</code> and <code>otelcol_loadbalancer_backend_latency</code> that you can use for health and performance monitoring of the OTLP endpoint collector.</p>"},{"location":"docs/collector/deployment/gateway/#tradeoffs","title":"Tradeoffs","text":"<p>Pros:</p> <ul> <li>Separation of concerns such as centrally managed credentials</li> <li>Centralized policy management (for example, filtering certain logs or   sampling)</li> </ul> <p>Cons:</p> <ul> <li>It's one more thing to maintain and that can fail (complexity)</li> <li>Added latency in case of cascaded collectors</li> <li>Higher overall resource usage (costs)</li> </ul>"},{"location":"docs/collector/deployment/no-collector/","title":"\u6ca1\u6709\u6536\u96c6\u5668","text":"<p>The simplest pattern is not to use a collector at all. This pattern consists of applications instrumented with an OpenTelemetry SDK that export telemetry signals (traces, metrics, logs) directly into a backend:</p> <p></p>"},{"location":"docs/collector/deployment/no-collector/#example","title":"Example","text":"<p>See the code instrumentation for programming languages for concrete end-to-end examples for how to export signals from your app directly into a backend.</p>"},{"location":"docs/collector/deployment/no-collector/#tradeoffs","title":"Tradeoffs","text":"<p>Pros:</p> <ul> <li>Simple to use (especially in a dev/test environment)</li> <li>No additional moving parts to operate (in production environments)</li> </ul> <p>Cons:</p> <ul> <li>Requires code changes if collection, processing, or ingestion changes</li> <li>Strong coupling between the application code and the backend</li> <li>There are limited number of exporters per language implementation</li> </ul>"},{"location":"docs/concepts/_index/","title":"\u5f00\u653e\u9065\u6d4b\u6982\u5ff5","text":"<p>\u5728\u672c\u8282\u4e2d\uff0c\u60a8\u5c06\u4e86\u89e3OpenTelemetry\u9879\u76ee\u7684\u6570\u636e\u6e90\u548c\u5173\u952e\u7ec4\u4ef6\u3002\u8fd9\u5c06\u5e2e\u52a9\u60a8\u7406\u89e3OpenTelemetry\u662f\u5982\u4f55\u5de5\u4f5c\u7684\u3002</p>"},{"location":"docs/concepts/components/","title":"\u7ec4\u4ef6","text":"<p>OpenTelemetry\u76ee\u524d\u7531\u51e0\u4e2a\u4e3b\u8981\u7ec4\u4ef6\u7ec4\u6210:</p> <ul> <li>\u8de8\u8bed\u8a00\u89c4\u8303</li> <li>OpenTelemetry \u6536\u96c6\u5668</li> <li>\u6bcf\u79cd\u8bed\u8a00sdk</li> <li>\u6bcf\u79cd\u8bed\u8a00\u7684\u5de5\u5177\u5e93</li> <li>\u6309\u8bed\u8a00\u81ea\u52a8\u68c0\u6d4b</li> <li>K8s \u64cd\u4f5c\u5668</li> </ul> <p>OpenTelemetry\u5141\u8bb8\u60a8\u66ff\u6362\u5bf9\u7279\u5b9a\u4e8e\u4f9b\u5e94\u5546\u7684sdk\u548c\u5de5\u5177\u7684\u9700\u6c42\uff0c\u4ee5\u751f\u6210\u548c\u5bfc\u51fa\u9065\u6d4b\u6570\u636e\u3002</p>"},{"location":"docs/concepts/components/#specification","title":"Specification","text":"<p>Describes the cross-language requirements and expectations for all implementations. Beyond a definition of terms, the specification defines the following:</p> <ul> <li>API: Defines data types and operations for generating and correlating   tracing, metrics, and logging data.</li> <li>SDK: Defines requirements for a language-specific implementation of the   API. Configuration, data processing, and exporting concepts are also defined   here.</li> <li>Data: Defines the OpenTelemetry Protocol (OTLP) and vendor-agnostic   semantic conventions that a telemetry backend can provide support for.</li> </ul> <p>For more information, see the specification.</p> <p>Additionally, extensively-commented protobuf interface files for API concepts can be found in the proto repository.</p>"},{"location":"docs/concepts/components/#collector","title":"Collector","text":"<p>The OpenTelemetry Collector is a vendor-agnostic proxy that can receive, process, and export telemetry data. It supports receiving telemetry data in multiple formats (for example, OTLP, Jaeger, Prometheus, as well as many commercial/proprietary tools) and sending data to one or more backends. It also supports processing and filtering telemetry data before it gets exported. Collector contrib packages bring support for more data formats and vendor backends.</p> <p>For more information, see Collector.</p>"},{"location":"docs/concepts/components/#language-sdks","title":"Language SDKs","text":"<p>OpenTelemetry also has language SDKs that let you use the OpenTelemetry API to generate telemetry data with your language of choice and export that data to a preferred backend. These SDKs also let you incorporate instrumentation libraries for common libraries and frameworks that you can use to connect to manual instrumentation in your application.</p> <p>For more information, see Instrumenting.</p>"},{"location":"docs/concepts/components/#instrumentation-libraries","title":"Instrumentation Libraries","text":"<p>OpenTelemetry supports a broad number of components that generate relevant telemetry data from popular libraries and frameworks for supported languages. For example, inbound and outbound HTTP requests from an HTTP library will generate data about those requests.</p> <p>It is a long-term goal that popular libraries are authored to be observable out of the box, such that pulling in a separate component is not required.</p> <p>For more information, see Instrumenting Libraries.</p>"},{"location":"docs/concepts/components/#automatic-instrumentation","title":"Automatic Instrumentation","text":"<p>If applicable a language specific implementation of OpenTelemetry will provide a way to instrument your application without touching your source code. While the underlying mechanism depends on the language, at a minimum this will add the OpenTelemetry API and SDK capabilities to your application. Additionally they may add a set of Instrumentation Libraries and exporter dependencies.</p> <p>For more information, see Instrumenting.</p>"},{"location":"docs/concepts/components/#k8s-operator","title":"K8s operator","text":"<p>The OpenTelemetry Operator is an implementation of a Kubernetes Operator. The operator manages the OpenTelemetry Collector and auto-instrumentation of the workloads using OpenTelemetry.</p> <p>For more information, see K8s Operator.</p>"},{"location":"docs/concepts/data-collection/","title":"\u6570\u636e\u6536\u96c6","text":"<p>OpenTelemetry\u9879\u76ee\u901a\u8fc7OpenTelemetry Collector\u4fc3\u8fdb\u4e86\u9065\u6d4b\u6570\u636e\u7684\u6536\u96c6\u3002 OpenTelemetry Collector\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e0e\u4f9b\u5e94\u5546\u65e0\u5173\u7684\u5b9e\u73b0\uff0c\u7528\u4e8e\u63a5\u6536\u3001\u5904\u7406\u548c\u5bfc\u51fa\u9065\u6d4b\u6570\u636e\u3002 \u5b83\u6d88\u9664\u4e86\u8fd0\u884c\u3001\u64cd\u4f5c\u548c\u7ef4\u62a4\u591a\u4e2a\u4ee3\u7406/\u6536\u96c6\u5668\u4ee5\u652f\u6301\u5411\u4e00\u4e2a\u6216\u591a\u4e2a\u5f00\u6e90\u6216\u5546\u4e1a\u540e\u7aef\u53d1\u9001\u7684\u5f00\u6e90\u53ef\u89c2\u5bdf\u6027\u6570\u636e\u683c\u5f0f(\u4f8b\u5982Jaeger\u3001Prometheus\u7b49)\u7684\u9700\u8981\u3002 \u6b64\u5916\uff0cCollector\u8fd8\u4e3a\u6700\u7ec8\u7528\u6237\u63d0\u4f9b\u4e86\u5bf9\u5176\u6570\u636e\u7684\u63a7\u5236\u3002 Collector\u662f\u4eea\u5668\u5e93\u5bfc\u51fa\u5176\u9065\u6d4b\u6570\u636e\u7684\u9ed8\u8ba4\u4f4d\u7f6e\u3002</p> <p>\u6536\u96c6\u5668\u53ef\u4ee5\u4f5c\u4e3a\u53d1\u884c\u7248\u63d0\u4f9b\uff0c\u8bf7\u53c2\u9605\u8fd9\u91cc\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\u3002</p>"},{"location":"docs/concepts/data-collection/#_1","title":"\u90e8\u7f72","text":"<p>\u5f00\u653e\u9065\u6d4b\u91c7\u96c6\u5668\u63d0\u4f9b\u5355\u4e00\u4e8c\u8fdb\u5236\u548c\u4e24\u79cd\u90e8\u7f72\u65b9\u6cd5:</p> <ul> <li>Agent: A Collector instance running with the application or on the same   host as the application (e.g. binary, sidecar, or daemonset).</li> <li>Gateway: One or more Collector instances running as a standalone service   (e.g. container or deployment) typically per cluster, data center or region.</li> </ul> <p>For information on how to use the Collector see the getting started documentation.</p>"},{"location":"docs/concepts/data-collection/#_2","title":"\u7ec4\u4ef6","text":"<p>The Collector is made up of the following components:</p> <ul> <li> <code>receivers</code>: How to get data into the Collector; these can be push or pull   based</li> <li> <code>processors</code>: What to do with received data</li> <li> <code>exporters</code>: Where to send received data; these can be push or pull based</li> </ul> <p>These components are enabled through <code>pipelines</code>. Multiple instances of components as well as pipelines can be defined via YAML configuration.</p> <p>For more information about these components see the configuration documentation.</p>"},{"location":"docs/concepts/data-collection/#_3","title":"\u5b58\u50a8\u5e93","text":"<p>The OpenTelemetry project provides two versions of the Collector:</p> <ul> <li>Core:   Foundational components such as configuration and generally applicable   receivers, processors, exporters, and extensions.</li> <li>Contrib:   All the components of core plus optional or possibly experimental components.   Offers support for popular open source projects including Jaeger, Prometheus,   and Fluent Bit. Also contains more specialized or vendor-specific receivers,   processors, exporters, and extensions.</li> </ul>"},{"location":"docs/concepts/distributions/","title":"\u5206\u5e03","text":"<p>The OpenTelemetry projects consists of multiple components that support multiple signals. The reference implementation of OpenTelemetry is available as:</p> <ul> <li>Language-specific instrumentation libraries</li> <li>A Collector binary</li> </ul> <p>From any reference implementation a distribution may be created.</p>"},{"location":"docs/concepts/distributions/#what-is-a-distribution","title":"What is a distribution?","text":"<p>A distribution, not to be confused with a fork, is customized version of an OpenTelemetry component. A distribution is a wrapper around an upstream OpenTelemetry repository with some customizations. Customizations in a distribution may include:</p> <ul> <li>Scripts to ease use or customize use for a specific back-end or vendor</li> <li>Changes to default settings required for a back-end, vendor, or end-user</li> <li>Additional packaging options that may be vendor or end-user specific</li> <li>Test, performance, and security coverage beyond what OpenTelemetry provides</li> <li>Additional capabilities beyond what OpenTelemetry provides</li> <li>Less capabilities from what OpenTelemetry provides</li> </ul> <p>Distributions would broadly fall into the following categories:</p> <ul> <li>\"Pure\": These distributions provide the same functionality as upstream and   are 100% compatible. Customizations would typically be to ease of use or   packaging. These customizations may be back-end, vendor, or end-user specific.</li> <li>\"Plus\": These distributions provide the same functionality as upstream   plus more. Customizations beyond those found in pure distributions would be   the inclusion of additional components. Examples of this would include   instrumentation libraries or vendor exporters not upstreamed to the   OpenTelemetry project.</li> <li>\"Minus\": These distributions provide a reduced set of functionality from   upstream. Examples of this would include the removal of instrumentation   libraries or receivers/processors/exporters/extensions found in the   OpenTelemetry Collector project. These distributions may be provided to   increase supportability and security considerations.</li> </ul>"},{"location":"docs/concepts/distributions/#who-would-create-a-distribution","title":"Who would create a distribution?","text":"<p>Anyone could create a distribution. Today, several vendors offer distributions. In addition, end-users may consider creating a distribution if they wish to use components in the Registry that are not upstreamed to the OpenTelemetry project.</p>"},{"location":"docs/concepts/distributions/#contribution-or-distribution","title":"Contribution or distribution?","text":"<p>Before you read on and learn how you can create your own distribution, ask yourself if your additions on top of an OpenTelemetry component would be beneficial for everyone and therefore should be included in the reference implementations:</p> <ul> <li>Can your scripts for \"ease of use\" be generalized?</li> <li>Can your changes to default settings be the better option for everyone?</li> <li>Are your additional packaging options really specific?</li> <li>Might your test, performance &amp; security coverage work with the reference   implementation as well?</li> <li>Have you checked with the community if your additional capabilities could be   part of the standard?</li> </ul>"},{"location":"docs/concepts/distributions/#creating-your-own-distribution","title":"Creating your own distribution","text":""},{"location":"docs/concepts/distributions/#collector","title":"Collector","text":"<p>A guide on how to create your own distribution is available in this blog post: \"Building your own OpenTelemetry Collector distribution\"</p> <p>If you are building your own distribution, the OpenTelemetry Collector Builder might be a good starting point.</p>"},{"location":"docs/concepts/distributions/#language-specific-instrumentation-libraries","title":"Language Specific Instrumentation libraries","text":"<p>There are language specific extensibility mechanisms to customize the instrumentation libraries:</p> <ul> <li>Javaagent</li> </ul>"},{"location":"docs/concepts/distributions/#what-you-should-know-about-distributions","title":"What you should know about distributions","text":"<p>When using OpenTelemetry project collateral such as logo and name for your distribution, make sure that you are in line with the OpenTelemetry Marketing Guidelines for Contributing Organizations.</p> <p>The OpenTelemetry project does not certify distributions at this time. In the future, OpenTelemetry may certify distributions and partners similarly to the Kubernetes project. When evaluating a distribution, ensure using the distribution does not result in vendor lock-in.</p> <p>Any support for a distribution comes from the distribution authors and not the OpenTelemetry authors.</p>"},{"location":"docs/concepts/glossary/","title":"\u672f\u8bed\u8868","text":"<p>OpenTelemetry\u9879\u76ee\u4f7f\u7528\u7684\u672f\u8bed\u60a8\u53ef\u80fd\u4e0d\u719f\u6089\uff0c\u4e5f\u53ef\u80fd\u4e0d\u719f\u6089\u3002 \u6b64\u5916\uff0c\u8be5\u9879\u76ee\u53ef\u80fd\u4ee5\u4e0d\u540c\u4e8e\u5176\u4ed6\u9879\u76ee\u7684\u65b9\u5f0f\u5b9a\u4e49\u672f\u8bed\u3002 \u672c\u9875\u5305\u542b\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u672f\u8bed\u53ca\u5176\u542b\u4e49\u3002</p>"},{"location":"docs/concepts/glossary/#_1","title":"\u901a\u7528\u672f\u8bed","text":""},{"location":"docs/concepts/glossary/#aggregation","title":"Aggregation","text":"<p>The process of combining multiple measurements into exact or estimated statistics about the measurements that took place during an interval of time, during program execution. Used by the <code>Metric</code> <code>Data Source</code>.</p>"},{"location":"docs/concepts/glossary/#api","title":"API","text":"<p>Application Programming Interface. In the OpenTelemetry project, used to define how telemetry data is generated per <code>Data Source</code>.</p>"},{"location":"docs/concepts/glossary/#application","title":"Application","text":"<p>One or more <code>Services</code> designed for end users or other applications.</p>"},{"location":"docs/concepts/glossary/#apm","title":"APM","text":"<p>Application Performance Monitoring is about monitoring software applications, their performance (speed, reliability, availability, etc.) to detect issues, alerting and tooling for finding the root cause.</p>"},{"location":"docs/concepts/glossary/#attribute","title":"Attribute","text":"<p>A key-value pair. Used across telemetry signals - e.g. in <code>Traces</code> to attach data to a <code>Span</code>, or in <code>Metrics</code>. See attribute spec.</p>"},{"location":"docs/concepts/glossary/#automatic-instrumentation","title":"Automatic Instrumentation","text":"<p>Refers to telemetry collection methods that do not require the end-user to modify application's source code. Methods vary by programming language, and examples include bytecode injection or monkey patching.</p>"},{"location":"docs/concepts/glossary/#baggage","title":"Baggage","text":"<p>A mechanism for propagating name/value pairs to help establish a causal relationship between events and services. See baggage spec.</p>"},{"location":"docs/concepts/glossary/#client-library","title":"Client Library","text":"<p>See <code>Instrumented Library</code>.</p>"},{"location":"docs/concepts/glossary/#client-side-app","title":"Client-side App","text":"<p>A component of an <code>Application</code> that is not running inside a private infrastructure and is typically used directly by end-users. Examples of client-side apps are browser apps, mobile apps, and apps running on IoT devices.</p>"},{"location":"docs/concepts/glossary/#collector","title":"Collector","text":"<p>A vendor-agnostic implementation on how to receive, process, and export telemetry data. A single binary that can be deployed as an agent or gateway.</p> <p>Also known as the OpenTelemetry Collector. More on the Collector here.</p>"},{"location":"docs/concepts/glossary/#contrib","title":"Contrib","text":"<p>Several <code>Instrumentation Libraries</code> and the <code>Collector</code> offer a set of core capabilities as well as a dedicated contrib repository for non-core capabilities including vendor <code>Exporters</code>.</p>"},{"location":"docs/concepts/glossary/#context-propagation","title":"Context Propagation","text":"<p>Allows all <code>Data Sources</code> to share an underlying context mechanism for storing state and accessing data across the lifespan of a <code>Transaction</code>. See context propagation spec.</p>"},{"location":"docs/concepts/glossary/#dag","title":"DAG","text":"<p>Directed Acyclic Graph.</p>"},{"location":"docs/concepts/glossary/#data-source","title":"Data Source","text":"<p>See <code>Signal</code></p>"},{"location":"docs/concepts/glossary/#dimension","title":"Dimension","text":"<p>See <code>Label</code>.</p>"},{"location":"docs/concepts/glossary/#distributed-tracing","title":"Distributed Tracing","text":"<p>Tracks the progression of a single <code>Request</code>, called a <code>Trace</code>, as it is handled by <code>Services</code> that make up an <code>Application</code>. A <code>Distributed Trace</code> transverses process, network and security boundaries.</p> <p>More on Distributed Tracing here.</p>"},{"location":"docs/concepts/glossary/#event","title":"Event","text":"<p>Something that happened where representation depends on the <code>Data Source</code>. For example, <code>Spans</code>.</p>"},{"location":"docs/concepts/glossary/#exporter","title":"Exporter","text":"<p>Provides functionality to emit telemetry to consumers. Used by <code>Instrumentation Libraries</code> and the <code>Collector</code>. Exporters can be push- or pull-based.</p>"},{"location":"docs/concepts/glossary/#field","title":"Field","text":"<p>Name/value pairs added to <code>Log Records</code> (similar to <code>Attributes</code> for <code>Spans</code> and <code>Labels</code> for <code>Metrics</code>). See field spec.</p>"},{"location":"docs/concepts/glossary/#grpc","title":"gRPC","text":"<p>A high-performance, open source universal <code>RPC</code> framework. More on gRPC here.</p>"},{"location":"docs/concepts/glossary/#http","title":"HTTP","text":"<p>Short for Hypertext Transfer Protocol.</p>"},{"location":"docs/concepts/glossary/#instrumented-library","title":"Instrumented Library","text":"<p>Denotes the <code>Library</code> for which the telemetry signals (<code>Traces</code>, <code>Metrics</code>, <code>Logs</code>) are gathered. See more.</p>"},{"location":"docs/concepts/glossary/#instrumentation-library","title":"Instrumentation Library","text":"<p>Denotes the <code>Library</code> that provides the instrumentation for a given <code>Instrumented Library</code>. <code>Instrumented Library</code> and <code>Instrumentation Library</code> may be the same <code>Library</code> if it has built-in OpenTelemetry instrumentation. See more.</p>"},{"location":"docs/concepts/glossary/#json","title":"JSON","text":"<p>Short for JavaScript Object Notation.</p>"},{"location":"docs/concepts/glossary/#label","title":"Label","text":"<p>See Attribute.</p>"},{"location":"docs/concepts/glossary/#language","title":"Language","text":"<p>Programming Language.</p>"},{"location":"docs/concepts/glossary/#library","title":"Library","text":"<p>A language-specific collection of behavior invoked by an interface.</p>"},{"location":"docs/concepts/glossary/#log","title":"Log","text":"<p>Sometimes used to refer to a collection of <code>Log Records</code>. May be ambiguous, since people also sometimes use <code>Log</code> to refer to a single <code>Log Record</code>, thus this term should be used carefully and in the context where ambiguity is possible additional qualifiers should be used (e.g. <code>Log Record</code>). See more.</p>"},{"location":"docs/concepts/glossary/#log-record","title":"Log Record","text":"<p>A recording of an <code>Event</code>. Typically the record includes a timestamp indicating when the <code>Event</code> happened as well as other data that describes what happened, where it happened, etc. See more.</p>"},{"location":"docs/concepts/glossary/#metadata","title":"Metadata","text":"<p>A name/value pair added to telemetry data. OpenTelemetry calls this <code>Attributes</code> on <code>Spans</code>, <code>Labels</code> on <code>Metrics</code> and <code>Fields</code> on <code>Logs</code>.</p>"},{"location":"docs/concepts/glossary/#metric","title":"Metric","text":"<p>Records a data point, either raw measurements or predefined aggregation, as time series with <code>Metadata</code>. See more.</p>"},{"location":"docs/concepts/glossary/#oc","title":"OC","text":"<p>Short form for <code>OpenCensus</code>.</p>"},{"location":"docs/concepts/glossary/#opencensus","title":"OpenCensus","text":"<p>A set of libraries for various languages that allow you to collect application metrics and distributed traces, then transfer the data to a backend of your choice in real time. Precursor to OpenTelemetry. See more.</p>"},{"location":"docs/concepts/glossary/#opentracing","title":"OpenTracing","text":"<p>Vendor-neutral APIs and instrumentation for distributed tracing. Precursor to OpenTelemetry. See more.</p>"},{"location":"docs/concepts/glossary/#ot","title":"OT","text":"<p>Short form for <code>OpenTracing</code>.</p>"},{"location":"docs/concepts/glossary/#otel","title":"OTel","text":"<p>Short form for OpenTelemetry.</p>"},{"location":"docs/concepts/glossary/#otelcol","title":"OTelCol","text":"<p>Short form for OpenTelemetry Collector.</p>"},{"location":"docs/concepts/glossary/#otlp","title":"OTLP","text":"<p>Short for OpenTelemetry Protocol.</p>"},{"location":"docs/concepts/glossary/#processor","title":"Processor","text":"<p>Operation performed on data between being received and being exported. For example, batching. Used by 'Instrumentation Libraries' and the Collector.</p>"},{"location":"docs/concepts/glossary/#propagators","title":"Propagators","text":"<p>Used to serialize and deserialize specific parts of telemetry data such as span context and <code>Baggage</code> in <code>Spans</code>. See more.</p>"},{"location":"docs/concepts/glossary/#proto","title":"Proto","text":"<p>Language independent interface types. See more.</p>"},{"location":"docs/concepts/glossary/#receiver","title":"Receiver","text":"<p>Term used by the <code>Collector</code> to define how telemetry data is received. Receivers can be push- or pull-based. See more.</p>"},{"location":"docs/concepts/glossary/#request","title":"Request","text":"<p>See <code>Distributed Tracing</code>.</p>"},{"location":"docs/concepts/glossary/#resource","title":"Resource","text":"<p>Captures information about the entity for which telemetry is recorded. For example, a process producing telemetry that is running in a container on Kubernetes has a pod name, it is in a namespace and possibly is part of a deployment which also has a name. All three of these attributes can be included in the <code>Resource</code> and applied to any data source.</p>"},{"location":"docs/concepts/glossary/#rest","title":"REST","text":"<p>Short for Representational State Transfer.</p>"},{"location":"docs/concepts/glossary/#rpc","title":"RPC","text":"<p>Short for Remote Procedure Call.</p>"},{"location":"docs/concepts/glossary/#sampling","title":"Sampling","text":"<p>A mechanism to control the amount of data exported. Most commonly used with the <code>Tracing</code> <code>Data Source</code>. See more.</p>"},{"location":"docs/concepts/glossary/#sdk","title":"SDK","text":"<p>Short for Software Development Kit. Refers to a telemetry SDK that denotes a <code>Library</code> that implement the OpenTelemetry <code>API</code>.</p>"},{"location":"docs/concepts/glossary/#semantic-conventions","title":"Semantic Conventions","text":"<p>Defines standard names and values of <code>Metadata</code> in order to provide vendor-agnostic telemetry data.</p>"},{"location":"docs/concepts/glossary/#service","title":"Service","text":"<p>A component of an <code>Application</code>. Multiple instances of a <code>Service</code> are typically deployed for high availability and scalability. A <code>Service</code> may be deployed in multiple locations.</p>"},{"location":"docs/concepts/glossary/#signal","title":"Signal","text":"<p>One of <code>Traces</code>, <code>Metrics</code> or <code>Logs</code>. More on Signals here.</p>"},{"location":"docs/concepts/glossary/#span","title":"Span","text":"<p>Represents a single operation within a <code>Trace</code>. See more.</p>"},{"location":"docs/concepts/glossary/#span-link","title":"Span Link","text":"<p>A span link is a link between causally-related spans. For details see Links between spans and Specifying Links.</p>"},{"location":"docs/concepts/glossary/#specification","title":"Specification","text":"<p>Describes the cross-language requirements and expectations for all implementations. See more.</p>"},{"location":"docs/concepts/glossary/#status","title":"Status","text":"<p>The result of the operation. Typically used to indicate whether an error occurred. See more.</p>"},{"location":"docs/concepts/glossary/#tag","title":"Tag","text":"<p>See <code>Metadata</code>.</p>"},{"location":"docs/concepts/glossary/#trace","title":"Trace","text":"<p>A <code>DAG</code> of <code>Spans</code>, where the edges between <code>Spans</code> are defined as parent/child relationship. See more.</p>"},{"location":"docs/concepts/glossary/#tracer","title":"Tracer","text":"<p>Responsible for creating <code>Spans</code>. See more.</p>"},{"location":"docs/concepts/glossary/#transaction","title":"Transaction","text":"<p>See <code>Distributed Tracing</code>.</p>"},{"location":"docs/concepts/glossary/#zpages","title":"zPages","text":"<p>An in-process alternative to external exporters. When included, they collect and aggregate tracing and metrics information in the background; this data is served on web pages when requested. See more.</p>"},{"location":"docs/concepts/glossary/#_2","title":"\u989d\u5916\u672f\u8bed","text":""},{"location":"docs/concepts/glossary/#traces","title":"Traces","text":""},{"location":"docs/concepts/glossary/#trace-api-terminology","title":"Trace API Terminology","text":""},{"location":"docs/concepts/glossary/#trace-sdk-terminology","title":"Trace SDK Terminology","text":""},{"location":"docs/concepts/glossary/#metrics","title":"Metrics","text":""},{"location":"docs/concepts/glossary/#metric-api-terminology","title":"Metric API Terminology","text":""},{"location":"docs/concepts/glossary/#metric-sdk-terminology","title":"Metric SDK Terminology","text":""},{"location":"docs/concepts/glossary/#logs","title":"Logs","text":""},{"location":"docs/concepts/glossary/#trace-context-fields","title":"Trace Context Fields","text":""},{"location":"docs/concepts/glossary/#severity-fields","title":"Severity Fields","text":""},{"location":"docs/concepts/glossary/#log-record-fields","title":"Log Record Fields","text":""},{"location":"docs/concepts/glossary/#semantic-conventions_1","title":"Semantic Conventions","text":""},{"location":"docs/concepts/glossary/#resource-conventions","title":"Resource Conventions","text":""},{"location":"docs/concepts/glossary/#span-conventions","title":"Span Conventions","text":""},{"location":"docs/concepts/glossary/#metric-conventions","title":"Metric Conventions","text":""},{"location":"docs/concepts/observability-primer/","title":"\u53ef\u89c2\u6d4b Primer","text":""},{"location":"docs/concepts/observability-primer/#_1","title":"\u4ec0\u4e48\u662f\u53ef\u89c2\u5bdf\u6027?","text":"<p>\u53ef\u89c2\u5bdf\u6027\u8ba9\u6211\u4eec\u5728\u4e0d\u77e5\u9053\u7cfb\u7edf\u5185\u90e8\u8fd0\u4f5c\u7684\u60c5\u51b5\u4e0b\u5bf9\u7cfb\u7edf\u63d0\u51fa\u95ee\u9898\uff0c\u4ece\u800c\u4ece\u5916\u90e8\u7406\u89e3\u7cfb\u7edf\u3002 \u6b64\u5916\uff0c\u5b83\u5141\u8bb8\u6211\u4eec\u8f7b\u677e\u5730\u6392\u9664\u6545\u969c\u5e76\u5904\u7406\u65b0\u95ee\u9898(\u5373\u201c\u672a\u77e5\u7684\u672a\u77e5\u201d)\uff0c\u5e76\u5e2e\u52a9\u6211\u4eec\u56de\u7b54\u201c\u4e3a\u4ec0\u4e48\u4f1a\u53d1\u751f\u8fd9\u79cd\u60c5\u51b5?\u201d</p> <p>\u4e3a\u4e86\u80fd\u591f\u5bf9\u7cfb\u7edf\u63d0\u51fa\u8fd9\u4e9b\u95ee\u9898\uff0c\u5fc5\u987b\u5bf9\u5e94\u7528\u7a0b\u5e8f\u8fdb\u884c\u9002\u5f53\u7684\u68c0\u6d4b\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u5fc5\u987b\u53d1\u51fa\u4fe1\u53f7\uff0c\u4f8b\u5982trace\uff0c metrics\u548clogs\u3002 \u5f53\u5f00\u53d1\u4eba\u5458\u4e0d\u9700\u8981\u6dfb\u52a0\u66f4\u591a\u7684\u68c0\u6d4b\u6765\u89e3\u51b3\u95ee\u9898\u65f6\uff0c\u5e94\u7528\u7a0b\u5e8f\u5c31\u88ab\u9002\u5f53\u5730\u68c0\u6d4b\u4e86\uff0c\u56e0\u4e3a\u4ed6\u4eec\u5df2\u7ecf\u62e5\u6709\u4e86\u6240\u9700\u7684\u6240\u6709\u4fe1\u606f\u3002</p> <p>OpenTelemetry\u662f\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u88ab\u68c0\u6d4b\u7684\u673a\u5236\uff0c\u4ee5\u5e2e\u52a9\u4f7f\u7cfb\u7edf\u53ef\u89c2\u5bdf\u3002</p>"},{"location":"docs/concepts/observability-primer/#_2","title":"\u53ef\u9760\u6027\u548c\u5ea6\u91cf","text":"<p>\u9065\u6d4b\u662f\u6307\u4ece\u7cfb\u7edf\u53d1\u51fa\u7684\u6709\u5173\u5176\u884c\u4e3a\u7684\u6570\u636e\u3002 \u6570\u636e\u53ef\u4ee5\u4ee5\u75d5\u8ff9\u3001\u6307\u6807\u548c\u65e5\u5fd7\u7684\u5f62\u5f0f\u51fa\u73b0\u3002</p> <p>\u53ef\u9760\u6027 \u56de\u7b54\u7684\u95ee\u9898\u662f:\u201c\u670d\u52a1\u662f\u5426\u5728\u505a\u7528\u6237\u671f\u671b\u5b83\u505a\u7684\u4e8b\u60c5?\u201d\u7cfb\u7edf\u53ef\u4ee5100%\u6b63\u5e38\u8fd0\u884c\uff0c\u4f46\u5982\u679c\u5f53\u7528\u6237\u70b9\u51fb\u201c\u6dfb\u52a0\u5230\u8d2d\u7269\u8f66\u201d\u5c06\u4e00\u6761\u9ed1\u8272\u88e4\u5b50\u6dfb\u52a0\u5230\u8d2d\u7269\u8f66\u65f6\uff0c\u7cfb\u7edf\u5374\u4e00\u76f4\u5728\u6dfb\u52a0\u4e00\u6761\u7ea2\u8272\u88e4\u5b50\uff0c\u90a3\u4e48\u7cfb\u7edf\u5c31\u4f1a\u88ab\u8ba4\u4e3a\u662f**\u4e0d**\u53ef\u9760\u7684\u3002</p> <p>\u6307\u6807 \u662f\u4e00\u6bb5\u65f6\u95f4\u5185\u5173\u4e8e\u57fa\u7840\u8bbe\u65bd\u6216\u5e94\u7528\u7a0b\u5e8f\u7684\u6570\u5b57\u6570\u636e\u7684\u805a\u5408\u3002 \u793a\u4f8b\u5305\u62ec:\u7cfb\u7edf\u9519\u8bef\u7387\u3001CPU\u5229\u7528\u7387\u3001\u7ed9\u5b9a\u670d\u52a1\u7684\u8bf7\u6c42\u7387\u3002</p> <p>SLI \uff0c\u5373\u670d\u52a1\u6c34\u5e73\u6307\u6807\uff0c\u8868\u793a\u5bf9\u670d\u52a1\u884c\u4e3a\u7684\u5ea6\u91cf\u3002 \u597d\u7684SLI\u4ece\u7528\u6237\u7684\u89d2\u5ea6\u6765\u8861\u91cf\u60a8\u7684\u670d\u52a1\u3002 \u4f8b\u5982\uff0cSLI\u53ef\u4ee5\u662f\u7f51\u9875\u52a0\u8f7d\u7684\u901f\u5ea6\u3002</p> <p>SLO \uff0c\u5373\u670d\u52a1\u6c34\u5e73\u76ee\u6807\uff0c\u662f\u5411\u7ec4\u7ec7/\u5176\u4ed6\u56e2\u961f\u4f20\u8fbe\u53ef\u9760\u6027\u7684\u624b\u6bb5\u3002 \u8fd9\u53ef\u4ee5\u901a\u8fc7\u5c06\u4e00\u4e2a\u6216\u591a\u4e2asli\u9644\u52a0\u5230\u4e1a\u52a1\u503c\u6765\u5b9e\u73b0\u3002</p>"},{"location":"docs/concepts/observability-primer/#_3","title":"\u7406\u89e3\u5206\u5e03\u5f0f\u8ddf\u8e2a","text":"<p>\u4e3a\u4e86\u7406\u89e3\u5206\u5e03\u5f0f\u8ddf\u8e2a\uff0c\u8ba9\u6211\u4eec\u4ece\u4e00\u4e9b\u57fa\u7840\u77e5\u8bc6\u5f00\u59cb\u3002</p>"},{"location":"docs/concepts/observability-primer/#_4","title":"\u65e5\u5fd7","text":"<p>\u65e5\u5fd7\u662f\u7531\u670d\u52a1\u6216\u5176\u4ed6\u7ec4\u4ef6\u53d1\u51fa\u7684\u5e26\u6709\u65f6\u95f4\u6233\u7684\u6d88\u606f\u3002 \u7136\u800c\uff0c\u4e0etraces\u4e0d\u540c\uff0c\u5b83\u4eec\u4e0d\u4e00\u5b9a\u4e0e\u4efb\u4f55\u7279\u5b9a\u7684\u7528\u6237\u8bf7\u6c42\u6216\u4e8b\u52a1\u76f8\u5173\u8054\u3002 \u5b83\u4eec\u5728\u8f6f\u4ef6\u4e2d\u51e0\u4e4e\u65e0\u5904\u4e0d\u5728\uff0c\u5e76\u4e14\u5728\u8fc7\u53bb\u88ab\u5f00\u53d1\u4eba\u5458\u548c\u64cd\u4f5c\u4eba\u5458\u4e25\u91cd\u4f9d\u8d56\uff0c\u4ee5\u5e2e\u52a9\u4ed6\u4eec\u7406\u89e3\u7cfb\u7edf\u884c\u4e3a\u3002</p> <p>\u793a\u4f8b\u65e5\u5fd7:</p> <pre><code>I, [2021-02-23T13:26:23.505892 #22473]  INFO -- : [6459ffe1-ea53-4044-aaa3-bf902868f730] Started GET \"/\" for ::1 at 2021-02-23 13:26:23 -0800\n</code></pre> <p>\u4e0d\u5e78\u7684\u662f\uff0c\u65e5\u5fd7\u5bf9\u4e8e\u8ddf\u8e2a\u4ee3\u7801\u6267\u884c\u5e76\u4e0d\u662f\u975e\u5e38\u6709\u7528\uff0c\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f8b\u5982\u4ece\u54ea\u91cc\u8c03\u7528\u5b83\u4eec\u3002</p> <p>\u5f53\u5b83\u4eec\u4f5c\u4e3aspan\u7684\u4e00\u90e8\u5206\u5305\u542b\u65f6\uff0c\u5b83\u4eec\u5c06\u53d8\u5f97\u66f4\u52a0\u6709\u7528\u3002</p>"},{"location":"docs/concepts/observability-primer/#spans","title":"Spans","text":"<p>span \u8868\u793a\u4e00\u4e2a\u5de5\u4f5c\u6216\u64cd\u4f5c\u5355\u5143\u3002 \u5b83\u8ddf\u8e2a\u8bf7\u6c42\u6240\u505a\u7684\u7279\u5b9a\u64cd\u4f5c\uff0c\u63cf\u7ed8\u51fa\u5728\u6267\u884c\u8be5\u64cd\u4f5c\u671f\u95f4\u53d1\u751f\u7684\u60c5\u51b5\u3002</p> <p>span\u5305\u542b\u540d\u79f0\u3001\u4e0e\u65f6\u95f4\u76f8\u5173\u7684\u6570\u636e\u3001\u7ed3\u6784\u5316\u65e5\u5fd7\u6d88\u606f\u548c\u5176\u4ed6\u5143\u6570\u636e(\u5373\u5c5e\u6027)\uff0c\u4ee5\u63d0\u4f9b\u5173\u4e8e\u5b83\u6240\u8ddf\u8e2a\u7684\u64cd\u4f5c\u7684\u4fe1\u606f\u3002</p>"},{"location":"docs/concepts/observability-primer/#span","title":"Span \u5c5e\u6027","text":"<p>\u4e0b\u8868\u5305\u542b\u4e86span\u5c5e\u6027\u7684\u793a\u4f8b:</p> Key Value net.transport <code>IP.TCP</code> net.peer.ip <code>10.244.0.1</code> net.peer.port <code>10243</code> net.host.name <code>localhost</code> http.method <code>GET</code> http.target <code>/cart</code> http.server_name <code>frontend</code> http.route <code>/cart</code> http.scheme <code>http</code> http.host <code>localhost</code> http.flavor <code>1.1</code> http.status_code <code>200</code> http.user_agent <code>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36</code> <p>For more on spans and how they pertain to OTel, see Spans.</p>"},{"location":"docs/concepts/observability-primer/#_5","title":"\u5206\u5e03\u5f0f\u8ddf\u8e2a","text":"<p>\u5206\u5e03\u5f0f\u8ddf\u8e2a\uff0c\u901a\u5e38\u79f0\u4e3a\u8ddf\u8e2a\uff0c\u8bb0\u5f55\u8bf7\u6c42(\u7531\u5e94\u7528\u7a0b\u5e8f\u6216\u6700\u7ec8\u7528\u6237\u53d1\u51fa)\u901a\u8fc7\u591a\u670d\u52a1\u67b6\u6784(\u5982\u5fae\u670d\u52a1\u548c\u65e0\u670d\u52a1\u5668\u5e94\u7528\u7a0b\u5e8f)\u4f20\u64ad\u65f6\u6240\u91c7\u53d6\u7684\u8def\u5f84\u3002</p> <p>\u5982\u679c\u4e0d\u8fdb\u884c\u8ddf\u8e2a\uff0c\u5c31\u5f88\u96be\u786e\u5b9a\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u6027\u80fd\u95ee\u9898\u7684\u539f\u56e0\u3002</p> <p>\u5b83\u63d0\u9ad8\u4e86\u5e94\u7528\u7a0b\u5e8f\u6216\u7cfb\u7edf\u8fd0\u884c\u72b6\u51b5\u7684\u53ef\u89c1\u6027\uff0c\u5e76\u5141\u8bb8\u6211\u4eec\u8c03\u8bd5\u96be\u4ee5\u5728\u672c\u5730\u91cd\u73b0\u7684\u884c\u4e3a\u3002 \u8ddf\u8e2a\u5bf9\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u901a\u5e38\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u6216\u8005\u8fc7\u4e8e\u590d\u6742\u800c\u65e0\u6cd5\u5728\u672c\u5730\u91cd\u73b0\u3002</p> <p>\u8ddf\u8e2a\u901a\u8fc7\u5206\u89e3\u8bf7\u6c42\u6d41\u7ecf\u5206\u5e03\u5f0f\u7cfb\u7edf\u65f6\u6240\u53d1\u751f\u7684\u4e8b\u60c5\uff0c\u4f7f\u8c03\u8bd5\u548c\u7406\u89e3\u5206\u5e03\u5f0f\u7cfb\u7edf\u53d8\u5f97\u4e0d\u90a3\u4e48\u4ee4\u4eba\u751f\u754f\u3002</p> <p>\u8ff9\u7ebf\u7531\u4e00\u4e2a\u6216\u591a\u4e2a\u8de8\u5ea6\u7ec4\u6210\u3002\u7b2c\u4e00\u4e2a\u8de8\u5ea6\u8868\u793a\u6839\u8de8\u5ea6\u3002 \u6bcf\u4e2a\u6839\u8de8\u5ea6\u4ee3\u8868\u4e00\u4e2a\u4ece\u5934\u5230\u5c3e\u7684\u8bf7\u6c42\u3002\u7236\u7c7b\u4e0b\u9762\u7684\u8de8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6df1\u5165\u7684\u4e0a\u4e0b\u6587\uff0c\u8bf4\u660e\u5728\u8bf7\u6c42\u671f\u95f4\u53d1\u751f\u4e86\u4ec0\u4e48(\u6216\u7ec4\u6210\u8bf7\u6c42\u7684\u6b65\u9aa4)\u3002</p> <p>\u8bb8\u591a\u53ef\u89c2\u5bdf\u6027\u540e\u7aef\u5c06\u8f68\u8ff9\u53ef\u89c6\u5316\u4e3a\u7011\u5e03\u56fe\uff0c\u5982\u4e0b\u56fe\u6240\u793a:</p> <p></p> <p>\u7011\u5e03\u56fe\u663e\u793a\u4e86\u6839\u8de8\u5ea6\u4e0e\u5176\u5b50\u8de8\u5ea6\u4e4b\u95f4\u7684\u7236\u5b50\u5173\u7cfb\u3002 \u5f53\u4e00\u4e2aspan\u5c01\u88c5\u53e6\u4e00\u4e2aspan\u65f6\uff0c\u8fd9\u4e5f\u8868\u793a\u5d4c\u5957\u5173\u7cfb\u3002</p> <p>\u6709\u5173trace\u53ca\u5176\u4e0eOTel\u7684\u5173\u7cfb\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1trace.</p>"},{"location":"docs/concepts/semantic-conventions/","title":"\u8bed\u4e49\u7ea6\u5b9a","text":"<p>OpenTelemetry\u5b9a\u4e49\u8bed\u4e49\u7ea6\u5b9a(\u6709\u65f6\u79f0\u4e3a\u8bed\u4e49\u5c5e\u6027)\uff0c\u4e3a\u4e0d\u540c\u7c7b\u578b\u7684\u64cd\u4f5c\u548c\u6570\u636e\u6307\u5b9a\u901a\u7528\u540d\u79f0\u3002 \u4f7f\u7528\u8bed\u4e49\u7ea6\u5b9a\u7684\u597d\u5904\u662f\u9075\u5faa\u4e00\u4e2a\u901a\u7528\u7684\u547d\u540d\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u53ef\u4ee5\u8de8\u4ee3\u7801\u5e93\u3001\u5e93\u548c\u5e73\u53f0\u8fdb\u884c\u6807\u51c6\u5316\u3002</p> <p>\u76ee\u524d\uff0c\u8bed\u4e49\u7ea6\u5b9a\u53ef\u7528\u4e8e\u8ddf\u8e2a\u3001\u5ea6\u91cf\u548c\u8d44\u6e90:</p> <ul> <li>\u8ddf\u8e2a\u8bed\u4e49\u7ea6\u5b9a</li> <li>\u5ea6\u91cf\u8bed\u4e49\u7ea6\u5b9a</li> <li>\u8d44\u6e90\u8bed\u4e49\u7ea6\u5b9a</li> </ul>"},{"location":"docs/concepts/instrumentation/_index/","title":"\u4eea\u8868","text":"<p>\u4e3a\u4e86\u4f7f\u7cfb\u7edf\u53ef\u89c2\u5bdf\uff0c\u5b83\u5fc5\u987b \u4eea\u5668\u5316 :\u4e5f\u5c31\u662f\u8bf4\uff0c\u6765\u81ea\u7cfb\u7edf\u7ec4\u4ef6\u7684\u4ee3\u7801\u5fc5\u987b\u53d1\u51fa\u8ddf\u8e2a\uff0c\u5ea6\u91cf\u548c\u65e5\u5fd7\u3002</p> <p>\u4e0d\u9700\u8981\u4fee\u6539\u6e90\u4ee3\u7801\uff0c\u60a8\u5c31\u53ef\u4ee5\u4f7f\u7528automatic instrumentation\u4ece\u5e94\u7528\u7a0b\u5e8f\u6536\u96c6\u9065\u6d4b\u6570\u636e\u3002 \u5982\u679c\u60a8\u4ee5\u524d\u4f7f\u7528APM\u4ee3\u7406\u4ece\u5e94\u7528\u7a0b\u5e8f\u4e2d\u63d0\u53d6\u9065\u6d4b\u6570\u636e\uff0c\u90a3\u4e48\u81ea\u52a8\u68c0\u6d4b\u5c06\u4e3a\u60a8\u63d0\u4f9b\u7c7b\u4f3c\u7684\u5f00\u7bb1\u5373\u7528\u4f53\u9a8c\u3002</p> <p>\u4e3a\u4e86\u66f4\u65b9\u4fbf\u5730\u68c0\u6d4b\u5e94\u7528\u7a0b\u5e8f\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u5bf9OpenTelemetry api\u8fdb\u884c\u7f16\u7801\u6765\u624b\u52a8\u68c0\u6d4b\u5e94\u7528\u7a0b\u5e8f\u3002</p> <p>\u4e3a\u6b64\uff0c\u4f60\u4e0d\u9700\u8981\u68c0\u6d4b\u5e94\u7528\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u7684\u6240\u6709\u4f9d\u8d56\u9879:</p> <ul> <li>\u901a\u8fc7\u76f4\u63a5\u8c03\u7528OpenTelemetry API\uff0c\u4f60\u7684\u4e00\u4e9b\u5e93\u5c06\u662f\u5f00\u7bb1\u5373\u7528\u7684\u53ef\u89c2\u5bdf\u7684\u3002   \u8fd9\u4e9b\u5e93\u6709\u65f6\u88ab\u79f0\u4e3a \u672c\u673a\u63d2\u88c5\u5e93\u3002</li> <li>\u5bf9\u4e8e\u6ca1\u6709\u8fd9\u79cd\u96c6\u6210\u7684\u5e93\uff0cOpenTelemetry\u9879\u76ee\u63d0\u4f9b\u4e86\u7279\u5b9a\u4e8e\u8bed\u8a00\u7684[\u4eea\u5668\u5e93][]</li> </ul> <p>\u8bf7\u6ce8\u610f\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u8bed\u8a00\uff0c\u53ef\u4ee5\u540c\u65f6\u4f7f\u7528\u624b\u52a8\u548c\u81ea\u52a8\u63d2\u88c5:\u81ea\u52a8\u63d2\u88c5\u5c06\u5141\u8bb8\u60a8\u5feb\u901f\u4e86\u89e3\u5e94\u7528\u7a0b\u5e8f\uff0c\u800c\u624b\u52a8\u63d2\u88c5\u5c06\u4f7f\u60a8\u80fd\u591f\u5c06\u7c92\u5ea6\u53ef\u89c2\u5bdf\u6027\u5d4c\u5165\u5230\u4ee3\u7801\u4e2d\u3002</p> <p>manual\u548cautomatic\u68c0\u6d4b\u7684\u786e\u5207\u5b89\u88c5\u673a\u5236\u56e0\u60a8\u6240\u4f7f\u7528\u7684\u5f00\u53d1\u8bed\u8a00\u800c\u5f02\uff0c\u4f46\u4e0b\u9762\u51e0\u8282\u5c06\u4ecb\u7ecd\u4e00\u4e9b\u76f8\u4f3c\u4e4b\u5904\u3002</p>"},{"location":"docs/concepts/instrumentation/automatic/","title":"\u81ea\u52a8","text":"<p>\u5982\u679c\u9002\u7528\uff0cOpenTelemetry\u7684\u7279\u5b9a\u8bed\u8a00\u5b9e\u73b0\u5c06\u63d0\u4f9b\u4e00\u79cd\u65b9\u6cd5\u6765\u68c0\u6d4b\u60a8\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u800c\u65e0\u9700\u89e6\u53ca\u60a8\u7684\u6e90\u4ee3\u7801\u3002 \u867d\u7136\u5e95\u5c42\u673a\u5236\u53d6\u51b3\u4e8e\u8bed\u8a00\uff0c\u4f46\u81f3\u5c11\u8fd9\u4f1a\u5c06OpenTelemetry API\u548cSDK\u529f\u80fd\u6dfb\u52a0\u5230\u60a8\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\u3002 \u6b64\u5916\uff0c\u4ed6\u4eec\u53ef\u80fd\u4f1a\u6dfb\u52a0\u4e00\u7ec4\u5de5\u5177\u5e93\u548c\u5bfc\u51fa\u5668\u4f9d\u8d56\u9879\u3002</p> <p>\u53ef\u4ee5\u901a\u8fc7\u73af\u5883\u53d8\u91cf\u548c\u7279\u5b9a\u4e8e\u8bed\u8a00\u7684\u65b9\u5f0f(\u5982Java\u4e2d\u7684\u7cfb\u7edf\u5c5e\u6027)\u8fdb\u884c\u914d\u7f6e\u3002 \u81f3\u5c11\uff0c\u5fc5\u987b\u914d\u7f6e\u670d\u52a1\u540d\u79f0\u6765\u6807\u8bc6\u88ab\u68c0\u6d4b\u7684\u670d\u52a1\u3002 \u5404\u79cd\u5176\u4ed6\u914d\u7f6e\u9009\u9879\u53ef\u7528\uff0c\u53ef\u80fd\u5305\u62ec:</p> <ul> <li>\u7279\u5b9a\u4e8e\u6570\u636e\u6e90\u7684\u914d\u7f6e</li> <li>\u5bfc\u51fa\u5668\u914d\u7f6e</li> <li>\u4f20\u64ad\u5668\u914d\u7f6e</li> <li>\u8d44\u6e90\u914d\u7f6e</li> </ul> <p>\u81ea\u52a8\u4eea\u8868\u53ef\u7528\u4e8e\u4ee5\u4e0b\u8bed\u8a00:</p> <ul> <li>.NET</li> <li>Java</li> <li>JavaScript</li> <li>PHP</li> <li>Python</li> </ul>"},{"location":"docs/concepts/instrumentation/libraries/","title":"\u5e93","text":"<p>OpenTelemetry\u4e3a\u8bb8\u591a\u5e93\u63d0\u4f9b\u4e86[\u5de5\u5177\u5e93][]\uff0c\u8fd9\u901a\u5e38\u662f\u901a\u8fc7\u5e93\u94a9\u5b50\u6216\u7334\u5b50\u8865\u4e01\u5e93\u4ee3\u7801\u5b8c\u6210\u7684\u3002</p> <p>\u4f7f\u7528OpenTelemetry\u7684\u672c\u673a\u5e93\u63d2\u88c5\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u89c2\u5bdf\u6027\u548c\u5f00\u53d1\u4f53\u9a8c\uff0c\u6d88\u9664\u4e86\u5e93\u66b4\u9732\u548c\u6587\u6863\u6302\u94a9\u7684\u9700\u8981:</p> <ul> <li>\u81ea\u5b9a\u4e49\u65e5\u5fd7\u94a9\u5b50\u53ef\u4ee5\u88ab\u5e38\u89c1\u7684\u548c\u6613\u4e8e\u4f7f\u7528\u7684OpenTelemetry api\u53d6\u4ee3\uff0c\u7528\u6237\u5c06\u53ea\u4e0eOpenTelemetry\u4ea4\u4e92</li> <li>\u6765\u81ea\u5e93\u548c\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u7684\u8ddf\u8e2a\u3001\u65e5\u5fd7\u3001\u6307\u6807\u662f\u76f8\u5173\u548c\u4e00\u81f4\u7684</li> <li>\u901a\u7528\u7ea6\u5b9a\u5141\u8bb8\u7528\u6237\u5728\u76f8\u540c\u7684\u6280\u672f\u548c\u8de8\u5e93\u548c\u8bed\u8a00\u4e2d\u83b7\u5f97\u76f8\u4f3c\u548c\u4e00\u81f4\u7684\u9065\u6d4b</li> <li>\u9065\u6d4b\u4fe1\u53f7\u53ef\u4ee5\u4f7f\u7528\u5404\u79cd\u8bb0\u5f55\u826f\u597d\u7684OpenTelemetry\u6269\u5c55\u70b9\u5bf9\u5404\u79cd\u6d88\u8d39\u573a\u666f\u8fdb\u884c\u5fae\u8c03(\u8fc7\u6ee4\u3001\u5904\u7406\u3001\u805a\u5408)\u3002</li> </ul>"},{"location":"docs/concepts/instrumentation/libraries/#_1","title":"\u8bed\u4e49\u7ea6\u5b9a","text":"<p>Check out available semantic conventions that cover web-frameworks, RPC clients, databases, messaging clients, infra pieces and more!</p> <p>If your library is one of those things - follow the conventions, they are the main source of truth and tell which information should be included on spans. Conventions make instrumentation consistent: users who work with telemetry don't have to learn library specifics and observability vendors can build experiences for a wide variety of technologies (e.g. databases or messaging systems). When libraries follow conventions, many scenarios may be enabled out of the box without the user's input or configuration.</p> <p>If you have any feedback or want to add a new convention - please come and contribute! Instrumentation Slack or Specification repo are a good places to start!</p>"},{"location":"docs/concepts/instrumentation/libraries/#_2","title":"\u5f53**\u4e0d**\u4eea\u5668","text":"<p>Some libraries are thin clients wrapping network calls. Chances are that OpenTelemetry has an instrumentation library for the underlying RPC client (check out the registry). In this case, instrumenting the wrapper library may not be necessary.</p> <p>Don't instrument if:</p> <ul> <li>your library is a thin proxy on top of documented or self-explanatory APIs</li> <li>and OpenTelemetry has instrumentation for underlying network calls</li> <li>and there are no conventions your library should follow to enrich telemetry</li> </ul> <p>If you're in doubt - don't instrument - you can always do it later when you see a need.</p> <p>If you choose not to instrument, it may still be useful to provide a way to configure OpenTelemetry handlers for your internal RPC client instance. It's essential in languages that don't support fully automatic instrumentation and still useful in others.</p> <p>The rest of this document gives guidance on what and how to instrument if you decide to do it.</p>"},{"location":"docs/concepts/instrumentation/libraries/#opentelemetry-api","title":"OpenTelemetry API","text":"<p>The first step is to take dependency on the OpenTelemetry API package.</p> <p>OpenTelemetry has two main modules - API and SDK. OpenTelemetry API is a set of abstractions and not-operational implementations. Unless your application imports the OpenTelemetry SDK, your instrumentation does nothing and does not impact application performance.</p> <p>Libraries should only use the OpenTelemetry API.</p> <p>You may be rightfully concerned about adding new dependencies, here are some considerations to help you decide how to minimize dependency hell:</p> <ul> <li>OpenTelemetry Trace API reached stability in early 2021, it follows   Semantic Versioning 2.0 and we   take API stability seriously.</li> <li>When taking dependency, use the earliest stable OpenTelemetry API (1.0.*) and   avoid updating it unless you have to use new features.</li> <li>While your instrumentation stabilizes, consider shipping it as a separate   package, so that will never cause issues for users who don't use it. You can   keep it in your repo, or   add it to OpenTelemetry,   so it will ship with other instrumentation packages.</li> <li>Semantic Conventions are stable, but subject to evolution: while this does   not cause any functional issues, you may need to update your instrumentation   every once in a while. Having it in a preview plugin or in OpenTelemetry   contrib repo may help keeping conventions up-to-date without breaking changes   for your users.</li> </ul>"},{"location":"docs/concepts/instrumentation/libraries/#_3","title":"\u83b7\u53d6\u8ffd\u8e2a\u5668","text":"<p>All application configuration is hidden from your library through the Tracer API. Libraries should obtain tracer from global <code>TracerProvider</code> by default.</p> <pre><code>private static final Tracer tracer = GlobalOpenTelemetry.getTracer(\"demo-db-client\", \"0.1.0-beta1\");\n</code></pre> <p>It's useful for libraries to have an API that allows applications to pass instances of <code>TracerProvider</code> explicitly which enables better dependency injection and simplifies testing.</p> <p>When obtaining the tracer, provide your library (or tracing plugin) name and version - they show up on the telemetry and help users process and filter telemetry, understand where it came from, and debug/report any instrumentation issues.</p>"},{"location":"docs/concepts/instrumentation/libraries/#_4","title":"\u4eea\u5668\u4eea\u8868","text":""},{"location":"docs/concepts/instrumentation/libraries/#public-apis","title":"Public APIs","text":"<p>Public APIs are a good candidates for tracing: spans created for public API calls allow users to map telemetry to application code, understand the duration and outcome of library calls. Which calls to trace:</p> <ul> <li>public methods that make network calls internally or local operations that   take significant time and may fail (e.g. IO)</li> <li>handlers that process requests or messages</li> </ul> <p>Instrumentation example:</p> <pre><code>private static final Tracer tracer = GlobalOpenTelemetry.getTracer(\"demo-db-client\", \"0.1.0-beta1\");\nprivate Response selectWithTracing(Query query) {\n// check out conventions for guidance on span names and attributes\nSpan span = tracer.spanBuilder(String.format(\"SELECT %s.%s\", dbName, collectionName))\n.setSpanKind(SpanKind.CLIENT)\n.setAttribute(\"db.name\", dbName)\n...\n.startSpan();\n// makes span active and allows correlating logs and nest spans\ntry (Scope unused = span.makeCurrent()) {\nResponse response = query.runWithRetries();\nif (response.isSuccessful()) {\nspan.setStatus(StatusCode.OK);\n}\nif (span.isRecording()) {\n// populate response attributes for response codes and other information\n}\n} catch (Exception e) {\nspan.recordException(e);\nspan.setStatus(StatusCode.ERROR, e.getClass().getSimpleName());\nthrow e;\n} finally {\nspan.end();\n}\n}\n</code></pre> <p>Follow conventions to populate attributes! If there is no applicable one, check out general conventions.</p>"},{"location":"docs/concepts/instrumentation/libraries/#nested-network-and-other-spans","title":"Nested network and other spans","text":"<p>Network calls are usually traced with OpenTelemetry auto-instrumentations through corresponding client implementation.</p> <p></p> <p>If OpenTelemetry does not support tracing your network client, use your best judgement, here are some considerations to help:</p> <ul> <li>Would tracing network calls improve observability for users or your ability to   support them?</li> <li>Is your library a wrapper on top of public, documented RPC API? Would users   need to get support from the underlying service in case of issues?</li> <li>instrument the library and make sure to trace individual network tries</li> <li>Would tracing those calls with spans be very verbose? or would it noticeably   impact performance?</li> <li>use logs with verbosity or span events: logs can be correlated to parent     (public API calls), while span events should be set on public API span.</li> <li>if they have to be spans (to carry and propagate unique trace context), put     them behind a configuration option and disable them by default.</li> </ul> <p>If OpenTelemetry already supports tracing your network calls, you probably don't want to duplicate it. There may be some exceptions:</p> <ul> <li>to support users without auto-instrumentation (which may not work in certain   environments or users may have concerns with monkey-patching)</li> <li>to enable custom (legacy) correlation and context propagation protocols with   underlying service</li> <li>enrich RPC spans with absolutely essential library/service-specific   information not covered by auto-instrumentation</li> </ul> <p>WARNING: Generic solution to avoid duplication is under construction \ud83d\udea7.</p>"},{"location":"docs/concepts/instrumentation/libraries/#events","title":"Events","text":"<p>Traces are one kind of signal that your apps can emit. Events (or logs) and traces complement, not duplicate, each other. Whenever you have something that should have a verbosity, logs are a better choice than traces.</p> <p>Chances are that your app uses logging or some similar module already. Your module might already have OpenTelemetry integration -- to find out, see the registry. Integrations usually stamp active trace context on all logs, so users can correlate them.</p> <p>If your language and ecosystem don't have common logging support, use span events to share additional app details. Events maybe more convenient if you want to add attributes as well.</p> <p>As a rule of thumb, use events or logs for verbose data instead of spans. Always attach events to the span instance that your instrumentation created. Avoid using the active span if you can, since you don't control what it refers to.</p>"},{"location":"docs/concepts/instrumentation/libraries/#context-propagation","title":"Context propagation","text":""},{"location":"docs/concepts/instrumentation/libraries/#extracting-context","title":"Extracting context","text":"<p>If you work on a library or a service that receives upstream calls, e.g. a web framework or a messaging consumer, you should extract context from the incoming request/message. OpenTelemetry provides the <code>Propagator</code> API, which hides specific propagation standards and reads the trace <code>Context</code> from the wire. In case of a single response, there is just one context on the wire, which becomes the parent of the new span the library creates.</p> <p>After you create a span, you should pass new trace context to the application code (callback or handler), by making the span active; if possible, you should do this explicitly.</p> <pre><code>// extract the context\nContext extractedContext = propagator.extract(Context.current(), httpExchange, getter);\nSpan span = tracer.spanBuilder(\"receive\")\n.setSpanKind(SpanKind.SERVER)\n.setParent(extractedContext)\n.startSpan();\n// make span active so any nested telemetry is correlated\ntry (Scope unused = span.makeCurrent()) {\nuserCode();\n} catch (Exception e) {\nspan.recordException(e);\nspan.setStatus(StatusCode.ERROR);\nthrow e;\n} finally {\nspan.end();\n}\n</code></pre> <p>Here're the full examples of context extraction in Java, check out OpenTelemetry documentation in your language.</p> <p>In the case of a messaging system, you may receive more than one message at once. Received messages become links on the span you create. Refer to messaging conventions for details (WARNING: messaging conventions are under constructions \ud83d\udea7).</p>"},{"location":"docs/concepts/instrumentation/libraries/#injecting-context","title":"Injecting context","text":"<p>When you make an outbound call, you will usually want to propagate context to the downstream service. In this case, you should create a new span to trace the outgoing call and use <code>Propagator</code> API to inject context into the message. There may be other cases where you might want to inject context, e.g. when creating messages for async processing.</p> <pre><code>Span span = tracer.spanBuilder(\"send\")\n.setSpanKind(SpanKind.CLIENT)\n.startSpan();\n// make span active so any nested telemetry is correlated\n// even network calls might have nested layers of spans, logs or events\ntry (Scope unused = span.makeCurrent()) {\n// inject the context\npropagator.inject(Context.current(), transportLayer, setter);\nsend();\n} catch (Exception e) {\nspan.recordException(e);\nspan.setStatus(StatusCode.ERROR);\nthrow e;\n} finally {\nspan.end();\n}\n</code></pre> <p>Here's the full example of context injection in Java.</p> <p>There might be some exceptions:</p> <ul> <li>downstream service does not support metadata or prohibits unknown fields</li> <li>downstream service does not define correlation protocols. Is it possible that   some future service version will support compatible context propagation?   Inject it!</li> <li>downstream service supports custom correlation protocol.</li> <li>best effort with custom propagator: use OpenTelemetry trace context if     compatible.</li> <li>or generate and stamp custom correlation ids on the span.</li> </ul>"},{"location":"docs/concepts/instrumentation/libraries/#in-process","title":"In-process","text":"<ul> <li>Make your spans active (aka current): it enables correlating spans with   logs and any nested auto-instrumentations.</li> <li>If the library has a notion of context, support optional explicit trace   context propagation in addition to active spans</li> <li>put spans (trace context) created by library in the context explicitly,     document how to access it</li> <li>allow users to pass trace context in your context</li> <li>Within the library, propagate trace context explicitly - active spans may   change during callbacks!</li> <li>capture active context from users on the public API surface as soon as you     can, use it as a parent context for your spans</li> <li>pass context around and stamp attributes, exceptions, events on explicitly     propagated instances</li> <li>this is essential if you start threads explicitly, do background processing     or other things that can break due to async context flow limitations in your     language</li> </ul>"},{"location":"docs/concepts/instrumentation/libraries/#misc","title":"Misc","text":""},{"location":"docs/concepts/instrumentation/libraries/#instrumentation-registry","title":"Instrumentation registry","text":"<p>Please add your instrumentation library to the OpenTelemetry registry, so users can find it.</p>"},{"location":"docs/concepts/instrumentation/libraries/#performance","title":"Performance","text":"<p>OpenTelemetry API is no-op and very performant when there is no SDK in the application. When OpenTelemetry SDK is configured, it consumes bound resources.</p> <p>Real-life applications, especially on the high scale, would frequently have head-based sampling configured. Sampled-out spans are cheap and you can check if the span is recording, to avoid extra allocations and potentially expensive calculations, while populating attributes.</p> <pre><code>// some attributes are important for sampling, they should be provided at creation time\nSpan span = tracer.spanBuilder(String.format(\"SELECT %s.%s\", dbName, collectionName))\n.setSpanKind(SpanKind.CLIENT)\n.setAttribute(\"db.name\", dbName)\n...\n.startSpan();\n// other attributes, especially those that are expensive to calculate\n// should be added if span is recording\nif (span.isRecording()) {\nspan.setAttribute(\"db.statement\", sanitize(query.statement()))\n}\n</code></pre>"},{"location":"docs/concepts/instrumentation/libraries/#error-handling","title":"Error handling","text":"<p>OpenTelemetry API is forgiving at runtime - does not fail on invalid arguments, never throws, and swallows exceptions. This way instrumentation issues do not affect application logic. Test the instrumentation to notice issues OpenTelemetry hides at runtime.</p>"},{"location":"docs/concepts/instrumentation/libraries/#testing","title":"Testing","text":"<p>Since OpenTelemetry has variety of auto-instrumentations, it's useful to try how your instrumentation interacts with other telemetry: incoming requests, outgoing requests, logs, etc. Use a typical application, with popular frameworks and libraries and all tracing enabled when trying out your instrumentation. Check out how libraries similar to yours show up.</p> <p>For unit testing, you can usually mock or fake <code>SpanProcessor</code> and <code>SpanExporter</code>.</p> <pre><code>@Test\npublic void checkInstrumentation() {\nSpanExporter exporter = new TestExporter();\nTracer tracer = OpenTelemetrySdk.builder()\n.setTracerProvider(SdkTracerProvider.builder()\n.addSpanProcessor(SimpleSpanProcessor.create(exporter)).build()).build()\n.getTracer(\"test\");\n// run test ...\nvalidateSpans(exporter.exportedSpans);\n}\nclass TestExporter implements SpanExporter {\npublic final List&lt;SpanData&gt; exportedSpans = Collections.synchronizedList(new ArrayList&lt;&gt;());\n@Override\npublic CompletableResultCode export(Collection&lt;SpanData&gt; spans) {\nexportedSpans.addAll(spans);\nreturn CompletableResultCode.ofSuccess();\n}\n...\n}\n</code></pre>"},{"location":"docs/concepts/instrumentation/manual/","title":"\u624b\u52a8","text":""},{"location":"docs/concepts/instrumentation/manual/#opentelemetry-apisdk","title":"\u5bfc\u5165OpenTelemetry API\u548cSDK","text":"<p>\u9996\u5148\u9700\u8981\u5c06OpenTelemetry\u5bfc\u5165\u5230\u670d\u52a1\u4ee3\u7801\u4e2d\u3002 \u5982\u679c\u60a8\u6b63\u5728\u5f00\u53d1\u4e00\u4e2a\u5e93\u6216\u5176\u4ed6\u6253\u7b97\u7531\u53ef\u8fd0\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\u4f7f\u7528\u7684\u7ec4\u4ef6\uff0c\u90a3\u4e48\u60a8\u53ea\u9700\u8981\u4f9d\u8d56\u4e8eAPI\u3002 \u5982\u679c\u60a8\u7684\u5de5\u4ef6\u662f\u4e00\u4e2a\u72ec\u7acb\u7684\u6d41\u7a0b\u6216\u670d\u52a1\uff0c\u90a3\u4e48\u60a8\u5c06\u4f9d\u8d56\u4e8eAPI\u548cSDK\u3002 \u6709\u5173OpenTelemetry API\u548cSDK\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1specification\u3002</p>"},{"location":"docs/concepts/instrumentation/manual/#opentelemetry-api","title":"\u914d\u7f6eOpenTelemetry API","text":"<p>\u4e3a\u4e86\u521b\u5efa\u8ddf\u8e2a\u6216\u5ea6\u91cf\uff0c\u60a8\u9700\u8981\u9996\u5148\u521b\u5efa\u8ddf\u8e2a\u7a0b\u5e8f\u548c/\u6216\u5ea6\u91cf\u63d0\u4f9b\u7a0b\u5e8f\u3002 \u901a\u5e38\uff0c\u6211\u4eec\u5efa\u8baeSDK\u5e94\u8be5\u4e3a\u8fd9\u4e9b\u5bf9\u8c61\u63d0\u4f9b\u5355\u4e2a\u9ed8\u8ba4\u63d0\u4f9b\u7a0b\u5e8f\u3002 \u7136\u540e\uff0c\u60a8\u5c06\u4ece\u8be5\u63d0\u4f9b\u7a0b\u5e8f\u83b7\u5f97\u8ddf\u8e2a\u7a0b\u5e8f\u6216\u4eea\u8868\u5b9e\u4f8b\uff0c\u5e76\u4e3a\u5176\u63d0\u4f9b\u540d\u79f0\u548c\u7248\u672c\u3002 \u60a8\u5728\u8fd9\u91cc\u9009\u62e9\u7684\u540d\u79f0\u5e94\u8be5\u786e\u5b9a\u8981\u68c0\u6d4b\u7684\u786e\u5207\u5185\u5bb9\u2014\u2014\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u6b63\u5728\u7f16\u5199\u4e00\u4e2a\u5e93\uff0c\u90a3\u4e48\u60a8\u5e94\u8be5\u4ee5\u60a8\u7684\u5e93(\u4f8b\u5982<code>com.legitimatebusiness.myLibrary</code>)\u6765\u547d\u540d\u5b83\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u540d\u79f0\u5c06\u547d\u540d\u751f\u6210\u7684\u6240\u6709\u8de8\u5ea6\u6216\u5ea6\u91cf\u4e8b\u4ef6\u3002 \u8fd8\u5efa\u8bae\u60a8\u63d0\u4f9b\u4e0e\u5e93\u6216\u670d\u52a1\u7684\u5f53\u524d\u7248\u672c\u5bf9\u5e94\u7684\u7248\u672c\u5b57\u7b26\u4e32(\u5373' semver:1.0.0 ')\u3002</p>"},{"location":"docs/concepts/instrumentation/manual/#opentelemetry-sdk","title":"\u914d\u7f6eOpenTelemetry SDK","text":"<p>\u5982\u679c\u60a8\u6b63\u5728\u6784\u5efa\u4e00\u4e2a\u670d\u52a1\u6d41\u7a0b\uff0c\u60a8\u8fd8\u9700\u8981\u4e3aSDK\u914d\u7f6e\u9002\u5f53\u7684\u9009\u9879\uff0c\u4ee5\u4fbf\u5c06\u9065\u6d4b\u6570\u636e\u5bfc\u51fa\u5230\u67d0\u4e2a\u5206\u6790\u540e\u7aef\u3002 \u6211\u4eec\u5efa\u8bae\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u6216\u5176\u4ed6\u673a\u5236\u4ee5\u7f16\u7a0b\u65b9\u5f0f\u5904\u7406\u6b64\u914d\u7f6e\u3002 \u60a8\u53ef\u80fd\u8fd8\u5e0c\u671b\u5229\u7528\u4e0d\u540c\u8bed\u8a00\u7684\u8c03\u4f18\u9009\u9879\u3002</p>"},{"location":"docs/concepts/instrumentation/manual/#_1","title":"\u521b\u5efa\u9065\u6d4b\u6570\u636e","text":"<p>\u914d\u7f6e\u597dAPI\u548cSDK\u4e4b\u540e\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u8fc7\u4ece\u63d0\u4f9b\u7a0b\u5e8f\u83b7\u5f97\u7684\u8ddf\u8e2a\u5668\u548c\u5ea6\u91cf\u5bf9\u8c61\u81ea\u7531\u5730\u521b\u5efa\u8ddf\u8e2a\u548c\u5ea6\u91cf\u4e8b\u4ef6\u3002 \u4e3a\u4f60\u7684\u4f9d\u8d56\u9879\u4f7f\u7528\u5de5\u5177\u5e93\u2014\u2014\u67e5\u770bregistry\u6216\u4f60\u7684\u8bed\u8a00\u7684\u5b58\u50a8\u5e93\uff0c\u4e86\u89e3\u66f4\u591a\u76f8\u5173\u4fe1\u606f\u3002</p>"},{"location":"docs/concepts/instrumentation/manual/#_2","title":"\u51fa\u53e3\u6570\u636e","text":"<p>\u4e00\u65e6\u60a8\u521b\u5efa\u4e86\u9065\u6d4b\u6570\u636e\uff0c\u60a8\u5c06\u5e0c\u671b\u5c06\u5176\u53d1\u9001\u5230\u67d0\u4e2a\u5730\u65b9\u3002 OpenTelemetry\u652f\u6301\u5c06\u6570\u636e\u4ece\u8fdb\u7a0b\u5bfc\u51fa\u5230\u5206\u6790\u540e\u7aef\u7684\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\uff0c\u8981\u4e48\u76f4\u63a5\u4ece\u8fdb\u7a0b\u5bfc\u51fa\uff0c\u8981\u4e48\u901a\u8fc7OpenTelemetry Collector\u8fdb\u884c\u4ee3\u7406\u3002</p> <p>\u8fdb\u7a0b\u5185\u5bfc\u51fa\u9700\u8981\u60a8\u5bfc\u5165\u5e76\u4f9d\u8d56\u4e8e\u4e00\u4e2a\u6216\u591a\u4e2a exporters\uff0c\u8fd9\u4e9b\u5e93\u5c06OpenTelemetry\u7684\u5185\u5b58\u8de8\u5ea6\u548c\u5ea6\u91cf\u5bf9\u8c61\u8f6c\u6362\u4e3a\u9002\u5408Jaeger\u6216Prometheus\u7b49\u9065\u6d4b\u5206\u6790\u5de5\u5177\u7684\u683c\u5f0f\u3002 \u6b64\u5916\uff0cOpenTelemetry\u8fd8\u652f\u6301\u4e00\u79cd\u540d\u4e3a\u201cOTLP\u201d\u7684\u6709\u7ebf\u534f\u8bae\uff0c\u6240\u6709OpenTelemetry sdk\u90fd\u652f\u6301\u8be5\u534f\u8bae\u3002 \u8be5\u534f\u8bae\u53ef\u7528\u4e8e\u5411OpenTelemetry Collector\u53d1\u9001\u6570\u636e\uff0cOpenTelemetry Collector\u662f\u4e00\u4e2a\u72ec\u7acb\u7684\u4e8c\u8fdb\u5236\u8fdb\u7a0b\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u670d\u52a1\u5b9e\u4f8b\u7684\u4ee3\u7406\u6216\u4fa7\u8f66\u8fd0\u884c\uff0c\u4e5f\u53ef\u4ee5\u5728\u5355\u72ec\u7684\u4e3b\u673a\u4e0a\u8fd0\u884c\u3002 \u7136\u540e\u53ef\u4ee5\u914d\u7f6eCollector\u6765\u8f6c\u53d1\u548c\u5bfc\u51fa\u8be5\u6570\u636e\u5230\u60a8\u9009\u62e9\u7684\u5206\u6790\u5de5\u5177\u3002</p> <p>\u9664\u4e86\u50cfJaeger\u6216Prometheus\u8fd9\u6837\u7684\u5f00\u6e90\u5de5\u5177\u4e4b\u5916\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u516c\u53f8\u652f\u6301\u4eceOpenTelemetry\u83b7\u53d6\u9065\u6d4b\u6570\u636e\u3002 \u8be6\u60c5\u8bf7\u53c2\u89c1vendor\u3002</p>"},{"location":"docs/concepts/sampling/","title":"\u91c7\u6837","text":"<p>\u4f7f\u7528\u5206\u5e03\u5f0f\u8ddf\u8e2a\uff0c\u60a8\u53ef\u4ee5\u89c2\u5bdf\u8bf7\u6c42\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4ece\u4e00\u4e2a\u670d\u52a1\u79fb\u52a8\u5230\u53e6\u4e00\u4e2a\u670d\u52a1\u7684\u8fc7\u7a0b\u3002 \u5b83\u975e\u5e38\u5b9e\u7528\uff0c\u539f\u56e0\u6709\u5f88\u591a\uff0c\u6bd4\u5982\u7406\u89e3\u60a8\u7684\u670d\u52a1\u8fde\u63a5\u548c\u8bca\u65ad\u5ef6\u8fdf\u95ee\u9898\uff0c\u8fd8\u6709\u8bb8\u591a\u5176\u4ed6\u597d\u5904\u3002</p> <p>However, if the majority of all your requests are successful 200s and finish without unacceptable latency or errors, do you really need all that data? Here\u2019s the thing\u2014you don\u2019t always need a ton of data to find the right insights. You just need the right sampling of data.</p> <p></p> <p>The idea behind sampling is to control the spans you send to your observability backend, resulting in lower ingest costs. Different organizations will have their own reasons for not just why they want to sample, but also what they want to sample. You might want to customize your sampling strategy to:</p> <ul> <li>Manage costs: If you have a high volume of telemetry, you risk incurring   heavy charges from a telemetry backend vendor or cloud provider to export and   store every span.</li> <li>Focus on interesting traces: For example, your frontend team may only want   to see traces with specific user attributes.</li> <li>Filter out noise: For example, you may want to filter out health checks.</li> </ul>"},{"location":"docs/concepts/sampling/#_1","title":"\u672f\u8bed","text":"<p>It's important to use consistent terminology when discussing sampling. A trace or span is considered \"sampled\" or \"not sampled\":</p> <ul> <li>Sampled: A trace or span is processed and exported. Because it is chosen   by the sampler as a representative of the population, it is considered   \"sampled\".</li> <li>Not sampled: A trace or span is not processed or exported. Because it is   not chosen by the sampler, it is considered \"not sampled\".</li> </ul> <p>Sometimes, the definitions of these terms get mixed up. You may find someone state that they are \"sampling out data\" or that data not processed or exported is considered \"sampled\". These are incorrect statements.</p>"},{"location":"docs/concepts/sampling/#_2","title":"\u5934\u62bd\u6837","text":"<p>Head sampling is a sampling technique used to make a sampling decision as early as possible. A decision to sample or drop a span or trace is not made by inspecting the trace as a whole.</p> <p>For example, the most common form of head sampling is Consistent Probability Sampling. It may also be referred to as Deterministic Sampling. In this case, a sampling decision is made based on the trace ID and a desired percentage of traces to sample. This ensures that whole traces are sampled - no missing spans - at a consistent rate, such as 5% of all traces.</p> <p>The upsides to head sampling are:</p> <ul> <li>Easy to understand</li> <li>Easy to configure</li> <li>Efficient</li> <li>Can be done at any point in the trace collection pipeline</li> </ul> <p>The primary downside to head sampling is that it is not possible make a sampling decision based on data in the entire trace. This means that head sampling is effective as a blunt instrument, but is wholly insufficient for sampling strategies that must take whole-system information into account. For example, it is not possible to use head sampling to ensure that all traces with an error within them are sampled. For this, you need Tail Sampling.</p>"},{"location":"docs/concepts/sampling/#_3","title":"\u5c3e\u5df4\u62bd\u6837","text":"<p>Tail sampling is where the decision to sample a trace takes place by considering all or most of the spans within the trace. Tail Sampling gives you the option to sample your traces based on specific criteria derived from different parts of a trace, which isn\u2019t an option with Head Sampling.</p> <p></p> <p>Some examples of how you can use Tail Sampling include:</p> <ul> <li>Always sampling traces that contain an error</li> <li>Sampling traces based on overall latency</li> <li>Sampling traces based on the presence or value of specific attributes on one   or more spans in a trace; for example, sampling more traces originating from a   newly deployed service</li> <li>Applying different sampling rates to traces based on certain criteria</li> </ul> <p>As you can see, tail sampling allows for a much higher degree of sophistication. For larger systems that must sample telemetry, it is almost always necessary to use Tail Sampling to balance data volume with usefulness of that data.</p> <p>There are three primary downsides to tail sampling today:</p> <ul> <li>Tail sampling can be difficult to implement. Depending on the kind of sampling   techniques available to you, it is not always a \"set and forget\" kind of   thing. As your systems change, so too will your sampling strategies. For a   large and sophisticated distributed system, rules that implement sampling   strategies can also be large and sophisticated.</li> <li>Tail sampling can be difficult to operate. The component(s) that implement   tail sampling must be stateful systems that can accept and store a large   amount of data. Depending on traffic patterns, this can require dozens or even   hundreds of nodes that all utilize resources differently. Furthermore, a tail   sampler may need to \"fall back\" to less computationally-intensive sampling   techniques if it is unable to keep up with the volume of data it is receiving.   Because of these factors, it is critical to monitor tail sampling components   to ensure that they have the resources they need to make the correct sampling   decisions.</li> <li>Tail samplers often end up being in the domain of vendor-specific technology   today. If you're using a paid vendor for Observability, the most effective   tail sampling options available to you may be limited to what the vendor   offers.</li> </ul> <p>Finally, for some systems, tail sampling may be used in conjunction with Head Sampling. For example, a set of services that produce an extremely high volume of trace data may first use head sampling to only sample a small percentage of traces, and then later in the telemetry pipeline use tail sampling to make more sophisticated sampling decisions before exporting to a backend. This is often done in the interest of protecting the telemetry pipeline from being overloaded.</p>"},{"location":"docs/concepts/sdk-configuration/_index/","title":"SDK \u914d\u7f6e","text":"<p>OpenTelemetry sdk\u652f\u6301\u6bcf\u79cd\u8bed\u8a00\u548c\u73af\u5883\u53d8\u91cf\u7684\u914d\u7f6e\u3002 \u4e0b\u9762\u7684\u9875\u9762\u63cf\u8ff0\u4e86\u53ef\u7528\u4e8e\u914d\u7f6eSDK\u7684\u73af\u5883\u53d8\u91cf\u3002 \u4f7f\u7528\u73af\u5883\u53d8\u91cf\u8bbe\u7f6e\u7684\u503c\u8986\u76d6\u5728\u4f7f\u7528SDK api\u7684\u4ee3\u7801\u4e2d\u5b8c\u6210\u7684\u7b49\u6548\u914d\u7f6e\u3002</p>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/","title":"\u901a\u7528SDK\u914d\u7f6e","text":""},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_service_name","title":"<code>OTEL_SERVICE_NAME</code>","text":"<p>\u8bbe\u7f6e' service.name '\u8d44\u6e90\u5c5e\u6027\u7684\u503c\u3002</p> <p>Default value: <code>\"unknown_service\"</code></p> <p>If <code>service.name</code> is also provided in <code>OTEL_RESOURCE_ATTRIBUTES</code>, then <code>OTEL_SERVICE_NAME</code> takes precedence.</p> <p>Example:</p> <p><code>export OTEL_SERVICE_NAME=\"your-service-name\"</code></p>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_resource_attributes","title":"<code>OTEL_RESOURCE_ATTRIBUTES</code>","text":"<p>Key-value pairs to be used as resource attributes. See Resource SDK for more details.</p> <p>Default value: Empty.</p> <p>See Resource semantic conventions for semantic conventions to follow for common resource types.</p> <p>Example:</p> <p><code>export OTEL_RESOURCE_ATTRIBUTES=\"key1=value1,key2=value2\"</code></p>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_traces_sampler","title":"<code>OTEL_TRACES_SAMPLER</code>","text":"<p>Specifies the Sampler used to sample traces by the SDK.</p> <p>Default value: <code>\"parentbased_always_on\"</code></p> <p>Example:</p> <p><code>export OTEL_TRACES_SAMPLER=\"traceidratio\"</code></p> <p>Accepted values for <code>OTEL_TRACES_SAMPLER</code> are:</p> <ul> <li><code>\"always_on\"</code>: <code>AlwaysOnSampler</code></li> <li><code>\"always_off\"</code>: <code>AlwaysOffSampler</code></li> <li><code>\"traceidratio\"</code>: <code>TraceIdRatioBased</code></li> <li><code>\"parentbased_always_on\"</code>: <code>ParentBased(root=AlwaysOnSampler)</code></li> <li><code>\"parentbased_always_off\"</code>: <code>ParentBased(root=AlwaysOffSampler)</code></li> <li><code>\"parentbased_traceidratio\"</code>: <code>ParentBased(root=TraceIdRatioBased)</code></li> <li><code>\"parentbased_jaeger_remote\"</code>: <code>ParentBased(root=JaegerRemoteSampler)</code></li> <li><code>\"jaeger_remote\"</code>: <code>JaegerRemoteSampler</code></li> <li><code>\"xray\"</code>:   AWS X-Ray Centralized Sampling   (third party)</li> </ul>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_traces_sampler_arg","title":"<code>OTEL_TRACES_SAMPLER_ARG</code>","text":"<p>Specifies arguments, if applicable, to the sampler defined in by <code>OTEL_TRACES_SAMPLER</code>. The specified value will only be used if <code>OTEL_TRACES_SAMPLER</code> is set. Each Sampler type defines its own expected input, if any. Invalid or unrecognized input is logged as an error.</p> <p>Default value: Empty.</p> <p>Example:</p> <pre><code>export OTEL_TRACES_SAMPLER=\"traceidratio\"\nexport OTEL_TRACES_SAMPLER_ARG=\"0.5\"\n</code></pre> <p>Depending on the value of <code>OTEL_TRACES_SAMPLER</code>, <code>OTEL_TRACES_SAMPLER_ARG</code> may be set as follows:</p> <ul> <li>For <code>traceidratio</code> and <code>parentbased_traceidratio</code> samplers: Sampling   probability, a number in the [0..1] range, e.g. \"0.25\". Default is 1.0 if   unset.</li> <li>For <code>jaeger_remote</code> and <code>parentbased_jaeger_remote</code>: The value is a comma   separated list:</li> <li>Example:     <code>\"endpoint=http://localhost:14250,pollingIntervalMs=5000,initialSamplingRate=0.25\"</code></li> <li><code>endpoint</code>: the endpoint in form of <code>scheme://host:port</code> of gRPC server that     serves the sampling strategy for the service     (sampling.proto).</li> <li><code>pollingIntervalMs</code>: in milliseconds indicating how often the sampler will     poll the backend for updates to sampling strategy.</li> <li><code>initialSamplingRate</code>: in the [0..1] range, which is used as the sampling     probability when the backend cannot be reached to retrieve a sampling     strategy. This value stops having an effect once a sampling strategy is     retrieved successfully, as the remote strategy will be used until a new     update is retrieved.</li> </ul>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_propagators","title":"<code>OTEL_PROPAGATORS</code>","text":"<p>Specifies Propagators to be used in a comma-separated list.</p> <p>Default value: `\"tracecontext,baggage\"</p> <p>Example:</p> <p><code>export OTEL_PROPAGATORS=\"b3\"</code></p> <p>Accepted values for <code>OTEL_PROPAGATORS</code> are:</p> <ul> <li><code>\"tracecontext\"</code>: W3C Trace Context</li> <li><code>\"baggage\"</code>: W3C Baggage</li> <li><code>\"b3\"</code>: B3 Single</li> <li><code>\"b3multi\"</code>:   B3 Multi</li> <li><code>\"jaeger\"</code>:   Jaeger</li> <li><code>\"xray\"</code>:   AWS X-Ray   (third party)</li> <li><code>\"ottrace\"</code>:   OT Trace (third   party)</li> <li><code>\"none\"</code>: No automatically configured propagator.</li> </ul>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_traces_exporter","title":"<code>OTEL_TRACES_EXPORTER</code>","text":"<p>Specifies which exporter is used for traces.</p> <p>Default value: <code>\"otlp\"</code></p> <p>Example:</p> <p><code>export OTEL_TRACES_EXPORTER=\"jaeger\"</code></p> <p>Accepted values for are:</p> <ul> <li><code>\"otlp\"</code>: OTLP</li> <li><code>\"jaeger\"</code>: export in Jaeger data model</li> <li><code>\"zipkin\"</code>: Zipkin</li> <li><code>\"none\"</code>: No automatically configured exporter for traces.</li> </ul>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_metrics_exporter","title":"<code>OTEL_METRICS_EXPORTER</code>","text":"<p>Specifies which exporter is used for metrics.</p> <p>Default value: <code>\"otlp\"</code></p> <p>Example:</p> <p><code>export OTEL_METRICS_EXPORTER=\"prometheus\"</code></p> <p>Accepted values for <code>OTEL_METRICS_EXPORTER</code> are:</p> <ul> <li><code>\"otlp\"</code>: OTLP</li> <li><code>\"prometheus\"</code>:   Prometheus</li> <li><code>\"none\"</code>: No automatically configured exporter for metrics.</li> </ul>"},{"location":"docs/concepts/sdk-configuration/general-sdk-configuration/#otel_logs_exporter","title":"<code>OTEL_LOGS_EXPORTER</code>","text":"<p>Specifies which exporter is used for logs.</p> <p>Default value: <code>\"otlp\"</code></p> <p>Example:</p> <p><code>export OTEL_LOGS_EXPORTER=\"otlp\"</code></p> <p>Accepted values for <code>OTEL_LOGS_EXPORTER</code> are:</p> <ul> <li><code>\"otlp\"</code>: OTLP</li> <li><code>\"none\"</code>: No automatically configured exporter for logs.</li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/","title":"OTLP\u5bfc\u51fa\u914d\u7f6e","text":""},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#endpoint-configuration","title":"Endpoint Configuration","text":"<p>The following environment variables let you configure an OTLP/gRPC or OTLP/HTTP endpoint for your traces, metrics, and logs.</p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_endpoint","title":"<code>OTEL_EXPORTER_OTLP_ENDPOINT</code>","text":"<p>A base endpoint URL for any signal type, with an optionally-specified port number. Helpful for when you're sending more than one signal to the same endpoint and want one environment variable to control the endpoint.</p> <p>Default value:</p> <ul> <li>gRPC: <code>\"http://localhost:4317\"</code></li> <li>HTTP: <code>\"http://localhost:4318\"</code></li> </ul> <p>Example:</p> <ul> <li>gRPC: <code>export OTEL_EXPORTER_OTLP_ENDPOINT=\"my-api-endpoint:443\"</code></li> <li>HTTP: <code>export OTEL_EXPORTER_OTLP_ENDPOINT=\"http://my-api-endpoint/\"</code></li> </ul> <p>For OTLP/HTTP, exporters in the SDK construct signal-specific URLs when this environment variable is set. This means that if you're sending traces, metrics, and logs, the following URLs are constructed from the example above:</p> <ul> <li>Traces: <code>\"http://my-api-endpoint/v1/traces\"</code></li> <li>Metrics: <code>\"http://my-api-endpoint/v1/metrics\"</code></li> <li>Logs: <code>\"http://my-api-endpoint/v1/logs\"</code></li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_traces_endpoint","title":"<code>OTEL_EXPORTER_OTLP_TRACES_ENDPOINT</code>","text":"<p>Endpoint URL for trace data only, with an optionally-specified port number. Must end with <code>v1/traces</code> if using OTLP/HTTP.</p> <p>Default value:</p> <ul> <li>gRPC: <code>\"http://localhost:4317\"</code></li> <li>HTTP: <code>\"http://localhost:4318/v1/traces\"</code></li> </ul> <p>Example:</p> <ul> <li>gRPC: <code>export OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=\"my-api-endpoint:443\"</code></li> <li>HTTP:   <code>export OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=\"http://my-api-endpoint/v1/traces\"</code></li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_metrics_endpoint","title":"<code>OTEL_EXPORTER_OTLP_METRICS_ENDPOINT</code>","text":"<p>Endpoint URL for metric data only, with an optionally-specified port number. Must end with <code>v1/metrics</code> if using OTLP/HTTP.</p> <p>Default value:</p> <ul> <li>gRPC: <code>\"http://localhost:4317\"</code></li> <li>HTTP: <code>\"http://localhost:4318/v1/metrics\"</code></li> </ul> <p>Example:</p> <ul> <li>gRPC: <code>export OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=\"my-api-endpoint:443\"</code></li> <li>HTTP:   <code>export OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=\"http://my-api-endpoint/v1/metrics\"</code></li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_logs_endpoint","title":"<code>OTEL_EXPORTER_OTLP_LOGS_ENDPOINT</code>","text":"<p>Endpoint URL for log data only, with an optionally-specified port number. Must end with <code>v1/logs</code> if using OTLP/HTTP.</p> <p>Default value:</p> <ul> <li>gRPC: <code>\"http://localhost:4317\"</code></li> <li>HTTP: <code>\"http://localhost:4318/v1/logs\"</code></li> </ul> <p>Example:</p> <ul> <li>gRPC: <code>export OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=\"my-api-endpoint:443\"</code></li> <li>HTTP:   <code>export OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=\"http://my-api-endpoint/v1/logs\"</code></li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#header-configuration","title":"Header configuration","text":"<p>The following environment variables let you configure additional headers as a list of key-value pairs to add in outgoing gRPC or HTTP requests.</p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_headers","title":"<code>OTEL_EXPORTER_OTLP_HEADERS</code>","text":"<p>A list of headers to apply to all outgoing data (traces, metrics, and logs).</p> <p>Default value: N/A</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_HEADERS=\"api-key=key,other-config-value=value\"</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_traces_headers","title":"<code>OTEL_EXPORTER_OTLP_TRACES_HEADERS</code>","text":"<p>A list of headers to apply to all outgoing traces.</p> <p>Default value: N/A</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_TRACES_HEADERS=\"api-key=key,other-config-value=value\"</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_metrics_headers","title":"<code>OTEL_EXPORTER_OTLP_METRICS_HEADERS</code>","text":"<p>A list of headers to apply to all outgoing metrics.</p> <p>Default value: N/A</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_METRICS_HEADERS=\"api-key=key,other-config-value=value\"</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_logs_headers","title":"<code>OTEL_EXPORTER_OTLP_LOGS_HEADERS</code>","text":"<p>A list of headers to apply to all outgoing logs.</p> <p>Default value: N/A</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_LOGS_HEADERS=\"api-key=key,other-config-value=value\"</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#timeout-configuration","title":"Timeout Configuration","text":"<p>The following environment variables configure the maximum time (in milliseconds) an OTLP Exporter will wait before transmitting the net batch of data.</p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_timeout","title":"<code>OTEL_EXPORTER_OTLP_TIMEOUT</code>","text":"<p>The timeout value for all outgoing data (traces, metrics, and logs) in milliseconds.</p> <p>Default value: <code>10000</code> (10s)</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_TIMEOUT=500</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_traces_timeout","title":"<code>OTEL_EXPORTER_OTLP_TRACES_TIMEOUT</code>","text":"<p>The timeout value for all outgoing traces in milliseconds.</p> <p>Default value: 10000 (10s)</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_TRACES_TIMEOUT=500</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_metrics_timeout","title":"<code>OTEL_EXPORTER_OTLP_METRICS_TIMEOUT</code>","text":"<p>The timeout value for all outgoing metrics in milliseconds.</p> <p>Default value: 10000 (10s)</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_METRICS_TIMEOUT=500</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_logs_timeout","title":"<code>OTEL_EXPORTER_OTLP_LOGS_TIMEOUT</code>","text":"<p>The timeout value for all outgoing logs in milliseconds.</p> <p>Default value: 10000 (10s)</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_LOGS_TIMEOUT=500</code></p>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_protocol","title":"<code>OTEL_EXPORTER_OTLP_PROTOCOL</code>","text":"<p>Specifies the OTLP transport protocol to be used for all telemetry data.</p> <p>Default value: SDK-dependent, but will typically be either <code>http/protobuf</code> or <code>grpc</code>.</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_PROTOCOL=grpc</code></p> <p>Valid values are:</p> <ul> <li><code>grpc</code> to use OTLP/gRPC</li> <li><code>http/protobuf</code> to use OTLP/HTTP + protobuf</li> <li><code>http/json</code> to use OTLP/HTTP + json</li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_traces_protocol","title":"<code>OTEL_EXPORTER_OTLP_TRACES_PROTOCOL</code>","text":"<p>Specifies the OTLP transport protocol to be used for trace data.</p> <p>Default value: SDK-dependent, but will typically be either <code>http/protobuf</code> or <code>grpc</code>.</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_TRACES_PROTOCOL=grpc</code></p> <p>Valid values are:</p> <ul> <li><code>grpc</code> to use OTLP/gRPC</li> <li><code>http/protobuf</code> to use OTLP/HTTP + protobuf</li> <li><code>http/json</code> to use OTLP/HTTP + json</li> </ul>"},{"location":"docs/concepts/sdk-configuration/otlp-exporter-configuration/#otel_exporter_otlp_metrics_protocol","title":"<code>OTEL_EXPORTER_OTLP_METRICS_PROTOCOL</code>","text":"<p>Specifies the OTLP transport protocol to be used for metrics data.</p> <p>Default value: SDK-dependent, but will typically be either <code>http/protobuf</code> or <code>grpc</code>.</p> <p>Example: <code>export OTEL_EXPORTER_OTLP_METRICS_PROTOCOL=grpc</code></p> <p>Valid values are:</p> <ul> <li><code>grpc</code> to use OTLP/gRPC</li> <li><code>http/protobuf</code> to use OTLP/HTTP + protobuf</li> <li><code>http/json</code> to use OTLP/HTTP + json</li> </ul>"},{"location":"docs/concepts/signals/_index/","title":"\u4fe1\u53f7","text":"<p>\u5728\u5f00\u653e\u5f0f\u9065\u6d4b\u4e2d\uff0c\u4e00\u4e2a \u4fe1\u53f7 \u8868\u793a\u9065\u6d4b\u7684\u4e00\u4e2a\u7c7b\u522b\u3002 \u672c\u8282\u5c06\u7b80\u8981\u4ecb\u7ecd\u5f53\u524d\u652f\u6301\u7684\u4fe1\u53f7\u3002</p>"},{"location":"docs/concepts/signals/baggage/","title":"Baggage","text":"<p>\u5728OpenTelemetry\u4e2d\uff0c\u5305\u88b1\u662f\u5728\u8de8\u5ea6\u4e4b\u95f4\u4f20\u9012\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002 \u5b83\u662f\u4e00\u4e2a\u952e\u503c\u5b58\u50a8\uff0c\u4f4d\u4e8e\u8ddf\u8e2a\u4e2d\u7684\u8de8\u5ea6\u4e0a\u4e0b\u6587\u65c1\u8fb9\uff0c\u4f7f\u8be5\u8ddf\u8e2a\u4e2d\u521b\u5efa\u7684\u4efb\u4f55\u8de8\u5ea6\u90fd\u53ef\u4ee5\u4f7f\u7528\u503c\u3002</p> <p>\u4f8b\u5982\uff0c\u5047\u8bbe\u60a8\u5e0c\u671b\u5728\u8ddf\u8e2a\u4e2d\u7684\u6bcf\u4e2aspan\u4e0a\u90fd\u6709\u4e00\u4e2a' CustomerId '\u5c5e\u6027\uff0c\u5176\u4e2d\u6d89\u53ca\u591a\u4e2a\u670d\u52a1;\u7136\u800c\uff0c' CustomerId '\u53ea\u5728\u4e00\u4e2a\u7279\u5b9a\u7684\u670d\u52a1\u4e2d\u53ef\u7528\u3002 \u4e3a\u4e86\u5b9e\u73b0\u60a8\u7684\u76ee\u6807\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u5f00\u653e\u9065\u6d4b\u884c\u674e\u5728\u60a8\u7684\u7cfb\u7edf\u4e2d\u4f20\u64ad\u8fd9\u4e2a\u503c\u3002</p> <p>OpenTelemetry\u4f7f\u7528Context Propagation\u6765\u4f20\u9012\u5305\u88b1\uff0c\u6bcf\u4e2a\u4e0d\u540c\u7684\u5e93\u5b9e\u73b0\u90fd\u6709\u4f20\u64ad\u5668\u6765\u89e3\u6790\u5e76\u4f7f\u5305\u88b1\u53ef\u7528\uff0c\u800c\u4e0d\u9700\u8981\u663e\u5f0f\u5730\u5b9e\u73b0\u5b83\u3002</p> <p></p>"},{"location":"docs/concepts/signals/baggage/#otel-baggage","title":"OTel Baggage \u4e3a\u4ec0\u4e48\u5b58\u5728?","text":"<p>\u5305\u88b1\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u5f0f\u6765\u5b58\u50a8\u548c\u8de8\u8ddf\u8e2a\u548c\u5176\u4ed6\u4fe1\u53f7\u4f20\u64ad\u4fe1\u606f\u3002 \u4f8b\u5982\uff0c\u60a8\u53ef\u80fd\u5e0c\u671b\u5c06\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7684\u4fe1\u606f\u9644\u52a0\u5230\u4e00\u4e2aspan\u4e0a\uff0c\u5e76\u5728\u5f88\u4e45\u4ee5\u540e\u68c0\u7d22\u8be5\u4fe1\u606f\uff0c\u7136\u540e\u5c06\u5176\u7528\u4e8e\u53e6\u4e00\u4e2aspan\u3002 \u7136\u800c\uff0cOpenTelemetry\u4e2d\u7684span\u5728\u521b\u5efa\u540e\u662f\u4e0d\u53ef\u53d8\u7684\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u4ee5\u540e\u9700\u8981\u5b83\u4eec\u7684\u4fe1\u606f\u4e4b\u524d\u5bfc\u51fa\u3002 \u901a\u8fc7\u63d0\u4f9b\u5b58\u50a8\u548c\u68c0\u7d22\u4fe1\u606f\u7684\u4f4d\u7f6e\uff0c\u5305\u88b1\u5141\u8bb8\u60a8\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002</p>"},{"location":"docs/concepts/signals/baggage/#otel","title":"OTel\u884c\u674e\u5e94\u8be5\u7528\u6765\u505a\u4ec0\u4e48?","text":"<p>OTel luggage\u5e94\u8be5\u7528\u4e8e\u90a3\u4e9b\u4f60\u4e0d\u4ecb\u610f\u66b4\u9732\u7ed9\u4efb\u4f55\u68c0\u67e5\u4f60\u7f51\u7edc\u6d41\u91cf\u7684\u4eba\u7684\u6570\u636e\u3002 \u8fd9\u662f\u56e0\u4e3a\u5b83\u4e0e\u5f53\u524d\u4e0a\u4e0b\u6587\u4e00\u8d77\u5b58\u50a8\u5728HTTP\u6807\u5934\u4e2d\u3002 \u5982\u679c\u60a8\u7684\u76f8\u5173\u7f51\u7edc\u6d41\u91cf\u5b8c\u5168\u5728\u60a8\u81ea\u5df1\u7684\u7f51\u7edc\u4e2d\uff0c\u5219\u6b64\u8b66\u544a\u53ef\u80fd\u4e0d\u9002\u7528\u3002</p> <p>\u5e38\u89c1\u7684\u7528\u4f8b\u5305\u62ec\u53ea\u80fd\u5728\u5806\u6808\u4e2d\u66f4\u4e0a\u5c42\u8bbf\u95ee\u7684\u4fe1\u606f\u3002 \u4f8b\u5982\uff0c\u8fd9\u53ef\u4ee5\u5305\u62ec\u5e10\u6237\u6807\u8bc6\u3001\u7528\u6237id\u3001\u4ea7\u54c1id\u548c\u539f\u59cbip\u7b49\u5185\u5bb9\u3002 \u5c06\u8fd9\u4e9b\u4fe1\u606f\u4f20\u9012\u5230\u4f60\u7684\u5806\u6808\u4e2d\uff0c\u4f60\u5c31\u53ef\u4ee5\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230\u4e0b\u6e38\u670d\u52a1\u7684span\u4e2d\uff0c\u8fd9\u6837\u5f53\u4f60\u5728\u53ef\u89c2\u5bdf\u6027\u540e\u7aef\u8fdb\u884c\u641c\u7d22\u65f6\uff0c\u5c31\u53ef\u4ee5\u66f4\u5bb9\u6613\u5730\u8fdb\u884c\u8fc7\u6ee4\u3002</p> <p>\u6ca1\u6709\u5185\u7f6e\u7684\u5b8c\u6574\u6027\u68c0\u67e5\u6765\u786e\u4fdd\u884c\u674e\u9879\u76ee\u662f\u60a8\u7684\uff0c\u56e0\u6b64\u5728\u68c0\u7d22\u5b83\u4eec\u65f6\u8981\u5c0f\u5fc3\u3002</p> <p></p>"},{"location":"docs/concepts/signals/baggage/#span","title":"\u884c\u674e\u4e0eSpan\u5c5e\u6027\u4e0d\u540c","text":"<p>\u5173\u4e8e\u201c\u5305\u88b1\u201d\u9700\u8981\u6ce8\u610f\u7684\u91cd\u8981\u4e00\u70b9\u662f\uff0c\u5b83\u4e0d\u662fSpan Attributes\u7684\u5b50\u96c6\u3002 \u5f53\u60a8\u5c06\u67d0\u4e9b\u5185\u5bb9\u6dfb\u52a0\u4e3a\u5305\u88b1\u65f6\uff0c\u5b83\u4e0d\u4f1a\u81ea\u52a8\u7ed3\u675f\u5728\u5b50\u7cfb\u7edf\u7684\u8de8\u7684Attributes\u4e2d\u3002 \u60a8\u5fc5\u987b\u663e\u5f0f\u5730\u4ece\u5305\u88b1\u4e2d\u53d6\u51fa\u4e00\u4e9b\u4e1c\u897f\uff0c\u5e76\u5c06\u5176\u9644\u52a0\u4e3aAttributes\u3002</p> <p>\u4f8b\u5982\uff0c\u5728.net\u4e2d\u4f60\u53ef\u4ee5\u8fd9\u6837\u505a:</p> <pre><code>var accountId = Baggage.GetBaggage(\"AccountId\");\nActivity.Current?.SetTag(\"AccountId\", accountId);\n</code></pre> <p>\u6b32\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u884c\u674e\u89c4\u683c.</p>"},{"location":"docs/concepts/signals/logs/","title":"Logs","text":"<p>**log**\u662f\u5e26\u6709\u65f6\u95f4\u6233\u7684\u6587\u672c\u8bb0\u5f55\uff0c\u53ef\u4ee5\u662f\u7ed3\u6784\u5316\u7684(\u63a8\u8350)\uff0c\u4e5f\u53ef\u4ee5\u662f\u975e\u7ed3\u6784\u5316\u7684\uff0c\u5e26\u6709\u5143\u6570\u636e\u3002 \u867d\u7136\u65e5\u5fd7\u662f\u72ec\u7acb\u7684\u6570\u636e\u6e90\uff0c\u4f46\u5b83\u4eec\u4e5f\u53ef\u4ee5\u9644\u52a0\u5230\u8de8\u5ea6\u4e0a\u3002 \u5728OpenTelemetry\u4e2d\uff0c\u4efb\u4f55\u4e0d\u5c5e\u4e8e\u5206\u5e03\u5f0f\u8ddf\u8e2a\u6216\u5ea6\u91cf\u7684\u6570\u636e\u90fd\u662f\u65e5\u5fd7\u3002 \u4f8b\u5982\uff0cevents \u662f\u4e00\u79cd\u7279\u5b9a\u7c7b\u578b\u7684\u65e5\u5fd7\u3002 \u65e5\u5fd7\u901a\u5e38\u7528\u4e8e\u786e\u5b9a\u95ee\u9898\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u4e14\u901a\u5e38\u5305\u542b\u5173\u4e8e\u8c01\u66f4\u6539\u4e86\u4ec0\u4e48\u4ee5\u53ca\u66f4\u6539\u7684\u7ed3\u679c\u7684\u4fe1\u606f\u3002</p> <p>\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u65e5\u5fd7\u89c4\u8303.</p>"},{"location":"docs/concepts/signals/metrics/","title":"Metrics","text":"<p>metric \u662f\u5173\u4e8e\u670d\u52a1\u7684\u5ea6\u91cf\uff0c\u5728\u8fd0\u884c\u65f6\u6355\u83b7\u3002 \u4ece\u903b\u8f91\u4e0a\u8bb2\uff0c\u6355\u83b7\u8fd9\u4e9b\u5ea6\u91cf\u4e4b\u4e00\u7684\u65f6\u523b\u79f0\u4e3a \u5ea6\u91cf\u4e8b\u4ef6 \uff0c\u5b83\u4e0d\u4ec5\u5305\u62ec\u5ea6\u91cf\u672c\u8eab\uff0c\u8fd8\u5305\u62ec\u6355\u83b7\u5ea6\u91cf\u7684\u65f6\u95f4\u548c\u76f8\u5173\u7684\u5143\u6570\u636e\u3002</p> <p>\u5e94\u7528\u7a0b\u5e8f\u548c\u8bf7\u6c42\u5ea6\u91cf\u662f\u53ef\u7528\u6027\u548c\u6027\u80fd\u7684\u91cd\u8981\u6307\u6807\u3002 \u81ea\u5b9a\u4e49\u5ea6\u91cf\u53ef\u4ee5\u6df1\u5165\u4e86\u89e3\u53ef\u7528\u6027\u6307\u6807\u5982\u4f55\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u6216\u4e1a\u52a1\u3002 \u6536\u96c6\u7684\u6570\u636e\u53ef\u7528\u4e8e\u53d1\u51fa\u505c\u673a\u8b66\u62a5\u6216\u89e6\u53d1\u8c03\u5ea6\u51b3\u7b56\uff0c\u4ee5\u4fbf\u5728\u9ad8\u9700\u6c42\u65f6\u81ea\u52a8\u6269\u5c55\u90e8\u7f72\u3002</p> <p>OpenTelemetry\u5b9a\u4e49\u4e86\u516d\u79cd \u5ea6\u91cf\u5de5\u5177\uff0c\u53ef\u4ee5\u901a\u8fc7OpenTelemetry API\u521b\u5efa:</p> <ul> <li>Counter: \u4e00\u4e2a\u968f\u7740\u65f6\u95f4\u79ef\u7d2f\u7684\u503c- - \u4f60\u53ef\u4ee5\u628a\u5b83\u60f3\u8c61\u6210\u6c7d\u8f66\u4e0a\u7684\u91cc\u7a0b\u8868;\u5b83\u53ea\u4f1a\u4e0a\u5347\u3002</li> <li>Asynchronous Counter: \u4e0e**Counter**\u76f8\u540c\uff0c\u4f46\u5bf9\u6bcf\u4e2a\u5bfc\u51fa\u53ea\u6536\u96c6\u4e00\u6b21\u3002   \u5982\u679c\u60a8\u4e0d\u80fd\u8bbf\u95ee\u8fde\u7eed\u589e\u91cf\uff0c\u800c\u53ea\u80fd\u8bbf\u95ee\u805a\u5408\u503c\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528\u3002</li> <li>UpDownCounter: \u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u800c\u79ef\u7d2f\u7684\u503c\uff0c\u4f46\u4e5f\u53ef\u4ee5\u518d\u6b21\u4e0b\u964d\u3002   \u4f8b\u5982\u961f\u5217\u957f\u5ea6\uff0c\u5b83\u5c06\u968f\u7740\u961f\u5217\u4e2d\u5de5\u4f5c\u9879\u7684\u6570\u91cf\u800c\u589e\u52a0\u6216\u51cf\u5c11\u3002</li> <li>Asynchronous UpDownCounter: \u4e0e**UpDownCounter**\u76f8\u540c\uff0c\u4f46\u6bcf\u4e2a\u5bfc\u51fa\u53ea\u6536\u96c6\u4e00\u6b21\u3002   \u5982\u679c\u60a8\u65e0\u6cd5\u8bbf\u95ee\u6301\u7eed\u66f4\u6539\uff0c\u800c\u53ea\u80fd\u8bbf\u95ee\u805a\u5408\u503c(\u4f8b\u5982\uff0c\u5f53\u524d\u961f\u5217\u5927\u5c0f)\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528\u3002</li> <li>(Asynchronous) Gauge: \u6d4b\u91cf\u8bfb\u53d6\u65f6\u7684\u7535\u6d41\u503c\u3002   \u4e00\u4e2a\u4f8b\u5b50\u5c31\u662f\u6c7d\u8f66\u4e0a\u7684\u71c3\u6cb9\u8868\u3002\u4eea\u8868*\u603b\u662f*\u5f02\u6b65\u7684\u3002</li> <li>Histogram: \u76f4\u65b9\u56fe\u662f\u503c\u7684\u5ba2\u6237\u7aef\u805a\u5408\uff0c\u4f8b\u5982\uff0c\u8bf7\u6c42\u5ef6\u8fdf\u3002   \u5982\u679c\u60a8\u6709\u5f88\u591a\u503c\uff0c\u5e76\u4e14\u5bf9\u6bcf\u4e2a\u5355\u72ec\u7684\u503c\u4e0d\u611f\u5174\u8da3\uff0c\u800c\u662f\u5bf9\u8fd9\u4e9b\u503c\u7684\u7edf\u8ba1\u6570\u636e\u611f\u5174\u8da3(\u4f8b\u5982\uff0c\u6709\u591a\u5c11\u8bf7\u6c42\u82b1\u8d39\u7684\u65f6\u95f4\u5c11\u4e8e15 ?)\uff0c\u76f4\u65b9\u56fe\u53ef\u80fd\u662f\u4e00\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002</li> </ul> <p>\u9664\u4e86\u5ea6\u91cf\u5de5\u5177\u4e4b\u5916\uff0caggregations \u7684\u6982\u5ff5\u4e5f\u662f\u4e00\u4e2a\u9700\u8981\u7406\u89e3\u7684\u91cd\u8981\u6982\u5ff5\u3002 \u805a\u5408\u662f\u4e00\u79cd\u6280\u672f\uff0c\u901a\u8fc7\u8fd9\u79cd\u6280\u672f\uff0c\u53ef\u4ee5\u5c06\u5927\u91cf\u5ea6\u91cf\u7ec4\u5408\u6210\u5173\u4e8e\u67d0\u4e2a\u65f6\u95f4\u7a97\u53e3\u5185\u53d1\u751f\u7684\u5ea6\u91cf\u4e8b\u4ef6\u7684\u7cbe\u786e\u6216\u4f30\u8ba1\u7edf\u8ba1\u4fe1\u606f\u3002 OTLP\u534f\u8bae\u4f20\u8f93\u8fd9\u6837\u7684\u805a\u5408\u5ea6\u91cf\u3002 OpenTelemetry API\u4e3a\u6bcf\u4e2a\u4eea\u5668\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ed8\u8ba4\u7684\u805a\u5408\uff0c\u53ef\u4ee5\u4f7f\u7528Views API\u8986\u76d6\u5b83\u3002 OpenTelemetry\u9879\u76ee\u65e8\u5728\u63d0\u4f9b\u7531\u53ef\u89c6\u5316\u5668\u548c\u9065\u6d4b\u540e\u7aef\u652f\u6301\u7684\u9ed8\u8ba4\u805a\u5408\u3002</p> <p>\u4e0e\u65e8\u5728\u6355\u83b7\u8bf7\u6c42\u751f\u547d\u5468\u671f\u5e76\u4e3a\u8bf7\u6c42\u7684\u5404\u4e2a\u90e8\u5206\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7684\u8bf7\u6c42\u8ddf\u8e2a\u4e0d\u540c\uff0c\u5ea6\u91cf\u65e8\u5728\u63d0\u4f9b\u6c47\u603b\u7684\u7edf\u8ba1\u4fe1\u606f\u3002 \u5ea6\u91cf\u7684\u4e00\u4e9b\u7528\u4f8b\u5305\u62ec:</p> <ul> <li>\u62a5\u544a\u4e1a\u52a1\u6309\u534f\u8bae\u7c7b\u578b\u8bfb\u51fa\u7684\u603b\u5b57\u8282\u6570\u3002</li> <li>\u62a5\u544a\u8bfb\u53d6\u7684\u603b\u5b57\u8282\u6570\u548c\u6bcf\u4e2a\u8bf7\u6c42\u7684\u5b57\u8282\u6570\u3002</li> <li>\u62a5\u544a\u7cfb\u7edf\u8c03\u7528\u7684\u6301\u7eed\u65f6\u95f4\u3002</li> <li>\u62a5\u544a\u8bf7\u6c42\u5927\u5c0f\uff0c\u4ee5\u786e\u5b9a\u8d8b\u52bf\u3002</li> <li>\u62a5\u544a\u8fdb\u7a0b\u7684CPU\u6216\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\u3002</li> <li>\u62a5\u544a\u8d26\u6237\u7684\u5e73\u5747\u4f59\u989d\u503c\u3002</li> <li>\u62a5\u544a\u5f53\u524d\u6b63\u5728\u5904\u7406\u7684\u6d3b\u52a8\u8bf7\u6c42\u3002</li> </ul> <p>\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u5ea6\u91cf\u89c4\u8303.</p>"},{"location":"docs/concepts/signals/traces/","title":"Traces","text":"<p>Traces\u5411\u6211\u4eec\u5c55\u793a\u4e86\u5f53\u5411\u5e94\u7528\u7a0b\u5e8f\u53d1\u51fa\u8bf7\u6c42\u65f6\u53d1\u751f\u7684\u60c5\u51b5\u3002 \u65e0\u8bba\u60a8\u7684\u5e94\u7528\u7a0b\u5e8f\u662f\u5177\u6709\u5355\u4e2a\u6570\u636e\u5e93\u7684\u5355\u4f53\u8fd8\u662f\u590d\u6742\u7684\u670d\u52a1\u7f51\u683c\uff0c\u8ddf\u8e2a\u5bf9\u4e8e\u7406\u89e3\u8bf7\u6c42\u5728\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7684\u5b8c\u6574\u201c\u8def\u5f84\u201d\u90fd\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u3002</p> <p>\u8003\u8651\u4ee5\u4e0b\u8ddf\u8e2a\u4e09\u4e2a\u5de5\u4f5c\u5355\u5143\u7684\u793a\u4f8b:</p> <pre><code>{\n\"name\": \"Hello-Greetings\",\n\"context\": {\n\"trace_id\": \"0x5b8aa5a2d2c872e8321cf37308d69df2\",\n\"span_id\": \"0x5fb397be34d26b51\",\n},\n\"parent_id\": \"0x051581bf3cb55c13\",\n\"start_time\": \"2022-04-29T18:52:58.114304Z\",\n\"end_time\": \"2022-04-29T22:52:58.114561Z\",\n\"attributes\": {\n\"http.route\": \"some_route1\"\n},\n\"events\": [\n{\n\"name\": \"hey there!\",\n\"timestamp\": \"2022-04-29T18:52:58.114561Z\",\n\"attributes\": {\n\"event_attributes\": 1\n}\n},\n{\n\"name\": \"bye now!\",\n\"timestamp\": \"2022-04-29T18:52:58.114585Z\",\n\"attributes\": {\n\"event_attributes\": 1\n}\n}\n],\n}\n{\n\"name\": \"Hello-Salutations\",\n\"context\": {\n\"trace_id\": \"0x5b8aa5a2d2c872e8321cf37308d69df2\",\n\"span_id\": \"0x93564f51e1abe1c2\",\n},\n\"parent_id\": \"0x051581bf3cb55c13\",\n\"start_time\": \"2022-04-29T18:52:58.114492Z\",\n\"end_time\": \"2022-04-29T18:52:58.114631Z\",\n\"attributes\": {\n\"http.route\": \"some_route2\"\n},\n\"events\": [\n{\n\"name\": \"hey there!\",\n\"timestamp\": \"2022-04-29T18:52:58.114561Z\",\n\"attributes\": {\n\"event_attributes\": 1\n}\n}\n],\n}\n{\n\"name\": \"Hello\",\n\"context\": {\n\"trace_id\": \"0x5b8aa5a2d2c872e8321cf37308d69df2\",\n\"span_id\": \"0x051581bf3cb55c13\",\n},\n\"parent_id\": null,\n\"start_time\": \"2022-04-29T18:52:58.114201Z\",\n\"end_time\": \"2022-04-29T18:52:58.114687Z\",\n\"attributes\": {\n\"http.route\": \"some_route3\"\n},\n\"events\": [\n{\n\"name\": \"Guten Tag!\",\n\"timestamp\": \"2022-04-29T18:52:58.114561Z\",\n\"attributes\": {\n\"event_attributes\": 1\n}\n}\n],\n}\n</code></pre> <p>\u8fd9\u4e2a\u793a\u4f8b\u8ddf\u8e2a\u8f93\u51fa\u6709\u4e09\u4e2a\u4e0d\u540c\u7684\u7c7b\u4f3c\u65e5\u5fd7\u7684\u9879\u76ee\uff0c\u79f0\u4e3aspan\uff0c\u5206\u522b\u547d\u540d\u4e3a\u201cHello-greetings\u201d\u3001\u201cHello-salutations\u201d\u548c\u201cHello\u201d\u3002 \u56e0\u4e3a\u6bcf\u4e2a\u8bf7\u6c42\u7684\u4e0a\u4e0b\u6587\u90fd\u6709\u76f8\u540c\u7684\u201ctrace_id\u201d\uff0c\u6240\u4ee5\u5b83\u4eec\u88ab\u8ba4\u4e3a\u662f\u540c\u4e00\u4e2aTrace\u7684\u4e00\u90e8\u5206\u3002</p> <p>\u60a8\u5c06\u6ce8\u610f\u5230\u7684\u53e6\u4e00\u4ef6\u4e8b\u662f\uff0c\u8fd9\u4e2a\u793a\u4f8bTrace\u7684\u6bcf\u4e2aSpan\u770b\u8d77\u6765\u90fd\u50cf\u4e00\u4e2a\u7ed3\u6784\u5316\u65e5\u5fd7\u3002 \u90a3\u662f\u56e0\u4e3a\u5b83\u786e\u5b9e\u662f! \u8003\u8651trace\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\uff0c\u5b83\u4eec\u662f\u5305\u542b\u4e0a\u4e0b\u6587\u3001\u76f8\u5173\u6027\u3001\u5c42\u6b21\u7ed3\u6784\u7b49\u5185\u5bb9\u7684\u7ed3\u6784\u5316\u65e5\u5fd7\u7684\u96c6\u5408\u3002 \u4f46\u662f\uff0c\u8fd9\u4e9b\u201c\u7ed3\u6784\u5316\u65e5\u5fd7\u201d\u53ef\u4ee5\u6765\u81ea\u4e0d\u540c\u7684\u8fdb\u7a0b\u3001\u670d\u52a1\u3001\u865a\u62df\u673a\u3001\u6570\u636e\u4e2d\u5fc3\u7b49\u3002 \u8fd9\u4f7f\u5f97\u8ddf\u8e2a\u80fd\u591f\u8868\u793a\u4efb\u4f55\u7cfb\u7edf\u7684\u7aef\u5230\u7aef\u89c6\u56fe\u3002</p> <p>\u4e3a\u4e86\u7406\u89e3\u5f00\u653e\u9065\u6d4b\u4e2d\u7684\u8ddf\u8e2a\u662f\u5982\u4f55\u5de5\u4f5c\u7684\uff0c\u8ba9\u6211\u4eec\u770b\u4e00\u4e0b\u5c06\u5728\u68c0\u6d4b\u4ee3\u7801\u4e2d\u53d1\u6325\u4f5c\u7528\u7684\u7ec4\u4ef6\u5217\u8868:</p> <ul> <li>Tracer</li> <li>Tracer Provider</li> <li>Trace Exporter</li> <li>Trace Context</li> </ul>"},{"location":"docs/concepts/signals/traces/#tracer-provider","title":"Tracer Provider","text":"<p>Tracer Provider(\u6709\u65f6\u79f0\u4e3a\u201cTracerProvider\u201d)\u662f\u201cTracer\u201d\u7684\u5de5\u5382\u3002 \u5728\u5927\u591a\u6570\u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u8ddf\u8e2a\u7a0b\u5e8f\u63d0\u4f9b\u7a0b\u5e8f\u521d\u59cb\u5316\u4e00\u6b21\uff0c\u5176\u751f\u547d\u5468\u671f\u4e0e\u5e94\u7528\u7a0b\u5e8f\u7684\u751f\u547d\u5468\u671f\u76f8\u5339\u914d\u3002 \u8ddf\u8e2a\u7a0b\u5e8f\u63d0\u4f9b\u7a0b\u5e8f\u521d\u59cb\u5316\u8fd8\u5305\u62ec\u8d44\u6e90\u548c\u5bfc\u51fa\u7a0b\u5e8f\u521d\u59cb\u5316\u3002 \u8fd9\u901a\u5e38\u662f\u4f7f\u7528OpenTelemetry\u8fdb\u884c\u8ddf\u8e2a\u7684\u7b2c\u4e00\u6b65\u3002 \u5728\u67d0\u4e9b\u8bed\u8a00sdk\u4e2d\uff0c\u5df2\u7ecf\u4e3a\u60a8\u521d\u59cb\u5316\u4e86\u5168\u5c40\u8ddf\u8e2a\u7a0b\u5e8f\u63d0\u4f9b\u7a0b\u5e8f\u3002</p>"},{"location":"docs/concepts/signals/traces/#tracer","title":"Tracer","text":"<p>\u8ddf\u8e2a\u5668\u521b\u5efa\u7684\u8303\u56f4\u5305\u542b\u6709\u5173\u7ed9\u5b9a\u64cd\u4f5c(\u4f8b\u5982\u670d\u52a1\u4e2d\u7684\u8bf7\u6c42)\u6b63\u5728\u53d1\u751f\u7684\u4e8b\u60c5\u7684\u66f4\u591a\u4fe1\u606f\u3002 \u8ddf\u8e2a\u7a0b\u5e8f\u662f\u4ece\u8ddf\u8e2a\u7a0b\u5e8f\u63d0\u4f9b\u7a0b\u5e8f\u521b\u5efa\u7684\u3002</p>"},{"location":"docs/concepts/signals/traces/#trace-exporters","title":"Trace Exporters","text":"<p>\u8ddf\u8e2a\u51fa\u53e3\u5546\u5c06\u8ddf\u8e2a\u53d1\u9001\u7ed9\u6d88\u8d39\u8005\u3002 \u8fd9\u4e2a\u6d88\u8d39\u8005\u53ef\u4ee5\u662f\u8c03\u8bd5\u548c\u5f00\u53d1\u65f6\u95f4\u7684\u6807\u51c6\u8f93\u51fa\u3001OpenTelemetry Collector\uff0c\u6216\u8005\u60a8\u9009\u62e9\u7684\u4efb\u4f55\u5f00\u6e90\u6216\u4f9b\u5e94\u5546\u540e\u7aef\u3002</p>"},{"location":"docs/concepts/signals/traces/#context-propagation","title":"Context Propagation","text":"<p>\u4e0a\u4e0b\u6587\u4f20\u64ad\u662f\u652f\u6301\u5206\u5e03\u5f0f\u8ddf\u8e2a\u7684\u6838\u5fc3\u6982\u5ff5\u3002 \u4f7f\u7528\u4e0a\u4e0b\u6587\u4f20\u64ad\uff0c\u65e0\u8bba\u5728\u54ea\u91cc\u751f\u6210span\uff0c\u90fd\u53ef\u4ee5\u5c06span\u76f8\u4e92\u5173\u8054\u5e76\u7ec4\u88c5\u5230\u8ddf\u8e2a\u4e2d\u3002 \u6211\u4eec\u901a\u8fc7\u4e24\u4e2a\u5b50\u6982\u5ff5\u5b9a\u4e49\u4e0a\u4e0b\u6587\u4f20\u64ad:\u4e0a\u4e0b\u6587\u548c\u4f20\u64ad\u3002</p> <p>\u4e0a\u4e0b\u6587 \u662f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5b83\u5305\u542b\u53d1\u9001\u548c\u63a5\u6536\u670d\u52a1\u7684\u4fe1\u606f\uff0c\u4ee5\u4fbf\u5c06\u4e00\u4e2a\u8de8\u5ea6\u4e0e\u53e6\u4e00\u4e2a\u8de8\u5ea6\u76f8\u5173\u8054\uff0c\u5e76\u5c06\u5176\u4e0e\u6574\u4e2a\u8ddf\u8e2a\u76f8\u5173\u8054\u3002 \u4f8b\u5982\uff0c\u5982\u679c\u670d\u52a1A\u8c03\u7528\u670d\u52a1B\uff0c\u90a3\u4e48\u6765\u81ea\u670d\u52a1A\u7684\u4e00\u4e2aspan(\u5176ID\u5728\u4e0a\u4e0b\u6587\u4e2d)\u5c06\u88ab\u7528\u4f5c\u5728\u670d\u52a1B\u4e2d\u521b\u5efa\u7684\u4e0b\u4e00\u4e2aspan\u7684\u7236span\u3002</p> <p>\u4f20\u64ad \u662f\u5728\u670d\u52a1\u548c\u8fdb\u7a0b\u4e4b\u95f4\u79fb\u52a8\u4e0a\u4e0b\u6587\u7684\u673a\u5236\u3002 \u901a\u8fc7\u8fd9\u6837\u505a\uff0c\u5b83\u7ec4\u88c5\u4e86\u4e00\u4e2a\u5206\u5e03\u5f0f\u8ddf\u8e2a\u3002 \u5b83\u5e8f\u5217\u5316\u6216\u53cd\u5e8f\u5217\u5316Span Context\uff0c\u5e76\u63d0\u4f9b\u8981\u4ece\u4e00\u4e2a\u670d\u52a1\u4f20\u64ad\u5230\u53e6\u4e00\u4e2a\u670d\u52a1\u7684\u76f8\u5173\u8ddf\u8e2a\u4fe1\u606f\u3002 \u6211\u4eec\u73b0\u5728\u6709\u4e86\u6211\u4eec\u6240\u8bf4\u7684: \u8ddf\u8e2a\u4e0a\u4e0b\u6587 \u3002</p> <p>\u4e0a\u4e0b\u6587\u662f\u4e00\u4e2a\u62bd\u8c61\u7684\u6982\u5ff5\u2014\u2014\u5b83\u9700\u8981\u4e00\u4e2a\u5177\u4f53\u7684\u5b9e\u73b0\u624d\u80fd\u771f\u6b63\u6709\u7528\u3002 OpenTelemetry\u652f\u6301\u51e0\u79cd\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\u683c\u5f0f\u3002 OpenTelemetry\u8ddf\u8e2a\u4e2d\u4f7f\u7528\u7684\u9ed8\u8ba4\u683c\u5f0f\u662fW3C  <code>TraceContext</code>\u3002 \u6bcf\u4e2aContext\u5bf9\u8c61\u90fd\u4e0e\u4e00\u4e2a\u8de8\u5ea6\u76f8\u5173\u8054\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u8de8\u5ea6\u4e0a\u8fdb\u884c\u8bbf\u95ee\u3002 \u53c2\u89c1Span Context\u3002</p> <p>\u901a\u8fc7\u7ed3\u5408\u4e0a\u4e0b\u6587\u548c\u4f20\u64ad\uff0c\u60a8\u73b0\u5728\u53ef\u4ee5\u7ec4\u88c5\u8ddf\u8e2a\u3002</p> <p>\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605\u8ddf\u8e2a\u89c4\u8303</p>"},{"location":"docs/concepts/signals/traces/#spans","title":"Spans","text":"<p>span\u8868\u793a\u4e00\u4e2a\u5de5\u4f5c\u6216\u64cd\u4f5c\u5355\u5143\u3002 \u8de8\u5ea6\u662ftrace\u7684\u6784\u5efa\u5757\u3002 \u5728OpenTelemetry\u4e2d\uff0c\u5b83\u4eec\u5305\u62ec\u4ee5\u4e0b\u4fe1\u606f:</p> <ul> <li>Name</li> <li>Parent span ID (empty for root spans)</li> <li>Start and End Timestamps</li> <li>Span Context</li> <li>Attributes</li> <li>Span Events</li> <li>Span Links</li> <li>Span Status</li> </ul> <p>Sample span:</p> <pre><code>{\n\"trace_id\": \"7bba9f33312b3dbb8b2c2c62bb7abe2d\",\n\"parent_id\": \"\",\n\"span_id\": \"086e83747d0e381e\",\n\"name\": \"/v1/sys/health\",\n\"start_time\": \"2021-10-22 16:04:01.209458162 +0000 UTC\",\n\"end_time\": \"2021-10-22 16:04:01.209514132 +0000 UTC\",\n\"status_code\": \"STATUS_CODE_OK\",\n\"status_message\": \"\",\n\"attributes\": {\n\"net.transport\": \"IP.TCP\",\n\"net.peer.ip\": \"172.17.0.1\",\n\"net.peer.port\": \"51820\",\n\"net.host.ip\": \"10.177.2.152\",\n\"net.host.port\": \"26040\",\n\"http.method\": \"GET\",\n\"http.target\": \"/v1/sys/health\",\n\"http.server_name\": \"mortar-gateway\",\n\"http.route\": \"/v1/sys/health\",\n\"http.user_agent\": \"Consul Health Check\",\n\"http.scheme\": \"http\",\n\"http.host\": \"10.177.2.152:26040\",\n\"http.flavor\": \"1.1\"\n},\n\"events\": [\n{\n\"name\": \"\",\n\"message\": \"OK\",\n\"timestamp\": \"2021-10-22 16:04:01.209512872 +0000 UTC\"\n}\n]\n}\n</code></pre> <p>span\u53ef\u4ee5\u5d4c\u5957\uff0c\u6b63\u5982\u7236span ID\u7684\u5b58\u5728\u6240\u6697\u793a\u7684\u90a3\u6837:\u5b50span\u8868\u793a\u5b50\u64cd\u4f5c\u3002 \u8fd9\u5141\u8bb8span\u66f4\u51c6\u786e\u5730\u6355\u83b7\u5e94\u7528\u7a0b\u5e8f\u4e2d\u5b8c\u6210\u7684\u5de5\u4f5c\u3002</p>"},{"location":"docs/concepts/signals/traces/#span","title":"Span \u4e0a\u4e0b\u6587","text":"<p>Span context\u662f\u4e00\u4e2a\u4e0d\u53ef\u53d8\u5bf9\u8c61\uff0c\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9:</p> <ul> <li>Trace ID\u8868\u793a\u8be5span\u662f\u5176\u4e2d\u4e00\u90e8\u5206\u7684\u8ddf\u8e2a</li> <li>span\u7684span ID</li> <li>\u8ddf\u8e2a\u6807\u5fd7\uff0c\u4e00\u79cd\u4e8c\u8fdb\u5236\u7f16\u7801\uff0c\u5305\u542b\u6709\u5173\u8ddf\u8e2a\u7684\u4fe1\u606f</li> <li>\u8ddf\u8e2a\u72b6\u6001\uff0c\u53ef\u4ee5\u643a\u5e26\u7279\u5b9a\u4e8e\u4f9b\u5e94\u5546\u7684\u8ddf\u8e2a\u4fe1\u606f\u7684\u952e\u503c\u5bf9\u5217\u8868</li> </ul> <p>Span\u4e0a\u4e0b\u6587\u662fSpan\u7684\u4e00\u90e8\u5206\uff0c\u5b83\u4e0e\u5206\u5e03\u5f0f\u4e0a\u4e0b\u6587\u548c\u5305\u88b1\u4e00\u8d77\u88ab\u5e8f\u5217\u5316\u548c\u4f20\u64ad\u3002</p> <p>\u56e0\u4e3aSpan Context\u5305\u542bTrace ID\uff0c\u6240\u4ee5\u5728\u521b\u5efaSpan Links\u65f6\u4f7f\u7528\u5b83\u3002</p>"},{"location":"docs/concepts/signals/traces/#_1","title":"\u5c5e\u6027","text":"<p>\u5c5e\u6027\u662f\u5305\u542b\u5143\u6570\u636e\u7684\u952e\u503c\u5bf9\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u5143\u6570\u636e\u5bf9Span\u8fdb\u884c\u6ce8\u91ca\uff0c\u4ee5\u643a\u5e26\u6709\u5173\u5b83\u6b63\u5728\u8ddf\u8e2a\u7684\u64cd\u4f5c\u7684\u4fe1\u606f\u3002</p> <p>\u4f8b\u5982\uff0c\u5982\u679cspan\u8ddf\u8e2a\u5728\u7535\u5b50\u5546\u52a1\u7cfb\u7edf\u4e2d\u5411\u7528\u6237\u7684\u8d2d\u7269\u8f66\u4e2d\u6dfb\u52a0\u5546\u54c1\u7684\u64cd\u4f5c\uff0c\u5219\u53ef\u4ee5\u6355\u83b7\u7528\u6237\u7684ID\u3001\u8981\u6dfb\u52a0\u5230\u8d2d\u7269\u8f66\u4e2d\u7684\u5546\u54c1\u7684ID\u548c\u8d2d\u7269\u8f66ID\u3002</p> <p>\u6bcf\u79cd\u8bed\u8a00SDK\u5b9e\u73b0\u7684\u5c5e\u6027\u6709\u4ee5\u4e0b\u89c4\u5219:</p> <ul> <li>\u952e\u5fc5\u987b\u4e3a\u975e\u7a7a\u5b57\u7b26\u4e32\u503c</li> <li>\u53d6\u503c\u5fc5\u987b\u4e3a\u975e\u7a7a\u5b57\u7b26\u4e32\u3001\u5e03\u5c14\u503c\u3001\u6d6e\u70b9\u6570\u3001\u6574\u6570\u6216\u8fd9\u4e9b\u503c\u7684\u6570\u7ec4</li> </ul> <p>\u6b64\u5916\uff0c\u8fd8\u6709\u8bed\u4e49\u5c5e\u6027\uff0c\u5b83\u4eec\u662f\u5df2\u77e5\u7684\u5143\u6570\u636e\u547d\u540d\u7ea6\u5b9a\uff0c\u901a\u5e38\u51fa\u73b0\u5728\u516c\u5171\u64cd\u4f5c\u4e2d\u3002 \u5c3d\u53ef\u80fd\u4f7f\u7528\u8bed\u4e49\u5c5e\u6027\u547d\u540d\u662f\u5f88\u6709\u5e2e\u52a9\u7684\uff0c\u8fd9\u6837\u53ef\u4ee5\u8de8\u7cfb\u7edf\u6807\u51c6\u5316\u5e38\u89c1\u7c7b\u578b\u7684\u5143\u6570\u636e\u3002</p>"},{"location":"docs/concepts/signals/traces/#span_1","title":"Span \u4e8b\u4ef6","text":"<p>\u53ef\u4ee5\u5c06Span\u4e8b\u4ef6\u770b\u4f5c\u662fSpan\u4e0a\u7684\u7ed3\u6784\u5316\u65e5\u5fd7\u6d88\u606f(\u6216\u6ce8\u91ca)\uff0c\u901a\u5e38\u7528\u4e8e\u8868\u793aSpan\u6301\u7eed\u671f\u95f4\u6709\u610f\u4e49\u7684\u5355\u4e00\u65f6\u95f4\u70b9\u3002</p> <p>\u4f8b\u5982\uff0c\u8003\u8651web\u6d4f\u89c8\u5668\u4e2d\u7684\u4e24\u79cd\u573a\u666f:</p> <ol> <li>\u8ddf\u8e2a\u9875\u9762\u52a0\u8f7d</li> <li>\u8868\u793a\u9875\u9762\u4f55\u65f6\u5177\u6709\u4ea4\u4e92\u6027</li> </ol> <p>Span\u6700\u9002\u5408\u7528\u4e8e\u7b2c\u4e00\u79cd\u573a\u666f\uff0c\u56e0\u4e3a\u5b83\u662f\u4e00\u4e2a\u6709\u5f00\u59cb\u548c\u7ed3\u675f\u7684\u64cd\u4f5c\u3002</p> <p>Span Event\u6700\u9002\u5408\u7528\u4e8e\u8ddf\u8e2a\u7b2c\u4e8c\u4e2a\u573a\u666f\uff0c\u56e0\u4e3a\u5b83\u4ee3\u8868\u4e86\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u3001\u5947\u5f02\u7684\u65f6\u95f4\u70b9\u3002</p>"},{"location":"docs/concepts/signals/traces/#span_2","title":"Span \u94fe\u63a5","text":"<p>\u5b58\u5728\u94fe\u63a5\uff0c\u4ee5\u4fbf\u60a8\u53ef\u4ee5\u5c06\u4e00\u4e2a\u8de8\u5ea6\u4e0e\u4e00\u4e2a\u6216\u591a\u4e2a\u8de8\u5ea6\u5173\u8054\u8d77\u6765\uff0c\u8fd9\u610f\u5473\u7740\u5b58\u5728\u56e0\u679c\u5173\u7cfb\u3002 \u4f8b\u5982\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u5176\u4e2d\u4e00\u4e9b\u64cd\u4f5c\u7531\u8ddf\u8e2a\u5668\u8ddf\u8e2a\u3002</p> <p>\u4e3a\u4e86\u54cd\u5e94\u5176\u4e2d\u7684\u4e00\u4e9b\u64cd\u4f5c\uff0c\u4e00\u4e2a\u989d\u5916\u7684\u64cd\u4f5c\u6392\u961f\u7b49\u5f85\u6267\u884c\uff0c\u4f46\u662f\u5b83\u7684\u6267\u884c\u662f\u5f02\u6b65\u7684\u3002 \u6211\u4eec\u4e5f\u53ef\u4ee5\u7528trace\u6765\u8ddf\u8e2a\u8fd9\u4e2a\u540e\u7eed\u64cd\u4f5c\u3002</p> <p>\u6211\u4eec\u5e0c\u671b\u5c06\u540e\u7eed\u64cd\u4f5c\u7684\u8ddf\u8e2a\u4e0e\u7b2c\u4e00\u4e2a\u8ddf\u8e2a\u76f8\u5173\u8054\uff0c\u4f46\u662f\u6211\u4eec\u65e0\u6cd5\u9884\u6d4b\u540e\u7eed\u64cd\u4f5c\u4f55\u65f6\u5f00\u59cb\u3002 \u6211\u4eec\u9700\u8981\u5c06\u8fd9\u4e24\u6761\u8f68\u8ff9\u5173\u8054\u8d77\u6765\uff0c\u56e0\u6b64\u6211\u4eec\u5c06\u4f7f\u7528\u4e00\u4e2a\u8de8\u5ea6\u94fe\u63a5\u3002</p> <p>\u60a8\u53ef\u4ee5\u5c06\u7b2c\u4e00\u4e2a\u8ddf\u8e2a\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u8de8\u5ea6\u94fe\u63a5\u5230\u7b2c\u4e8c\u4e2a\u8ddf\u8e2a\u4e2d\u7684\u7b2c\u4e00\u4e2a\u8de8\u5ea6\u3002 \u73b0\u5728\uff0c\u5b83\u4eec\u4e92\u4e3a\u56e0\u679c\u5173\u7cfb\u3002</p> <p>\u94fe\u63a5\u662f\u53ef\u9009\u7684\uff0c\u4f46\u5b83\u662f\u5c06\u8ddf\u8e2a\u8de8\u5ea6\u76f8\u4e92\u5173\u8054\u7684\u597d\u65b9\u6cd5\u3002</p>"},{"location":"docs/concepts/signals/traces/#span_3","title":"Span \u72b6\u6001","text":"<p>\u4e00\u4e2a\u72b6\u6001\u5c06\u88ab\u9644\u52a0\u5230\u4e00\u4e2aSpan\u4e0a\u3002 \u901a\u5e38\uff0c\u5f53\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u4e2d\u5b58\u5728\u5df2\u77e5\u9519\u8bef(\u4f8b\u5982\u5f02\u5e38)\u65f6\uff0c\u60a8\u5c06\u8bbe\u7f6e\u4e00\u4e2aspan\u72b6\u6001\u3002 Span Status\u5c06\u88ab\u6807\u8bb0\u4e3a\u4ee5\u4e0b\u503c\u4e4b\u4e00:</p> <ul> <li><code>Unset</code></li> <li><code>Ok</code></li> <li><code>Error</code></li> </ul> <p>\u5904\u7406\u5f02\u5e38\u65f6\uff0c\u53ef\u4ee5\u5c06Span\u72b6\u6001\u8bbe\u7f6e\u4e3aError\u3002 \u5426\u5219\uff0cSpan\u72b6\u6001\u4e3aUnset\u72b6\u6001\u3002 \u901a\u8fc7\u5c06Span\u72b6\u6001\u8bbe\u7f6e\u4e3aUnset\uff0c\u5904\u7406Span\u7684\u540e\u7aef\u73b0\u5728\u53ef\u4ee5\u5206\u914d\u6700\u7ec8\u72b6\u6001\u3002</p>"},{"location":"docs/concepts/signals/traces/#span_4","title":"Span \u7c7b\u578b","text":"<p>\u5f53\u521b\u5efa\u4e00\u4e2aspan\u65f6\uff0c\u5b83\u662f\u201cClient\u201d\u3001\u201cServer\u201d\u3001\u201cInternal\u201d\u3001\u201cProducer\u201d\u6216\u201cConsumer\u201d\u4e2d\u7684\u4e00\u4e2a\u3002 \u6b64\u8de8\u5ea6\u7c7b\u578b\u4e3a\u8ddf\u8e2a\u540e\u7aef\u63d0\u4f9b\u4e86\u5173\u4e8e\u5982\u4f55\u7ec4\u88c5\u8ddf\u8e2a\u7684\u63d0\u793a\u3002 \u6839\u636eOpenTelemetry\u89c4\u8303\uff0c\u670d\u52a1\u5668\u8de8\u5ea6\u7684\u7236\u8282\u70b9\u901a\u5e38\u662f\u8fdc\u7a0b\u5ba2\u6237\u7aef\u8de8\u5ea6\uff0c\u800c\u5ba2\u6237\u7aef\u8de8\u5ea6\u7684\u5b50\u8282\u70b9\u901a\u5e38\u662f\u670d\u52a1\u5668\u8de8\u5ea6\u3002 \u7c7b\u4f3c\u5730\uff0c\u6d88\u8d39\u8005span\u7684\u7236\u7c7b\u59cb\u7ec8\u662f\u751f\u4ea7\u8005\uff0c\u751f\u4ea7\u8005span\u7684\u5b50\u7c7b\u59cb\u7ec8\u662f\u6d88\u8d39\u8005\u3002 \u5982\u679c\u6ca1\u6709\u63d0\u4f9b\uff0c\u5219\u5047\u5b9aspan\u7c7b\u578b\u662f\u5185\u90e8\u7684\u3002</p> <p>\u6709\u5173SpanKind\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1SpanKind.</p>"},{"location":"docs/concepts/signals/traces/#_2","title":"\u5ba2\u6237\u7aef","text":"<p>\u5ba2\u6237\u7aef\u8303\u56f4\u8868\u793a\u540c\u6b65\u4f20\u51fa\u8fdc\u7a0b\u8c03\u7528\uff0c\u4f8b\u5982\u4f20\u51faHTTP\u8bf7\u6c42\u6216\u6570\u636e\u5e93\u8c03\u7528\u3002 \u8bf7\u6ce8\u610f\uff0c\u5728\u8fd9\u4e2a\u4e0a\u4e0b\u6587\u4e2d\uff0c\u201c\u540c\u6b65\u201d\u4e0d\u662f\u6307\u201casync/await\u201d\uff0c\u800c\u662f\u6307\u5b83\u6ca1\u6709\u6392\u961f\u7b49\u5f85\u7a0d\u540e\u7684\u5904\u7406\u3002</p>"},{"location":"docs/concepts/signals/traces/#_3","title":"\u670d\u52a1\u5668","text":"<p>\u670d\u52a1\u5668\u8303\u56f4\u8868\u793a\u540c\u6b65\u4f20\u5165\u7684\u8fdc\u7a0b\u8c03\u7528\uff0c\u4f8b\u5982\u4f20\u5165\u7684HTTP\u8bf7\u6c42\u6216\u8fdc\u7a0b\u8fc7\u7a0b\u8c03\u7528\u3002</p>"},{"location":"docs/concepts/signals/traces/#internal","title":"Internal","text":"<p>\u5185\u90e8Span\u8868\u793a\u4e0d\u8de8\u8d8a\u6d41\u7a0b\u8fb9\u754c\u7684\u64cd\u4f5c\u3002 \u63d2\u88c5\u51fd\u6570\u8c03\u7528\u6216\u5feb\u901f\u4e2d\u95f4\u4ef6\u4e4b\u7c7b\u7684\u4e8b\u60c5\u53ef\u80fd\u4f1a\u4f7f\u7528\u5185\u90e8Span\u3002</p>"},{"location":"docs/concepts/signals/traces/#producer","title":"Producer","text":"<p>\u751f\u4ea7\u8005Span\u8868\u793a\u7a0d\u540e\u53ef\u80fd\u5f02\u6b65\u5904\u7406\u7684\u4f5c\u4e1a\u7684\u521b\u5efa\u3002 \u5b83\u53ef\u4ee5\u662f\u8fdc\u7a0b\u4f5c\u4e1a\uff0c\u4f8b\u5982\u63d2\u5165\u4f5c\u4e1a\u961f\u5217\u7684\u4f5c\u4e1a\uff0c\u4e5f\u53ef\u4ee5\u662f\u7531\u4e8b\u4ef6\u4fa6\u542c\u5668\u5904\u7406\u7684\u672c\u5730\u4f5c\u4e1a\u3002</p>"},{"location":"docs/concepts/signals/traces/#consumer","title":"Consumer","text":"<p>\u6d88\u8d39\u8005Span\u8868\u793a\u7531\u751f\u4ea7\u8005\u521b\u5efa\u7684\u4f5c\u4e1a\u7684\u5904\u7406\uff0c\u5e76\u4e14\u53ef\u80fd\u5728\u751f\u4ea7\u8005Span\u5df2\u7ecf\u7ed3\u675f\u5f88\u4e45\u4e4b\u540e\u624d\u5f00\u59cb\u3002</p>"},{"location":"docs/demo/_index/","title":"OpenTelemetry \u6f14\u793a\u6587\u6863","text":"<p>\u6b22\u8fce\u6765\u5230OpenTelemetry Demo\u6587\u6863\uff0c\u5b83\u6db5\u76d6\u4e86\u5982\u4f55\u5b89\u88c5\u548c\u8fd0\u884c\u6f14\u793a\uff0c\u4ee5\u53ca\u4e00\u4e9b\u53ef\u4ee5\u7528\u6765\u67e5\u770bOpenTelemetry\u7684\u573a\u666f\u3002</p>"},{"location":"docs/demo/_index/#demo","title":"\u8fd0\u884cDemo","text":"<p>\u60f3\u8981\u90e8\u7f72\u6f14\u793a\u5e76\u67e5\u770b\u5b9e\u9645\u60c5\u51b5\u5417?\u4ece\u8fd9\u91cc\u5f00\u59cb\u3002</p> <ul> <li>Docker</li> <li>Kubernetes</li> </ul>"},{"location":"docs/demo/_index/#_1","title":"\u8bed\u8a00\u7279\u6027\u53c2\u8003","text":"<p>\u60f3\u8981\u4e86\u89e3\u7279\u5b9a\u8bed\u8a00\u7684\u68c0\u6d4b\u662f\u5982\u4f55\u5de5\u4f5c\u7684?\u4ece\u8fd9\u91cc\u5f00\u59cb\u3002</p> Language Automatic Instrumentation Instrumentation Libraries Manual Instrumentation .NET Cart Service Cart Service C++ Currency Service Erlang/Elixir Feature Flag Service Feature Flag Service Go Accounting Service, Checkout Service, Product Catalog Service Checkout Service, Product Catalog Service Java Ad Service Ad Service JavaScript Frontend Frontend, Payment Service Kotlin Fraud Detection Service PHP Quote Service Quote Service Python Recommendation Service Recommendation Service Ruby Email Service Email Service Rust Shipping Service Shipping Service"},{"location":"docs/demo/_index/#_2","title":"\u670d\u52a1\u6587\u6863","text":"<p>Specific information about how OpenTelemetry is deployed in each service can be found here:</p> <ul> <li>Ad Service</li> <li>Cart Service</li> <li>Checkout Service</li> <li>Email Service</li> <li>Feature Flag Service</li> <li>Frontend</li> <li>Load Generator</li> <li>Payment Service</li> <li>Product Catalog Service</li> <li>Quote Service</li> <li>Recommendation Service</li> <li>Shipping Service</li> </ul>"},{"location":"docs/demo/_index/#_3","title":"\u573a\u666f","text":"<p>How can you solve problems with OpenTelemetry? These scenarios walk you through some pre-configured problems and show you how to interpret OpenTelemetry data to solve them.</p> <p>We'll be adding more scenarios over time.</p> <ul> <li>Generate a Product Catalog error for <code>GetProduct</code> requests   with product id: <code>OLJCESPC7Z</code> using the Feature Flag service</li> <li>Discover a memory leak and diagnose it using metrics and traces.   Read more</li> </ul>"},{"location":"docs/demo/_index/#_4","title":"\u53c2\u8003","text":"<p>Project reference documentation, like requirements and feature matrices.</p> <ul> <li>Architecture</li> <li>Development</li> <li>Feature Flags Reference</li> <li>Metric Feature Matrix</li> <li>Requirements</li> <li>Screenshots</li> <li>Service Roles Table</li> <li>Span Attributes Reference</li> <li>Tests</li> <li>Trace Feature Matrix</li> </ul>"},{"location":"docs/demo/architecture/","title":"\u6f14\u793a\u67b6\u6784","text":"<p>OpenTelemetry\u6f14\u793a \u662f\u7531\u7528\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u7f16\u5199\u7684\u5fae\u670d\u52a1\u7ec4\u6210\u7684\uff0c\u8fd9\u4e9b\u5fae\u670d\u52a1\u901a\u8fc7gRPC\u548cHTTP\u76f8\u4e92\u901a\u4fe1;\u4ee5\u53ca\u4f7f\u7528\u8757\u866b\u4f2a\u9020\u7528\u6237\u6d41\u91cf\u7684\u8d1f\u8f7d\u751f\u6210\u5668\u3002</p> <pre><code>graph TD\nsubgraph Service Diagram\naccountingservice(Accounting Service):::golang\nadservice(Ad Service):::java\ncache[(Cache&lt;br/&gt;&amp;#40redis&amp;#41)]\ncartservice(Cart Service):::dotnet\ncheckoutservice(Checkout Service):::golang\ncurrencyservice(Currency Service):::cpp\nemailservice(Email Service):::ruby\nfrauddetectionservice(Fraud Detection Service):::kotlin\nfrontend(Frontend):::typescript\nfrontendproxy(Frontend Proxy &lt;br/&gt;&amp;#40Envoy&amp;#41):::cpp\nloadgenerator([Load Generator]):::python\npaymentservice(Payment Service):::javascript\nproductcatalogservice(Product Catalog Service):::golang\nquoteservice(Quote Service):::php\nrecommendationservice(Recommendation Service):::python\nshippingservice(Shipping Service):::rust\nfeatureflagservice(Feature Flag Service):::erlang\nfeatureflagstore[(Feature Flag Store&lt;br/&gt;&amp;#40PostgreSQL DB&amp;#41)]\nqueue[(queue&lt;br/&gt;&amp;#40Kafka&amp;#41)]\n\nInternet --&gt;|HTTP| frontendproxy\nfrontendproxy --&gt;|HTTP| frontend\nfrontendproxy --&gt;|HTTP| featureflagservice\nloadgenerator --&gt;|HTTP| frontend\n\naccountingservice --&gt;|TCP| queue\n\ncheckoutservice ---&gt;|gRPC| cartservice --&gt; cache\ncheckoutservice ---&gt;|gRPC| productcatalogservice\ncheckoutservice ---&gt;|gRPC| currencyservice\ncheckoutservice ---&gt;|HTTP| emailservice\ncheckoutservice ---&gt;|gRPC| paymentservice\ncheckoutservice --&gt;|gRPC| shippingservice\ncheckoutservice ----&gt;|TCP| queue\n\nfrontend --&gt;|gRPC| adservice\nfrontend --&gt;|gRPC| cartservice\nfrontend --&gt;|gRPC| productcatalogservice\nfrontend --&gt;|gRPC| checkoutservice\nfrontend --&gt;|gRPC| currencyservice\nfrontend --&gt;|gRPC| recommendationservice --&gt;|gRPC| productcatalogservice\nfrontend --&gt;|gRPC| shippingservice --&gt;|HTTP| quoteservice\n\nfrauddetectionservice --&gt;|TCP| queue\n\nadservice --&gt;|gRPC| featureflagservice\n\nproductcatalogservice --&gt;|gRPC| featureflagservice\n\nrecommendationservice --&gt;|gRPC| featureflagservice\n\nshippingservice --&gt;|gRPC| featureflagservice\n\nfeatureflagservice --&gt; featureflagstore\n\nend\n\nclassDef dotnet fill:#178600,color:white;\nclassDef cpp fill:#f34b7d,color:white;\nclassDef erlang fill:#b83998,color:white;\nclassDef golang fill:#00add8,color:black;\nclassDef java fill:#b07219,color:white;\nclassDef javascript fill:#f1e05a,color:black;\nclassDef kotlin fill:#560ba1,color:white;\nclassDef php fill:#4f5d95,color:white;\nclassDef python fill:#3572A5,color:white;\nclassDef ruby fill:#701516,color:white;\nclassDef rust fill:#dea584,color:black;\nclassDef typescript fill:#e98516,color:black;</code></pre> <pre><code>graph TD\nsubgraph Service Legend\n  dotnetsvc(.NET):::dotnet\n  cppsvc(C++):::cpp\n  erlangsvc(Erlang/Elixir):::erlang\n  golangsvc(Go):::golang\n  javasvc(Java):::java\n  javascriptsvc(JavaScript):::javascript\n  kotlinsvc(Kotlin):::kotlin\n  phpsvc(PHP):::php\n  pythonsvc(Python):::python\n  rubysvc(Ruby):::ruby\n  rustsvc(Rust):::rust\n  typescriptsvc(TypeScript):::typescript\nend\n\nclassDef dotnet fill:#178600,color:white;\nclassDef cpp fill:#f34b7d,color:white;\nclassDef erlang fill:#b83998,color:white;\nclassDef golang fill:#00add8,color:black;\nclassDef java fill:#b07219,color:white;\nclassDef javascript fill:#f1e05a,color:black;\nclassDef kotlin fill:#560ba1,color:white;\nclassDef php fill:#4f5d95,color:white;\nclassDef python fill:#3572A5,color:white;\nclassDef ruby fill:#701516,color:white;\nclassDef rust fill:#dea584,color:black;\nclassDef typescript fill:#e98516,color:black;</code></pre> <p>\u6309\u7167\u8fd9\u4e9b\u94fe\u63a5\u67e5\u770b\u6f14\u793a\u5e94\u7528\u7a0b\u5e8f\u7684metric\u548ctrace\u68c0\u6d4b\u7684\u5f53\u524d\u72b6\u6001\u3002</p> <p>\u6536\u96c6\u5668\u5728otelcol-config.yml\u4e2d\u914d\u7f6e\uff0c\u5176\u4ed6\u5bfc\u51fa\u5668\u53ef\u4ee5\u5728\u8fd9\u91cc\u914d\u7f6e\u3002</p> <pre><code>graph TB\nsubgraph tdf[Telemetry Data Flow]\n    subgraph subgraph_padding [ ]\n        style subgraph_padding fill:none,stroke:none;\n        %% padding to stop the titles clashing\n        subgraph od[Open Telemetry Demo]\n        ms(Microservice)\n        end\n\n        ms -.-&gt;|\"OTLP&lt;br/&gt;gRPC\"| oc-grpc\n        ms -.-&gt;|\"OTLP&lt;br/&gt;HTTP POST\"| oc-http\n\n        subgraph oc[OTel Collector]\n            style oc fill:#97aef3,color:black;\n            oc-grpc[/\"OTLP Receiver&lt;br/&gt;listening on&lt;br/&gt;grpc://localhost:4317/\"/]\n            oc-http[/\"OTLP Receiver&lt;br/&gt;listening on &lt;br/&gt;http://localhost:4318/&lt;br/&gt;https://localhost:4318/\"/]\n            oc-proc(Processors)\n            oc-prom[/\"Prometheus Exporter&lt;br/&gt;listening on&lt;br/&gt;http://localhost:9464/\"/]\n            oc-jag[/\"Jaeger Exporter\"/]\n\n            oc-grpc --&gt; oc-proc\n            oc-http --&gt; oc-proc\n\n            oc-proc --&gt; oc-prom\n            oc-proc --&gt; oc-jag\n        end\n\n        oc-prom --&gt;|\"http://localhost:9464/metrics\"| pr-sc\n        oc-jag --&gt;|gRPC| ja-col\n\n        subgraph pr[Prometheus]\n            style pr fill:#e75128,color:black;\n            pr-sc[/\"Prometheus Scraper&lt;br/&gt;polling every 5 seconds\"/]\n            pr-tsdb[(Prometheus TSDB)]\n            pr-http[/\"Prometheus HTTP&lt;br/&gt;listening on&lt;br/&gt;http://localhost:9090\"/]\n\n            pr-sc --&gt; pr-tsdb\n            pr-tsdb --&gt; pr-http\n        end\n\n        pr-b{{\"Browser&lt;br/&gt;Prometheus UI\"}}\n        pr-http ----&gt;|\"http://localhost:9090/graph\"| pr-b\n\n        subgraph ja[Jaeger]\n            style ja fill:#60d0e4,color:black;\n            ja-col[/\"Jaeger Collector&lt;br/&gt;listening on&lt;br/&gt;grpc://jaeger:4317/\"/]\n            ja-db[(Jaeger DB)]\n            ja-http[/\"Jaeger HTTP&lt;br/&gt;listening on&lt;br/&gt;http://localhost:16686\"/]\n\n            ja-col --&gt; ja-db\n            ja-db --&gt; ja-http\n        end\n\n        subgraph gr[Grafana]\n            style gr fill:#f8b91e,color:black;\n            gr-srv[\"Grafana Server\"]\n            gr-http[/\"Grafana HTTP&lt;br/&gt;listening on&lt;br/&gt;http://localhost:3000\"/]\n\n            gr-srv --&gt; gr-http\n        end\n\n        pr-http --&gt; |\"http://localhost:9090/api\"| gr-srv\n        ja-http --&gt; |\"http://localhost:16686/api\"| gr-srv\n\n        ja-b{{\"Browser&lt;br/&gt;Jaeger UI\"}}\n        ja-http ----&gt;|\"http://localhost:16686/search\"| ja-b\n\n        gr-b{{\"Browser&lt;br/&gt;Grafana UI\"}}\n        gr-http --&gt;|\"http://localhost:3000/dashboard\"| gr-b\n    end\nend</code></pre> <p>\u5728<code>/pb/</code>\u76ee\u5f55\u4e2d\u627e\u5230<code>\u534f\u8bae\u7f13\u51b2\u533a\u5b9a\u4e49</code>\u3002</p>"},{"location":"docs/demo/development/","title":"\u5f00\u53d1","text":"<p>Development for this demo requires tooling in several programming languages. Minimum required versions will be noted where possible, but it is recommended to update to the latest version for all tooling. The OpenTelemetry demo team will attempt to keep the services in this repository up to date with the latest version for dependencies and tooling when possible.</p>"},{"location":"docs/demo/development/#generate-protobuf-files","title":"Generate protobuf files","text":"<p>The <code>make generate-protobuf</code> command is provided to generate protobuf files for all services. This can be used to compile code locally (without Docker) and receive hints from IDEs such as IntelliJ or VS Code. It may be necessary to run <code>npm install</code> within the frontend source folder before generating the files.</p>"},{"location":"docs/demo/development/#development-tooling-requirements","title":"Development tooling requirements","text":""},{"location":"docs/demo/development/#net","title":".NET","text":"<ul> <li>.NET 6.0+</li> </ul>"},{"location":"docs/demo/development/#c","title":"C++","text":"<ul> <li>build-essential</li> <li>cmake</li> <li>libcurl4-openssl-dev</li> <li>libprotobuf-dev</li> <li>nlohmann-json3-dev</li> <li>pkg-config</li> <li>protobuf-compiler</li> </ul>"},{"location":"docs/demo/development/#elixir","title":"Elixir","text":"<ul> <li>Erlang/OTP 23+</li> <li>Elixir 1.13+</li> <li>Rebar3 3.20+</li> </ul>"},{"location":"docs/demo/development/#go","title":"Go","text":"<ul> <li>Go 1.19+</li> <li>protoc-gen-go</li> <li>protoc-gen-go-grpc</li> </ul>"},{"location":"docs/demo/development/#java","title":"Java","text":"<ul> <li>JDK 17+</li> <li>Gradle 7+</li> </ul>"},{"location":"docs/demo/development/#javascript","title":"JavaScript","text":"<ul> <li>Node.js 16+</li> </ul>"},{"location":"docs/demo/development/#php","title":"PHP","text":"<ul> <li>PHP 8.1+</li> <li>Composer 2.4+</li> </ul>"},{"location":"docs/demo/development/#python","title":"Python","text":"<ul> <li>Python 3.10</li> <li>grpcio-tools 1.48+</li> </ul>"},{"location":"docs/demo/development/#ruby","title":"Ruby","text":"<ul> <li>Ruby 3.1+</li> </ul>"},{"location":"docs/demo/development/#rust","title":"Rust","text":"<ul> <li>Rust 1.61+</li> <li>protoc 3.21+</li> <li>protobuf-dev</li> </ul>"},{"location":"docs/demo/docker-deployment/","title":"Docker \u90e8\u7f72","text":""},{"location":"docs/demo/docker-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker</li> <li>Docker Compose   v2.0.0+</li> <li>4 GB of RAM for the application</li> </ul>"},{"location":"docs/demo/docker-deployment/#get-and-run-the-demo","title":"Get and run the demo","text":"<ol> <li> <p>Clone the Webstore Demo repository:</p> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-demo.git\n</code></pre> </li> <li> <p>Change to the demo folder:</p> <pre><code>cd opentelemetry-demo/\n</code></pre> </li> <li> <p>Run docker compose1 to start the demo:</p> <pre><code>docker compose up --no-build\n</code></pre> <p>Notes:</p> <ul> <li>The <code>--no-build</code> flag is used to fetch released docker images from   ghcr instead of building from   source. Removing the <code>--no-build</code> command line option will rebuild all   images from source. It may take more than 20 minutes to build if the   flag is omitted.</li> <li>If you're running on Apple Silicon, run <code>docker compose build</code>1 in   order to create local images vs. pulling them from the repository.</li> </ul> </li> </ol>"},{"location":"docs/demo/docker-deployment/#verify-the-webstore-and-telemetry","title":"Verify the Webstore and Telemetry","text":"<p>Once the images are built and containers are started you can access:</p> <ul> <li>Webstore: http://localhost:8080/</li> <li>Grafana: http://localhost:8080/grafana/</li> <li>Feature Flags UI: http://localhost:8080/feature/</li> <li>Load Generator UI: http://localhost:8080/loadgen/</li> <li>Jaeger UI: http://localhost:8080/jaeger/ui/</li> </ul>"},{"location":"docs/demo/docker-deployment/#bring-your-own-backend","title":"Bring your own backend","text":"<p>Likely you want to use the Webstore as a demo application for an observability backend you already have (e.g., an existing instance of Jaeger, Zipkin, or one of the vendor of your choice.</p> <p>OpenTelemetry Collector can be used to export telemetry data to multiple backends. By default, the collector in the demo application will merge the configuration from two files:</p> <ul> <li><code>otelcol-config.yml</code></li> <li><code>otelcol-config-extras.yml</code></li> </ul> <p>To add your backend, open the file src/otelcollector/otelcol-config-extras.yml with an editor.</p> <ul> <li>Start by adding a new exporter. For example, if your backend supports OTLP   over HTTP, add the following:</li> </ul> <pre><code>exporters:\notlphttp/example:\nendpoint: &lt;your-endpoint-url&gt;\n</code></pre> <ul> <li>Then add a new pipeline with your new exporter:</li> </ul> <pre><code>service:\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlphttp/example]\n</code></pre> <p>Vendor backends might require you to add additional parameters for authentication, please check their documentation. Some backends require different exporters, you may find them and their documentation available at opentelemetry-collector-contrib/exporter.</p> <p>After updating the <code>otelcol-config-extras.yml</code>, start the demo by running <code>docker compose up</code>1. After a while, you should see the traces flowing into your backend as well.</p> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"docs/demo/feature-flags/","title":"\u529f\u80fd\u6807\u5fd7","text":"<p>This demo comes with several feature flags which can control failure conditions in specific services. By default the flags are disabled. Using the Feature Flags UI http://localhost:8080/feature you will be able to control the status of these feature flags.</p> Feature Flag Service(s) Description <code>adServiceFailure</code> Ad Service Generate an error for <code>GetAds</code> 1/10th of the time <code>cartServiceFailure</code> Cart Service Generate an error for <code>EmptyCart</code> 1/10th of the time <code>productCatalogFailure</code> Product Catalog Generate an error for <code>GetProduct</code> requests with product id: <code>OLJCESPC7Z</code> <code>recommendationCache</code> Recommendation Create a memory leak due to an exponentially growing cache. 1.4x growth, 50% of requests trigger growth."},{"location":"docs/demo/features/","title":"\u6f14\u793a\u529f\u80fd","text":"<ul> <li>Kubernetes: the app is designed to run on   Kubernetes (both locally, as well as on the cloud) using a Helm chart.</li> <li>Docker: this forked sample can also be executed   only with Docker.</li> <li>gRPC: microservices use a high volume of gRPC calls to   communicate to each other.</li> <li>HTTP: microservices use   HTTP where gRPC is unavailable or not well supported.</li> <li>OpenTelemetry Traces: all services are   instrumented using OpenTelemetry available instrumentation libraries.</li> <li>OpenTelemetry Metrics: Select services   are instrumented using OpenTelemetry available instrumentation libraries. More   will be added as the relevant SDKs are released.</li> <li>OpenTelemetry Collector: all services are instrumented   and sending the generated traces and metrics to the OpenTelemetry Collector   via gRPC. The received traces are then exported to the logs and to Jaeger;   received metrics and exemplars1 are exported to logs and Prometheus.</li> <li>Jaeger: all generated traces are being   sent to Jaeger.</li> <li>Synthetic Load Generation: the application demo comes with a background   job that creates realistic usage patterns on the website using   Locust load generator.</li> <li>Prometheus: all generated metrics and exemplars   are scraped by Prometheus.</li> <li>Grafana: all metric dashboards are stored in   Grafana.</li> <li>Envoy: Envoy is used as a reverse proxy for   user-facing web interfaces such as the frontend, load generator, and feature   flag service.</li> </ul> <ol> <li> <p>Only exemplars attached to histograms are currently exported to Prometheus. For details, see Collector issue #18201.\u00a0\u21a9</p> </li> </ol>"},{"location":"docs/demo/forking/","title":"\u5206\u53c9\u6f14\u793a\u5b58\u50a8\u5e93","text":"<p>The [demo repository][] is designed to be forked and used as a tool to show off what you are doing with OpenTelemetry.</p> <p>Setting up a fork or a demo usually only requires overriding some environment variables and possibly replacing some container images.</p> <p>Live demos can be added to the demo README.</p>"},{"location":"docs/demo/forking/#suggestions-for-fork-maintainers","title":"Suggestions for Fork Maintainers","text":"<ul> <li>If you'd like to enhance the telemetry data emitted or collected by the demo,   then we strongly encourage you to backport your changes to this repository.   For vendor or implementation specific changes, a strategy of modifying   telemetry in the pipeline via config is preferable to underlying code changes.</li> <li>Extend rather than replace. Adding net-new services that interface with the   existing API is a great way to add vendor-specific or tool-specific features   that can't be accomplished through telemetry modification.</li> <li>To support extensibility, please use repository or facade patterns around   resources like queues, databases, caches, etc. This will allow for different   implementations of these services to be shimmed in for different platforms.</li> <li>Please do not attempt to backport vendor or tool-specific enhancements to this   repository.</li> </ul> <p>If you have any questions or would like to suggest ways that we can make your life easier as a fork maintainer, please open an issue.</p> <p>[demo repository]: {{% param repo %}}</p>"},{"location":"docs/demo/kubernetes-deployment/","title":"Kubernetes \u5f00\u53d1","text":"<p>We provide a OpenTelemetry Demo Helm chart to help deploy the demo to an existing Kubernetes cluster.</p> <p>Helm must be installed to use the charts. Please refer to Helm's documentation to get started.</p>"},{"location":"docs/demo/kubernetes-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes 1.23+</li> <li>4 GB of free RAM for the application</li> <li>Helm 3.9+ (for Helm installation method only</li> </ul>"},{"location":"docs/demo/kubernetes-deployment/#install-using-helm-recommended","title":"Install using Helm (recommended)","text":"<p>Add OpenTelemetry Helm repository:</p> <pre><code>helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts\n</code></pre> <p>To install the chart with the release name my-otel-demo, run the following command:</p> <pre><code>helm install my-otel-demo open-telemetry/opentelemetry-demo\n</code></pre> <p>Note The OpenTelemetry Demo Helm chart version 0.11.0 or greater is required to perform all usage methods mentioned below.</p>"},{"location":"docs/demo/kubernetes-deployment/#install-using-kubectl","title":"Install using kubectl","text":"<p>The following command will install the demo application to your Kubernetes cluster.</p> <pre><code>kubectl create namespace otel-demo\nkubectl apply --namespace otel-demo -f https://raw.githubusercontent.com/open-telemetry/opentelemetry-demo/main/kubernetes/opentelemetry-demo.yaml\n</code></pre> <p>Note These manifests are generated from the Helm chart and are provided for convenience. It is recommended to use the Helm chart for installation.</p>"},{"location":"docs/demo/kubernetes-deployment/#use-the-demo","title":"Use the Demo","text":"<p>The demo application will need the services exposed outside of the Kubernetes cluster in order to use them. You can expose the services to your local system using the <code>kubectl port-forward</code> command or by configuring service types (ie: LoadBalancer) with optionally deployed ingress resources.</p>"},{"location":"docs/demo/kubernetes-deployment/#expose-services-using-kubectl-port-forward","title":"Expose services using kubectl port-forward","text":"<p>To expose the frontendproxy service use the following command (replace <code>my-otel-demo</code> with your Helm chart release name accordingly):</p> <pre><code>kubectl port-forward svc/my-otel-demo-frontendproxy 8080:8080\n</code></pre> <p>In order for spans from the browser to be properly collected, you will also need to expose the OpenTelemetry Collector's OTLP/HTTP port (replace <code>my-otel-demo</code> with your Helm chart release name accordingly):</p> <pre><code>kubectl port-forward svc/my-otel-demo-otelcol 4318:4318\n</code></pre> <p>Note: <code>kubectl port-forward</code> will proxy the port until the process terminates. You may need to create separate terminal sessions for each use of <code>kubectl port-forward</code>, and use Ctrl-C to terminate the process when done.</p> <p>With the frontendproxy and Collector port-forward set up, you can access:</p> <ul> <li>Webstore: http://localhost:8080/</li> <li>Grafana: http://localhost:8080/grafana/</li> <li>Feature Flags UI: http://localhost:8080/feature/</li> <li>Load Generator UI: http://localhost:8080/loadgen/</li> <li>Jaeger UI: http://localhost:8080/jaeger/ui/</li> </ul>"},{"location":"docs/demo/kubernetes-deployment/#expose-services-using-service-type-configurations","title":"Expose services using service type configurations","text":"<p>Note Kubernetes clusters may not have the proper infrastructure components to enable LoadBalancer service types or ingress resources. Verify your cluster has the proper support before using these configuration options.</p> <p>Each demo service (ie: frontendproxy) offers a way to have its Kubernetes service type configured. By default these will be <code>ClusterIP</code> but you can change each one using the <code>serviceType</code> property for each service.</p> <p>To configure the frontendproxy service to use a LoadBalancer service type you would specify the following in your values file:</p> <pre><code>components:\nfrontendProxy:\nservice:\ntype: LoadBalancer\n</code></pre> <p>Note It is recommended to use a values file when installing the Helm chart in order to specify additional configuration options.</p> <p>The Helm chart does not provide facilities to create ingress resources. If required these would need to be created manually after installing the Helm chart. Some Kubernetes providers require specific service types in order to be used by ingress resources (ie: EKS ALB ingress, requires a NodePort service type).</p> <p>In order for spans from the browser to be properly collected, you will also need to expose the OpenTelemetry Collector's OTLP/HTTP port to be accessible to user web browsers. The location where the OpenTelemetry Collector is exposed must also be passed into the frontend service using the <code>PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT</code> environment variable. You can do this using the following in your values file:</p> <pre><code>components:\nfrontend:\nenv:\n- name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\nvalue: http://otel-demo-collector.mydomain.com:4318/v1/traces\n</code></pre> <p>To install the Helm chart with a custom <code>my-values-file.yaml</code> values file use:</p> <pre><code>helm install my-otel-demo open-telemetry/opentelemetry-demo --values my-values-file.yaml\n</code></pre> <p>With the frontendproxy and Collector exposed, you can access the demo UI at the base path for the frontendproxy. Other demo components can be accessed at the following sub-paths:</p> <ul> <li>Webstore: <code>/</code> (base)</li> <li>Grafana: <code>/grafana</code></li> <li>Feature Flags UI: <code>/feature</code></li> <li>Load Generator UI: <code>/loadgen/</code> (must include trailing slash)</li> <li>Jaeger UI: <code>/jaeger/ui</code></li> </ul>"},{"location":"docs/demo/kubernetes-deployment/#bring-your-own-backend","title":"Bring your own backend","text":"<p>Likely you want to use the Webstore as a demo application for an observability backend you already have (e.g. an existing instance of Jaeger, Zipkin, or one of the vendor of your choice.</p> <p>The OpenTelemetry Collector's configuration is exposed in the Helm chart. Any additions you do will be merged into the default configuration. You can use this to add your own exporters, and add them to the desired pipeline(s)</p> <pre><code>opentelemetry-collector:\nconfig:\nexporters:\notlphttp/example:\nendpoint: &lt;your-endpoint-url&gt;\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nprocessors: [batch]\nexporters: [otlphttp/example]\n</code></pre> <p>Note When merging YAML values with Helm, objects are merged and arrays are replaced.</p> <p>Vendor backends might require you to add additional parameters for authentication, please check their documentation. Some backends require different exporters, you may find them and their documentation available at opentelemetry-collector-contrib/exporter.</p> <p>To install the Helm chart with a custom <code>my-values-file.yaml</code> values file use:</p> <pre><code>helm install my-otel-demo open-telemetry/opentelemetry-demo --values my-values-file.yaml\n</code></pre>"},{"location":"docs/demo/manual-span-attributes/","title":"\u624b\u52a8\u8de8\u5ea6\u5c5e\u6027","text":"<p>This document contains the list of manual Span Attributes used throughout the demo:</p>"},{"location":"docs/demo/manual-span-attributes/#adservice","title":"AdService","text":"Name Type Description <code>app.ads.category</code> string Category for returned ad <code>app.ads.contextKeys</code> string Context keys used to find related ads <code>app.ads.contextKeys.count</code> number Count of unique context keys used <code>app.ads.count</code> number Count of ads returned to user <code>app.ads.ad_request_type</code> string Either <code>targeted</code> or <code>not_targeted</code> <code>app.ads.ad_response_type</code> string Either <code>targeted</code> or <code>random</code>"},{"location":"docs/demo/manual-span-attributes/#cartservice","title":"CartService","text":"Name Type Description <code>app.cart.items.count</code> number Number of unique items in cart <code>app.product.id</code> string Product Id for cart item <code>app.product.quantity</code> string Quantity for cart item <code>app.user.id</code> string User Id"},{"location":"docs/demo/manual-span-attributes/#checkoutservice","title":"CheckoutService","text":"Name Type Description <code>app.cart.items.count</code> number Total number of items in cart <code>app.order.amount</code> number Order amount <code>app.order.id</code> string Order Id <code>app.order.items.count</code> number Number of unique items in order <code>app.payment.transaction.id</code> string Payment transaction Id <code>app.shipping.amount</code> number Shipping amount <code>app.shipping.tracking.id</code> string Shipping tracking Id <code>app.user.currency</code> string User currency <code>app.user.id</code> string User Id"},{"location":"docs/demo/manual-span-attributes/#currencyservice","title":"CurrencyService","text":"Name Type Description <code>app.currency.conversion.from</code> string Currency code to convert from <code>app.currency.conversion.to</code> string Currency code to convert to"},{"location":"docs/demo/manual-span-attributes/#emailservice","title":"EmailService","text":"Name Type Description <code>app.email.recipient</code> string Email used for order confirmation <code>app.order.id</code> string Order Id"},{"location":"docs/demo/manual-span-attributes/#featureflagservice","title":"FeatureFlagService","text":"Name Type Description <code>app.featureflag.name</code> string Name of the feature flag <code>app.featureflag.description</code> string Admin description <code>app.featureflag.enabled</code> boolean The feature flag status"},{"location":"docs/demo/manual-span-attributes/#frontend","title":"Frontend","text":"Name Type Description <code>app.cart.size</code> number Total number of items in cart <code>app.cart.items.count</code> number Count of unique items in cart <code>app.cart.shipping.cost</code> number Cart shipping cost <code>app.cart.total.price</code> number Cart total price <code>app.currency</code> string User currency <code>app.currency.new</code> string New currency to set <code>app.order.total</code> number Order total cost <code>app.product.id</code> string Product Id <code>app.product.quantity</code> number Product quantity <code>app.products.count</code> number Total products displayed <code>app.request.id</code> string Request Id <code>app.session.id</code> string Session Id <code>app.user.id</code> string User Id"},{"location":"docs/demo/manual-span-attributes/#loadgenerator","title":"LoadGenerator","text":"Name Type Description None yet"},{"location":"docs/demo/manual-span-attributes/#paymentservice","title":"PaymentService","text":"Name Type Description <code>app.payment.amount</code> number Total payment amount <code>app.payment.card_type</code> string Type of card used for payment <code>app.payment.card_valid</code> boolean Was the card used valid <code>app.payment.charged</code> boolean Was the charge successful (false with loadgenerator)"},{"location":"docs/demo/manual-span-attributes/#productcatalogservice","title":"ProductCatalogService","text":"Name Type Description <code>app.product.id</code> string Product Id <code>app.product.name</code> string Product name <code>app.products.count</code> number Number of products in catalog <code>app.products_search.count</code> number Number of products returned in search"},{"location":"docs/demo/manual-span-attributes/#quoteservice","title":"QuoteService","text":"Name Type Description <code>app.quote.items.count</code> number Total items to ship <code>app.quote.cost.total</code> number Total shipping quote"},{"location":"docs/demo/manual-span-attributes/#recommendationservice","title":"RecommendationService","text":"Name Type Description <code>app.filtered_products.count</code> number Number of filtered products returned <code>app.products.count</code> number Number of products in catalog <code>app.products_recommended.count</code> number Number of recommended products returned <code>app.cache_hit</code> boolean If cache was accessed or not"},{"location":"docs/demo/manual-span-attributes/#shippingservice","title":"ShippingService","text":"Name Type Description <code>app.shipping.cost.total</code> number Total shipping cost <code>app.shipping.items.count</code> number Total items to ship <code>app.shipping.tracking.id</code> string Shipping tracking Id <code>app.shipping.zip_code</code> string Zip code used to ship item(s)"},{"location":"docs/demo/metric-features/","title":"\u6309\u670d\u52a1\u5ea6\u91cf\u7279\u5f81\u8986\u76d6\u7387","text":"Service Language Auto-instrumentation Manual Instrumentation Multiple Instruments Views Custom Attributes Resource Detection Trace Exemplars Accounting Go \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Ad Java \u2705 \u2705 \ud83d\udea7 \ud83d\udea7 \u2705 \u2705 \u2705 Cart .NET \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Checkout Go \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Currency C++ \ud83d\udd15 \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Email Ruby \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Feature Flag Erlang / Elixir \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Fraud Detection Kotlin \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \u2705 \ud83d\udea7 Frontend TypeScript \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Payment JavaScript \ud83d\udea7 \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \u2705 \ud83d\udea7 Product Catalog Go \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Quote PHP \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Recommendation Python \u2705 \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Shipping Rust \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 <p>Emoji Legend:</p> <ul> <li>Completed: \u2705</li> <li>Not Applicable: \ud83d\udd15</li> <li>Not Present (Yet): \ud83d\udea7</li> </ul>"},{"location":"docs/demo/service-table/","title":"\u670d\u52a1\u7684\u89d2\u8272","text":"<p>View Service Graph to visualize request flows.</p> Service Language Description accountingservice Go Processes incoming orders and count the sum of all orders (mock/). adservice Java Provides text ads based on given context words. cartservice DotNet Stores the items in the user's shopping cart in Redis and retrieves it. checkoutservice Go Retrieves user cart, prepares order and orchestrates the payment, shipping and the email notification. currencyservice C++ Converts one money amount to another currency. Uses real values fetched from European Central Bank. It's the highest QPS service. emailservice Ruby Sends users an order confirmation email (mock/). frauddetectionservice Kotlin Analyzes incoming orders and detects fraud attempts (mock/). featureflagservice Erlang/Elixir CRUD feature flag service to demonstrate various scenarios like fault injection &amp; how to emit telemetry from a feature flag reliant service. frontend JavaScript Exposes an HTTP server to serve the website. Does not require signup/login and generates session IDs for all users automatically. loadgenerator Python/Locust Continuously sends requests imitating realistic user shopping flows to the frontend. paymentservice JavaScript Charges the given credit card info (mock/) with the given amount and returns a transaction ID. productcatalogservice Go Provides the list of products from a JSON file and ability to search products and get individual products. quoteservice PHP Calculates the shipping costs, based on the number of items to be shipped. recommendationservice Python Recommends other products based on what's given in the cart. shippingservice Rust Gives shipping cost estimates based on the shopping cart. Ships items to the given address (mock/)."},{"location":"docs/demo/tests/","title":"\u6d4b\u8bd5","text":"<p>Currently, the repository includes E2E tests for both the frontend and backend services. For the Frontend we are using Cypress execute the different flows in the webstore. While the backend services use AVA as the main testing framework.</p> <p>To run the test you can simply run <code>make run-tests</code> at the root directory.</p> <p>In case you need to run a specific suite of tests you can execute <code>docker compose run frontendTests</code>1 for the frontend tests or <code>docker compose run integrationTests</code>1 for the backend tests.</p> <ol> <li> <p>{{% _param notes.docker-compose-v2 %}}\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"docs/demo/trace-features/","title":"\u6309\u670d\u52a1\u8ddf\u8e2a\u529f\u80fd\u8986\u76d6","text":"\u670d\u52a1 \u8bed\u8a00 \u5de5\u5177\u5e93 \u624b\u521bSpan Span\u6570\u636e\u5145\u5b9e RPC\u4e0a\u4e0b\u6587\u4f20\u64ad Span\u94fe\u63a5 \u884c\u674e \u8d44\u6e90\u53d1\u73b0 Accounting Service Go \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \u2705 Ad Java \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Cart .NET \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \u2705 Checkout Go \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \u2705 Currency C++ \ud83d\udd15 \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Email Ruby \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Feature Flag Erlang / Elixir \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Fraud Detection Kotlin \u2705 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 \ud83d\udea7 Frontend JavaScript \u2705 \u2705 \u2705 \ud83d\udd15 \u2705 \u2705 \u2705 Payment JavaScript \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \u2705 \u2705 Product Catalog Go \u2705 \ud83d\udd15 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Quote Service PHP \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Recommendation Python \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 Shipping Rust \ud83d\udd15 \u2705 \u2705 \u2705 \ud83d\udd15 \ud83d\udd15 \ud83d\udea7 <p>Emoji\u4f20\u5947:</p> <ul> <li>\u5b8c\u6210: \u2705</li> <li>\u4e0d\u9002\u7528: \ud83d\udd15</li> <li>\u4e0d\u5728\u573a(\u5c1a\u672a): \ud83d\udea7</li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/","title":"\u91c7\u96c6\u5668\u6570\u636e\u6d41\u4eea\u8868\u677f","text":"<p>Monitoring data flow through the OpenTelemetry Collector is crucial for several reasons. Gaining a macro-level perspective on incoming data, such as sample counts and cardinality, is essential for comprehending the collector's internal dynamics. However, when delving into the details, the interconnections can become complex. The Collector Data Flow Dashboard aims to demonstrate the capabilities of the OpenTelemetry demo application, offering a solid foundation for users to build upon. Collector Data Flow Dashboard provides valuable guidance on which metrics to monitor. Users can tailor their own dashboard variations by adding necessary metrics specific to their use cases, such as memory_delimiter processor or other data flow indicators. This demo dashboard serves as a starting point, enabling users to explore diverse usage scenarios and adapt the tool to their unique monitoring needs.</p>"},{"location":"docs/demo/collector-data-flow-dashboard/#data-flow-overview","title":"Data Flow Overview","text":"<p>The diagram below provides an overview of the system components, showcasing the configuration derived from the OpenTelemetry Collector (otelcol) configuration file utilized by the OpenTelemetry demo application. Additionally, it highlights the observability data (traces and metrics) flow within the system.</p> <p></p>"},{"location":"docs/demo/collector-data-flow-dashboard/#ingressegress-metrics","title":"Ingress/Egress Metrics","text":"<p>The metrics depicted in the diagram below are employed to monitor both egress and ingress data flows. These metrics are generated by the otelcol process, exported on port 8888, and subsequently scraped by Prometheus. The namespace associated with these metrics is \"otelcol,\" and the job name is labeled as <code>otel.</code></p> <p></p> <p>Labels serve as a valuable tool for identifying specific metric sets (such as exporter, receiver, or job), enabling differentiation among metric sets within the overall namespace. It is important to note that you will only encounter refused metrics if the memory limits, as defined in the memory delimiter processor, are exceeded.</p>"},{"location":"docs/demo/collector-data-flow-dashboard/#ingress-traces-pipeline","title":"Ingress Traces Pipeline","text":"<ul> <li><code>otelcol_receiver_accepted_spans</code></li> <li><code>otelcol_receiver_refused_spans</code></li> <li><code>by (receiver,transport)</code></li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/#ingress-metrics-pipeline","title":"Ingress Metrics Pipeline","text":"<ul> <li><code>otelcol_receiver_accepted_metric_points</code></li> <li><code>otelcol_receiver_refused_metric_points</code></li> <li><code>by (receiver,transport)</code></li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/#processor","title":"Processor","text":"<p>Currently, the only processor present in the demo application is a batch processor, which is used by both traces and metrics pipelines.</p> <ul> <li><code>otelcol_processor_batch_batch_send_size_sum</code></li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/#egress-traces-pipeline","title":"Egress Traces Pipeline","text":"<ul> <li><code>otelcol_exporter_sent_spans</code></li> <li><code>otelcol_exporter_send_failed_spans</code></li> <li><code>by (exporter)</code></li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/#egress-metrics-pipeline","title":"Egress Metrics Pipeline","text":"<ul> <li><code>otelcol_exporter_sent_metric_points</code></li> <li><code>otelcol_exporter_send_failed_metric_points</code></li> <li><code>by (exporter)</code></li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/#prometheus-scraping","title":"Prometheus Scraping","text":"<ul> <li><code>scrape_samples_scraped</code></li> <li><code>by (job)</code></li> </ul>"},{"location":"docs/demo/collector-data-flow-dashboard/#dashboard","title":"Dashboard","text":"<p>You can access the dashboard by navigating to the Grafana UI, selecting the OpenTelemetry Collector Data Flow dashboard under browse icon on the left-hand side of the screen.</p> <p></p> <p>The dashboard has four main sections:</p> <ol> <li>Process Metrics</li> <li>Traces Pipeline</li> <li>Metrics Pipeline</li> <li>Prometheus Scraping</li> </ol> <p>Sections 2,3 and 4 represent overall data flow using the metrics mentioned above. Additionally, export ratio is calculated for each pipeline to understand the data flow.</p>"},{"location":"docs/demo/collector-data-flow-dashboard/#export-ratio","title":"Export Ratio","text":"<p>Export ratio is basically the ratio between receiver and exporter metrics. You can notice over the dashboard screenshot above that the export ratio on metrics is way too high than the received metrics. This is because the demo application is configured to generate span metrics which is a processor that generates metrics from spans inside collector as illustrated in overview diagram.</p>"},{"location":"docs/demo/collector-data-flow-dashboard/#process-metrics","title":"Process Metrics","text":"<p>Very limited but informative process metrics are added to dashboard. For example, you might observe more than one instance of otelcol running on the system during restarts or similar. This can be useful for understanding spikes on dataflow.</p> <p></p>"},{"location":"docs/demo/requirements/_index/","title":"\u6f14\u793a\u9700\u6c42","text":"<p>\u4e0b\u9762\u7684\u6587\u6863\u6355\u83b7\u4e86\u6211\u4eec\u5171\u4eab\u7684\u6f14\u793a\u5e94\u7528\u7a0b\u5e8f\u7684\u5e94\u7528\u7a0b\u5e8f\u3001OpenTelemetry (OTel)\u548c\u7cfb\u7edf\u9700\u6c42\u3002 \u8fd9\u4e9b\u662f\u5728\u6b63\u5728\u8fdb\u884c\u7684SIG\u4f1a\u8bae\u4e0a\u51b3\u5b9a\u7684\u3002</p> <ol> <li>\u5e94\u7528\u7a0b\u5e8f\u9700\u6c42</li> <li>OpenTelemetry\u9700\u6c42</li> <li>\u7cfb\u7edf\u9700\u6c42</li> </ol>"},{"location":"docs/demo/requirements/_index/#_1","title":"\u76ee\u6807\u89d2\u8272","text":"<p>\u6211\u4eec\u6b63\u5728\u7528\u51e0\u4e2a\u4e0d\u540c\u7684\u76ee\u6807\u4eba\u7269\u89d2\u8272\u6784\u5efa\u6f14\u793a\u5e94\u7528\u7a0b\u5e8f:</p> <ol> <li>\u516c\u53f8\u7684 \u7231\u597d\u8005 \u53ef\u4ee5\u4f7f\u7528\u6f14\u793a\u5e94\u7528\u7a0b\u5e8f\u4f5c\u4e3a\u4e2a\u4eba\u5728\u4ed6\u4eec\u7684\u7ec4\u7ec7\u5185\u5021\u5bfcOTel\u3002</li> <li>\u5177\u6709\u7279\u5b9a\u8bed\u8a00\u6280\u80fd\u7684 \u5f00\u53d1\u4eba\u5458 \u5e0c\u671b\u770b\u5230\u66f4\u5927\u7684\u89c6\u56fe\u3002</li> <li>APM\u4f9b\u5e94\u5546 \u53ef\u4ee5\u5bf9OTel\u8fdb\u884c\u603b\u4f53\u8bc4\u4f30\u6216\u9700\u8981\u4e3a\u5ba2\u6237\u63d0\u4f9bOTel\u529f\u80fd\u6f14\u793a\u3002</li> <li>\u8003\u8651\u91c7\u7528OTel\u5e76\u5bf9\u4e86\u89e3\u751f\u4ea7-\u751f\u6d3b\u4f53\u9a8c\u611f\u5174\u8da3\u7684 \u4f01\u4e1a\u3002</li> </ol>"},{"location":"docs/demo/requirements/application/","title":"\u5e94\u7528\u9700\u6c42","text":"<p>The following requirements were decided upon to define what OpenTelemetry (OTel) signals the application will produce &amp; when support for future SDKs should be added:</p> <ol> <li> <p>Every supported language that has a GA Traces or Metrics SDK must have at    least 1 service example.</p> </li> <li> <p>Mobile support (Swift) is not an initial priority and not included in the      above requirement.</p> </li> <li> <p>Application processes must be language independent.</p> </li> <li> <p>gRPC is preferred where available and HTTP is to be used where it is not.</p> </li> <li> <p>Services should be architected to be modular components that can be switched    out.</p> </li> <li> <p>Individual services can and should be encouraged to have multiple language      options available.</p> </li> <li> <p>The architecture must allow for the possible integration of platform generic    components like a database, queue, or blob storage.</p> </li> <li> <p>There is no requirement for a particular component type - at least 1      generic component should be present in general.</p> </li> <li> <p>A load generator must be provided to simulate user load against the demo.</p> </li> </ol>"},{"location":"docs/demo/requirements/architecture/","title":"\u67b6\u6784\u9700\u6c42","text":""},{"location":"docs/demo/requirements/architecture/#summary","title":"Summary","text":"<p>The OpenTelemetry Community Demo application is intended to be a 'showcase' for OpenTelemetry API, SDK, and tools in a production-lite cloud native application. The overall goal of this application is not only to provide a canonical 'demo' of OpenTelemetry components, but also to act as a framework for further customization by end-users, vendors, and other stakeholders.</p>"},{"location":"docs/demo/requirements/architecture/#requirements","title":"Requirements","text":"<ul> <li>Application Requirements</li> <li>OpenTelemetry Requirements</li> <li>System Requirements</li> </ul>"},{"location":"docs/demo/requirements/architecture/#application-goals","title":"Application Goals","text":"<ul> <li>Provide developers with a robust sample application they can use in learning   OpenTelemetry instrumentation.</li> <li>Provide observability vendors with a single, well-supported, demo platform   that they can further customize (or simply use OOB).</li> <li>Provide the OpenTelemetry community with a living artifact that demonstrates   the features and capabilities of OTel APIs, SDKs, and tools.</li> <li>Provide OpenTelemetry maintainers and WGs a platform to demonstrate new   features/concepts 'in the wild'.</li> </ul> <p>The following is a general description of the logical components of the demo application.</p>"},{"location":"docs/demo/requirements/architecture/#main-application","title":"Main Application","text":"<p>The bulk of the demo app is a self-contained microservice-based application that does some useful 'real-world' work, such as an eCommerce site. This application is composed of multiple services that communicate with each other over gRPC and HTTP and runs on Kubernetes (or Docker, locally).</p> <p>Each service shall be instrumented with OpenTelemetry for traces, metrics, and logs (as applicable/available).</p> <p>Each service should be interchangeable with a service that performs the same business logic, implementing the same gRPC endpoints, but written in a different language/implementation. For the initial implementation of the demo, we should focus on adding as many missing languages as possible by swapping out existing services with implementations in un-represented languages. For future versions we will look to add more distinct language options per service.</p> <p>Each service should communicate with a feature flag service in order to enable/disable 'faults' that can be used to illustrate how telemetry helps solve problems in distributed applications.</p> <p>A PHP service should be added to the main application as an 'admin service'. A Database should be added to enable CRUD functionality on the Product Catalog.</p> <p>The 'shippingservice' should be reimplemented in Rust.</p> <p>The 'currencyservice' should be reimplemented in C++.</p> <p>The 'emailservice' should be reimplemented in Ruby.</p> <p>For future iterations, the 'frontend' service can be extended with a mobile application written in Swift.</p>"},{"location":"docs/demo/requirements/architecture/#feature-flag-component","title":"Feature Flag Component","text":"<p>This component should consist of one (or more) services that provides a simple feature flag configuration utility for the main application. It is made up of a browser-based client/admin interface and a backend service or services. The role of the client is to allow an operator to visualize the available feature flags and toggle their state. The server should provide a catalog of feature flags that main application services can register with and interrogate for their current status and targeting rules.</p> <p>The feature flag component should be implemented as an Erlang+Elixir/Phoenix service. The catalog of feature flags should be stored in a Database.</p>"},{"location":"docs/demo/requirements/architecture/#orchestration-and-deployment","title":"Orchestration and Deployment","text":"<p>All services should run on Kubernetes. The OpenTelemetry Collector should be deployed via the OpenTelemetry Operator, and run in a sidecar + gateway mode. Telemetry from each pod should be routed from agents to a gateway, and the gateway should export telemetry by default to an open source trace + metrics visualizer.</p> <p>For local/non-Kubernetes deployment, the Collector should be deployed via compose file and monitor not only traces/metrics from applications, but also the docker containers via <code>dockerstatsreceiver</code>.</p> <p>A design goal of this project is to include a CI/CD pipeline for self-deployment into cloud environments. This could be skipped for local development.</p>"},{"location":"docs/demo/requirements/opentelemetry/","title":"OpenTelemetry \u9700\u6c42","text":"<p>The following requirements were decided upon to define what OpenTelemetry (OTel) signals the application will produce &amp; when support for future SDKs should be added:</p> <ol> <li>The demo must produce OTel logs, traces, &amp; metrics out of the box for    languages that have a GA SDK.</li> <li>Languages that have a Beta SDK available may be included but are not required    like GA SDKs.</li> <li>Native OTel metrics should be produced where possible.</li> <li>Both manual instrumentation and instrumentation libraries    (auto-instrumentation) should be demonstrated in each language.</li> <li>All data should be exported to the Collector first.</li> <li>The Collector must be configurable to allow for a variety of consumption    experiences but default tools must be selected for each signal.</li> <li>The demo application architecture using the Collector should be designed to    be a best practices reference architecture.</li> </ol>"},{"location":"docs/demo/requirements/system/","title":"\u7cfb\u7edf\u9700\u6c42","text":"<p>To ensure the demo runs correctly please ensure your environment meets the following system requirements:</p> <ol> <li>Your system must meet Docker Desktop    system requirements or you should use your preferred Cloud Service.</li> <li>The demo must be able to work on the following Operating Systems (OS): Linux,    macOS and Windows with documentation provided for each OS.</li> </ol>"},{"location":"docs/demo/scenarios/recommendation-cache/","title":"\u4f7f\u7528\u5ea6\u91cf\u548c\u8ddf\u8e2a\u6765\u8bca\u65ad\u5185\u5b58\u6cc4\u6f0f","text":"<p>Application telemetry, such as the kind that OpenTelemetry can provide, is very useful for diagnosing issues in a distributed system. In this scenario, we will walk through a scenario demonstrating how to move from high-level metrics and traces to determine the cause of a memory leak.</p>"},{"location":"docs/demo/scenarios/recommendation-cache/#setup","title":"Setup","text":"<p>To run this scenario, you will need to deploy the demo application and enable the <code>recommendationCache</code> feature flag. Let the application run for about 10 minutes or so after enabling the feature flag to allow for data to populate.</p>"},{"location":"docs/demo/scenarios/recommendation-cache/#diagnosis","title":"Diagnosis","text":"<p>The first step in diagnosing a problem is to determine that a problem exists. Often the first stop will be a metrics dashboard provided by a tool such as Grafana.</p> <p>A demo dashboard folder should exist after launching the demo with two dashboards; One is to monitor your OpenTelemetry Collector, and the other contains several queries and charts to analyze latency and request rate from each service.</p> <p></p> <p>This dashboard will contain a number of charts, but a few should appear interesting:</p> <ul> <li>Recommendation Service (CPU% and Memory)</li> <li>Service Latency (from SpanMetrics)</li> <li>Error Rate</li> </ul> <p>Recommendation Service charts are generated from OpenTelemetry Metrics exported to Prometheus, while the Service Latency and Error Rate charts are generated through the OpenTelemetry Collector Span Metrics processor.</p> <p>From our dashboard, we can see that there seems to be anomalous behavior in the recommendation service -- spiky CPU utilization, as well as long tail latency in our p95, 99, and 99.9 histograms. We can also see that there are intermittent spikes in the memory utilization of this service.</p> <p>We know that we're emitting trace data from our application as well, so let's think about another way that we'd be able to determine that a problem exist.</p> <p></p> <p>Jaeger allows us to search for traces and display the end-to-end latency of an entire request with visibility into each individual part of the overall request. Perhaps we noticed an increase in tail latency on our frontend requests. Jaeger allows us to then search and filter our traces to include only those that include requests to recommendation service.</p> <p>By sorting by latency, we're able to quickly find specific traces that took a long time. Clicking on a trace in the right panel, we're able to view the waterfall view.</p> <p></p> <p>We can see that the recommendation service is taking a long time to complete its work, and viewing the details allows us to get a better idea of what's going on.</p>"},{"location":"docs/demo/scenarios/recommendation-cache/#confirming-the-diagnosis","title":"Confirming the Diagnosis","text":"<p>We can see in our waterfall view that the <code>app.cache_hit</code> attribute is set to <code>false</code>, and that the <code>app.products.count</code> value is extremely high.</p> <p>Returning to the search UI, filter to <code>recommendationservice</code> in the Service dropdown, and search for <code>app.cache_hit=true</code> in the Tags box. Notice that requests tend to be faster when the cache is hit. Now search for <code>app.cache_hit=false</code> and compare the latency. You should notice some changes in the visualization at the top of the trace list.</p> <p>Now, since this is a contrived scenario, we know where to find the underlying bug in our code. However, in a real-world scenario, we may need to perform further searching to find out what's going on in our code, or the interactions between services that cause it.</p>"},{"location":"docs/demo/screenshots/","title":"\u6f14\u793a\u622a\u56fe","text":""},{"location":"docs/demo/screenshots/#webstore","title":"Webstore","text":"Home Page Checkout Screen"},{"location":"docs/demo/screenshots/#jaeger","title":"Jaeger","text":"Jaeger UI Trace View System Architecture"},{"location":"docs/demo/screenshots/#prometheus","title":"Prometheus","text":""},{"location":"docs/demo/screenshots/#grafana","title":"Grafana","text":"Prometheus Data Source Jaeger Data Source"},{"location":"docs/demo/screenshots/#feature-flag-ui","title":"Feature Flag UI","text":""},{"location":"docs/demo/screenshots/#load-generator-ui","title":"Load Generator UI","text":""},{"location":"docs/demo/services/accounting/","title":"Accounting Service","text":"<p>This service calculates the total amount of sold products. This is only mocked and received orders are printed out.</p> <p>Accounting Service</p>"},{"location":"docs/demo/services/accounting/#traces","title":"Traces","text":""},{"location":"docs/demo/services/accounting/#initializing-tracing","title":"Initializing Tracing","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code> using the <code>initTracerProvider</code> function.</p> <pre><code>func initTracerProvider() (*sdktrace.TracerProvider, error) {\nctx := context.Background()\nexporter, err := otlptracegrpc.New(ctx)\nif err != nil {\nreturn nil, err\n}\ntp := sdktrace.NewTracerProvider(\nsdktrace.WithBatcher(exporter),\nsdktrace.WithResource(initResource()),\n)\notel.SetTracerProvider(tp)\notel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{}))\nreturn tp, nil\n}\n</code></pre> <p>You should call <code>TracerProvider.Shutdown()</code> when your service is shutdown to ensure all spans are exported. This service makes that call as part of a deferred function in main</p> <pre><code>    tp, err := initTracerProvider()\nif err != nil {\nlog.Fatal(err)\n}\ndefer func() {\nif err := tp.Shutdown(context.Background()); err != nil {\nlog.Printf(\"Error shutting down tracer provider: %v\", err)\n}\n}()\n</code></pre>"},{"location":"docs/demo/services/accounting/#adding-kafka-sarama-auto-instrumentation","title":"Adding Kafka ( Sarama ) auto-instrumentation","text":"<p>This service will receive the processed results of the Checkout Service via a Kafka topic. To instrument the Kafka client the ConsumerHandler implemented by the developer has to be wrapped.</p> <pre><code>    handler := groupHandler{} // implements sarama.ConsumerGroupHandler\nwrappedHandler := otelsarama.WrapConsumerGroupHandler(&amp;handler)\n</code></pre>"},{"location":"docs/demo/services/ad/","title":"Ad Service","text":"<p>This service determines appropriate ads to serve to users based on context keys. The ads will be for products available in the store.</p> <p>Ad service source</p>"},{"location":"docs/demo/services/ad/#auto-instrumentation","title":"Auto-instrumentation","text":"<p>This service relies on the OpenTelemetry Java Agent to automatically instrument libraries such as gRPC, and to configure the OpenTelemetry SDK. The agent is passed into the process using the <code>-javaagent</code> command line argument. Command line arguments are added through the <code>JAVA_TOOL_OPTIONS</code> in the <code>Dockerfile</code>, and leveraged during the automatically generated Gradle startup script.</p> <pre><code>ENV JAVA_TOOL_OPTIONS=-javaagent:/app/opentelemetry-javaagent.jar\n</code></pre>"},{"location":"docs/demo/services/ad/#traces","title":"Traces","text":""},{"location":"docs/demo/services/ad/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span from context.</p> <pre><code>    Span span = Span.current();\n</code></pre> <p>Adding attributes to a span is accomplished using <code>setAttribute</code> on the span object. In the <code>getAds</code> function multiples attribute are added to the span.</p> <pre><code>    span.setAttribute(\"app.ads.contextKeys\", req.getContextKeysList().toString());\nspan.setAttribute(\"app.ads.contextKeys.count\", req.getContextKeysCount());\n</code></pre>"},{"location":"docs/demo/services/ad/#add-span-events","title":"Add span events","text":"<p>Adding an event to a span is accomplished using <code>addEvent</code> on the span object. In the <code>getAds</code> function an event with an attribute is added when an exception is caught.</p> <pre><code>    span.addEvent(\"Error\", Attributes.of(AttributeKey.stringKey(\"exception.message\"), e.getMessage()));\n</code></pre>"},{"location":"docs/demo/services/ad/#setting-span-status","title":"Setting span status","text":"<p>If the result of the operation is an error, the span status should be set accordingly using <code>setStatus</code> on the span object. In the <code>getAds</code> function the span status is set when an exception is caught.</p> <pre><code>    span.setStatus(StatusCode.ERROR);\n</code></pre>"},{"location":"docs/demo/services/ad/#create-new-spans","title":"Create new spans","text":"<p>New spans can be created and started using <code>Tracer.spanBuilder(\"spanName\").startSpan()</code>. Newly created spans should be set into context using <code>Span.makeCurrent()</code>. The <code>getRandomAds</code> function will create a new span, set it into context, perform an operation, and finally end the span.</p> <pre><code>    // create and start a new span manually\nTracer tracer = GlobalOpenTelemetry.getTracer(\"adservice\");\nSpan span = tracer.spanBuilder(\"getRandomAds\").startSpan();\n// put the span into context, so if any child span is started the parent will be set properly\ntry (Scope ignored = span.makeCurrent()) {\nCollection&lt;Ad&gt; allAds = adsMap.values();\nfor (int i = 0; i &lt; MAX_ADS_TO_SERVE; i++) {\nads.add(Iterables.get(allAds, random.nextInt(allAds.size())));\n}\nspan.setAttribute(\"app.ads.count\", ads.size());\n} finally {\nspan.end();\n}\n</code></pre>"},{"location":"docs/demo/services/ad/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/ad/#initializing-metrics","title":"Initializing Metrics","text":"<p>Similar to creating spans, the first step in creating metrics is initializing a <code>Meter</code> instance, e.g. <code>GlobalOpenTelemetry.getMeter(\"adservice\")</code>. From there, use the various builder methods available on the <code>Meter</code> instance to create the desired metric instrument, e.g.:</p> <pre><code>meter\n.counterBuilder(\"app.ads.ad_requests\")\n.setDescription(\"Counts ad requests by request and response type\")\n.build();\n</code></pre>"},{"location":"docs/demo/services/ad/#current-metrics-produced","title":"Current Metrics Produced","text":"<p>Note that all the metric names below appear in Prometheus/Grafana with <code>.</code> characters transformed to <code>_</code>.</p>"},{"location":"docs/demo/services/ad/#custom-metrics","title":"Custom metrics","text":"<p>The following custom metrics are currently available:</p> <ul> <li><code>app.ads.ad_requests</code>: A counter of ad requests with dimensions describing   whether the request was targeted with context keys or not, and whether the   response was targeted or random ads.</li> </ul>"},{"location":"docs/demo/services/ad/#auto-instrumented-metrics","title":"Auto-instrumented metrics","text":"<p>The following auto-instrumented metrics are available for the application:</p> <ul> <li>Runtime metrics for the JVM.</li> <li>Latency metrics for RPCs</li> </ul>"},{"location":"docs/demo/services/ad/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/cart/","title":"Cart Service","text":"<p>This service maintains items placed in the shopping cart by users. It interacts with a Redis caching service for fast access to shopping cart data.</p> <p>Cart service source</p> <p>Note OpenTelemetry for .NET uses the <code>System.Diagnostic</code> library as its API in lieu of the standard OpenTelemetry API.</p>"},{"location":"docs/demo/services/cart/#traces","title":"Traces","text":""},{"location":"docs/demo/services/cart/#initializing-tracing","title":"Initializing Tracing","text":"<p>OpenTelemetry is configured in the .NET DI container. The <code>AddOpenTelemetry()</code> builder method is used to configure desired instrumentation libraries, add exporters, and set other options. Configuration of the exporter and resource attributes is performed through environment variables.</p> <pre><code>Action&lt;ResourceBuilder&gt; appResourceBuilder =\nresource =&gt; resource\n.AddTelemetrySdk()\n.AddEnvironmentVariableDetector()\n.AddDetector(new ContainerResourceDetector());\nbuilder.Services.AddOpenTelemetry()\n.ConfigureResource(appResourceBuilder)\n.WithTracing(builder =&gt; builder\n.AddRedisInstrumentation(\ncartStore.GetConnection(),\noptions =&gt; options.SetVerboseDatabaseStatements = true)\n.AddAspNetCoreInstrumentation()\n.AddGrpcClientInstrumentation()\n.AddHttpClientInstrumentation()\n.AddOtlpExporter());\n</code></pre>"},{"location":"docs/demo/services/cart/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span (activity) from context.</p> <pre><code>    var activity = Activity.Current;\n</code></pre> <p>Adding attributes (tags in .NET) to a span (activity) is accomplished using <code>SetTag</code> on the activity object. In the <code>AddItem</code> function from <code>services/CartService.cs</code> several attributes are added to the auto-instrumented span.</p> <pre><code>    activity?.SetTag(\"app.user.id\", request.UserId);\nactivity?.SetTag(\"app.product.quantity\", request.Item.Quantity);\nactivity?.SetTag(\"app.product.id\", request.Item.ProductId);\n</code></pre>"},{"location":"docs/demo/services/cart/#add-span-events","title":"Add span events","text":"<p>Adding span (activity) events is accomplished using <code>AddEvent</code> on the activity object. In the <code>GetCart</code> function from <code>services/CartService.cs</code> a span event is added.</p> <pre><code>    activity?.AddEvent(new(\"Fetch cart\"));\n</code></pre>"},{"location":"docs/demo/services/cart/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/cart/#initializing-metrics","title":"Initializing Metrics","text":"<p>Similar to configuring OpenTelemetry Traces, the .NET DI container requires a call to <code>AddOpenTelemetry()</code>. This builder configures desired instrumentation libraries, exporters, etc.</p> <pre><code>Action&lt;ResourceBuilder&gt; appResourceBuilder =\nresource =&gt; resource\n.AddTelemetrySdk()\n.AddEnvironmentVariableDetector()\n.AddDetector(new ContainerResourceDetector());\nbuilder.Services.AddOpenTelemetry()\n.ConfigureResource(appResourceBuilder)\n.WithMetrics(builder =&gt; builder\n.AddRuntimeInstrumentation()\n.AddAspNetCoreInstrumentation()\n.AddOtlpExporter());\n</code></pre>"},{"location":"docs/demo/services/cart/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/checkout/","title":"Checkout Service","text":"<p>This service is responsible to process a checkout order from the user. The checkout service will call many other services in order to process an order.</p> <p>Checkout service source</p>"},{"location":"docs/demo/services/checkout/#traces","title":"Traces","text":""},{"location":"docs/demo/services/checkout/#initializing-tracing","title":"Initializing Tracing","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code> using the <code>initTracerProvider</code> function.</p> <pre><code>func initTracerProvider() *sdktrace.TracerProvider {\nctx := context.Background()\nexporter, err := otlptracegrpc.New(ctx)\nif err != nil {\nlog.Fatal(err)\n}\ntp := sdktrace.NewTracerProvider(\nsdktrace.WithBatcher(exporter),\nsdktrace.WithResource(initResource()),\n)\notel.SetTracerProvider(tp)\notel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{}))\nreturn tp\n}\n</code></pre> <p>You should call <code>TracerProvider.Shutdown()</code> when your service is shutdown to ensure all spans are exported. This service makes that call as part of a deferred function in main</p> <pre><code>    tp := initTracerProvider()\ndefer func() {\nif err := tp.Shutdown(context.Background()); err != nil {\nlog.Printf(\"Error shutting down tracer provider: %v\", err)\n}\n}()\n</code></pre>"},{"location":"docs/demo/services/checkout/#adding-grpc-auto-instrumentation","title":"Adding gRPC auto-instrumentation","text":"<p>This service receives gRPC requests, which are instrumented in the main function as part of the gRPC server creation.</p> <pre><code>    var srv = grpc.NewServer(\ngrpc.UnaryInterceptor(otelgrpc.UnaryServerInterceptor()),\ngrpc.StreamInterceptor(otelgrpc.StreamServerInterceptor()),\n)\n</code></pre> <p>This service will issue several outgoing gRPC calls, which are all instrumented by wrapping the gRPC client with instrumentation</p> <pre><code>func createClient(ctx context.Context, svcAddr string) (*grpc.ClientConn, error) {\nreturn grpc.DialContext(ctx, svcAddr,\ngrpc.WithTransportCredentials(insecure.NewCredentials()),\ngrpc.WithUnaryInterceptor(otelgrpc.UnaryClientInterceptor()),\ngrpc.WithStreamInterceptor(otelgrpc.StreamClientInterceptor()),\n)\n}\n</code></pre>"},{"location":"docs/demo/services/checkout/#adding-kafka-sarama-auto-instrumentation","title":"Adding Kafka ( Sarama ) auto-instrumentation","text":"<p>This service will write the processed results onto a Kafka topic which will then be in turn be processed by other microservices. To instrument the Kafka client the Producer has to be wrapped after it has been created.</p> <pre><code>    saramaConfig := sarama.NewConfig()\nproducer, err := sarama.NewAsyncProducer(brokers, saramaConfig)\nif err != nil {\nreturn nil, err\n}\nproducer = otelsarama.WrapAsyncProducer(saramaConfig, producer)\n</code></pre>"},{"location":"docs/demo/services/checkout/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span from context.</p> <pre><code>    span := trace.SpanFromContext(ctx)\n</code></pre> <p>Adding attributes to a span is accomplished using <code>SetAttributes</code> on the span object. In the <code>PlaceOrder</code> function several attributes are added to the span.</p> <pre><code>    span.SetAttributes(\nattribute.String(\"app.order.id\", orderID.String()), shippingTrackingAttribute,\nattribute.Float64(\"app.shipping.amount\", shippingCostFloat),\nattribute.Float64(\"app.order.amount\", totalPriceFloat),\nattribute.Int(\"app.order.items.count\", len(prep.orderItems)),\n)\n</code></pre>"},{"location":"docs/demo/services/checkout/#add-span-events","title":"Add span events","text":"<p>Adding span events is accomplished using <code>AddEvent</code> on the span object. In the <code>PlaceOrder</code> function several span events are added. Some events have additional attributes, others do not.</p> <p>Adding a span event without attributes:</p> <pre><code>    span.AddEvent(\"prepared\")\n</code></pre> <p>Adding a span event with additional attributes:</p> <pre><code>    span.AddEvent(\"charged\",\ntrace.WithAttributes(attribute.String(\"app.payment.transaction.id\", txID)))\n</code></pre>"},{"location":"docs/demo/services/checkout/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/checkout/#initializing-metrics","title":"Initializing Metrics","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code> using the <code>initMeterProvider</code> function.</p> <pre><code>func initMeterProvider() *sdkmetric.MeterProvider {\nctx := context.Background()\nexporter, err := otlpmetricgrpc.New(ctx)\nif err != nil {\nlog.Fatalf(\"new otlp metric grpc exporter failed: %v\", err)\n}\nmp := sdkmetric.NewMeterProvider(sdkmetric.WithReader(sdkmetric.NewPeriodicReader(exporter)))\nglobal.SetMeterProvider(mp)\nreturn mp\n}\n</code></pre> <p>You should call <code>MeterProvider.Shutdown()</code> when your service is shutdown to ensure all records are exported. This service makes that call as part of a deferred function in main</p> <pre><code>    mp := initMeterProvider()\ndefer func() {\nif err := mp.Shutdown(context.Background()); err != nil {\nlog.Printf(\"Error shutting down meter provider: %v\", err)\n}\n}()\n</code></pre>"},{"location":"docs/demo/services/checkout/#adding-golang-runtime-auto-instrumentation","title":"Adding golang runtime auto-instrumentation","text":"<p>Golang runtime are instrumented in the main function</p> <pre><code>    err := runtime.Start(runtime.WithMinimumReadMemStatsInterval(time.Second))\nif err != nil {\nlog.Fatal(err)\n}\n</code></pre>"},{"location":"docs/demo/services/checkout/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/currency/","title":"Currency Service","text":"<p>This service provides functionality to convert amounts between different currencies.</p> <p>Currency service source</p>"},{"location":"docs/demo/services/currency/#traces","title":"Traces","text":""},{"location":"docs/demo/services/currency/#initializing-tracing","title":"Initializing Tracing","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code> using the <code>initTracer</code> function defined in <code>tracer_common.h</code></p> <pre><code>void initTracer()\n{\nauto exporter = opentelemetry::exporter::otlp::OtlpGrpcExporterFactory::Create();\nauto processor =\nopentelemetry::sdk::trace::SimpleSpanProcessorFactory::Create(std::move(exporter));\nstd::vector&lt;std::unique_ptr&lt;opentelemetry::sdk::trace::SpanProcessor&gt;&gt; processors;\nprocessors.push_back(std::move(processor));\nstd::shared_ptr&lt;opentelemetry::sdk::trace::TracerContext&gt; context =\nopentelemetry::sdk::trace::TracerContextFactory::Create(std::move(processors));\nstd::shared_ptr&lt;opentelemetry::trace::TracerProvider&gt; provider =\nopentelemetry::sdk::trace::TracerProviderFactory::Create(context);\n// Set the global trace provider\nopentelemetry::trace::Provider::SetTracerProvider(provider);\n// set global propagator\nopentelemetry::context::propagation::GlobalTextMapPropagator::SetGlobalPropagator(\nopentelemetry::nostd::shared_ptr&lt;opentelemetry::context::propagation::TextMapPropagator&gt;(\nnew opentelemetry::trace::propagation::HttpTraceContext()));\n}\n</code></pre>"},{"location":"docs/demo/services/currency/#create-new-spans","title":"Create new spans","text":"<p>New spans can be created and started using <code>Tracer-&gt;StartSpan(\"spanName\", attributes, options)</code>. After a span is created you need to start and put it into active context using <code>Tracer-&gt;WithActiveSpan(span)</code>. You can find an example of this in the <code>Convert</code> function.</p> <pre><code>    std::string span_name = \"CurrencyService/Convert\";\nauto span =\nget_tracer(\"currencyservice\")-&gt;StartSpan(span_name,\n{{SemanticConventions::kRpcSystem, \"grpc\"},\n{SemanticConventions::kRpcService, \"CurrencyService\"},\n{SemanticConventions::kRpcMethod, \"Convert\"},\n{SemanticConventions::kRpcGrpcStatusCode, 0}},\noptions);\nauto scope = get_tracer(\"currencyservice\")-&gt;WithActiveSpan(span);\n</code></pre>"},{"location":"docs/demo/services/currency/#adding-attributes-to-spans","title":"Adding attributes to spans","text":"<p>You can add an attribute to a span using <code>Span-&gt;SetAttribute(key, value)</code>.</p> <pre><code>    span-&gt;SetAttribute(\"app.currency.conversion.from\", from_code);\nspan-&gt;SetAttribute(\"app.currency.conversion.to\", to_code);\n</code></pre>"},{"location":"docs/demo/services/currency/#add-span-events","title":"Add span events","text":"<p>Adding span events is accomplished using <code>Span-&gt;AddEvent(name)</code>.</p> <pre><code>    span-&gt;AddEvent(\"Conversion successful, response sent back\");\n</code></pre>"},{"location":"docs/demo/services/currency/#set-span-status","title":"Set span status","text":"<p>Make sure to set your span status to Ok, or Error accordingly. You can do this using <code>Span-&gt;SetStatus(status)</code></p> <pre><code>    span-&gt;SetStatus(StatusCode::kOk);\n</code></pre>"},{"location":"docs/demo/services/currency/#tracing-context-propagation","title":"Tracing context propagation","text":"<p>In C++ propagation is not automatically handled. You need to extract it from the caller and inject the propagation context into subsequent spans. The <code>GrpcServerCarrier</code> class defines a method to extract context from inbound gRPC requests which is leveraged in the service call implementations.</p> <p>The <code>GrpcServerCarrier</code> class is defined in <code>tracer_common.h</code> as follows:</p> <pre><code>class GrpcServerCarrier : public opentelemetry::context::propagation::TextMapCarrier\n{\npublic:\nGrpcServerCarrier(ServerContext *context) : context_(context) {}\nGrpcServerCarrier() = default;\nvirtual opentelemetry::nostd::string_view Get(\nopentelemetry::nostd::string_view key) const noexcept override\n{\nauto it = context_-&gt;client_metadata().find(key.data());\nif (it != context_-&gt;client_metadata().end())\n{\nreturn it-&gt;second.data();\n}\nreturn \"\";\n}\nvirtual void Set(opentelemetry::nostd::string_view key,\nopentelemetry::nostd::string_view value) noexcept override\n{\n// Not required for server\n}\nServerContext *context_;\n};\n</code></pre> <p>This class is leveraged in the <code>Convert</code> method to extract context and create a <code>StartSpanOptions</code> object to contain the right context which is used when creating new spans.</p> <pre><code>    StartSpanOptions options;\noptions.kind = SpanKind::kServer;\nGrpcServerCarrier carrier(context);\nauto prop        = context::propagation::GlobalTextMapPropagator::GetGlobalPropagator();\nauto current_ctx = context::RuntimeContext::GetCurrent();\nauto new_context = prop-&gt;Extract(carrier, current_ctx);\noptions.parent   = GetSpan(new_context)-&gt;GetContext();\n</code></pre>"},{"location":"docs/demo/services/currency/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/currency/#initializing-metrics","title":"Initializing Metrics","text":"<p>The OpenTelemetry <code>MeterProvider</code> is initialized from <code>main()</code> using the <code>initMeter()</code> function defined in <code>meter_common.h</code>.</p> <pre><code>void initMeter()\n{\n// Build MetricExporter\notlp_exporter::OtlpGrpcMetricExporterOptions otlpOptions;\n// Configuration via environment variable not supported yet\notlpOptions.endpoint = \"otelcol:4317\";\notlpOptions.aggregation_temporality = metric_sdk::AggregationTemporality::kDelta;\nauto exporter = otlp_exporter::OtlpGrpcMetricExporterFactory::Create(otlpOptions);\n// Build MeterProvider and Reader\nmetric_sdk::PeriodicExportingMetricReaderOptions options;\noptions.export_interval_millis = std::chrono::milliseconds(1000);\noptions.export_timeout_millis = std::chrono::milliseconds(500);\nstd::unique_ptr&lt;metric_sdk::MetricReader&gt; reader{\nnew metric_sdk::PeriodicExportingMetricReader(std::move(exporter), options) };\nauto provider = std::shared_ptr&lt;metrics_api::MeterProvider&gt;(new metric_sdk::MeterProvider());\nauto p = std::static_pointer_cast&lt;metric_sdk::MeterProvider&gt;(provider);\np-&gt;AddMetricReader(std::move(reader));\nmetrics_api::Provider::SetMeterProvider(provider);\n}\n</code></pre>"},{"location":"docs/demo/services/currency/#starting-intcounter","title":"Starting IntCounter","text":"<p>A global <code>currency_counter</code> variable is created at <code>main()</code> calling the function <code>initIntCounter()</code> defined in <code>meter_common.h</code>.</p> <pre><code>nostd::unique_ptr&lt;metrics_api::Counter&lt;uint64_t&gt;&gt; initIntCounter()\n{\nstd::string counter_name = name + \"_counter\";\nauto provider = metrics_api::Provider::GetMeterProvider();\nnostd::shared_ptr&lt;metrics_api::Meter&gt; meter = provider-&gt;GetMeter(name, version);\nauto int_counter = meter-&gt;CreateUInt64Counter(counter_name);\nreturn int_counter;\n}\n</code></pre>"},{"location":"docs/demo/services/currency/#counting-currency-conversion-requests","title":"Counting currency conversion requests","text":"<p>The method <code>CurrencyCounter()</code> is implemented as follows:</p> <pre><code>void CurrencyCounter(const std::string&amp; currency_code)\n{\nstd::map&lt;std::string, std::string&gt; labels = { {\"currency_code\", currency_code} };\nauto labelkv = common::KeyValueIterableView&lt;decltype(labels)&gt;{ labels };\ncurrency_counter-&gt;Add(1, labelkv);\n}\n</code></pre> <p>Every time the function <code>Convert()</code> is called, the currency code received as <code>to_code</code> is used to count the conversions.</p> <pre><code>CurrencyCounter(to_code);\n</code></pre>"},{"location":"docs/demo/services/currency/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/email/","title":"Email Service","text":"<p>This service will send a confirmation email to the user when an order is placed.</p> <p>Email service source</p>"},{"location":"docs/demo/services/email/#initializing-tracing","title":"Initializing Tracing","text":"<p>You will need to require the core OpenTelemetry SDK and exporter Ruby gems, as well as any gem that will be needed for auto-instrumentation libraries (ie: Sinatra)</p> <pre><code>require \"opentelemetry/sdk\"\nrequire \"opentelemetry/exporter/otlp\"\nrequire \"opentelemetry/instrumentation/sinatra\"\n</code></pre> <p>The Ruby SDK uses OpenTelemetry standard environment variables to configure OTLP export, resource attributes, and service name automatically. When initializing the OpenTelemetry SDK, you will also specify which auto-instrumentation libraries to leverage (ie: Sinatra)</p> <pre><code>OpenTelemetry::SDK.configure do |c|\nc.use \"OpenTelemetry::Instrumentation::Sinatra\"\nend\n</code></pre>"},{"location":"docs/demo/services/email/#traces","title":"Traces","text":""},{"location":"docs/demo/services/email/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span from context.</p> <pre><code>  current_span = OpenTelemetry::Trace.current_span\n</code></pre> <p>Adding multiple attributes to a span is accomplished using <code>add_attributes</code> on the span object.</p> <pre><code>  current_span.add_attributes({\n\"app.order.id\" =&gt; data.order.order_id,\n})\n</code></pre> <p>Adding only a single attribute can be accomplished using <code>set_attribute</code> on the span object.</p> <pre><code>    span.set_attribute(\"app.email.recipient\", data.email)\n</code></pre>"},{"location":"docs/demo/services/email/#create-new-spans","title":"Create new spans","text":"<p>New spans can be created and placed into active context using <code>in_span</code> from an OpenTelemetry Tracer object. When used in conjunction with a <code>do..end</code> block, the span will automatically be ended when the block ends execution.</p> <pre><code>  tracer = OpenTelemetry.tracer_provider.tracer('emailservice')\ntracer.in_span(\"send_email\") do |span|\n# logic in context of span here\nend\n</code></pre>"},{"location":"docs/demo/services/email/#metrics","title":"Metrics","text":"<p>TBD</p>"},{"location":"docs/demo/services/email/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/feature-flag/","title":"Feature Flag Service","text":"<p>This service is written in Erlang/Elixir and it is responsible for creating, reading, updating and deleting feature flags in a PostgreSQL DB. It is called by Product Catalog and Shipping services.</p> <p>Feature Flag Service Source</p>"},{"location":"docs/demo/services/feature-flag/#traces","title":"Traces","text":""},{"location":"docs/demo/services/feature-flag/#initializing-tracing","title":"Initializing Tracing","text":"<p>In order to set up OpenTelemetry instrumentation for Phoenix, and Ecto, , we need to call the setup methods of their instrumentation packages before starting the Supervisor.</p> <p>This is done in the <code>application.ex</code> as follows:</p> <pre><code>@impl true\ndef start(_type, _args) do\nOpentelemetryEcto.setup([:featureflagservice, :repo])\nOpentelemetryPhoenix.setup()\nchildren = [\n# Start the Ecto repository\nFeatureflagservice.Repo,\n# Start the PubSub system\n{Phoenix.PubSub, name: Featureflagservice.PubSub},\n# Start the Endpoint (http/https)\nFeatureflagserviceWeb.Endpoint\n# Start a worker by calling: Featureflagservice.Worker.start_link(arg)\n# {Featureflagservice.Worker, arg}\n]\n# See https://hexdocs.pm/elixir/Supervisor.html\n# for other strategies and supported options\nopts = [strategy: :one_for_one, name: Featureflagservice.Supervisor]\nSupervisor.start_link(children, opts)\nend\n</code></pre> <p>To add tracing to grpcbox, we need to add the appropriate interceptor.</p> <p>This is configured in the <code>runtime.exs</code> file, as follows:</p> <pre><code>config :grpcbox,\nservers: [\n%{\n:grpc_opts =&gt; %{\n:service_protos =&gt; [:ffs_demo_pb],\n:unary_interceptor =&gt; {:otel_grpcbox_interceptor, :unary},\n:services =&gt; %{:\"hipstershop.FeatureFlagService\" =&gt; :ffs_service}\n},\n:listen_opts =&gt; %{:port =&gt; grpc_port}\n}\n]\n</code></pre>"},{"location":"docs/demo/services/feature-flag/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Adding attributes to a span is accomplished by using <code>?set_attribute</code> on the span object. In the <code>get_flag</code> function two attributes are added to the span.</p> <pre><code>-include_lib(\"grpcbox/include/grpcbox.hrl\").\n-include_lib(\"opentelemetry_api/include/otel_tracer.hrl\").\n-spec get_flag(ctx:t(), ffs_demo_pb:get_flag_request()) -&gt;\n{ok, ffs_demo_pb:get_flag_response(), ctx:t()} | grpcbox_stream:grpc_error_response().\nget_flag(Ctx, #{name := Name}) -&gt;\ncase 'Elixir.Featureflagservice.FeatureFlags':get_feature_flag_by_name(Name) of\nnil -&gt;\n{grpc_error, {?GRPC_STATUS_NOT_FOUND, &lt;&lt;\"the requested feature flag does not exist\"&gt;&gt;}};\n#{'__struct__' := 'Elixir.Featureflagservice.FeatureFlags.FeatureFlag',\ndescription := Description,\nenabled := Enabled,\ninserted_at := CreatedAt,\nupdated_at := UpdatedAt\n} -&gt;\n?set_attribute('app.featureflag.name', Name),\n?set_attribute('app.featureflag.enabled', Enabled),\n{ok, Epoch} = 'Elixir.NaiveDateTime':from_erl({{1970, 1, 1}, {0, 0, 0}}),\nCreatedAtSeconds = 'Elixir.NaiveDateTime':diff(CreatedAt, Epoch),\nUpdatedAtSeconds = 'Elixir.NaiveDateTime':diff(UpdatedAt, Epoch),\nFlag = #{name =&gt; Name,\ndescription =&gt; Description,\nenabled =&gt; Enabled,\ncreated_at =&gt; #{seconds =&gt; CreatedAtSeconds, nanos =&gt; 0},\nupdated_at =&gt; #{seconds =&gt; UpdatedAtSeconds, nanos =&gt; 0}},\n{ok, #{flag =&gt; Flag}, Ctx}\nend.\n</code></pre>"},{"location":"docs/demo/services/feature-flag/#metrics","title":"Metrics","text":"<p>TBD</p>"},{"location":"docs/demo/services/feature-flag/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/fraud-detection/","title":"Fraud Detection Service","text":"<p>This service analyses incoming orders and detects malicious customers. This is only mocked and received orders are printed out.</p>"},{"location":"docs/demo/services/fraud-detection/#auto-instrumentation","title":"Auto-instrumentation","text":"<p>This service relies on the OpenTelemetry Java Agent to automatically instrument libraries such as Kafka, and to configure the OpenTelemetry SDK. The agent is passed into the process using the <code>-javaagent</code> command line argument. Command line arguments are added through the <code>JAVA_TOOL_OPTIONS</code> in the <code>Dockerfile</code>, and leveraged during the automatically generated Gradle startup script.</p> <pre><code>ENV JAVA_TOOL_OPTIONS=-javaagent:/app/opentelemetry-javaagent.jar\n</code></pre>"},{"location":"docs/demo/services/frontend-proxy/","title":"Frontend Proxy (Envoy)","text":"<p>The frontend proxy is used as a reverse proxy for user-facing web interfaces such as the frontend, Jaeger, Grafana, load generator, and feature flag service.</p>"},{"location":"docs/demo/services/frontend-proxy/#enabling-opentelemetry","title":"Enabling OpenTelemetry","text":"<p>NOTE: Only non-synthetic requests will trigger the envoy tracing.</p> <p>In order to enable Envoy to produce spans whenever receiving a request, the following configuration is required:</p> <pre><code>static_resources:\nlisteners:\n- address:\nsocket_address:\naddress: 0.0.0.0\nport_value: ${ENVOY_PORT}\nfilter_chains:\n- filters:\n- name: envoy.filters.network.http_connection_manager\ntyped_config:\n'@type': type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\ncodec_type: AUTO\nstat_prefix: ingress_http\ntracing:\nprovider:\nname: envoy.tracers.opentelemetry\ntyped_config:\n'@type': type.googleapis.com/envoy.config.trace.v3.OpenTelemetryConfig\ngrpc_service:\nenvoy_grpc:\ncluster_name: opentelemetry_collector\ntimeout: 0.250s\nservice_name: frontend-proxy\nclusters:\n- name: opentelemetry_collector\ntype: STRICT_DNS\nlb_policy: ROUND_ROBIN\ntyped_extension_protocol_options:\nenvoy.extensions.upstreams.http.v3.HttpProtocolOptions:\n'@type': type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\nexplicit_http_config:\nhttp2_protocol_options: {}\nload_assignment:\ncluster_name: opentelemetry_collector\nendpoints:\n- lb_endpoints:\n- endpoint:\naddress:\nsocket_address:\naddress: ${OTEL_COLLECTOR_HOST}\nport_value: ${OTEL_COLLECTOR_PORT}\n</code></pre> <p>Where <code>OTEL_COLLECTOR_HOST</code> and <code>OTEL_COLLECTOR_PORT</code> are passed via environment variables.</p>"},{"location":"docs/demo/services/frontend/","title":"Frontend","text":"<p>The frontend is responsible to provide a UI for users, as well as an API leveraged by the UI or other clients. The application is based on Next.JS to provide a React web-based UI and API routes.</p> <p>Frontend source</p>"},{"location":"docs/demo/services/frontend/#server-instrumentation","title":"Server Instrumentation","text":"<p>It is recommended to use a Node required module when starting your NodeJS application to initialize the SDK and auto-instrumentation. When initializing the OpenTelemetry Node.js SDK, you optionally specify which auto-instrumentation libraries to leverage, or make use of the <code>getNodeAutoInstrumentations()</code> function which includes most popular frameworks. The <code>utils/telemetry/Instrumentation.js</code> file contains all code required to initialize the SDK and auto-instrumentation based on standard OpenTelemetry environment variables for OTLP export, resource attributes, and service name.</p> <pre><code>const opentelemetry = require('@opentelemetry/sdk-node');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\nconst {\nOTLPTraceExporter,\n} = require('@opentelemetry/exporter-trace-otlp-grpc');\nconst {\nOTLPMetricExporter,\n} = require('@opentelemetry/exporter-metrics-otlp-grpc');\nconst { PeriodicExportingMetricReader } = require('@opentelemetry/sdk-metrics');\nconst {\nalibabaCloudEcsDetector,\n} = require('@opentelemetry/resource-detector-alibaba-cloud');\nconst {\nawsEc2Detector,\nawsEksDetector,\n} = require('@opentelemetry/resource-detector-aws');\nconst {\ncontainerDetector,\n} = require('@opentelemetry/resource-detector-container');\nconst { gcpDetector } = require('@opentelemetry/resource-detector-gcp');\nconst {\nenvDetector,\nhostDetector,\nosDetector,\nprocessDetector,\n} = require('@opentelemetry/resources');\nconst sdk = new opentelemetry.NodeSDK({\ntraceExporter: new OTLPTraceExporter(),\ninstrumentations: [\ngetNodeAutoInstrumentations({\n// only instrument fs if it is part of another trace\n'@opentelemetry/instrumentation-fs': {\nrequireParentSpan: true,\n},\n}),\n],\nmetricReader: new PeriodicExportingMetricReader({\nexporter: new OTLPMetricExporter(),\n}),\nresourceDetectors: [\ncontainerDetector,\nenvDetector,\nhostDetector,\nosDetector,\nprocessDetector,\nalibabaCloudEcsDetector,\nawsEksDetector,\nawsEc2Detector,\ngcpDetector,\n],\n});\nsdk.start();\n</code></pre> <p>Node required modules are loaded using the <code>--require</code> command line argument. This can be done in the <code>scripts.start</code> section of <code>package.json</code> and starting the application using <code>npm start</code>.</p> <pre><code>  \"scripts\": {\n\"start\": \"node --require ./Instrumentation.js server.js\",\n},\n</code></pre>"},{"location":"docs/demo/services/frontend/#traces","title":"Traces","text":""},{"location":"docs/demo/services/frontend/#span-exceptions-and-status","title":"Span Exceptions and status","text":"<p>You can use the span object's <code>recordException</code> function to create a span event with the full stack trace of a handled error. When recording an exception also be sure to set the span's status accordingly. You can see this in the catch block of the <code>NextApiHandler</code> function in the <code>utils/telemetry/InstrumentationMiddleware.ts</code> file.</p> <pre><code>span.recordException(error as Exception);\nspan.setStatus({ code: SpanStatusCode.ERROR });\n</code></pre>"},{"location":"docs/demo/services/frontend/#create-new-spans","title":"Create new spans","text":"<p>New spans can be created and started using <code>Tracer.startSpan(\"spanName\", options)</code>. Several options can be used to specify how the span can be created.</p> <ul> <li><code>root: true</code> will create a new trace, setting this span as the root.</li> <li><code>links</code> are used to specify links to other spans (even within another trace)   that should be referenced.</li> <li><code>attributes</code> are key/value pairs added to a span, typically used for   application context.</li> </ul> <pre><code>span = tracer.startSpan(`HTTP ${method}`, {\nroot: true,\nkind: SpanKind.SERVER,\nlinks: [{ context: syntheticSpan.spanContext() }],\nattributes: {\n'app.synthetic_request': true,\n[SemanticAttributes.HTTP_TARGET]: target,\n[SemanticAttributes.HTTP_STATUS_CODE]: response.statusCode,\n[SemanticAttributes.HTTP_METHOD]: method,\n[SemanticAttributes.HTTP_USER_AGENT]: headers['user-agent'] || '',\n[SemanticAttributes.HTTP_URL]: `${headers.host}${url}`,\n[SemanticAttributes.HTTP_FLAVOR]: httpVersion,\n},\n});\n</code></pre>"},{"location":"docs/demo/services/frontend/#browser-instrumentation","title":"Browser Instrumentation","text":"<p>The web-based UI that the frontend provides is also instrumented for web browsers. OpenTelemetry instrumentation is included as part of the Next.js App component in <code>pages/_app.tsx</code>. Here instrumentation is imported and initialized.</p> <pre><code>import FrontendTracer from '../utils/telemetry/FrontendTracer';\nif (typeof window !== 'undefined') FrontendTracer();\n</code></pre> <p>The <code>utils/telemetry/FrontendTracer.ts</code> file contains code to initialize a TracerProvider, establish an OTLP export, register trace context propagators, and register web specific auto-instrumentation libraries. Since the browser will send data to an OpenTelemetry collector that will likely be on a separate domain, CORS headers are also setup accordingly.</p> <p>As part of the changes to carry over the <code>synthetic_request</code> attribute flag for the backend services, the <code>applyCustomAttributesOnSpan</code> configuration function has been added to the <code>instrumentation-fetch</code> library custom span attributes logic that way every browser-side span will include it.</p> <pre><code>import {\nCompositePropagator,\nW3CBaggagePropagator,\nW3CTraceContextPropagator,\n} from '@opentelemetry/core';\nimport { WebTracerProvider } from '@opentelemetry/sdk-trace-web';\nimport { SimpleSpanProcessor } from '@opentelemetry/sdk-trace-base';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\nimport { getWebAutoInstrumentations } from '@opentelemetry/auto-instrumentations-web';\nimport { Resource } from '@opentelemetry/resources';\nimport { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';\nconst FrontendTracer = async () =&gt; {\nconst { ZoneContextManager } = await import('@opentelemetry/context-zone');\nconst provider = new WebTracerProvider({\nresource: new Resource({\n[SemanticResourceAttributes.SERVICE_NAME]:\nprocess.env.NEXT_PUBLIC_OTEL_SERVICE_NAME,\n}),\n});\nprovider.addSpanProcessor(new SimpleSpanProcessor(new OTLPTraceExporter()));\nconst contextManager = new ZoneContextManager();\nprovider.register({\ncontextManager,\npropagator: new CompositePropagator({\npropagators: [\nnew W3CBaggagePropagator(),\nnew W3CTraceContextPropagator(),\n],\n}),\n});\nregisterInstrumentations({\ntracerProvider: provider,\ninstrumentations: [\ngetWebAutoInstrumentations({\n'@opentelemetry/instrumentation-fetch': {\npropagateTraceHeaderCorsUrls: /.*/,\nclearTimingResources: true,\napplyCustomAttributesOnSpan(span) {\nspan.setAttribute('app.synthetic_request', 'false');\n},\n},\n}),\n],\n});\n};\nexport default FrontendTracer;\n</code></pre>"},{"location":"docs/demo/services/frontend/#metrics","title":"Metrics","text":"<p>TBD</p>"},{"location":"docs/demo/services/frontend/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/frontend/#baggage","title":"Baggage","text":"<p>OpenTelemetry Baggage is leveraged in the frontend to check if the request is synthetic (from the load generator). Synthetic requests will force the creation of a new trace. The root span from the new trace will contain many of the same attributes as an HTTP request instrumented span.</p> <p>To determine if a Baggage item is set, you can leverage the <code>propagation</code> API to parse the Baggage header, and leverage the <code>baggage</code> API to get or set entries.</p> <pre><code>    const baggage = propagation.getBaggage(context.active());\nif (baggage?.getEntry(\"synthetic_request\")?.value == \"true\") {...}\n</code></pre>"},{"location":"docs/demo/services/kafka/","title":"Kafka","text":"<p>This is used as a message queue service to connect the checkout service with the accounting and fraud detection services.</p> <p>Kafka service source</p>"},{"location":"docs/demo/services/kafka/#auto-instrumentation","title":"Auto-instrumentation","text":"<p>This service relies on the OpenTelemetry Java Agent and the built in JMX Metric Insight Module to capture kafka broker metrics and send them off to the collector via OTLP.</p> <p>The agent is passed into the process using the <code>-javaagent</code> command line argument. Command line arguments are added through the <code>KAFKA_OPTS</code> in the <code>Dockerfile</code>.</p> <pre><code>ENV KAFKA_OPTS=\"-javaagent:/tmp/opentelemetry-javaagent.jar -Dotel.jmx.target.system=kafka-broker\"\n</code></pre>"},{"location":"docs/demo/services/load-generator/","title":"Load Generator","text":"<p>The load generator is based on the Python load testing framework Locust. By default it will simulate users requesting several different routes from the frontend.</p> <p>Load generator source</p>"},{"location":"docs/demo/services/load-generator/#traces","title":"Traces","text":""},{"location":"docs/demo/services/load-generator/#initializing-tracing","title":"Initializing Tracing","text":"<p>Since this service is a locustfile, the OpenTelemetry SDK is initialized after the import statements. This code will create a tracer provider, and establish a Span Processor to use. Export endpoints, resource attributes, and service name are automatically set using OpenTelemetry environment variables.</p> <pre><code>tracer_provider = TracerProvider()\ntrace.set_tracer_provider(tracer_provider)\ntracer_provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter()))\n</code></pre>"},{"location":"docs/demo/services/load-generator/#adding-instrumentation-libraries","title":"Adding instrumentation libraries","text":"<p>To add instrumentation libraries you need to import the Instrumentors for each library in your Python code. Locust uses the <code>Requests</code> and<code>URLLib3</code> libraries, so we will import their Instrumentors.</p> <pre><code>from opentelemetry.instrumentation.requests import RequestsInstrumentor\nfrom opentelemetry.instrumentation.urllib3 import URLLib3Instrumentor\n</code></pre> <p>In your code before the library is leveraged, the Instrumentor needs to be initialized by calling <code>instrument()</code>.</p> <pre><code>RequestsInstrumentor().instrument()\nURLLib3Instrumentor().instrument()\n</code></pre> <p>Once initialized, every Locust requests for this load generator will have their own trace with a span for each of the <code>Requests</code> and <code>URLLib3</code> libraries.</p>"},{"location":"docs/demo/services/load-generator/#metrics","title":"Metrics","text":"<p>TBD</p>"},{"location":"docs/demo/services/load-generator/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/load-generator/#baggage","title":"Baggage","text":"<p>OpenTelemetry Baggage is used by the load generator to indicate that the traces are synthetically generated. This is done in the <code>on_start</code> function by creating a context object containing the baggage item, and associating that context for all tasks by the load generator.</p> <pre><code>    ctx = baggage.set_baggage(\"synthetic_request\", \"true\")\ncontext.attach(ctx)\n</code></pre>"},{"location":"docs/demo/services/payment/","title":"Payment Service","text":"<p>This service is responsible to process credit card payments for orders. It will return an error if the credit card is invalid or the payment can not be processed.</p> <p>Payment service source</p>"},{"location":"docs/demo/services/payment/#initializing-opentelemetry","title":"Initializing OpenTelemetry","text":"<p>It is recommended to <code>require</code> Node.js app using an initializer file that initializes the SDK and auto-instrumentation. When initializing the OpenTelemetry Node.js SDK in that module, you optionally specify which auto-instrumentation libraries to leverage, or make use of the <code>getNodeAutoInstrumentations()</code> function which includes most popular frameworks. The below example of an initializer file (<code>opentelemetry.js</code>) contains all code required to initialize the SDK and auto-instrumentation based on standard OpenTelemetry environment variables for OTLP export, resource attributes, and service name. It then <code>require</code>s your app at <code>./index.js</code> to start it up once the SDK is initialized.</p> <pre><code>const opentelemetry = require('@opentelemetry/sdk-node');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\nconst {\nOTLPTraceExporter,\n} = require('@opentelemetry/exporter-trace-otlp-grpc');\nconst {\nOTLPMetricExporter,\n} = require('@opentelemetry/exporter-metrics-otlp-grpc');\nconst { PeriodicExportingMetricReader } = require('@opentelemetry/sdk-metrics');\nconst {\nalibabaCloudEcsDetector,\n} = require('@opentelemetry/resource-detector-alibaba-cloud');\nconst {\nawsEc2Detector,\nawsEksDetector,\n} = require('@opentelemetry/resource-detector-aws');\nconst {\ncontainerDetector,\n} = require('@opentelemetry/resource-detector-container');\nconst { gcpDetector } = require('@opentelemetry/resource-detector-gcp');\nconst {\nenvDetector,\nhostDetector,\nosDetector,\nprocessDetector,\n} = require('@opentelemetry/resources');\nconst sdk = new opentelemetry.NodeSDK({\ntraceExporter: new OTLPTraceExporter(),\ninstrumentations: [\ngetNodeAutoInstrumentations({\n// only instrument fs if it is part of another trace\n'@opentelemetry/instrumentation-fs': {\nrequireParentSpan: true,\n},\n}),\n],\nmetricReader: new PeriodicExportingMetricReader({\nexporter: new OTLPMetricExporter(),\n}),\nresourceDetectors: [\ncontainerDetector,\nenvDetector,\nhostDetector,\nosDetector,\nprocessDetector,\nalibabaCloudEcsDetector,\nawsEksDetector,\nawsEc2Detector,\ngcpDetector,\n],\n});\nsdk.start();\n</code></pre> <p>You can then use <code>opentelemetry.js</code> to start your app. This can be done in the <code>ENTRYPOINT</code> command for the service's <code>Dockerfile</code>.</p> <pre><code>ENTRYPOINT [ \"node\", \"./opentelemetry.js\" ]\n</code></pre>"},{"location":"docs/demo/services/payment/#traces","title":"Traces","text":""},{"location":"docs/demo/services/payment/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span from context.</p> <pre><code>const span = opentelemetry.trace.getActiveSpan();\n</code></pre> <p>Adding attributes to a span is accomplished using <code>setAttributes</code> on the span object. In the <code>chargeServiceHandler</code> function an attributes is added to the span as an anonymous object (map) for the attribute key/values pair.</p> <pre><code>span.setAttributes({\n'app.payment.amount': parseFloat(`${amount.units}.${amount.nanos}`),\n});\n</code></pre>"},{"location":"docs/demo/services/payment/#span-exceptions-and-status","title":"Span Exceptions and status","text":"<p>You can use the span object's <code>recordException</code> function to create a span event with the full stack trace of a handled error. When recording an exception also be sure to set the span's status accordingly. You can see this in the <code>chargeServiceHandler</code> function</p> <pre><code>span.recordException(err);\nspan.setStatus({ code: opentelemetry.SpanStatusCode.ERROR });\n</code></pre>"},{"location":"docs/demo/services/payment/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/payment/#creating-meters-and-instruments","title":"Creating Meters and Instruments","text":"<p>Meters can be created using the <code>@opentelemetry/api-metrics</code> package. You can create meters as seen below, and then use the created meter to create instruments.</p> <pre><code>const { metrics } = require('@opentelemetry/api-metrics');\nconst meter = metrics.getMeter('paymentservice');\nconst transactionsCounter = meter.createCounter('app.payment.transactions');\n</code></pre> <p>Meters and Instruments are supposed to stick around. This means you should get a Meter or an Instrument once , and then re-use it as needed, if possible.</p>"},{"location":"docs/demo/services/payment/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/payment/#baggage","title":"Baggage","text":"<p>OpenTelemetry Baggage is leveraged in this service to check if the request is synthetic (from the load generator). Synthetic requests will not be charged, which is indicated with a span attribute. The <code>charge.js</code> file which does the actual payment processing, has logic to check the baggage.</p> <pre><code>// check baggage for synthetic_request=true, and add charged attribute accordingly\nconst baggage = propagation.getBaggage(context.active());\nif (\nbaggage &amp;&amp;\nbaggage.getEntry('synthetic_request') &amp;&amp;\nbaggage.getEntry('synthetic_request').value == 'true'\n) {\nspan.setAttribute('app.payment.charged', false);\n} else {\nspan.setAttribute('app.payment.charged', true);\n}\n</code></pre>"},{"location":"docs/demo/services/product-catalog/","title":"Product Catalog Service","text":"<p>This service is responsible to return information about products. The service can be used to get all products, search for specific products, or return details about any single product.</p> <p>Product Catalog service source</p>"},{"location":"docs/demo/services/product-catalog/#traces","title":"Traces","text":""},{"location":"docs/demo/services/product-catalog/#initializing-tracing","title":"Initializing Tracing","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code> using the <code>initTracerProvider</code> function.</p> <pre><code>func initTracerProvider() *sdktrace.TracerProvider {\nctx := context.Background()\nexporter, err := otlptracegrpc.New(ctx)\nif err != nil {\nlog.Fatalf(\"OTLP Trace gRPC Creation: %v\", err)\n}\ntp := sdktrace.NewTracerProvider(\nsdktrace.WithBatcher(exporter),\nsdktrace.WithResource(initResource()),\n)\notel.SetTracerProvider(tp)\notel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{}))\nreturn tp\n}\n</code></pre> <p>You should call <code>TracerProvider.Shutdown()</code> when your service is shutdown to ensure all spans are exported. This service makes that call as part of a deferred function in main</p> <pre><code>    tp := InitTracerProvider()\ndefer func() {\nif err := tp.Shutdown(context.Background()); err != nil {\nlog.Fatalf(\"Tracer Provider Shutdown: %v\", err)\n}\n}()\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#adding-grpc-auto-instrumentation","title":"Adding gRPC auto-instrumentation","text":"<p>This service receives gRPC requests, which are instrumented in the main function as part of the gRPC server creation.</p> <pre><code>    srv := grpc.NewServer(\ngrpc.UnaryInterceptor(otelgrpc.UnaryServerInterceptor()),\ngrpc.StreamInterceptor(otelgrpc.StreamServerInterceptor()),\n)\n</code></pre> <p>This service will issue outgoing gRPC calls, which are all instrumented by wrapping the gRPC client with instrumentation.</p> <pre><code>func createClient(ctx context.Context, svcAddr string) (*grpc.ClientConn, error) {\nreturn grpc.DialContext(ctx, svcAddr,\ngrpc.WithTransportCredentials(insecure.NewCredentials()),\ngrpc.WithUnaryInterceptor(otelgrpc.UnaryClientInterceptor()),\ngrpc.WithStreamInterceptor(otelgrpc.StreamClientInterceptor()),\n)\n}\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span from context.</p> <pre><code>    span := trace.SpanFromContext(ctx)\n</code></pre> <p>Adding attributes to a span is accomplished using <code>SetAttributes</code> on the span object. In the <code>GetProduct</code> function an attribute for the product id is added to the span.</p> <pre><code>    span.SetAttributes(\nattribute.String(\"app.product.id\", req.Id),\n)\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#setting-span-status","title":"Setting span status","text":"<p>This service can catch and handle an error condition based on a feature flag. In an error condition, the span status is set accordingly using <code>SetStatus</code> on the span object. You can see this in the <code>GetProduct</code> function.</p> <pre><code>    msg := fmt.Sprintf(\"Error: ProductCatalogService Fail Feature Flag Enabled\")\nspan.SetStatus(otelcodes.Error, msg)\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#add-span-events","title":"Add span events","text":"<p>Adding span events is accomplished using <code>AddEvent</code> on the span object. In the <code>GetProduct</code> function a span event is added when an error condition is handled, or when a product is successfully found.</p> <pre><code>    span.AddEvent(msg)\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/product-catalog/#initializing-metrics","title":"Initializing Metrics","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code> using the <code>initMeterProvider</code> function.</p> <pre><code>func initMeterProvider() *sdkmetric.MeterProvider {\nctx := context.Background()\nexporter, err := otlpmetricgrpc.New(ctx)\nif err != nil {\nlog.Fatalf(\"new otlp metric grpc exporter failed: %v\", err)\n}\nmp := sdkmetric.NewMeterProvider(sdkmetric.WithReader(sdkmetric.NewPeriodicReader(exporter)))\nglobal.SetMeterProvider(mp)\nreturn mp\n}\n</code></pre> <p>You should call <code>initMeterProvider.Shutdown()</code> when your service is shutdown to ensure all records are exported. This service makes that call as part of a deferred function in main.</p> <pre><code>    mp := initMeterProvider()\ndefer func() {\nif err := mp.Shutdown(context.Background()); err != nil {\nlog.Fatalf(\"Error shutting down meter provider: %v\", err)\n}\n}()\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#adding-golang-runtime-auto-instrumentation","title":"Adding golang runtime auto-instrumentation","text":"<p>Golang runtime is instrumented in the main function</p> <pre><code>    err := runtime.Start(runtime.WithMinimumReadMemStatsInterval(time.Second))\nif err != nil {\nlog.Fatal(err)\n}\n</code></pre>"},{"location":"docs/demo/services/product-catalog/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/quote/","title":"Quote Service","text":"<p>This service is responsible for calculating shipping costs, based on the number of items to be shipped. The quote service is called from Shipping Service via HTTP.</p> <p>The Quote Service is implemented using the Slim framework and php-di for managing the Dependency Injection.</p> <p>The PHP instrumentation may vary when using a different framework.</p> <p>Quote service source</p>"},{"location":"docs/demo/services/quote/#traces","title":"Traces","text":""},{"location":"docs/demo/services/quote/#initializing-tracing","title":"Initializing Tracing","text":"<p>In this demo, the OpenTelemetry SDK has been automatically created as part of SDK autoloading, which happens as part of composer autoloading.</p> <p>This is enabled by setting the environment variable <code>OTEL_PHP_AUTOLOAD_ENABLED=true</code>.</p> <pre><code>    require __DIR__ . '/../vendor/autoload.php';\n</code></pre> <p>There are multiple ways to create or obtain a <code>Tracer</code>, in this example we obtain one from the global tracer provider which was initialized above, as part of SDK autoloading:</p> <pre><code>    $tracer = Globals::tracerProvider()-&gt;getTracer('manual-instrumentation');\n</code></pre>"},{"location":"docs/demo/services/quote/#manually-creating-spans","title":"Manually creating spans","text":"<p>Creating a span manually can be done via a <code>Tracer</code>. The span will be default be a child of the active span in the current execution context:</p> <pre><code>    $span = Globals::tracerProvider()\n        -&gt;getTracer('manual-instrumentation')\n        -&gt;spanBuilder('calculate-quote')\n        -&gt;setSpanKind(SpanKind::KIND_INTERNAL)\n        -&gt;startSpan();\n    /* calculate quote */\n    $span-&gt;end();\n</code></pre>"},{"location":"docs/demo/services/quote/#add-span-attributes","title":"Add span attributes","text":"<p>You can obtain the current span using <code>OpenTelemetry\\API\\Trace\\Span</code>.</p> <pre><code>    $span = Span::getCurrent();\n</code></pre> <p>Adding attributes to a span is accomplished using <code>setAttribute</code> on the span object. In the <code>calculateQuote</code> function 2 attributes are added to the <code>childSpan</code>.</p> <pre><code>    $childSpan-&gt;setAttribute('app.quote.items.count', $numberOfItems);\n    $childSpan-&gt;setAttribute('app.quote.cost.total', $quote);\n</code></pre>"},{"location":"docs/demo/services/quote/#add-span-events","title":"Add span events","text":"<p>Adding span events is accomplished using <code>addEvent</code> on the span object. In the <code>getquote</code> route span events are added. Some events have additional attributes, others do not.</p> <p>Adding a span event without attributes:</p> <pre><code>    $span-&gt;addEvent('Received get quote request, processing it');\n</code></pre> <p>Adding a span event with additional attributes:</p> <pre><code>    $span-&gt;addEvent('Quote processed, response sent back', [\n        'app.quote.cost.total' =&gt; $payload\n    ]);\n</code></pre>"},{"location":"docs/demo/services/quote/#metrics","title":"Metrics","text":"<p>TBD</p>"},{"location":"docs/demo/services/quote/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/recommendation/","title":"Recommendation Service","text":"<p>This service is responsible to get a list of recommended products for the user based on existing product ids the user is browsing.</p> <p>Recommendation service source</p>"},{"location":"docs/demo/services/recommendation/#auto-instrumentation","title":"Auto-instrumentation","text":"<p>This Python based service, makes use of the OpenTelemetry auto-instrumentor for Python, accomplished by leveraging the <code>opentelemetry-instrument</code> Python wrapper to run the scripts. This can be done in the <code>ENTRYPOINT</code> command for the service's <code>Dockerfile</code>.</p> <pre><code>ENTRYPOINT [ \"opentelemetry-instrument\", \"python\", \"recommendation_server.py\" ]\n</code></pre>"},{"location":"docs/demo/services/recommendation/#traces","title":"Traces","text":""},{"location":"docs/demo/services/recommendation/#initializing-tracing","title":"Initializing Tracing","text":"<p>The OpenTelemetry SDK is initialized in the <code>__main__</code> code block. This code will create a tracer provider, and establish a Span Processor to use. Export endpoints, resource attributes, and service name are automatically set by the OpenTelemetry auto instrumentor based on environment variables.</p> <pre><code>    tracer = trace.get_tracer_provider().get_tracer(\"recommendationservice\")\n</code></pre>"},{"location":"docs/demo/services/recommendation/#add-attributes-to-auto-instrumented-spans","title":"Add attributes to auto-instrumented spans","text":"<p>Within the execution of auto-instrumented code you can get current span from context.</p> <pre><code>    span = trace.get_current_span()\n</code></pre> <p>Adding attributes to a span is accomplished using <code>set_attribute</code> on the span object. In the <code>ListRecommendations</code> function an attribute is added to the span.</p> <pre><code>    span.set_attribute(\"app.products_recommended.count\", len(prod_list))\n</code></pre>"},{"location":"docs/demo/services/recommendation/#create-new-spans","title":"Create new spans","text":"<p>New spans can be created and placed into active context using <code>start_as_current_span</code> from an OpenTelemetry Tracer object. When used in conjunction with a <code>with</code> block, the span will automatically be ended when the block ends execution. This is done in the <code>get_product_list</code> function.</p> <pre><code>    with tracer.start_as_current_span(\"get_product_list\") as span:\n</code></pre>"},{"location":"docs/demo/services/recommendation/#metrics","title":"Metrics","text":""},{"location":"docs/demo/services/recommendation/#initializing-metrics","title":"Initializing Metrics","text":"<p>The OpenTelemetry SDK is initialized in the <code>__main__</code> code block. This code will create a meter provider. Export endpoints, resource attributes, and service name are automatically set by the OpenTelemetry auto instrumentor based on environment variables.</p> <pre><code>    meter = metrics.get_meter_provider().get_meter(\"recommendationservice\")\n</code></pre>"},{"location":"docs/demo/services/recommendation/#custom-metrics","title":"Custom metrics","text":"<p>The following custom metrics are currently available:</p> <ul> <li><code>app_recommendations_counter</code>: Cumulative count of # recommended products per   service call</li> </ul>"},{"location":"docs/demo/services/recommendation/#auto-instrumented-metrics","title":"Auto-instrumented metrics","text":"<p>The following metrics are available through auto-instrumentation, courtesy of the <code>opentelemetry-instrumentation-system-metrics</code>, which is installed as part of <code>opentelemetry-bootstrap</code> on building the recommendationservice Docker image:</p> <ul> <li><code>runtime.cpython.cpu_time</code></li> <li><code>runtime.cpython.memory</code></li> <li><code>runtime.cpython.gc_count</code></li> </ul>"},{"location":"docs/demo/services/recommendation/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/demo/services/shipping/","title":"Shipping Service","text":"<p>This service is responsible for providing shipping information including pricing and tracking information, when requested from Checkout Service.</p> <p>Shipping service is built primarily with Tonic, Reqwest, and OpenTelemetry Libraries/Components. Other sub-dependencies are included in <code>Cargo.toml</code>.</p> <p>Depending on your framework and runtime, you may consider consulting rust docs to supplement. You'll find examples of async and sync spans in quote requests and tracking ID's respectively.</p> <p>The <code>build.rs</code> supports development outside docker, given a rust installation. Otherwise, consider building with <code>docker compose</code> to edit / assess changes as needed.</p> <p>Shipping service source</p>"},{"location":"docs/demo/services/shipping/#traces","title":"Traces","text":""},{"location":"docs/demo/services/shipping/#initializing-tracing","title":"Initializing Tracing","text":"<p>The OpenTelemetry SDK is initialized from <code>main</code>.</p> <pre><code>fn init_tracer() -&gt; Result&lt;sdktrace::Tracer, TraceError&gt; {\nglobal::set_text_map_propagator(TraceContextPropagator::new());\nlet os_resource = OsResourceDetector.detect(Duration::from_secs(0));\nlet process_resource = ProcessResourceDetector.detect(Duration::from_secs(0));\nlet sdk_resource = SdkProvidedResourceDetector.detect(Duration::from_secs(0));\nlet env_resource = EnvResourceDetector::new().detect(Duration::from_secs(0));\nopentelemetry_otlp::new_pipeline()\n.tracing()\n.with_exporter(\nopentelemetry_otlp::new_exporter()\n.tonic()\n.with_endpoint(format!(\n\"{}{}\",\nenv::var(\"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\")\n.unwrap_or_else(|_| \"http://otelcol:4317\".to_string()),\n\"/v1/traces\"\n)), // TODO: assume this ^ is true from config when opentelemetry crate &gt; v0.17.0\n// https://github.com/open-telemetry/opentelemetry-rust/pull/806 includes the environment variable.\n)\n.with_trace_config(\nsdktrace::config()\n.with_resource(os_resource.merge(&amp;process_resource).merge(&amp;sdk_resource).merge(&amp;env_resource)),\n)\n.install_batch(opentelemetry::runtime::Tokio)\n}\n</code></pre> <p>Spans and other metrics are created in this example throughout <code>tokio</code> async runtimes found within <code>tonic</code> server functions. Be mindful of async runtime, context guards, and inability to move and clone <code>spans</code> when replicating from these samples.</p>"},{"location":"docs/demo/services/shipping/#adding-grpc-instrumentation","title":"Adding gRPC instrumentation","text":"<p>This service receives gRPC requests, which are instrumented in the middleware.</p> <p>The root span is started and passed down as reference in the same thread to another closure where we call <code>quoteservice</code>.</p> <pre><code>    let tracer = global::tracer(\"shippingservice\");\nlet mut span = tracer.span_builder(\"hipstershop.ShippingService/GetQuote\").with_kind(SpanKind::Server).start_with_context(&amp;tracer, &amp;parent_cx);\nspan.set_attribute(semcov::trace::RPC_SYSTEM.string(RPC_SYSTEM_GRPC));\nspan.add_event(\"Processing get quote request\".to_string(), vec![]);\nlet cx = Context::current_with_span(span);\nlet q = match create_quote_from_count(itemct)\n.with_context(cx.clone())\n.await\n//-&gt; create_quote_from_count()...\nlet f = match request_quote(count).await {\nOk(float) =&gt; float,\nErr(err) =&gt; {\nlet msg = format!(\"{}\", err);\nreturn Err(tonic::Status::unknown(msg));\n}\n};\nOk(get_active_span(|span| {\nlet q = create_quote_from_float(f);\nspan.add_event(\n\"Received Quote\".to_string(),\nvec![KeyValue::new(\"app.shipping.cost.total\", format!(\"{}\", q))],\n);\nspan.set_attribute(KeyValue::new(\"app.shipping.items.count\", count as i64));\nspan.set_attribute(KeyValue::new(\"app.shipping.cost.total\", format!(\"{}\", q)));\nq\n}))\n//&lt;- create_quote_from_count()...\ncx.span().set_attribute(semcov::trace::RPC_GRPC_STATUS_CODE.i64(RPC_GRPC_STATUS_CODE_OK));\n</code></pre> <p>Note that we create a context around the root span and send a clone to the async function create_quote_from_count(). After create_quote_from_count() completes, we can add additional attributes to the root span as appropriate.</p> <p>You may also notice the <code>attributes</code> set on the span in this example, and <code>events</code> propagated similarly. With any valid <code>span</code> pointer (attached to context) the OpenTelemetry API will work.</p>"},{"location":"docs/demo/services/shipping/#adding-http-instrumentation","title":"Adding HTTP instrumentation","text":"<p>A child client span is also produced for the outgoing HTTP call to <code>quoteservice</code> via the <code>reqwest</code> client. This span pairs up with the corresponding <code>quoteservice</code> server span. The tracing instrumentation is implemented in the client middleware making use of the available <code>reqwest-middleware</code>, <code>reqwest-tracing</code> and <code>tracing-opentelementry</code> libraries:</p> <pre><code>    let reqwest_client = reqwest::Client::new();\nlet client = ClientBuilder::new(reqwest_client)\n.with(TracingMiddleware::&lt;SpanBackendWithUrl&gt;::new())\n.build();\n</code></pre>"},{"location":"docs/demo/services/shipping/#add-span-attributes","title":"Add span attributes","text":"<p>Provided you are on the same thread, or in a context passed from a span-owning thread, or a <code>ContextGuard</code> is in scope, you can get an active span with <code>get_active_span</code>. You can find examples of all of these in the demo, with context available in <code>shipping_service</code> for sync/async runtime. You should consult <code>quote.rs</code> and/or the example above to see context-passed-to-async runtime.</p> <p>See below for a snippet from <code>shiporder</code> that holds context and a span in scope. This is appropriate in our case of a sync runtime.</p> <pre><code>    let parent_cx =\nglobal::get_text_map_propagator(|prop| prop.extract(&amp;MetadataMap(request.metadata())));\n// in this case, generating a tracking ID is trivial\n// we'll create a span and associated events all in this function.\nlet tracer = global::tracer(\"shippingservice\");\nlet mut span = tracer\n.span_builder(\"hipstershop.ShippingService/ShipOrder\").with_kind(SpanKind::Server).start_with_context(&amp;tracer, &amp;parent_cx);\n</code></pre> <p>You must add attributes to a span in context with <code>set_attribute</code>, followed by a <code>KeyValue</code> object, containing a key, and value.</p> <pre><code>    let tid = create_tracking_id();\nspan.set_attribute(KeyValue::new(\"app.shipping.tracking.id\", tid.clone()));\ninfo!(\"Tracking ID Created: {}\", tid);\n</code></pre>"},{"location":"docs/demo/services/shipping/#add-span-events","title":"Add span events","text":"<p>Adding span events is accomplished using <code>add_event</code> on the span object. Both server routes, for <code>ShipOrderRequest</code> (sync) and <code>GetQuoteRequest</code> (async), have events on spans. Attributes are not included here, but are simple to include.</p> <p>Adding a span event:</p> <pre><code>    let tid = create_tracking_id();\nspan.set_attribute(KeyValue::new(\"app.shipping.tracking.id\", tid.clone()));\ninfo!(\"Tracking ID Created: {}\", tid);\n</code></pre>"},{"location":"docs/demo/services/shipping/#metrics","title":"Metrics","text":"<p>TBD</p>"},{"location":"docs/demo/services/shipping/#logs","title":"Logs","text":"<p>TBD</p>"},{"location":"docs/faas/_index/","title":"Functions as a Service","text":"<p>Functions as a Service (FaaS) is an important serverless compute platform for cloud native applications. However, platform quirks usually mean these applications have slightly different monitoring guidance and requirements than applications running on Kubernetes or Virtual Machines.</p> <p>The initial vendor scope of the FaaS documentation is around Microsoft Azure, Google Cloud Platform (GCP), and Amazon Web Services (AWS). AWS functions are also known as Lambda.</p>"},{"location":"docs/faas/_index/#community-assets","title":"Community Assets","text":"<p>The OpenTelemetry community currently provides pre-built Lambda layers able to auto-instrument your application as well as a the option of standalone Collector Lambda layer that can be used when instrumenting applications manually or automatically.</p> <p>The release status can be tracked in the OpenTelemetry-Lambda repository.</p>"},{"location":"docs/faas/lambda-auto-instrument/","title":"Lambda Auto-Instrumentation","text":"<p>The OpenTelemetry community provides standalone instrumentation Lambda layers for the following languages:</p> <ul> <li>Java</li> <li>JavaScript</li> <li>Python</li> </ul> <p>These can be added to your Lambda using the AWS portal to automatically instrument your application. These layers do not include the Collector which is a required addition unless you configure an external Collector instance to send your data.</p>"},{"location":"docs/faas/lambda-auto-instrument/#add-the-arn-of-the-otel-collector-lambda-layer","title":"Add the ARN of the OTel Collector Lambda layer","text":"<p>See the Collector Lambda layer guidance to add the layer to your application and configure the Collector. We recommend you add this first.</p>"},{"location":"docs/faas/lambda-auto-instrument/#language-requirements","title":"Language Requirements","text":"<p>{{&lt; tabpane text=true &gt;}} {{% tab Java %}}</p> <p>The Lambda layer supports the Java 11 (Corretto) Lambda runtime. It does not support the Java 8 Lambda runtimes. For more information about supported Java versions, see the OpenTelemetry Java documentation.</p> <p>Note: The Java Auto-instrumentation Agent is in the Lambda layer - Automatic instrumentation has a notable impact on startup time on AWS Lambda and you will generally need to use this along with provisioned concurrency and warmup requests to serve production requests without causing timeouts on initial requests while it initializes.</p> <p>By default, the OTel Java Agent in the Layer will try to auto-instrument all the code in your application. This can have a negative impact on the Lambda cold startup time.</p> <p>We recommend that you only enable auto-instrumentation for the libraries/frameworks that are used by your application.</p> <p>To enable only specific instrumentations you can use the following environment variables:</p> <pre><code>* OTEL_INSTRUMENTATION_COMMON_DEFAULT_ENABLED - When set to false, disables auto-instrumentation in the Layer, requiring each instrumentation to be enabled individually.\n* OTEL_INSTRUMENTATION_[NAME]_ENABLED - Set to true to enable auto-instrumentation for a specific library or framework. [NAME] should be replaced by the instrumentation that you want to enable. The full list of available instrumentations can be found in this link.\n</code></pre> <p>For example, to only enable auto-instrumentation for Lambda and the AWS SDK, you would have to set the following environment variables:</p> <pre><code>```bash\nCopy\nOTEL_INSTRUMENTATION_COMMON_DEFAULT_ENABLED=false\nOTEL_INSTRUMENTATION_AWS_LAMBDA_ENABLED=true\nOTEL_INSTRUMENTATION_AWS_SDK_ENABLED=true\n```\n</code></pre> <p>{{% /tab %}} {{% tab JavaScript %}}</p> <p>The Lambda layer supports Node.js v14+ Lambda runtimes. For more information about supported JavaScript and Node.js versions, see the OpenTelemetry JavaScript documentation.</p> <p>{{% /tab %}} {{% tab Python %}}</p> <p>The Lambda layer supports Python 3.8 and Python 3.9 Lambda runtimes. For more information about supported Python versions, see the OpenTelemetry Python documentation and the package on PyPi.</p> <p>{{% /tab %}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/faas/lambda-auto-instrument/#add-the-arn-of-instrumentation-lambda-layer","title":"Add the ARN of Instrumentation Lambda Layer","text":"<p>To enable the OTel auto-instrumentation in your Lambda function, you need to add and configure the instrumentation and Collector layers, and then enable tracing.</p> <ol> <li>Open the Lambda function you intend to instrument in the AWS console.</li> <li>In the Layers in Designer section, choose Add a layer.</li> <li>Under specify an ARN, paste the layer ARN, and then choose Add.</li> </ol>"},{"location":"docs/faas/lambda-auto-instrument/#configure-your-sdk-exporters","title":"Configure your SDK exporters","text":"<p>The default exporters used by the Lambda layers will work without any changes if there is an embedded Collector with gRPC / HTTP receivers. The environment variables do not need to be updated. However, there are varying levels of protocol support and default values by language which are documented below.</p> <p>{{&lt; tabpane text=true &gt;}} {{% tab Java %}}</p> <p><code>OTEL_EXPORTER_OTLP_PROTOCOL=grpc</code> Supports: <code>grpc</code>, <code>http/protobuf</code> and <code>http/json</code> <code>OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317</code></p> <p>{{% /tab %}} {{% tab Python %}}</p> <p><code>OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf</code> Supports: <code>http/protobuf</code> and <code>http/json</code> <code>OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318</code></p> <p>{{% /tab %}} {{% tab JavaScript %}}</p> <p><code>OTEL_EXPORTER_OTLP_PROTOCOL</code> env var is not supported The hard coded exporter uses the protocol <code>http/protobuf</code> <code>OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318</code></p> <p>{{% /tab %}} {{&lt; /tabpane &gt;}}</p>"},{"location":"docs/faas/lambda-auto-instrument/#publish-your-lambda","title":"Publish your Lambda","text":"<p>Publish a new version of your Lambda to deploy the new changes and instrumentation.</p>"},{"location":"docs/faas/lambda-collector/","title":"Lambda Collector Configuration","text":"<p>The OpenTelemetry community offers the Collector in a separate Lambda layer from the instrumentation layers to give users maximum flexibility. This is different than the current AWS Distribution of OpenTelemetry (ADOT) implementation which bundles instrumentation and the Collector together.</p>"},{"location":"docs/faas/lambda-collector/#add-the-arn-of-the-otel-collector-lambda-layer","title":"Add the ARN of the OTel Collector Lambda layer","text":"<p>Once you've instrumented your application you should add the Collector Lambda layer to collect and submit your data to your chosen backend.</p> <p>Note: Lambda layers are a regionalized resource, meaning that they can only be used in the Region in which they are published. Make sure to use the layer in the same region as your Lambda functions.</p> <p>Find the supported regions and amd64(x86_64)/arm64 layer ARN in the table below for the ARNs to consume.</p>"},{"location":"docs/faas/lambda-collector/#configure-the-otel-collector","title":"Configure the OTel Collector","text":"<p>The configuration of the OTel Collector Lambda layer follows the OpenTelemetry standard.</p> <p>By default, the OTel Collector Lambda layer uses the config.yaml.</p>"},{"location":"docs/faas/lambda-collector/#set-the-environment-variable-for-your-preferred-backend","title":"Set the Environment Variable for your Preferred Backend","text":"<p>In the Lambda environment variable settings create a new variable that holds your authorization token.</p>"},{"location":"docs/faas/lambda-collector/#update-the-default-exporters","title":"Update the Default Exporters","text":"<p>In your <code>config.yaml</code> file add your preferred exporter(s) if they are not already present. Configure your exporter(s) using the environment variables you set for your access tokens in the previous step.</p> <p>Without an environment variable being set for your exporters the default configuration only supports emitting data using the logging exporter. Here is the default configuration:</p> <pre><code>receivers:\notlp:\nprotocols:\ngrpc:\nendpoint: 'localhost:4317'\nhttp:\nendpoint: 'localhost:4318'\nexporters:\nlogging:\nloglevel: debug\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [logging]\nmetrics:\nreceivers: [otlp]\nexporters: [logging]\ntelemetry:\nmetrics:\naddress: localhost:8888\n</code></pre>"},{"location":"docs/faas/lambda-collector/#publish-your-lambda","title":"Publish your Lambda","text":"<p>Publish a new version of your Lambda to enable the changes you made.</p>"},{"location":"docs/faas/lambda-collector/#advanced-otel-collector-configuration","title":"Advanced OTel Collector Configuration","text":"<p>Please find the list of available components supported for custom configuration here. To enable debugging, you can use the configuration file to set log level to debug. See the example below.</p>"},{"location":"docs/faas/lambda-collector/#choose-your-preferred-confmap-provider","title":"Choose your Preferred Confmap Provider","text":"<p>The OTel Lambda Layers supports the following types of confmap providers: <code>file</code>, <code>env</code>, <code>yaml</code>, <code>http</code>, <code>https</code>, and <code>s3</code>. To customize the OTel collector configuration using different Confmap providers, Please refer to Amazon Distribution of OpenTelemetry Confmap providers document for more information.</p>"},{"location":"docs/faas/lambda-collector/#create-a-custom-configuration-file","title":"Create a Custom Configuration File","text":"<p>Here is a sample configuration file of <code>collector.yaml</code> in the root directory:</p> <pre><code>#collector.yaml in the root directory\n#Set an environment variable 'OPENTELEMETRY_COLLECTOR_CONFIG_FILE' to '/var/task/collector.yaml'\nreceivers:\notlp:\nprotocols:\ngrpc:\nendpoint: 'localhost:4317'\nhttp:\nendpoint: 'localhost:4318'\nexporters:\nlogging:\nawsxray:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [awsxray]\nmetrics:\nreceivers: [otlp]\nexporters: [logging]\ntelemetry:\nmetrics:\naddress: localhost:8888\n</code></pre>"},{"location":"docs/faas/lambda-collector/#map-your-custom-configuration-file-using-environment-variables","title":"Map your Custom Configuration File using Environment Variables","text":"<p>Once your collector configuration is set through a confmap provider, create an environment variable on your Lambda function <code>OPENTELEMETRY_COLLECTOR_CONFIG_FILE</code> and set the path of configuration w.r.t to the confmap provider as its value. for e.g, if you are using a file configmap provider, set its value to <code>/var/task/&lt;path&gt;/&lt;to&gt;/&lt;filename&gt;</code>. This will tell the extension where to find the collector configuration.</p>"},{"location":"docs/faas/lambda-collector/#custom-collector-configuration-using-the-cli","title":"Custom Collector Configuration Using the CLI","text":"<p>You can set this via the Lambda console, or via the AWS CLI.</p> <pre><code>aws lambda update-function-configuration --function-name Function --environment Variables={OPENTELEMETRY_COLLECTOR_CONFIG_FILE=/var/task/collector.yaml}\n</code></pre>"},{"location":"docs/faas/lambda-collector/#set-configuration-environment-variables-from-cloudformation","title":"Set Configuration Environment Variables from CloudFormation","text":"<p>You can configure environment variables via CloudFormation template as well:</p> <pre><code>Function:\nType: AWS::Serverless::Function\nProperties:\n...\nEnvironment:\nVariables:\nOPENTELEMETRY_COLLECTOR_CONFIG_FILE: /var/task/collector.yaml\n</code></pre>"},{"location":"docs/faas/lambda-collector/#load-configuration-from-an-s3-object","title":"Load Configuration from an S3 Object","text":"<p>Loading configuration from S3 will require that the IAM role attached to your function includes read access to the relevant bucket.</p> <pre><code>  Function:\nType: AWS::Serverless::Function\nProperties:\n...\nEnvironment:\nVariables:\nOPENTELEMETRY_COLLECTOR_CONFIG_FILE: s3://&lt;bucket_name&gt;.s3.&lt;region&gt;.amazonaws.com/collector_config.yaml\n</code></pre>"},{"location":"docs/faas/lambda-manual-instrument/","title":"Lambda Manual Instrumentation","text":"<p>For languages not covered in the Lambda auto-instrumentation document, the community does not have a standalone instrumentation layer.</p> <p>Users will need to follow the generic instrumentation guidance for their chosen language and add the Collector Lambda layer to submit their data.</p>"},{"location":"docs/faas/lambda-manual-instrument/#add-the-arn-of-the-otel-collector-lambda-layer","title":"Add the ARN of the OTel Collector Lambda layer","text":"<p>See the Collector Lambda layer guidance to add the layer to your application and configure the Collector. We recommend you add this first.</p>"},{"location":"docs/faas/lambda-manual-instrument/#instrument-the-lambda-with-otel","title":"Instrument the Lambda with OTel","text":"<p>Review the language instrumentation guidance on how to manually instrument your application.</p>"},{"location":"docs/faas/lambda-manual-instrument/#publish-your-lambda","title":"Publish your Lambda","text":"<p>Publish a new version of your Lambda to deploy the new changes and instrumentation.</p>"},{"location":"docs/getting-started/_index/","title":"\u5165\u95e8","text":"<p>\u9009\u62e9\u89d2\u82721\u5f00\u59cb:</p> <ul> <li>Dev</li> <li>Ops</li> </ul> <p>\u4f60\u4e5f\u53ef\u4ee5\u5c1d\u8bd5\u5b98\u65b9\u7684OpenTelemetry\u6f14\u793a\u6765 \u770b\u770b OpenTelemetry\u7684\u53ef\u89c2\u5bdf\u6027\u662f\u4ec0\u4e48\u6837\u7684!</p> <ul> <li>\u8bd5\u8bd5\u8fd9\u4e2a\u6f14\u793a</li> </ul> <ol> <li> <p>\u5982\u679c\u8fd9\u4e9b\u89d2\u8272\u90fd\u4e0d\u9002\u5408\u4f60\uff0c\u3010\u8bf7\u544a\u8bc9\u6211\u4eec!]let us know!.\u00a0\u21a9</p> </li> </ol>"},{"location":"docs/getting-started/dev/","title":"\u5f00\u53d1\u8005\u5165\u95e8\u6307\u5357","text":"<p>\u8fd9\u662f\u60a8\u7684\u5165\u95e8\u9875\u9762\uff0c\u5982\u679c:</p> <ul> <li>\u4f60\u5f00\u53d1\u8f6f\u4ef6\u3002</li> <li>\u60a8\u7684\u76ee\u6807\u662f\u901a\u8fc7\u7f16\u5199\u4ee3\u7801\u83b7\u5f97\u53ef\u89c2\u5bdf\u6027\u3002</li> <li>\u60a8\u5e0c\u671b\u8ba9\u60a8\u7684\u4f9d\u8d56\u9879\u81ea\u52a8\u4e3a\u60a8\u53d1\u9001\u9065\u6d4b\u4fe1\u606f\u3002</li> </ul> <p>\u5f00\u653e\u9065\u6d4b\u53ef\u4ee5\u5e2e\u52a9\u4f60! \u4e3a\u4e86\u5b9e\u73b0\u81ea\u52a8\u68c0\u6d4b\u4f9d\u8d56\u5173\u7cfb\u548c\u624b\u52a8\u4f7f\u7528\u6211\u4eec\u7684API\u68c0\u6d4b\u81ea\u5df1\u7684\u4ee3\u7801\u7684\u76ee\u6807\uff0c\u6211\u4eec\u5efa\u8bae\u60a8\u9996\u5148\u5b66\u4e60\u4ee5\u4e0b\u6982\u5ff5:</p> <ul> <li>\u4ec0\u4e48\u662f\u5f00\u653e\u5f0f\u9065\u6d4b?</li> <li>\u5982\u4f55\u5728\u4e0d\u89e6\u53ca\u5b83\u4eec\u7684\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u4f9d\u8d56\u5173\u7cfb?</li> <li>\u5982\u4f55\u624b\u52a8\u68c0\u6d4b\u6211\u7684\u5e94\u7528\u7a0b\u5e8f?</li> </ul> <p>\u5982\u679c\u4f60\u5f00\u53d1\u7684\u5e93\u3001\u6846\u67b6\u6216\u4e2d\u95f4\u4ef6\u5728\u5176\u4ed6\u8f6f\u4ef6\u4e2d\u88ab\u7528\u4f5c\u4f9d\u8d56\u9879\uff0c\u6211\u4eec\u5efa\u8bae\u4f60\u5b66\u4e60\u5982\u4f55\u672c\u5730\u63d0\u4f9b\u9065\u6d4b:</p> <ul> <li>\u5982\u4f55\u5c06\u672c\u673a\u68c0\u6d4b\u6dfb\u52a0\u5230\u5e93\u4e2d?</li> </ul> <p>\u63a5\u4e0b\u6765\uff0c\u4f60\u53ef\u4ee5\u6df1\u5165\u4e86\u89e3\u4f60\u6b63\u5728\u4f7f\u7528\u7684\u8bed\u8a00\u7684\u6587\u6863:</p> <ul> <li>C++</li> <li>.NET</li> <li>Erlang / Elixir</li> <li>Go</li> <li>Java</li> <li>JavaScript / TypeScript</li> <li>PHP</li> <li>Python</li> <li>Ruby</li> <li>Rust</li> <li>Swift</li> <li>\u5176\u5b83</li> </ul>"},{"location":"docs/getting-started/ops/","title":"Ops\u5165\u95e8","text":"<p>\u8fd9\u662f\u4f60\u7684[\u5165\u95e8]\u9875\u9762\uff0c\u5982\u679c:</p> <ul> <li>\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u8fd0\u884c\u4e00\u7ec4\u5e94\u7528\u7a0b\u5e8f\u3002</li> <li>\u60a8\u7684\u76ee\u6807\u662f\u5728\u4e0d\u89e6\u53ca\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u9065\u6d4b\u529f\u80fd\u3002</li> <li>\u60a8\u5e0c\u671b\u4ece\u591a\u4e2a\u670d\u52a1\u6536\u96c6\u8ddf\u8e2a\u3001\u6307\u6807\u548c\u65e5\u5fd7\uff0c\u5e76\u5c06\u5b83\u4eec\u53d1\u9001\u5230\u53ef\u89c2\u5bdf\u6027\u540e\u7aef\u3002</li> </ul> <p>\u5f00\u653e\u9065\u6d4b\u53ef\u4ee5\u5e2e\u52a9\u4f60!\u4e3a\u4e86\u5b9e\u73b0\u5728\u4e0d\u89e6\u53ca\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u4ece\u5e94\u7528\u7a0b\u5e8f\u4e2d\u83b7\u53d6\u9065\u6d4b\u6280\u672f\u7684\u76ee\u6807\uff0c\u6211\u4eec\u5efa\u8bae\u60a8\u5b66\u4e60\u4ee5\u4e0b\u5185\u5bb9:</p> <ul> <li>\u4ec0\u4e48\u662f\u5f00\u653e\u9065\u6d4b?</li> <li>\u5982\u4f55\u5728\u4e0d\u89e6\u53ca\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u5e94\u7528\u7a0b\u5e8f?</li> <li>\u6211\u5982\u4f55\u5efa\u7acb\u4e00\u4e2a\u6536\u96c6\u5668?</li> <li>\u5982\u4f55\u4f7f\u7528OpenTelemetry\u7b97\u5b50\u5b9e\u73b0Kubernetes\u7684\u81ea\u52a8\u5316?</li> </ul> <p>\u5982\u679c\u4f60\u6b63\u5728\u5bfb\u627e\u4e00\u7ec4\u5e94\u7528\u7a0b\u5e8f\u6765\u5c1d\u8bd5\uff0c\u4f60\u4f1a\u53d1\u73b0\u6211\u4eec\u7684\u5b98\u65b9OpenTelemetry\u6f14\u793a\u5f88\u6709\u7528!</p>"},{"location":"docs/instrumentation/_index/","title":"\u4eea\u8868","text":"<p>OpenTelemetry\u4ee3\u7801\u690d\u5165\u652f\u6301\u4e0b\u9762\u5217\u51fa\u7684\u8bed\u8a00\u3002 \u6839\u636e\u8bed\u8a00\u7684\u4e0d\u540c\uff0c\u6240\u6db5\u76d6\u7684\u4e3b\u9898\u5c06\u5305\u62ec\u4ee5\u4e0b\u90e8\u5206\u6216\u5168\u90e8:</p> <ul> <li>\u81ea\u52a8\u4eea\u8868</li> <li>\u624b\u52a8\u5de5\u5177</li> <li>\u5bfc\u51fa\u6570\u636e</li> </ul> <p>\u5982\u679c\u4f60\u6b63\u5728\u4f7f\u7528Kubernetes\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528OpenTelemetry Operator for Kubernetes\u6765\u4e3aJava, Node.js\u548cPython\u6ce8\u5165\u81ea\u52a8\u68c0\u6d4b\u5e93\u3002</p>"},{"location":"docs/instrumentation/_index/#_1","title":"\u72b6\u6001\u548c\u53d1\u5e03","text":"<p>OpenTelemetry\u4e3b\u8981\u529f\u80fd\u7ec4\u4ef6\u7684\u73b0\u72b6\u5982\u4e0b:</p> <p>{{% telemetry_support_table \" \" %}}</p>"},{"location":"docs/instrumentation/cpp/_index/","title":"C++","text":"<p>{{% lang_instrumentation_index_head cpp /%}}</p>"},{"location":"docs/instrumentation/cpp/_index/#repositories","title":"Repositories","text":"<ul> <li>Main: opentelemetry-cpp</li> <li>Contrib:   opentelemetry-cpp-contrib</li> </ul>"},{"location":"docs/instrumentation/cpp/exporters/","title":"Exporters","text":"<p>In order to visualize and analyze your traces and metrics, you will need to export them to a backend.</p>"},{"location":"docs/instrumentation/cpp/exporters/#trace-exporters","title":"Trace exporters","text":""},{"location":"docs/instrumentation/cpp/exporters/#ostream-exporter","title":"OStream exporter","text":"<p>The OStream exporter is useful for development and debugging tasks, and is the simplest to set up.</p> <pre><code>#include \"opentelemetry/exporters/ostream/span_exporter_factory.h\"\nnamespace trace_exporter = opentelemetry::exporter::trace;\nauto exporter = trace_exporter::OStreamSpanExporterFactory::Create();\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#otlp-endpoint","title":"OTLP endpoint","text":"<p>To send trace data to an OTLP endpoint (like the collector or Jaeger) you'll want to configure an OTLP exporter that sends to your endpoint.</p>"},{"location":"docs/instrumentation/cpp/exporters/#otlp-http-exporter","title":"OTLP HTTP Exporter","text":"<pre><code>#include \"opentelemetry/exporters/otlp/otlp_http_exporter_factory.h\"\n#include \"opentelemetry/exporters/otlp/otlp_http_exporter_options.h\"\nnamespace otlp = opentelemetry::exporter::otlp;\notlp::OtlpHttpExporterOptions opts;\nopts.url = \"http://localhost:4318/v1/traces\";\nauto exporter = otlp::OtlpHttpExporterFactory::Create(opts);\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#otlp-grpc-exporter","title":"OTLP gRPC Exporter","text":"<pre><code>#include \"opentelemetry/exporters/otlp/otlp_grpc_exporter_factory.h\"\n#include \"opentelemetry/exporters/otlp/otlp_grpc_exporter_options.h\"\nnamespace otlp = opentelemetry::exporter::otlp;\notlp::OtlpGrpcExporterOptions opts;\nopts.endpoint = \"localhost:4317\";\nopts.use_ssl_credentials = true;\nopts.ssl_credentials_cacert_as_string = \"ssl-certificate\";\nauto exporter = otlp::OtlpGrpcExporterFactory::Create(opts);\n</code></pre> <p>You can find an example of how to use the OTLP exporter here.</p>"},{"location":"docs/instrumentation/cpp/exporters/#jaeger","title":"Jaeger","text":"<p>To try out the OTLP exporter, you can run Jaeger as an OTLP endpoint and for trace visualization in a docker container:</p> <pre><code>docker run -d --name jaeger \\\n-e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n-e COLLECTOR_OTLP_ENABLED=true \\\n-p 6831:6831/udp \\\n-p 6832:6832/udp \\\n-p 5778:5778 \\\n-p 16686:16686 \\\n-p 4317:4317 \\\n-p 4318:4318 \\\n-p 14250:14250 \\\n-p 14268:14268 \\\n-p 14269:14269 \\\n-p 9411:9411 \\\njaegertracing/all-in-one:latest\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#zipkin","title":"Zipkin","text":"<p>To send trace data to a Zipkin endpoint you'll want to configure a Zipkin exporter that sends to your endpoint.</p> <pre><code>#include \"opentelemetry/exporters/zipkin/zipkin_exporter_factory.h\"\n#include \"opentelemetry/exporters/zipkin/zipkin_exporter_options.h\"\nnamespace zipkin = opentelemetry::exporter::zipkin;\nzipkin::ZipkinExporterOptions opts;\nopts.endpoint = \"http://localhost:9411/api/v2/spans\" ; // or export OTEL_EXPORTER_ZIPKIN_ENDPOINT=\"...\"\nopts.service_name = \"default_service\" ;\nauto exporter = zipkin::ZipkinExporterFactory::Create(opts);\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#trace-processors","title":"Trace processors","text":""},{"location":"docs/instrumentation/cpp/exporters/#simple-span-processor","title":"Simple span processor","text":"<p>A simple processor will send spans one by one to an exporter.</p> <pre><code>#include \"opentelemetry/sdk/trace/simple_processor_factory.h\"\nnamespace trace_sdk = opentelemetry::sdk::trace;\nauto processor = trace_sdk::SimpleSpanProcessorFactory::Create(std::move(exporter));\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#batch-span-processor","title":"Batch span processor","text":"<p>A batch span processor will group several spans together, before sending them to an exporter.</p> <pre><code>#include \"opentelemetry/sdk/trace/batch_span_processor_factory.h\"\n#include \"opentelemetry/sdk/trace/batch_span_processor_options.h\"\nnamespace trace_sdk = opentelemetry::sdk::trace;\ntrace_sdk::BatchSpanProcessorOptions opts;\nopts.max_queue_size = 2048;\nopts.max_export_batch_size = 512;\nauto processor = trace_sdk::BatchSpanProcessorFactory::Create(std::move(exporter), opts);\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#tracer-provider","title":"Tracer provider","text":"<pre><code>#include \"opentelemetry/sdk/trace/tracer_provider_factory.h\"\nnamespace trace_api = opentelemetry::trace;\nnamespace trace_sdk = opentelemetry::sdk::trace;\nauto provider = trace_sdk::TracerProviderFactory::Create(std::move(processor));\ntrace_api::Provider::SetTracerProvider(provider);\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#metrics-exporters","title":"Metrics exporters","text":""},{"location":"docs/instrumentation/cpp/exporters/#otlp-http-exporter_1","title":"OTLP HTTP Exporter","text":"<pre><code>opentelemetry::exporter::otlp::OtlpHttpExporterOptions otlpOptions;\notlpOptions.url = \"http://localhost:4318/v1/metrics\"; // or \"http://localhost:4318/\notlpOptions.aggregation_temporality = opentelemetry::sdk::metrics::AggregationTemporality::kCumulative; // or kDelta\nauto exporter = opentelemetry::exporter::otlp::OtlpHttpMetricExporterFactory::Create(otlpOptions);\n// Initialize and set the periodic metrics reader\nopentelemetry::sdk::metrics::PeriodicExportingMetricReaderOptions options;\noptions.export_interval_millis = std::chrono::milliseconds(1000);\noptions.export_timeout_millis  = std::chrono::milliseconds(500);\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MetricReader&gt; reader{\nnew opentelemetry::sdk::metrics::PeriodicExportingMetricReader(std::move(exporter), options)};\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#otlp-grpc-exporter_1","title":"OTLP gRPC Exporter","text":"<pre><code>opentelemetry::exporter::otlp::OtlpGrpcMetricExporterOptions otlpOptions;\notlpOptions.endpoint = \"localhost:4317/v1/metrics\";  // or \"localhost:4317\notlpOptions.aggregation_temporality = opentelemetry::sdk::metrics::AggregationTemporality::kDelta; // or kCumulative\nauto exporter = opentelemetry::exporter::otlp::OtlpGrpcMetricExporterFactory::Create(otlpOptions);\n// Initialize and set the periodic metrics reader\nopentelemetry::sdk::metrics::PeriodicExportingMetricReaderOptions options;\noptions.export_interval_millis = std::chrono::milliseconds(1000);\noptions.export_timeout_millis  = std::chrono::milliseconds(500);\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MetricReader&gt; reader{\nnew opentelemetry::sdk::metrics::PeriodicExportingMetricReader(std::move(exporter), options)};\n</code></pre>"},{"location":"docs/instrumentation/cpp/exporters/#prometheus","title":"Prometheus","text":"<p>To send metrics to a Prometheus endpoint you'll want to configure a prometheus exporter</p> <pre><code>opentelemetry::sdk::metrics::PeriodicExportingMetricReaderOptions options;\noptions.export_interval_millis = std::chrono::milliseconds(1000); //optional, to override default values\noptions.export_timeout_millis  = std::chrono::milliseconds(500); // optional, to override default values\nopentelemetry::exporter::metrics::PrometheusExporterOptions prometheusOptions;\nprometheusOptions.url = \"localhost:8080\";\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MetricExporter&gt; exporter{new opentelemetry::exporter::metrics::PrometheusExporter(prometheusOptions)};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MetricReader&gt; reader{\nnew opentelemetry::sdk::metrics::PeriodicExportingMetricReader(std::move(exporter), options)};\n</code></pre> <p>To learn more on how to use the Prometheus exporter, try out the prometheus example</p>"},{"location":"docs/instrumentation/cpp/exporters/#next-steps","title":"Next steps","text":"<p>Enriching your codebase with manual instrumentation gives you customized observability data.</p>"},{"location":"docs/instrumentation/cpp/getting-started/","title":"Getting Started","text":"<p>Welcome to the OpenTelemetry C++ getting started guide! This guide will walk you through the basic steps in installing, instrumenting with, configuring, and exporting data from OpenTelemetry.</p> <p>You can use CMake or Bazel for building OpenTelemetry C++. The following getting started guide will make use of CMake and only provide you the most essential steps to have a working example application (a HTTP server &amp; HTTP client). For more details read these instructions.</p>"},{"location":"docs/instrumentation/cpp/getting-started/#prerequisites","title":"Prerequisites","text":"<p>You can build OpenTelemetry C++ on Windows, macOS or Linux. First you need to install some dependencies:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab \"Linux (apt)\" &gt;}} sudo apt-get install git cmake g++ libcurl4-openssl-dev {{&lt; /tab &gt;}}</p> <p>{{&lt; tab \"Linux (yum)\" &gt;}} sudo yum install git cmake g++ libcurl-devel {{&lt; /tab &gt;}}</p> <p>{{&lt; tab \"Linux (alpine)\" &gt;}} sudo apk add git cmake g++ make curl-dev {{&lt; /tab &gt;}}</p> <p>{{&lt; tab \"MacOS (homebrew)\" &gt;}} xcode-select \u2014install /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" brew install git cmake {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/cpp/getting-started/#building","title":"Building","text":"<p>Get the <code>opentelemetry-cpp</code> source:</p> <pre><code>git clone --recursive https://github.com/open-telemetry/opentelemetry-cpp\n</code></pre> <p>Navigate to the repository cloned above, and create the CMake build configuration:</p> <pre><code>cd opentelemetry-cpp\nmkdir build &amp;&amp; cd build\ncmake -DBUILD_TESTING=OFF -DWITH_EXAMPLES_HTTP=ON ..\n</code></pre> <p>Once build configuration is created, build the CMake targets <code>http_client</code> and <code>http_server</code>:</p> <pre><code>cmake --build . --target http_client http_server\n</code></pre> <p>If all goes well, you should find binaries <code>http_server</code> and <code>http_client</code> in <code>./examples/http</code>:</p> <pre><code>$ ls ./examples/http\nCMakeFiles  Makefile  cmake_install.cmake  http_client  http_server\n</code></pre>"},{"location":"docs/instrumentation/cpp/getting-started/#run-application","title":"Run Application","text":"<p>Open two terminals, in the first terminal, start the HTTP server:</p> <pre><code>$ ./examples/http/http_server\nServer is running..Press ctrl-c to exit..\n</code></pre> <p>In the other terminal, run the HTTP client:</p> <pre><code>./examples/http/http_client\n</code></pre> <p>You should see client output similar to this:</p> <pre><code>{\nname          : /helloworld\ntrace_id      : 05eec7a55d3544434265dad89d7fe96f\nspan_id       : 45fb62c58c907f05\ntracestate    :\nparent_span_id: 0000000000000000\nstart         : 1665577080650384378\nduration      : 1640298\ndescription   :\nspan kind     : Client\nstatus        : Unset\nattributes    :\nhttp.header.Date: Wed, 12 Oct 2022 12:18:00 GMT\nhttp.header.Content-Length: 0\nhttp.status_code: 200\nhttp.method: GET\n.header.Host: localhost\nhttp.header.Content-Type: text/plain\nhttp.header.Connection: keep-alive\n.scheme: http\nhttp.url: http://localhost:8800/helloworld\nevents        :\nlinks         :\nresources     :\nservice.name: unknown_service\ntelemetry.sdk.version: 1.6.1\ntelemetry.sdk.name: opentelemetry\ntelemetry.sdk.language: cpp\ninstr-lib     : http-client\n}\n</code></pre> <p>Also the server should dump you a trace to the console:</p> <pre><code>{\nname          : /helloworld\ntrace_id      : 05eec7a55d3544434265dad89d7fe96f\nspan_id       : 8df967d8547813fe\ntracestate    :\nparent_span_id: 45fb62c58c907f05\nstart         : 1665577080651459495\nduration      : 46331\ndescription   :\nspan kind     : Server\nstatus        : Unset\nattributes    :\nhttp.header.Traceparent: 00-05eec7a55d3544434265dad89d7fe96f-45fb62c58c907f05-01\nhttp.header.Accept: */*\nhttp.request_content_length: 0\nhttp.header.Host: localhost:8800\nhttp.scheme: http\nhttp.client_ip: 127.0.0.1:49466\nhttp.method: GET\nnet.host.port: 8800\nnet.host.name: localhost\nevents        :\n{\nname          : Processing request\ntimestamp     : 1665577080651472827\nattributes    :\n}\nlinks         :\nresources     :\nservice.name: unknown_service\ntelemetry.sdk.version: 1.6.1\ntelemetry.sdk.name: opentelemetry\ntelemetry.sdk.language: cpp\ninstr-lib     : http-server\n}\n</code></pre>"},{"location":"docs/instrumentation/cpp/getting-started/#whats-next","title":"What's next","text":"<p>Enrich your instrumentation generated automatically with manual of your own codebase. This gets you customized observability data.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p>"},{"location":"docs/instrumentation/cpp/manual/","title":"Manual Instrumentation","text":"<p>Manual instrumentation is the process of adding observability code to your application.</p>"},{"location":"docs/instrumentation/cpp/manual/#tracing","title":"Tracing","text":""},{"location":"docs/instrumentation/cpp/manual/#initializing-tracing","title":"Initializing tracing","text":"<pre><code>auto provider = opentelemetry::trace::Provider::GetTracerProvider();\nauto tracer = provider-&gt;GetTracer(\"foo_library\", \"1.0.0\");\n</code></pre> <p>The <code>TracerProvider</code> acquired in the first step is a singleton object that is usually provided by the OpenTelemetry C++ SDK. It is used to provide specific implementations for API interfaces. In case no SDK is used, the API provides a default no-op implementation of a <code>TracerProvider</code>.</p> <p>The <code>Tracer</code> acquired in the second step is needed to create and start Spans.</p>"},{"location":"docs/instrumentation/cpp/manual/#start-a-span","title":"Start a span","text":"<pre><code>auto span = tracer-&gt;StartSpan(\"HandleRequest\");\n</code></pre> <p>This creates a span, sets its name to <code>\"HandleRequest\"</code>, and sets its start time to the current time. Refer to the API documentation for other operations that are available to enrich spans with additional data.</p>"},{"location":"docs/instrumentation/cpp/manual/#mark-a-span-as-active","title":"Mark a span as active","text":"<pre><code>auto scope = tracer-&gt;WithActiveSpan(span);\n</code></pre> <p>This marks a span as active and returns a <code>Scope</code> object. The scope object controls how long a span is active. The span remains active for the lifetime of the scope object.</p> <p>The concept of an active span is important, as any span that is created without explicitly specifying a parent is parented to the currently active span. A span without a parent is called root span.</p>"},{"location":"docs/instrumentation/cpp/manual/#create-nested-spans","title":"Create nested Spans","text":"<pre><code>auto outer_span = tracer-&gt;StartSpan(\"Outer operation\");\nauto outer_scope = tracer-&gt;WithActiveSpan(outer_span);\n{\nauto inner_span = tracer-&gt;StartSpan(\"Inner operation\");\nauto inner_scope = tracer-&gt;WithActiveSpan(inner_span);\n// ... perform inner operation\ninner_span-&gt;End();\n}\n// ... perform outer operation\nouter_span-&gt;End();\n</code></pre> <p>Spans can be nested, and have a parent-child relationship with other spans. When a given span is active, the newly created span inherits the active span\u2019s trace ID, and other context attributes.</p>"},{"location":"docs/instrumentation/cpp/manual/#context-propagation","title":"Context Propagation","text":"<pre><code>// set global propagator\nopentelemetry::context::propagation::GlobalTextMapPropagator::SetGlobalPropagator(\nnostd::shared_ptr&lt;opentelemetry::context::propagation::TextMapPropagator&gt;(\nnew opentelemetry::trace::propagation::HttpTraceContext()));\n// get global propagator\nHttpTextMapCarrier&lt;opentelemetry::ext::http::client::Headers&gt; carrier;\nauto propagator =\nopentelemetry::context::propagation::GlobalTextMapPropagator::GetGlobalPropagator();\n//inject context to headers\nauto current_ctx = opentelemetry::context::RuntimeContext::GetCurrent();\npropagator-&gt;Inject(carrier, current_ctx);\n//Extract headers to context\nauto current_ctx = opentelemetry::context::RuntimeContext::GetCurrent();\nauto new_context = propagator-&gt;Extract(carrier, current_ctx);\nauto remote_span = opentelemetry::trace::propagation::GetSpan(new_context);\n</code></pre> <p><code>Context</code> contains the meta-data of the currently active Span including Span Id, Trace Id, and flags. Context Propagation is an important mechanism in distributed tracing to transfer this Context across service boundary often through HTTP headers. OpenTelemetry provides a text-based approach to propagate context to remote services using the W3C Trace Context HTTP headers.</p>"},{"location":"docs/instrumentation/cpp/manual/#further-reading","title":"Further Reading","text":"<ul> <li>Traces API</li> <li>Traces SDK</li> <li>Simple Metrics Example</li> </ul>"},{"location":"docs/instrumentation/cpp/manual/#metrics","title":"Metrics","text":""},{"location":"docs/instrumentation/cpp/manual/#initialize-exporter-and-reader","title":"Initialize Exporter and Reader","text":"<p>Initialize an exporter and a reader. In this case, we initialize an OStream Exporter which will print to stdout by default. The reader periodically collects metrics from the Aggregation Store and exports them.</p> <pre><code>std::unique_ptr&lt;opentelemetry::sdk::metrics::MetricExporter&gt; exporter{new opentelemetry::exporters::OStreamMetricExporter};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MetricReader&gt; reader{\nnew opentelemetry::sdk::metrics::PeriodicExportingMetricReader(std::move(exporter), options)};\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#initialize-meter-provider","title":"Initialize Meter Provider","text":"<p>Initialize a MeterProvider and add the reader. We will use this to obtain Meter objects in the future.</p> <pre><code>auto provider = std::shared_ptr&lt;opentelemetry::metrics::MeterProvider&gt;(new opentelemetry::sdk::metrics::MeterProvider());\nauto p = std::static_pointer_cast&lt;opentelemetry::sdk::metrics::MeterProvider&gt;(provider);\np-&gt;AddMetricReader(std::move(reader));\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#create-a-counter","title":"Create a Counter","text":"<p>Create a Counter instrument from the Meter, and record the measurement. Every Meter pointer returned by the MeterProvider points to the same Meter. This means that the Meter will be able to combine metrics captured from different functions without having to constantly pass the Meter around the library.</p> <pre><code>auto meter = provider-&gt;GetMeter(name, \"1.2.0\");\nauto double_counter = meter-&gt;CreateDoubleCounter(counter_name);\n// Create a label set which annotates metric values\nstd::map&lt;std::string, std::string&gt; labels = {{\"key\", \"value\"}};\nauto labelkv = common::KeyValueIterableView&lt;decltype(labels)&gt;{labels};\ndouble_counter-&gt;Add(val, labelkv);\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#create-a-histogram","title":"Create a Histogram","text":"<p>Create a Histogram instrument from the Meter, and record the measurement.</p> <pre><code>auto meter = provider-&gt;GetMeter(name, \"1.2.0\");\nauto histogram_counter = meter-&gt;CreateDoubleHistogram(\"histogram_name\");\nhistogram_counter-&gt;Record(val, labelkv);\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#create-observable-counter","title":"Create Observable Counter","text":"<p>Create a Observable Counter Instrument from the Meter, and add a callback. The callback would be used to record the measurement during metrics collection. Ensure to keep the Instrument object active for the lifetime of collection.</p> <pre><code>auto meter = provider-&gt;GetMeter(name, \"1.2.0\");\nauto counter = meter-&gt;CreateDoubleObservableCounter(counter_name);\ncounter-&gt;AddCallback(MeasurementFetcher::Fetcher, nullptr);\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#create-views","title":"Create Views","text":""},{"location":"docs/instrumentation/cpp/manual/#map-the-counter-instrument-to-sum-aggregation","title":"Map the Counter Instrument to Sum Aggregation","text":"<p>Create a view to map the Counter Instrument to Sum Aggregation. Add this view to provider. View creation is optional unless we want to add custom aggregation config, and attribute processor. Metrics SDK will implicitly create a missing view with default mapping between Instrument and Aggregation.</p> <pre><code>std::unique_ptr&lt;opentelemetry::sdk::metrics::InstrumentSelector&gt; instrument_selector{\nnew opentelemetry::sdk::metrics::InstrumentSelector(opentelemetry::sdk::metrics::InstrumentType::kCounter, \"counter_name\")};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MeterSelector&gt; meter_selector{\nnew opentelemetry::sdk::metrics::MeterSelector(name, version, schema)};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::View&gt; sum_view{\nnew opentelemetry::sdk::metrics::View{name, \"description\", opentelemetry::sdk::metrics::AggregationType::kSum}};\np-&gt;AddView(std::move(instrument_selector), std::move(meter_selector), std::move(sum_view));\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#map-the-histogram-instrument-to-histogram-aggregation","title":"Map the Histogram Instrument to Histogram Aggregation","text":"<pre><code>std::unique_ptr&lt;opentelemetry::sdk::metrics::InstrumentSelector&gt; histogram_instrument_selector{\nnew opentelemetry::sdk::metrics::InstrumentSelector(opentelemetry::sdk::metrics::InstrumentType::kHistogram, \"histogram_name\")};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MeterSelector&gt; histogram_meter_selector{\nnew opentelemetry::sdk::metrics::MeterSelector(name, version, schema)};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::View&gt; histogram_view{\nnew opentelemetry::sdk::metrics::View{name, \"description\", opentelemetry::sdk::metrics::AggregationType::kHistogram}};\np-&gt;AddView(std::move(histogram_instrument_selector), std::move(histogram_meter_selector),\nstd::move(histogram_view));\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#map-the-observable-counter-instrument-to-sum-aggregation","title":"Map the Observable Counter Instrument to Sum Aggregation","text":"<pre><code>std::unique_ptr&lt;opentelemetry::sdk::metrics::InstrumentSelector&gt; observable_instrument_selector{\nnew opentelemetry::sdk::metrics::InstrumentSelector(opentelemetry::sdk::metrics::InstrumentType::kObservableCounter,\n\"observable_counter_name\")};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::MeterSelector&gt; observable_meter_selector{\nnew opentelemetry::sdk::metrics::MeterSelector(name, version, schema)};\nstd::unique_ptr&lt;opentelemetry::sdk::metrics::View&gt; observable_sum_view{\nnew opentelemetry::sdk::metrics::View{name, \"description\", opentelemetry::sdk::metrics::AggregationType::kSum}};\np-&gt;AddView(std::move(observable_instrument_selector), std::move(observable_meter_selector),\nstd::move(observable_sum_view));\n</code></pre>"},{"location":"docs/instrumentation/cpp/manual/#further-reading_1","title":"Further Reading","text":"<ul> <li>Metrics API</li> <li>Metrics SDK</li> <li>Simple Metrics Example</li> </ul>"},{"location":"docs/instrumentation/erlang/_index/","title":"Erlang/Elixir","text":"<p>{{% lang_instrumentation_index_head erlang %}}</p> <p>Packages of the API, SDK and OTLP exporter are published to <code>hex.pm</code> as <code>opentelemetry_api</code>, <code>opentelemetry</code> and <code>opentelemetry_exporter</code>.</p>"},{"location":"docs/instrumentation/erlang/_index/#version-support","title":"Version support","text":"<p>OpenTelemetry Erlang supports Erlang 23+ and Elixir 1.13+.</p>"},{"location":"docs/instrumentation/erlang/_index/#repositories","title":"Repositories","text":"<ul> <li>opentelemetry-erlang:   Main repo containing the API, SDK and OTLP Exporter.</li> <li>opentelemetry-erlang-contrib:   Helpful libraries and instrumentation libraries for Erlang/Elixir projects   like Phoenix and   Ecto</li> </ul> <p>{{% /lang_instrumentation_index_head %}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/","title":"Getting Started","text":"<p>Welcome to the OpenTelemetry for Erlang/Elixir getting started guide! This guide will walk you through the basic steps in installing, configuring, and exporting data from OpenTelemetry.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#phoenix","title":"Phoenix","text":"<p>This part of the guide will show you how to get started with OpenTelemetry in the Phoenix Web Framework.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have erlang, elixir, postgres (or the database of your choice), and phoenix installed locally. The phoenix installation guide will help you get set up with everything you need.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#example-application","title":"Example Application","text":"<p>The following example uses a basic Phoenix web application. For reference, a complete example of the code you will build can be found here: opentelemetry-erlang-contrib/examples/dice_game. You can git clone that project or just follow along in your browser.</p> <p>Additional examples can be found here.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#dependencies","title":"Dependencies","text":"<p>We'll need a few other dependencies that Phoenix doesn't come with.</p> <ul> <li><code>opentelemetry_api</code>: contains the interfaces you'll use to instrument your   code. Things like <code>Tracer.with_span</code> and <code>Tracer.set_attribute</code> are defined   here.</li> <li><code>opentelemetry</code>: contains the SDK that implements the interfaces defined in   the API. Without it, all the functions in the API are no-ops.</li> <li><code>opentelemetry_exporter</code>: allows you to send your telemetry data to an   OpenTelemetry Collector and/or to self-hosted or commercial services.</li> <li><code>opentelemetry_phoenix</code>: creates OpenTelemetry spans from the Elixir   <code>:telemetry</code> events created by Phoenix.</li> <li><code>opentelemetry_cowboy</code>: creates OpenTelemetry spans from the Elixir   <code>:telemetry</code> events created by the Cowboy web server (which is used by   Phoenix).</li> </ul> <pre><code># mix.exs\ndef deps do\n[\n{:opentelemetry, \"~&gt; 1.3\"},\n{:opentelemetry_api, \"~&gt; 1.2\"},\n{:opentelemetry_exporter, \"~&gt; 1.4\"},\n{:opentelemetry_phoenix, \"~&gt; 1.1\"},\n{:opentelemetry_cowboy, \"~&gt; 0.2\"}\n]\nend\n</code></pre> <p>The last two also need to be setup when your application starts:</p> <pre><code># application.ex\n@impl true\ndef start(_type, _args) do\n:opentelemetry_cowboy.setup()\nOpentelemetryPhoenix.setup(adapter: :cowboy2)\nend\n</code></pre> <p>If you're using ecto, you'll also want to add <code>OpentelemetryEcto.setup([:dice_game, :repo])</code>.</p> <p>We also need to configure the <code>opentelemetry</code> application as temporary by adding a <code>releases</code> section to your project configuration. This will ensure that if it terminates, even abnormally, the <code>dice_game</code> application will be terminated.</p> <pre><code># mix.exs\ndef project do\n[\napp: :dice_game,\nversion: \"0.1.0\",\nelixir: \"~&gt; 1.14\",\nelixirc_paths: elixirc_paths(Mix.env()),\nstart_permanent: Mix.env() == :prod,\nreleases: [\ndice_game: [\napplications: [opentelemetry: :temporary]\n]\n],\naliases: aliases(),\ndeps: deps()\n]\nend\n</code></pre> <p>Now we can use the new <code>mix setup</code> command to install the dependencies, build the assets, and create and migrate the database.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#try-it-out","title":"Try It Out","text":"<p>We can ensure everything is working by setting the stdout exporter as opentelemetry's traces_exporter and then starting the app with <code>mix phx.server</code>.</p> <pre><code># config/dev.exs\nconfig :opentelemetry, traces_exporter: {:otel_exporter_stdout, []}\n</code></pre> <p>If everything went well, you should be able to visit <code>localhost:4000</code> in your browser and see quite a few lines that look like this in your terminal.</p> <p>(Don't worry if the format looks a little unfamiliar. Spans are recorded in the Erlang <code>record</code> data structure. You can find more information about records here, and this file describes the <code>span</code> record structure, and explains what the different fields are.)</p> <pre><code>*SPANS FOR DEBUG*\n{span,64480120921600870463539706779905870846,11592009751350035697,[],\n      undefined,&lt;&lt;\"/\"&gt;&gt;,server,-576460731933544855,-576460731890088522,\n      {attributes,128,infinity,0,\n                  #{'http.status_code' =&gt; 200,\n'http.client_ip' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'http.flavor' =&gt; '1.1','http.method' =&gt; &lt;&lt;\"GET\"&gt;&gt;,\n                    'http.scheme' =&gt; &lt;&lt;\"http\"&gt;&gt;,'http.target' =&gt; &lt;&lt;\"/\"&gt;&gt;,\n                    'http.user_agent' =&gt;\n                        &lt;&lt;\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"&gt;&gt;,\n                    'net.transport' =&gt; 'IP.TCP',\n                    'net.host.name' =&gt; &lt;&lt;\"localhost\"&gt;&gt;,\n                    'net.host.port' =&gt; 4000,'net.peer.port' =&gt; 62839,\n                    'net.sock.host.addr' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'net.sock.peer.addr' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'http.route' =&gt; &lt;&lt;\"/\"&gt;&gt;,'phoenix.action' =&gt; home,\n                    'phoenix.plug' =&gt;\n                        'Elixir.DiceGameWeb.PageController'}},\n      {events,128,128,infinity,0,[]},\n      {links,128,128,infinity,0,[]},\n      undefined,1,false,\n      {instrumentation_scope,&lt;&lt;\"opentelemetry_phoenix\"&gt;&gt;,&lt;&lt;\"1.1.0\"&gt;&gt;,\n                             undefined}}\n</code></pre> <p>These are the raw Erlang records that will get serialized and sent when you configure the exporter for your preferred service.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#rolling-the-dice","title":"Rolling The Dice","text":"<p>Now we'll check out the API endpoint that will let us roll the dice and return a random number between 1 and 6.</p> <p>Before we call our API, let's add our first bit of manual instrumentation. In our <code>DiceController</code> we call a private <code>dice_roll</code> method that generates our random number. This seems like a pretty important operation, so in order to capture it in our trace we'll need to wrap it in a span.</p> <pre><code>  defp dice_roll do\nTracer.with_span(\"dice_roll\") do\nto_string(Enum.random(1..6))\nend\nend\n</code></pre> <p>It would also be nice to know what number it generated, so we can extract it as a local variable and add it as an attribute on the span.</p> <pre><code>  defp dice_roll do\nTracer.with_span(\"dice_roll\") do\nroll = Enum.random(1..6)\nTracer.set_attribute(:roll, roll)\nto_string(roll)\nend\nend\n</code></pre> <p>Now if you point your browser/curl/etc. to <code>localhost:4000/api/rolldice</code> you should get a random number in response, and 3 spans in your console.</p> View the full spans <pre><code>*SPANS FOR DEBUG*\n{span,224439009126930788594246993907621543552,5581431573601075988,[],\n      undefined,&lt;&lt;\"/api/rolldice\"&gt;&gt;,server,-576460729549928500,\n      -576460729491912750,\n      {attributes,128,infinity,0,\n                  #{'http.request_content_length' =&gt; 0,\n'http.response_content_length' =&gt; 1,\n                    'http.status_code' =&gt; 200,\n                    'http.client_ip' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'http.flavor' =&gt; '1.1','http.host' =&gt; &lt;&lt;\"localhost\"&gt;&gt;,\n                    'http.host.port' =&gt; 4000,'http.method' =&gt; &lt;&lt;\"GET\"&gt;&gt;,\n                    'http.scheme' =&gt; &lt;&lt;\"http\"&gt;&gt;,\n                    'http.target' =&gt; &lt;&lt;\"/api/rolldice\"&gt;&gt;,\n                    'http.user_agent' =&gt;\n                        &lt;&lt;\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"&gt;&gt;,\n                    'net.host.ip' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'net.transport' =&gt; 'IP.TCP',\n                    'http.route' =&gt; &lt;&lt;\"/api/rolldice\"&gt;&gt;,\n                    'phoenix.action' =&gt; roll,\n                    'phoenix.plug' =&gt; 'Elixir.DiceGameWeb.DiceController'}},\n      {events,128,128,infinity,0,[]},\n      {links,128,128,infinity,0,[]},\n      undefined,1,false,\n      {instrumentation_scope,&lt;&lt;\"opentelemetry_cowboy\"&gt;&gt;,&lt;&lt;\"0.2.1\"&gt;&gt;,\n                             undefined}}\n{span,237952789931001653450543952469252891760,13016664705250513820,[],\n      undefined,&lt;&lt;\"HTTP GET\"&gt;&gt;,server,-576460729422104083,-576460729421433042,\n      {attributes,128,infinity,0,\n                  #{'http.request_content_length' =&gt; 0,\n'http.response_content_length' =&gt; 1258,\n                    'http.status_code' =&gt; 200,\n                    'http.client_ip' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'http.flavor' =&gt; '1.1','http.host' =&gt; &lt;&lt;\"localhost\"&gt;&gt;,\n                    'http.host.port' =&gt; 4000,'http.method' =&gt; &lt;&lt;\"GET\"&gt;&gt;,\n                    'http.scheme' =&gt; &lt;&lt;\"http\"&gt;&gt;,\n                    'http.target' =&gt; &lt;&lt;\"/favicon.ico\"&gt;&gt;,\n                    'http.user_agent' =&gt;\n                        &lt;&lt;\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"&gt;&gt;,\n                    'net.host.ip' =&gt; &lt;&lt;\"127.0.0.1\"&gt;&gt;,\n                    'net.transport' =&gt; 'IP.TCP'}},\n      {events,128,128,infinity,0,[]},\n      {links,128,128,infinity,0,[]},\n      undefined,1,false,\n      {instrumentation_scope,&lt;&lt;\"opentelemetry_cowboy\"&gt;&gt;,&lt;&lt;\"0.2.1\"&gt;&gt;,\n                             undefined}}\n{span,224439009126930788594246993907621543552,17387612312604368700,[],\n      5581431573601075988,&lt;&lt;\"dice_roll\"&gt;&gt;,internal,-576460729494399167,\n      -576460729494359917,\n      {attributes,128,infinity,0,#{roll =&gt; 2}},\n      {events,128,128,infinity,0,[]},\n      {links,128,128,infinity,0,[]},\n      undefined,1,false,\n      {instrumentation_scope,&lt;&lt;\"dice_game\"&gt;&gt;,&lt;&lt;\"0.1.0\"&gt;&gt;,undefined}}\n</code></pre>"},{"location":"docs/instrumentation/erlang/getting-started/#apirolldice","title":"<code>&lt;&lt;\"/api/rolldice\"&gt;&gt;</code>","text":"<p>This is the first span in the request, aka the root span. That <code>undefined</code> next to the span name tells you that it doesn't have a parent span. The two very large negative numbers are the start and end time of the span, in the <code>native</code> time unit. If you're curious, you can calculate the duration in milliseconds like so <code>System.convert_time_unit(-576460729491912750 - -576460729549928500, :native, :millisecond)</code>. The <code>phoenix.plug</code> and <code>phoenix.action</code> will tell you the controller and function that handled the request. You'll notice however, that the instrumentation_scope is <code>opentelemetry_cowboy</code>. When we told opentelemetry_phoenix's setup function that we want to use the <code>:cowboy2</code> adapter, that let it know not to create and additional span, but to instead append attributes to the existing cowboy span. This ensures we have more accurate latency data in our traces.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#http-get","title":"<code>&lt;&lt;\"HTTP GET\"&gt;&gt;</code>","text":"<p>This is the request for the favicon, which you can see in the <code>'http.target' =&gt; &lt;&lt;\"/favicon.ico\"&gt;&gt;</code> attribute. I believe it has a generic name because it does not have an <code>http.route</code>.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#dice_roll","title":"<code>&lt;&lt;\"dice_roll\"&gt;&gt;</code>","text":"<p>This is the custom span we added to our private method. You'll notice it only has the one attribute that we set, <code>roll =&gt; 2</code>. You should also note that it is part of the same trace as our <code>&lt;&lt;\"/api/rolldice\"&gt;&gt;</code> span, <code>224439009126930788594246993907621543552</code> and has a parent span id of <code>5581431573601075988</code> which is the span id of the <code>&lt;&lt;\"/api/rolldice\"&gt;&gt;</code> span. That means that this span is a child of that one, and will be shown below it when rendered in your tracing tool of choice.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#next-steps","title":"Next Steps","text":"<p>Enrich your automatically generated instrumentation with manual instrumentation of your own codebase. This allows you to customize the observability data your application emits.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#creating-a-new-mixrebar-project","title":"Creating a New Mix/Rebar Project","text":"<p>To get started with this guide, create a new project with <code>rebar3</code> or <code>mix</code>:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} rebar3 new release otel_getting_started {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} mix new --sup otel_getting_started {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Then, in the project you just created, add both <code>opentelemetry_api</code> and <code>opentelemetry</code> as dependencies. We add both because this is a project we will run as a Release and export spans from.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} {deps, [{opentelemetry_api, \"~&gt; 1.2\"},         {opentelemetry, \"~&gt; 1.3\"}]}. {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} def deps do   [     {:opentelemetry_api, \"~&gt; 1.2\"},     {:opentelemetry, \"~&gt; 1.3\"}   ] end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>In the case of Erlang, the API Application will also need to be added to <code>src/otel_getting_started.app.src</code> and a <code>relx</code> section to <code>rebar.config</code>. In an Elixir project, a <code>releases</code> section needs to be added to <code>mix.exs</code>:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% src/otel_getting_started.app.src ... {applications, [kernel,                 stdlib,                 opentelemetry_api]}, ...</p> <p>%% rebar.config {relx, [{release, {otel_getting_started, \"0.1.0\"},          [{opentelemetry, temporary},           otel_getting_started]},</p> <pre><code>   ...]}.\n</code></pre> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#mixexs","title":"mix.exs","text":"<p>releases: [   otel_getting_started: [     version: \"0.0.1\",     applications: [opentelemetry: :temporary, otel_getting_started: :permanent]   ] ] {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>The SDK <code>opentelemetry</code> should be added as early as possible in the Release boot process to ensure it is available before any telemetry is produced. Here it is also set to <code>temporary</code> under the assumption that we prefer to have a running Release not producing telemetry over crashing the entire Release.</p> <p>In addition to the API and SDK, an exporter for getting data out is needed. The SDK comes with an exporter for debugging purposes that prints to stdout and there are separate packages for exporting over the OpenTelemetry Protocol (OTLP) and the Zipkin protocol.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#initialization-and-configuration","title":"Initialization and Configuration","text":"<p>Configuration is done through the Application environment or OS Environment Variables. The SDK (<code>opentelemetry</code> Application) uses the configuration to initialize a Tracer Provider, its Span Processors and the Exporter.</p>"},{"location":"docs/instrumentation/erlang/getting-started/#using-the-console-exporter","title":"Using the Console Exporter","text":"<p>Exporters are packages that allow telemetry data to be emitted somewhere - either to the console (which is what we're doing here), or to a remote system or collector for further analysis and/or enrichment. OpenTelemetry supports a variety of exporters through its ecosystem, including popular open source tools like Jaeger and Zipkin.</p> <p>To configure OpenTelemetry to use a particular exporter, in this case <code>otel_exporter_stdout</code>, the Application environment for <code>opentelemetry</code> must set the <code>exporter</code> for the span processor <code>otel_batch_processor</code>, a type of span processor that batches up multiple spans over a period of time:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% config/sys.config.src [  {opentelemetry,   [{span_processor, batch},    {traces_exporter, {otel_exporter_stdout, []}}]} ]. {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#configruntimeexs","title":"config/runtime.exs","text":"<p>config :opentelemetry,   span_processor: :batch,   traces_exporter: {:otel_exporter_stdout, []} {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#working-with-spans","title":"Working with Spans","text":"<p>Now that the dependencies and configuration are set up, we can create a module with a function <code>hello/0</code> that starts some spans:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% apps/otel_getting_started/src/otel_getting_started.erl -module(otel_getting_started).</p> <p>-export([hello/0]).</p> <p>-include_lib(\"opentelemetry_api/include/otel_tracer.hrl\").</p> <p>hello() -&gt;     %% start an active span and run a local function     ?with_span(operation, #{}, fun nice_operation/1).</p> <p>nice_operation(_SpanCtx) -&gt;     ?add_event(&lt;&lt;\"Nice operation!\"&gt;&gt;, [{&lt;&lt;\"bogons\"&gt;&gt;, 100}]),     ?set_attributes([{another_key, &lt;&lt;\"yes\"&gt;&gt;}]),</p> <pre><code>%% start an active span and run an anonymous function\n?with_span(&lt;&lt;\"Sub operation...\"&gt;&gt;, #{},\n           fun(_ChildSpanCtx) -&gt;\n                   ?set_attributes([{lemons_key, &lt;&lt;\"five\"&gt;&gt;}]),\n                   ?add_event(&lt;&lt;\"Sub span event!\"&gt;&gt;, [])\n           end).\n</code></pre> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#libotel_getting_startedex","title":"lib/otel_getting_started.ex","text":"<p>defmodule OtelGettingStarted do   require OpenTelemetry.Tracer, as: Tracer</p> <p>def hello do     Tracer.with_span :operation do       Tracer.add_event(\"Nice operation!\", [{\"bogons\", 100}])       Tracer.set_attributes([{:another_key, \"yes\"}])</p> <pre><code>  Tracer.with_span \"Sub operation...\" do\n    Tracer.set_attributes([{:lemons_key, \"five\"}])\n    Tracer.add_event(\"Sub span event!\", [])\n  end\nend\n</code></pre> <p>end end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>In this example, we're using macros that use the process dictionary for context propagation and for getting the tracer.</p> <p>Inside our function, we're creating a new span named <code>operation</code> with the <code>with_span</code> macro. The macro sets the new span as <code>active</code> in the current context -- stored in the process dictionary, since we aren't passing a context as a variable.</p> <p>Spans can have attributes and events, which are metadata and log statements that help you interpret traces after-the-fact. The first span has an event <code>Nice operation!</code>, with attributes on the event, as well as an attribute set on the span itself.</p> <p>Finally, in this code snippet, we can see an example of creating a child span of the currently-active span. When the <code>with_span</code> macro starts a new span, it uses the active span of the current context as the parent. So when you run this program, you'll see that the <code>Sub operation...</code> span has been created as a child of the <code>operation</code> span.</p> <p>To test out this project and see the spans created, you can run with <code>rebar3 shell</code> or <code>iex -S mix</code>, each will pick up the corresponding configuration for the release, resulting in the tracer and exporter to started.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} $ rebar3 shell ===&gt; Compiling otel_getting_started Erlang/OTP 23 [erts-11.1] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]</p> <p>Eshell V11.1  (abort with ^G) 1&gt; 1&gt; otel_getting_started:hello(). true SPANS FOR DEBUG {span,177312096541376795265675405126880478701,5706454085098543673,undefined,       13736713257910636645,&lt;&lt;\"Sub operation...\"&gt;&gt;,internal,       -576460750077844044,-576460750077773674,       [{lemons_key,&lt;&lt;\"five\"&gt;&gt;}],       [{event,-576460750077786044,&lt;&lt;\"Sub span event!\"&gt;&gt;,[]}],       [],undefined,1,false,undefined} {span,177312096541376795265675405126880478701,13736713257910636645,undefined,       undefined,operation,internal,-576460750086570890,       -576460750077752627,       [{another_key,&lt;&lt;\"yes\"&gt;&gt;}],       [{event,-576460750077877345,&lt;&lt;\"Nice operation!\"&gt;&gt;,[{&lt;&lt;\"bogons\"&gt;&gt;,100}]}],       [],undefined,1,false,undefined} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} $ iex -S mix Erlang/OTP 23 [erts-11.1] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]</p> <p>Compiling 1 file (.ex) Interactive Elixir (1.11.0) - press Ctrl+C to exit (type h() ENTER for help) iex(1)&gt; OtelGettingStarted.hello() true iex(2)&gt; SPANS FOR DEBUG {span,180094370450826032544967824850795294459,5969980227405956772,undefined,       14276444653144535440,&lt;&lt;\"Sub operation...\"&gt;&gt;,'INTERNAL',       -576460741349434100,-576460741349408901,       [{lemons_key,&lt;&lt;\"five\"&gt;&gt;}],       [{event,-576460741349414157,&lt;&lt;\"Sub span event!\"&gt;&gt;,[]}],       [],undefined,1,false,undefined} {span,180094370450826032544967824850795294459,14276444653144535440,undefined,       undefined,:operation,'INTERNAL',-576460741353342627,       -576460741349400034,       [{another_key,&lt;&lt;\"yes\"&gt;&gt;}],       [{event,-576460741349446725,&lt;&lt;\"Nice operation!\"&gt;&gt;,[{&lt;&lt;\"bogons\"&gt;&gt;,100}]}],       [],undefined,1,false,undefined} {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#exporting-to-the-opentelemetry-collector","title":"Exporting to the OpenTelemetry Collector","text":"<p>The Collector provides a vendor agnostic way to receive, process and export telemetry data. The package opentelemetry_exporter provides support for both exporting over both HTTP (the default) and gRPC to the collector, which can then export Spans to a self-hosted service like Zipkin or Jaeger, as well as commercial services. For a full list of available exporters, see the registry.</p> <p>For testing purposes the <code>opentelemetry-erlang</code> repo has a Collector configuration, config/otel-collector-config.yaml that can be used as a starting point. This configuration is used in docker-compose.yml to start the Collector with receivers for both HTTP and gRPC that then export to Zipkin also run by docker-compose.</p> <p>To export to the running Collector the <code>opentelemetry_exporter</code> package must be added to the project's dependencies:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} {deps, [{opentelemetry_api, \"~&gt; 1.3\"},         {opentelemetry, \"~&gt; 1.3\"},         {opentelemetry_exporter, \"~&gt; 1.4\"}]}. {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} def deps do   [     {:opentelemetry_api, \"~&gt; 1.3\"},     {:opentelemetry, \"~&gt; 1.3\"},     {:opentelemetry_exporter, \"~&gt; 1.4\"}   ] end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>It should then be added to the configuration of the Release before the SDK Application to ensure the exporter's dependencies are started before the SDK attempts to initialize and use the exporter.</p> <p>Example of Release configuration in <code>rebar.config</code> and for mix's Release task:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% rebar.config {relx, [{release, {my_instrumented_release, \"0.1.0\"},          [opentelemetry_exporter,           {opentelemetry, temporary},           my_instrumented_app]},</p> <pre><code>   ...]}.\n</code></pre> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#mixexs_1","title":"mix.exs","text":"<p>def project do   [     releases: [       my_instrumented_release: [         applications: [opentelemetry_exporter: :permanent, opentelemetry: :temporary]       ],</p> <pre><code>  ...\n]\n</code></pre> <p>] end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Finally, the runtime configuration of the <code>opentelemetry</code> and <code>opentelemetry_exporter</code> Applications are set to export to the Collector. The configurations below show the defaults that are used if none are set, which are the HTTP protocol with endpoint of <code>localhost</code> on port <code>4318</code>. If using <code>grpc</code> for the <code>otlp_protocol</code> the endpoint should be changed to <code>http://localhost:4317</code>.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% config/sys.config.src [  {opentelemetry,   [{span_processor, batch},    {traces_exporter, otlp}]},</p> <p>{opentelemetry_exporter,   [{otlp_protocol, http_protobuf},    {otlp_endpoint, \"http://localhost:4318\"}]}]} ]. {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/getting-started/#configruntimeexs_1","title":"config/runtime.exs","text":"<p>config :opentelemetry,   span_processor: :batch,   traces_exporter: :otlp</p> <p>config :opentelemetry_exporter,   otlp_protocol: :http_protobuf,   otlp_endpoint: \"http://localhost:4318\" {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/","title":"Manual","text":"<p>Instrumentation is the act of adding observability code to your application. This can be done with direct calls to the OpenTelemetry API within your code or including a dependency which calls the API and hooks into your project, like a middleware for an HTTP server.</p>"},{"location":"docs/instrumentation/erlang/manual/#tracing","title":"Tracing","text":""},{"location":"docs/instrumentation/erlang/manual/#initialize-tracing","title":"Initialize Tracing","text":"<p>To start tracing a <code>TracerProvider</code> is required for creating a <code>Tracer</code>. When the OpenTelemetry SDK Application (<code>opentelemetry</code>) boots, it starts and configures a global <code>TracerProvider</code>. A <code>Tracer</code> for each loaded OTP Application is created once the <code>TracerProvider</code> has started.</p> <p>If a TracerProvider is not successfully created (for example, the <code>opentelemetry</code> application is not booted or fails to boot), the OpenTelemetry APIs for tracing will use a no-op implementation and will not generate data.</p>"},{"location":"docs/instrumentation/erlang/manual/#acquiring-a-tracer","title":"Acquiring a Tracer","text":"<p>Each OTP Application has a <code>Tracer</code> created for it when the <code>opentelemetry</code> Application boots. The name and version of each <code>Tracer</code> is the same as the name and version of the OTP Application the module using the <code>Tracer</code> is in. If the call to use a <code>Tracer</code> is not in a module, for example when using the interactive shell, a <code>Tracer</code> with a blank name and version is used.</p> <p>The created <code>Tracer</code>'s record can be looked up by the name of a module in the OTP Application:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} opentelemetry:get_application_tracer(?MODULE) {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} :opentelemetry.get_application_tracer(MODULE) {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>This is how the Erlang and Elixir macros for starting and updating <code>Spans</code> get a <code>Tracer</code> automatically without need for you to pass the variable in each call.</p>"},{"location":"docs/instrumentation/erlang/manual/#create-spans","title":"Create Spans","text":"<p>Now that you have Tracers initialized, you can create Spans.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} ?with_span(main, #{}, fun() -&gt;                         %% do work here.                         %% when this function returns the Span ends                       end).</p> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} require OpenTelemetry.Tracer</p> <p>...</p> <p>OpenTelemetry.Tracer.with_span :main do   # do work here   # when the block ends the Span ends end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>The above code sample shows how to create an active Span, which is the most common kind of Span to create.</p>"},{"location":"docs/instrumentation/erlang/manual/#create-nested-spans","title":"Create Nested Spans","text":"<p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} parent_function() -&gt;     ?with_span(parent, #{}, fun child_function/0).</p> <p>child_function() -&gt;     %% this is the same process, so the span parent set as the active     %% span in the with_span call above will be the active span in this function     ?with_span(child, #{},                fun() -&gt;                    %% do work here. when this function returns, child will complete.                end).</p> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} require OpenTelemetry.Tracer</p> <p>def parent_function() do     OpenTelemetry.Tracer.with_span :parent do         child_function()     end end</p> <p>def child_function() do     # this is the same process, so the span :parent set as the active     # span in the with_span call above will be the active span in this function     OpenTelemetry.Tracer.with_span :child do         ## do work here. when this function returns, :child will complete.     end end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#spans-in-separate-processes","title":"Spans in Separate Processes","text":"<p>The examples in the previous section were Spans with a child-parent relationship within the same process where the parent is available in the process dictionary when creating a child Span. Using the process dictionary this way isn't possible when crossing processes, either by spawning a new process or sending a message to an existing process. Instead, the context must be manually passed as a variable.</p> <p>To pass Spans across processes we need to start a Span that isn't connected to particular process. This can be done with the macro <code>start_span</code>. Unlike <code>with_span</code>, the <code>start_span</code> macro does not set the new span as the currently active span in the context of the process dictionary.</p> <p>Connecting a span as a parent to a child in a new process can be done by attaching the context and setting the new span as currently active in the process. The whole context should be attached in order to not lose other telemetry data like baggage.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} SpanCtx = ?start_span(child),</p> <p>Ctx = otel_ctx:get_current(),</p> <p>proc_lib:spawn_link(fun() -&gt;                         otel_ctx:attach(Ctx),                         ?set_current_span(SpanCtx),</p> <pre><code>                    %% do work here\n\n                    ?end_span(SpanCtx)\n                end),\n</code></pre> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} span_ctx = OpenTelemetry.Tracer.start_span(:child) ctx = OpenTelemetry.Ctx.get_current()</p> <p>task = Task.async(fn -&gt;                       OpenTelemetry.Ctx.attach(ctx)                       OpenTelemetry.Tracer.set_current_span(span_ctx)                       # do work here</p> <pre><code>                  # end span here\n                  OpenTelemetry.Tracer.end_span(span_ctx)\n              end)\n</code></pre> <p>_ = Task.await(task) {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#linking-the-new-span","title":"Linking the New Span","text":"<p>A Span can be created with zero or more Span Links that causally link it to another Span. A Link needs a Span context to be created.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} Parent = ?current_span_ctx, proc_lib:spawn_link(fun() -&gt;                         %% a new process has a new context so the span created                         %% by the following <code>with_span</code> will have no parent                         Link = opentelemetry:link(Parent),                         ?with_span('other-process', #{links =&gt; [Link]},                                    fun() -&gt; ok end)                     end), {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} parent = OpenTelemetry.current_span_ctx() task = Task.async(fn -&gt;                     # a new process has a new context so the span created                     # by the following <code>with_span</code> will have no parent                     link = OpenTelemetry.link(parent)                     Tracer.with_span :\"my-task\", %{links: [link]} do                       :hello                     end                  end) {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#adding-attributes-to-a-span","title":"Adding Attributes to a Span","text":"<p>Attributes let you attach key/value pairs to a Span so it carries more information about the current operation that it\u2019s tracking.</p> <p>The following example shows the two ways of setting attributes on a span by both setting an attribute in the start options and then again with <code>set_attributes</code> in the body of the span operation:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} ?with_span(my_span, #{attributes =&gt; [{'start-opts-attr', &lt;&lt;\"start-opts-value\"&gt;&gt;}]},            fun() -&gt;                ?set_attributes([{'my-attribute', &lt;&lt;\"my-value\"&gt;&gt;},                                 {another_attribute, &lt;&lt;\"value-of-attribute\"&gt;&gt;}])            end) {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} Tracer.with_span :span_1, %{attributes: [{:\"start-opts-attr\", &lt;&lt;\"start-opts-value\"&gt;&gt;}]} do   Tracer.set_attributes([{:\"my-attributes\", \"my-value\"},                          {:another_attribute, \"value-of-attributes\"}]) end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#semantic-attributes","title":"Semantic Attributes","text":"<p>Semantic Attributes are attributes that are defined by the OpenTelemetry Specification in order to provide a shared set of attribute keys across multiple languages, frameworks, and runtimes for common concepts like HTTP methods, status codes, user agents, and more. These attribute keys are generated from the specification and provided in opentelemetry_semantic_conventions.</p> <p>For example, an instrumentation for an HTTP client or server would need to include semantic attributes like the scheme of the URL:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} -include_lib(\"opentelemetry_semantic_conventions/include/trace.hrl\").</p> <p>?with_span(my_span, #{attributes =&gt; [{?HTTP_SCHEME, &lt;&lt;\"https\"&gt;&gt;}]},            fun() -&gt;              ...            end) {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} alias OpenTelemetry.SemanticConventions.Trace, as: Trace</p> <p>Tracer.with_span :span_1, %{attributes: [{Trace.http_scheme(), &lt;&lt;\"https\"&gt;&gt;}]} do</p> <p>end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#adding-events","title":"Adding Events","text":"<p>A Span Event is a human-readable message on an Span that represents a discrete event with no duration that can be tracked by a single time stamp. You can think of it like a primitive log.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} ?add_event(&lt;&lt;\"Gonna try it\"&gt;&gt;),</p> <p>%% Do the thing</p> <p>?add_event(&lt;&lt;\"Did it!\"&gt;&gt;), {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} Tracer.add_event(\"Gonna try it\")</p> <p>%% Do the thing</p> <p>Tracer.add_event(\"Did it!\") {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Events can also have attributes of their own:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} ?add_event(&lt;&lt;\"Process exited with reason\"&gt;&gt;, [{pid, Pid)}, {reason, Reason}])) {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} Tracer.add_event(\"Process exited with reason\", pid: pid, reason: Reason) {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#set-span-status","title":"Set Span Status","text":"<p>A Status can be set on a Span, typically used to specify that a Span has not completed successfully - <code>StatusCode.ERROR</code>. In rare scenarios, you could override the Error status with <code>StatusCode.OK</code>, but don\u2019t set <code>StatusCode.OK</code> on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} -include_lib(\"opentelemetry_api/include/opentelemetry.hrl\").</p> <p>?set_status(?OTEL_STATUS_ERROR, &lt;&lt;\"this is not ok\"&gt;&gt;) {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} Tracer.set_status(:error, \"this is not ok\") {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/manual/#creating-metrics","title":"Creating Metrics","text":"<p>The metrics API, found in <code>apps/opentelemetry_experimental_api</code> of the opentelemetry-erlang repository, is currently unstable, documentation TBA.</p>"},{"location":"docs/instrumentation/erlang/propagation/","title":"Propagation","text":""},{"location":"docs/instrumentation/erlang/propagation/#cross-service-propagators","title":"Cross Service Propagators","text":"<p>Distributed traces extend beyond a single service, meaning some context must be propagated across services to create the parent-child relationship between Spans. This requires cross service context propagation, a mechanism where identifiers for a Trace are sent to remote processes.</p> <p>Instrumentation Libraries for HTTP frameworks and servers like Phoenix, Cowboy, Elli and clients like Tesla will automatically inject or extract context using the globally registered propagators. By default the global propagators used are the W3C Trace Context and Baggage formats.</p> <p>These global propagators can be configured by the Application environment variable <code>text_map_propagators</code>:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% sys.config ... {text_map_propagators, [baggage,                         trace_context]}, ... {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/propagation/#runtimeexs","title":"runtime.exs","text":"<p>... text_map_propagators: [:baggage, :trace_context], ... {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Or through a comma separated list with the environment variable <code>OTEL_PROPAGATORS</code>. Both forms of configuration accept the values <code>trace_context</code>, <code>baggage</code>, <code>b3</code> and <code>b3multi</code>.</p> <p>To manually inject or extract context the <code>otel_propagator_text_map</code> module can be used:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% uses the context from the process dictionary to add to an empty list of headers Headers = otel_propagator_text_map:inject([]),</p> <p>%% creates a context in the process dictionary from Headers otel_propagator_text_map:extract(Headers), {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/propagation/#uses-the-context-from-the-process-dictionary-to-add-to-an-empty-list-of-headers","title":"uses the context from the process dictionary to add to an empty list of headers","text":"<p>headers = :otel_propagator_text_map.inject([])</p>"},{"location":"docs/instrumentation/erlang/propagation/#creates-a-context-in-the-process-dictionary-from-headers","title":"creates a context in the process dictionary from headers","text":"<p>:otel_propagator_text_map.extract(headers) {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p><code>otel_propagator_text_map:inject/1</code> and <code>otel_propagator_text_map:extract/1</code> use globally registered propagators. To use a specific propagator <code>otel_propagator_text_map:inject/2</code> and <code>otel_propagator_text_map:extract/2</code> can be used with the first argument being the name of the propagator module to call.</p>"},{"location":"docs/instrumentation/erlang/resources/","title":"Resources","text":"<p>A resource represents an entity producing telemetry as attributes. For example, an OTP Release producing telemetry that is running in a container on Kubernetes has an OTP Release name, a Pod name, a namespace, and possibly a deployment name. All four of these attributes can be included in the resource.</p> <p>In your observability backend, you can use resource information to better investigate interesting behavior. For example, if your trace or metrics data indicate latency in your system, you can narrow it down to a specific container, pod, or Kubernetes deployment.</p>"},{"location":"docs/instrumentation/erlang/resources/#using-resource-detectors","title":"Using resource detectors","text":"<p>Resource detectors fetch resource attributes from various sources. The default detectors use the OS environment variable <code>OTEL_RESOURCE_ATTRIBUTES</code> and the <code>opentelemetry</code> OTP Application environment variable <code>resource</code>.</p> <p>The detectors to use is a list of module names and can be configured in the Application configuration:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% sys.config {resource_detectors, [otel_resource_env_var, otel_resource_app_env]} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/resources/#runtimeexs","title":"runtime.exs","text":"<p>resource_detectors: [:otel_resource_env_var, :otel_resource_app_env] {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Or through the environment variable <code>OTEL_RESOURCE_DETECTORS</code>:</p> <pre><code>OTEL_RESOURCE_DETECTORS=otel_resource_env_var,otel_resource_app_env\n</code></pre> <p>All resources detectors are protected with a timeout, in milliseconds, after which they return an empty value. This allows for resource detectors to do things like hit the network without potentially hanging the entire program indefinitely. The default is 5000 milliseconds and can be set with environment variable <code>OTEL_RESOURCE_DETECTOR_TIMEOUT</code> or Application variable <code>otel_resource_detector_timeout</code>.</p>"},{"location":"docs/instrumentation/erlang/resources/#adding-resources-with-os-and-application-environment-variables","title":"Adding resources with OS and Application environment variables","text":"<p>With the two default resource detectors enabled you can set resource attributes either with the OS environment variable <code>OTEL_RESOURCE_ATTRIBUTES</code>:</p> <pre><code>OTEL_RESOURCE_ATTRIBUTES=\"deployment.environment=development\"\n</code></pre> <p>Alternatively, use the <code>resource</code> Application environment under the <code>opentelemetry</code> Application configuration of <code>sys.config</code> or <code>runtime.exs</code>:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% sys.config {resource, #{deployment =&gt; #{environment =&gt; &lt;&lt;\"development\"&gt;&gt;}} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/resources/#runtimeexs_1","title":"runtime.exs","text":"<p>resource: %{deployment: %{environment: \"development\" }} {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Resource attributes in the <code>resource</code> Application environment variable are flattened and combined with <code>.</code>, so <code>#{deployment =&gt; #{environment =&gt; &lt;&lt;\"development\"&gt;&gt; }</code> is the same as <code>#{'deployment.environment' =&gt; &lt;&lt;\"development\"&gt;&gt;}</code>.</p>"},{"location":"docs/instrumentation/erlang/resources/#custom-resource-detectors","title":"Custom resource detectors","text":"<p>Custom resource detectors can be created by implementing the <code>otel_resource_detector</code> behaviour which contains a single callback <code>get_resource/1</code> that returns an <code>otel_resource</code>.</p> <p>Note that there are semantic conventions defined for <code>resource</code> that should be followed if they apply when adding new resource attributes.</p>"},{"location":"docs/instrumentation/erlang/sampling/","title":"Sampling","text":"<p>Sampling is a process that restricts the amount of traces that are generated by a system. The Erlang SDK offers several head samplers.</p>"},{"location":"docs/instrumentation/erlang/sampling/#default-behavior","title":"Default behavior","text":"<p>By default, all spans are sampled, and thus, 100% of traces are sampled. If you do not need to manage data volume, you do not need to configure a sampler.</p>"},{"location":"docs/instrumentation/erlang/sampling/#parentbasedsampler","title":"ParentBasedSampler","text":"<p>When sampling, the <code>ParentBasedSampler</code> is most often used for head sampling. It uses the sampling decision of the Span's parent, or the fact that there is no parent, to know which secondary sampler to use.</p> <p>The sampler can be configured with the environment variables <code>OTEL_TRACES_SAMPLER</code> and <code>OTEL_TRACES_SAMPLER_ARG</code> or using the Application configuration allows you to configure each of the 5 potential states of a Span's parent:</p> <ul> <li><code>root</code> - No parent</li> <li><code>remote_parent_sampled</code> - Parent is from a remote Span that is sampled</li> <li><code>remote_parent_not_sampled</code> - Parent is from a remote Span that is not sampled</li> <li><code>local_parent_sampled</code> - Parent is from a local Span that is sampled</li> <li><code>local_parent_not_sampled</code> - Parent is from a local Span that is not sampled</li> </ul>"},{"location":"docs/instrumentation/erlang/sampling/#traceidratiobasedsampler","title":"TraceIdRatioBasedSampler","text":"<p>Within the <code>ParentBasedSampler</code> the most common is the <code>TraceIdRatioBasedSampler</code>. It deterministically samples a percentage of traces that you pass in as a parameter.</p>"},{"location":"docs/instrumentation/erlang/sampling/#environment-variables","title":"Environment Variables","text":"<p>You can configure the <code>TraceIdRatioBasedSampler</code> with environment variables:</p> <pre><code>export OTEL_TRACES_SAMPLER=\"parentbased_traceidratio\"\nexport OTEL_TRACES_SAMPLER_ARG=\"0.1\"\n</code></pre> <p>This tells the SDK to sample spans such that only 10% of Traces get created.</p>"},{"location":"docs/instrumentation/erlang/sampling/#application-configuration","title":"Application configuration","text":"<p>Example in the Application configuration with a root sampler for sampling 10% of Traces and using the parent decision in the other cases:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% config/sys.config.src {sampler, {parent_based, #{root =&gt; {trace_id_ratio_based, 0.10},                            remote_parent_sampled =&gt; always_on,                            remote_parent_not_sampled =&gt; always_off,                            local_parent_sampled =&gt; always_on,                            local_parent_not_sampled =&gt; always_off}}} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/sampling/#configruntimeexs","title":"config/runtime.exs","text":"<p>sampler: {:parent_based, %{root: {:trace_id_ratio_based, 0.10},                            remote_parent_sampled: :always_on,                            remote_parent_not_sampled: :always_off,                            local_parent_sampled: :always_on,                            local_parent_not_sampled: :always_off}}</p> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/sampling/#alwayson-and-alwaysoff-sampler","title":"AlwaysOn and AlwaysOff Sampler","text":"<p>The other two built-in samplers are the <code>AlwaysOnSampler</code> and the <code>AlwaysOffSampler</code>.</p>"},{"location":"docs/instrumentation/erlang/sampling/#environment-variables_1","title":"Environment Variables","text":"<p>You can configure the <code>ParentBasedSampler</code> to use either the <code>AlwaysOnSampler</code> or <code>AlwaysOffSampler</code> with the environment variable <code>OTEL_TRACES_SAMPLER</code>:</p> <pre><code>export OTEL_TRACES_SAMPLER=\"parentbased_always_on\"\n</code></pre> <p>And for the <code>AlwaysOffSampler</code>:</p> <pre><code>export OTEL_TRACES_SAMPLER=\"parentbased_always_off\"\n</code></pre>"},{"location":"docs/instrumentation/erlang/sampling/#application-configuration_1","title":"Application configuration","text":"<p>Here's an example in the Application configuration with a root sampler that always samples and using the parent decision in the other cases:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% config/sys.config.src {sampler, {parent_based, #{root =&gt; always_on,                            remote_parent_sampled =&gt; always_on,                            remote_parent_not_sampled =&gt; always_off,                            local_parent_sampled =&gt; always_on,                            local_parent_not_sampled =&gt; always_off}}} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/sampling/#configruntimeexs_1","title":"config/runtime.exs","text":"<p>sampler: {:parent_based, %{root: :always_on,                            remote_parent_sampled: :always_on,                            remote_parent_not_sampled: :always_off,                            local_parent_sampled: :always_on,                            local_parent_not_sampled: :always_off}}</p> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/sampling/#custom-sampler","title":"Custom Sampler","text":"<p>Custom samplers can be created by implementing the <code>otel_sampler</code> behaviour. This example sampler:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} -module(attribute_sampler).</p> <p>-behavior(otel_sampler).</p> <p>-export([description/1,          setup/1,          should_sample/7]).</p> <p>-include(\"otel_sampler.hrl\").</p> <p>setup(Attributes) when is_map(Attributes) -&gt;     Attributes; setup(_) -&gt;     #{}.</p> <p>description(_) -&gt;     &lt;&lt;\"AttributeSampler\"&gt;&gt;.</p> <p>should_sample(_Ctx, _TraceId, _Links, _SpanName, _SpanKind, Attributes, ConfigAttributes) -&gt;     case maps:intersect(Attributes, ConfigAttributes) of         Map when map_size(Map) &gt; 0 -&gt;             {?DROP, [], []};         _ -&gt;             {?RECORD_AND_SAMPLE, [], []}     end. {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} defmodule AttributesSampler do   def setup(attributes) when is_map(attributes) do     attributes   end</p> <p>def setup(_) do     %{}   end</p> <p>def description(_) do     \"ExampleSampler\"   end</p> <p>def should_sample(_ctx, _trace_id, _links, _span_name, _span_kind, attributes, config_attributes) do     case :maps.intersect(attributes, config_attributes) do       map when map_size(map) &gt; 0 -&gt;         {:drop, [], []}       _ -&gt;         {:record_and_sample, [], []}     end   end end  {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Will sample Spans that do not have any attributes that match the attributes passed as the sampler's configuration.</p> <p>Example configuration to not sample any Span with an attribute specifying the URL requested is <code>/healthcheck</code>:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} {sampler, {attributes_sampler, #{'http.target' =&gt; &lt;&lt;\"/healthcheck\"&gt;&gt;}}} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} sampler: {AttributesSampler, %{\"http.target\": \"/healthcheck\"}} {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/testing/","title":"Testing","text":"<p>When relying on OpenTelemetry for your Observability needs, it can be important to test that certain spans are created and attributes correctly set. For example, can you be sure that you attaching the right metadata to data that ultimately powers an SLO? This document covers an approach to that kind of validation.</p>"},{"location":"docs/instrumentation/erlang/testing/#setup","title":"Setup","text":"<p>Only the <code>opentelemetry</code> and <code>opentelemetry_api</code> libraries are required for testing in Elixir/Erlang:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} {deps, [{opentelemetry_api, \"~&gt; 1.0\"},         {opentelemetry, \"~&gt; 1.0\"}]}. {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} def deps do   [     {:opentelemetry_api, \"~&gt; 1.0\"},     {:opentelemetry, \"~&gt; 1.0\"}   ] end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Set your <code>exporter</code> to <code>:none</code> and the span processor to <code>:otel_simple_processor</code>. This ensure that your tests don't actually export data to a destination, and that spans can be analyzed after they are processed.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% config/sys.config.src {opentelemetry,   [{traces_exporter, none},    {processors,      [{otel_simple_processor, #{}}]}]} {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/testing/#configtestexs","title":"config/test.exs","text":"<p>import Config</p> <p>config :opentelemetry,     traces_exporter: :none</p> <p>config :opentelemetry, :processors, [   {:otel_simple_processor, %{}} ] {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>A modified version of the <code>hello</code> function from the Getting Started guide will serve as our test case:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} %% apps/otel_getting_started/src/otel_getting_started.erl -module(otel_getting_started).</p> <p>-export([hello/0]).</p> <p>-include_lib(\"opentelemetry_api/include/otel_tracer.hrl\").</p> <p>hello() -&gt;     %% start an active span and run a local function     ?with_span(&lt;&lt;\"operation\"&gt;&gt;, #{}, fun nice_operation/1).</p> <p>nice_operation(_SpanCtx) -&gt;     ?set_attributes([{a_key, &lt;&lt;\"a value\"&gt;&gt;}]),     world {{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}}</p>"},{"location":"docs/instrumentation/erlang/testing/#libotel_getting_startedex","title":"lib/otel_getting_started.ex","text":"<p>defmodule OtelGettingStarted do   require OpenTelemetry.Tracer, as: Tracer</p> <p>def hello do     Tracer.with_span \"operation\" do       Tracer.set_attributes([{:a_key, \"a value\"}])       :world     end   end end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/erlang/testing/#testing","title":"Testing","text":"<p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab Erlang &gt;}} -module(otel_getting_started_SUITE).</p> <p>-compile(export_all).</p> <p>-include_lib(\"stdlib/include/assert.hrl\"). -include_lib(\"common_test/include/ct.hrl\").</p> <p>-include_lib(\"opentelemetry/include/otel_span.hrl\").</p> <p>-define(assertReceive(SpanName),         receive             {span, Span=#span{name=SpanName}} -&gt;                 Span         after             1000 -&gt;                 ct:fail(\"Did not receive the span after 1s\")         end).</p> <p>all() -&gt;     [greets_the_world].</p> <p>init_per_suite(Config) -&gt;     application:load(opentelemetry),     application:set_env(opentelemetry, processors, [{otel_simple_processor, #{}}]),     {ok, _} = application:ensure_all_started(opentelemetry),     Config.</p> <p>end_per_suite(_Config) -&gt;     _ = application:stop(opentelemetry),     _ = application:unload(opentelemetry),     ok.</p> <p>init_per_testcase(greets_the_world, Config) -&gt;     otel_simple_processor:set_exporter(otel_exporter_pid, self()),     Config.</p> <p>end_per_testcase(greets_the_world, _Config) -&gt;     otel_simple_processor:set_exporter(none),     ok.</p> <p>greets_the_world(_Config) -&gt;     otel_getting_started:hello(),</p> <pre><code>ExpectedAttributes = otel_attributes:new(#{a_key =&gt; &lt;&lt;\"a_value\"&gt;&gt;}, 128, infinity),\n#span{attributes=ReceivedAttributes} = ?assertReceive(&lt;&lt;\"operation\"&gt;&gt;),\n\n%% use an assertMatch instead of matching in the `receive'\n%% so we get a nice error message if it fails\n?assertMatch(ReceivedAttributes, ExpectedAttributes),\n\nok.\n</code></pre> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab Elixir &gt;}} defmodule OtelGettingStartedTest do   use ExUnit.Case</p> <p># Use Record module to extract fields of the Span record from the opentelemetry dependency.   require Record   @fields Record.extract(:span, from: \"deps/opentelemetry/include/otel_span.hrl\")   # Define macros for <code>Span</code>.   Record.defrecordp(:span, @fields)</p> <p>test \"greets the world\" do     # Set exporter to :otel_exporter_pid, which sends spans     # to the given process - in this case self() - in the format {:span, span}     :otel_simple_processor.set_exporter(:otel_exporter_pid, self())</p> <pre><code># Call the function to be tested.\nOtelGettingStarted.hello()\n\n# Use Erlang's `:otel_attributes` module to create attributes to match against.\n# See the `:otel_events` module for testing events.\nattributes = :otel_attributes.new([a_key: \"a value\"], 128, :infinity)\n\n# Assert that the span emitted by OtelGettingStarted.hello/0 was received and contains the desired attributes.\nassert_receive {:span,\n                span(\n                  name: \"operation\",\n                  attributes: ^attributes\n                )}\n</code></pre> <p>end end {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/java/_index/","title":"Java","text":"<p>{{% lang_instrumentation_index_head java /%}}</p>"},{"location":"docs/instrumentation/java/_index/#repositories","title":"Repositories","text":"<p>OpenTelemetry Java consists of the following repositories:</p> <ul> <li>opentelemetry-java:   Components for manual instrumentation including API and SDK as well as   extensions, the OpenTracing shim.</li> <li>opentelemetry-java-docs: Manual instrumentation examples.</li> <li>opentelemetry-java-instrumentation:   Built on top of opentelemetry-java and provides a Java agent JAR that can be   attached to any Java 8+ application and dynamically injects bytecode to   capture telemetry from a number of popular libraries and frameworks.</li> <li>opentelemetry-java-contrib:   Provides helpful libraries and standalone OpenTelemetry-based utilities that   don't fit the express scope of the OpenTelemetry Java or Java Instrumentation   projects. For example, JMX metric gathering.</li> </ul>"},{"location":"docs/instrumentation/java/_index/#components","title":"Components","text":"<p>See components for a complete list of published components.</p>"},{"location":"docs/instrumentation/java/_index/#releases","title":"Releases","text":"<p>Published releases are available on maven central. We strongly recommend using our BOM to keep the versions of the various components in sync.</p>"},{"location":"docs/instrumentation/java/_index/#maven","title":"Maven","text":"<pre><code>&lt;project&gt;\n&lt;dependencyManagement&gt;\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-bom&lt;/artifactId&gt;\n&lt;version&gt;{{% param javaVersion %}}&lt;/version&gt;\n&lt;type&gt;pom&lt;/type&gt;\n&lt;scope&gt;import&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/project&gt;\n</code></pre>"},{"location":"docs/instrumentation/java/_index/#gradle","title":"Gradle","text":"<pre><code>dependencies {\nimplementation(platform(\"io.opentelemetry:opentelemetry-bom:{{% param javaVersion %}}\"))\nimplementation(\"io.opentelemetry:opentelemetry-api\")\n}\n</code></pre>"},{"location":"docs/instrumentation/java/getting-started/","title":"Getting Started","text":"<p>This page will show you how to get started with OpenTelemetry in Java.</p> <p>You will learn how you can instrument a simple java application automatically, in such a way that traces, metrics and logs are emitted to the console.</p>"},{"location":"docs/instrumentation/java/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have the following installed locally:</p> <ul> <li>Java JDK</li> <li>Gradle</li> </ul>"},{"location":"docs/instrumentation/java/getting-started/#example-application","title":"Example Application","text":"<p>The following example uses a basic Spring Boot application. If you are not using Spring Boot, that's ok \u2014 you can use OpenTelemetry Java with other web frameworks as well, such as Apache Wicket and Play. For a complete list of libraries for supported frameworks, see the registry.</p> <p>For more elaborate examples, see examples.</p>"},{"location":"docs/instrumentation/java/getting-started/#dependencies","title":"Dependencies","text":"<p>To begin, set up an environment in a new directory called <code>java-simple</code>. Within that directory, create a file called <code>build.gradle.kts</code> with the following content:</p> <pre><code>plugins {\nid(\"java\")\nid(\"org.springframework.boot\") version \"3.0.6\"\nid(\"io.spring.dependency-management\") version \"1.1.0\"\n}\nsourceSets {\nmain {\njava.setSrcDirs(setOf(\".\"))\n}\n}\nrepositories {\nmavenCentral()\n}\ndependencies {\nimplementation(\"org.springframework.boot:spring-boot-starter-web\")\n}\n</code></pre>"},{"location":"docs/instrumentation/java/getting-started/#create-and-launch-an-http-server","title":"Create and launch an HTTP Server","text":"<p>In that same folder, create a file called <code>DiceApplication.java</code> and add the following code to the file:</p> <pre><code>package otel;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.Banner;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n@SpringBootApplication\npublic class DiceApplication {\npublic static void main(String[] args) {\nSpringApplication app = new SpringApplication(DiceApplication.class);\napp.setBannerMode(Banner.Mode.OFF);\napp.run(args);\n}\n}\n</code></pre> <p>Create another file called <code>RollController.java</code> and add the following code to the file:</p> <pre><code>package otel;\nimport java.util.Optional;\nimport java.util.concurrent.ThreadLocalRandom;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.bind.annotation.RestController;\n@RestController\npublic class RollController {\nprivate static final Logger logger = LoggerFactory.getLogger(RollController.class);\n@GetMapping(\"/rolldice\")\npublic String index(@RequestParam(\"player\") Optional&lt;String&gt; player) {\nint result = this.getRandomNumber(1, 6);\nif (player.isPresent()) {\nlogger.info(\"{} is rolling the dice: {}\", player.get(), result);\n} else {\nlogger.info(\"Anonymous player is rolling the dice: {}\", result);\n}\nreturn Integer.toString(result);\n}\npublic int getRandomNumber(int min, int max) {\nreturn ThreadLocalRandom.current().nextInt(min, max + 1);\n}\n}\n</code></pre> <p>Build and run the application with the following command, then open http://localhost:8080/rolldice in your web browser to ensure it is working.</p> <pre><code>gradle assemble\njava -jar ./build/libs/java-simple.jar\n</code></pre>"},{"location":"docs/instrumentation/java/getting-started/#instrumentation","title":"Instrumentation","text":"<p>Next, you'll use a Java agent to automatically instrument the application at launch time. While you can configure the Java agent in a number of ways, the steps below use environment variables.</p> <ol> <li>Download opentelemetry-javaagent.jar from Releases of the    <code>opentelemetry-java-instrumentation</code> repo. The JAR file contains the agent    and all automatic instrumentation packages:</li> </ol> <pre><code>curl -L -O https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar\n</code></pre> <p>{{% alert color=\"info\" %}} Take note of the path    to the JAR file.{{% /alert %}}</p> <ol> <li>Set and export variables that specify the Java agent JAR and a console    exporter, using a notation suitable for your shell/terminal environment    \u2014 we illustrate a notation for bash-like shells:</li> </ol> <pre><code>$ export JAVA_TOOL_OPTIONS=\"-javaagent:PATH/TO/opentelemetry-javaagent.jar\" \\\nOTEL_TRACES_EXPORTER=logging \\\nOTEL_METRICS_EXPORTER=logging \\\nOTEL_LOGS_EXPORTER=logging\n</code></pre> <p>{{% alert title=\"Important\" color=\"warning\" %}}Replace <code>PATH/TO</code> above, with    your path to the JAR.{{% /alert %}}</p> <ol> <li>Run your application once again:</li> </ol> <pre><code>$ java -jar ./build/libs/java-simple.jar\n...\n</code></pre> <p>Note the output from the <code>otel.javaagent</code>.</p> <ol> <li>From another terminal, send a request using <code>curl</code>:</li> </ol> <pre><code>$ curl localhost:8080/rolldice\n</code></pre> <ol> <li>Stop the server process.</li> </ol> <p>At step 4, you should have seen trace &amp; log output from the server and client that looks something like this (trace output is line-wrapped for convenience):</p> <pre><code>[otel.javaagent 2023-04-24 17:33:54:567 +0200] [http-nio-8080-exec-1] INFO\nio.opentelemetry.exporter.logging.LoggingSpanExporter - 'RollController.index' :\n 70c2f04ec863a956e9af975ba0d983ee 7fd145f5cda13625 INTERNAL [tracer:\n io.opentelemetry.spring-webmvc-6.0:1.25.0-alpha] AttributesMap{data=\n{thread.id=39, thread.name=http-nio-8080-exec-1}, capacity=128,\n totalAddedValues=2}\n[otel.javaagent 2023-04-24 17:33:54:568 +0200] [http-nio-8080-exec-1] INFO\nio.opentelemetry.exporter.logging.LoggingSpanExporter - 'GET /rolldice' :\n70c2f04ec863a956e9af975ba0d983ee 647ad186ad53eccf SERVER [tracer:\nio.opentelemetry.tomcat-10.0:1.25.0-alpha] AttributesMap{\ndata={user_agent.original=curl/7.87.0, net.host.name=localhost,\n  net.transport=ip_tcp, http.target=/rolldice, net.sock.peer.addr=127.0.0.1,\n  thread.name=http-nio-8080-exec-1, net.sock.peer.port=53422,\n  http.route=/rolldice, net.sock.host.addr=127.0.0.1, thread.id=39,\n  net.protocol.name=http, http.status_code=200, http.scheme=http,\n  net.protocol.version=1.1, http.response_content_length=1,\n  net.host.port=8080, http.method=GET}, capacity=128, totalAddedValues=17}\n</code></pre> <p>At step 5, when stopping the server, you should see an output of all the metrics collected (metrics output is line-wrapped and shortened for convenience):</p> <pre><code>[otel.javaagent 2023-04-24 17:34:25:347 +0200] [PeriodicMetricReader-1] INFO\nio.opentelemetry.exporter.logging.LoggingMetricExporter - Received a collection\n of 19 metrics for export.\n[otel.javaagent 2023-04-24 17:34:25:347 +0200] [PeriodicMetricReader-1] INFO\nio.opentelemetry.exporter.logging.LoggingMetricExporter - metric:\nImmutableMetricData{resource=Resource{schemaUrl=\nhttps://opentelemetry.io/schemas/1.19.0, attributes={host.arch=\"aarch64\",\nhost.name=\"OPENTELEMETRY\", os.description=\"Mac OS X 13.3.1\", os.type=\"darwin\",\nprocess.command_args=[/bin/java, -jar, java-simple.jar],\nprocess.executable.path=\"/bin/java\", process.pid=64497,\nprocess.runtime.description=\"Homebrew OpenJDK 64-Bit Server VM 20\",\nprocess.runtime.name=\"OpenJDK Runtime Environment\",\nprocess.runtime.version=\"20\", service.name=\"java-simple\",\ntelemetry.auto.version=\"1.25.0\", telemetry.sdk.language=\"java\",\ntelemetry.sdk.name=\"opentelemetry\", telemetry.sdk.version=\"1.25.0\"}},\ninstrumentationScopeInfo=InstrumentationScopeInfo{name=io.opentelemetry.runtime-metrics,\nversion=1.25.0, schemaUrl=null, attributes={}},\nname=process.runtime.jvm.buffer.limit, description=Total capacity of the buffers\nin this pool, unit=By, type=LONG_SUM, data=ImmutableSumData{points=\n[ImmutableLongPointData{startEpochNanos=1682350405319221000,\nepochNanos=1682350465326752000, attributes=\n{pool=\"mapped - 'non-volatile memory'\"}, value=0, exemplars=[]},\nImmutableLongPointData{startEpochNanos=1682350405319221000,\nepochNanos=1682350465326752000, attributes={pool=\"mapped\"},\nvalue=0, exemplars=[]},\nImmutableLongPointData{startEpochNanos=1682350405319221000,\nepochNanos=1682350465326752000, attributes={pool=\"direct\"},\nvalue=8192, exemplars=[]}], monotonic=false, aggregationTemporality=CUMULATIVE}}\n...\n</code></pre>"},{"location":"docs/instrumentation/java/getting-started/#what-next","title":"What next?","text":"<p>For more:</p> <ul> <li>Run this example with another exporter for telemetry data.</li> <li>Try automatic instrumentation on one of your own apps.</li> <li>For light-weight customized telemetry, try annotations.</li> <li>Learn about manual instrumentation and try out more   examples.</li> </ul>"},{"location":"docs/instrumentation/java/manual/","title":"Manual Instrumentation","text":"<p>Libraries that want to export telemetry data using OpenTelemetry MUST only depend on the <code>opentelemetry-api</code> package and should never configure or depend on the OpenTelemetry SDK. The SDK configuration must be provided by Applications which should also depend on the <code>opentelemetry-sdk</code> package, or any other implementation of the OpenTelemetry API. This way, libraries will obtain a real implementation only if the user application is configured for it. For more details, check out the Library Guidelines.</p>"},{"location":"docs/instrumentation/java/manual/#setup","title":"Setup","text":"<p>The first step is to get a handle to an instance of the <code>OpenTelemetry</code> interface.</p> <p>If you are an application developer, you need to configure an instance of the <code>OpenTelemetrySdk</code> as early as possible in your application. This can be done using the <code>OpenTelemetrySdk.builder()</code> method. The returned <code>OpenTelemetrySdkBuilder</code> instance gets the providers related to the signals, tracing and metrics, in order to build the <code>OpenTelemetry</code> instance.</p> <p>You can build the providers by using the <code>SdkTracerProvider.builder()</code> and <code>SdkMeterProvider.builder()</code> methods. It is also strongly recommended to define a <code>Resource</code> instance as a representation of the entity producing the telemetry; in particular the <code>service.name</code> attribute is the most important piece of telemetry source-identifying info.</p>"},{"location":"docs/instrumentation/java/manual/#maven","title":"Maven","text":"<pre><code>&lt;project&gt;\n&lt;dependencyManagement&gt;\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-bom&lt;/artifactId&gt;\n&lt;version&gt;{{% param javaVersion %}}&lt;/version&gt;\n&lt;type&gt;pom&lt;/type&gt;\n&lt;scope&gt;import&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;\n&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-sdk&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-exporter-otlp&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-semconv&lt;/artifactId&gt;\n&lt;version&gt;{{% param javaVersion %}}-alpha&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/project&gt;\n</code></pre> <p>See releases for a full list of artifact coordinates.</p>"},{"location":"docs/instrumentation/java/manual/#gradle","title":"Gradle","text":"<pre><code>dependencies {\nimplementation 'io.opentelemetry:opentelemetry-api:{{% param javaVersion %}}'\nimplementation 'io.opentelemetry:opentelemetry-sdk:{{% param javaVersion %}}'\nimplementation 'io.opentelemetry:opentelemetry-exporter-otlp:{{% param javaVersion %}}'\nimplementation 'io.opentelemetry:opentelemetry-semconv:{{% param javaVersion %}}-alpha'\n}\n</code></pre> <p>See releases for a full list of artifact coordinates.</p>"},{"location":"docs/instrumentation/java/manual/#imports","title":"Imports","text":"<pre><code>import io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.api.common.Attributes;\nimport io.opentelemetry.api.trace.propagation.W3CTraceContextPropagator;\nimport io.opentelemetry.context.propagation.ContextPropagators;\nimport io.opentelemetry.exporter.otlp.metrics.OtlpGrpcMetricExporter;\nimport io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporter;\nimport io.opentelemetry.sdk.OpenTelemetrySdk;\nimport io.opentelemetry.sdk.metrics.SdkMeterProvider;\nimport io.opentelemetry.sdk.metrics.export.PeriodicMetricReader;\nimport io.opentelemetry.sdk.resources.Resource;\nimport io.opentelemetry.sdk.trace.SdkTracerProvider;\nimport io.opentelemetry.sdk.trace.export.BatchSpanProcessor;\nimport io.opentelemetry.semconv.resource.attributes.ResourceAttributes;\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#example","title":"Example","text":"<pre><code>Resource resource = Resource.getDefault()\n.merge(Resource.create(Attributes.of(ResourceAttributes.SERVICE_NAME, \"logical-service-name\")));\nSdkTracerProvider sdkTracerProvider = SdkTracerProvider.builder()\n.addSpanProcessor(BatchSpanProcessor.builder(OtlpGrpcSpanExporter.builder().build()).build())\n.setResource(resource)\n.build();\nSdkMeterProvider sdkMeterProvider = SdkMeterProvider.builder()\n.registerMetricReader(PeriodicMetricReader.builder(OtlpGrpcMetricExporter.builder().build()).build())\n.setResource(resource)\n.build();\n// TODO: add log configuration when stable\nOpenTelemetry openTelemetry = OpenTelemetrySdk.builder()\n.setTracerProvider(sdkTracerProvider)\n.setMeterProvider(sdkMeterProvider)\n.setPropagators(ContextPropagators.create(W3CTraceContextPropagator.getInstance()))\n.buildAndRegisterGlobal();\n</code></pre> <p>As an aside, if you are writing library instrumentation, it is strongly recommended that you provide your users the ability to inject an instance of <code>OpenTelemetry</code> into your instrumentation code. If this is not possible for some reason, you can fall back to using an instance from the <code>GlobalOpenTelemetry</code> class. Note that you can't force end-users to configure the global, so this is the most brittle option for library instrumentation.</p>"},{"location":"docs/instrumentation/java/manual/#acquiring-a-tracer","title":"Acquiring a Tracer","text":"<p>To do Tracing you'll need to acquire a <code>Tracer</code>.</p> <p>Note: Methods of the OpenTelemetry SDK should never be called.</p> <p>First, a <code>Tracer</code> must be acquired, which is responsible for creating spans and interacting with the Context. A tracer is acquired by using the OpenTelemetry API specifying the name and version of the library instrumenting the instrumented library or application to be monitored. More information is available in the specification chapter Obtaining a Tracer.</p> <pre><code>import io.opentelemetry.api;\n//...\nTracer tracer =\nopenTelemetry.getTracer(\"instrumentation-library-name\", \"1.0.0\");\n</code></pre> <p>Important: the \"name\" and optional version of the tracer are purely informational. All <code>Tracer</code>s that are created by a single <code>OpenTelemetry</code> instance will interoperate, regardless of name.</p>"},{"location":"docs/instrumentation/java/manual/#create-spans","title":"Create Spans","text":"<p>To create Spans, you only need to specify the name of the span. The start and end time of the span is automatically set by the OpenTelemetry SDK.</p> <pre><code>Span span = tracer.spanBuilder(\"my span\").startSpan();\n// Make the span the current span\ntry (Scope ss = span.makeCurrent()) {\n// In this scope, the span is the current/active span\n} finally {\nspan.end();\n}\n</code></pre> <p>It's required to call <code>end()</code> to end the span when you want it to end.</p>"},{"location":"docs/instrumentation/java/manual/#create-nested-spans","title":"Create nested Spans","text":"<p>Most of the time, we want to correlate spans for nested operations. OpenTelemetry supports tracing within processes and across remote processes. For more details how to share context between remote processes, see Context Propagation.</p> <p>For a method <code>a</code> calling a method <code>b</code>, the spans could be manually linked in the following way:</p> <pre><code>void parentOne() {\nSpan parentSpan = tracer.spanBuilder(\"parent\").startSpan();\ntry {\nchildOne(parentSpan);\n} finally {\nparentSpan.end();\n}\n}\nvoid childOne(Span parentSpan) {\nSpan childSpan = tracer.spanBuilder(\"child\")\n.setParent(Context.current().with(parentSpan))\n.startSpan();\ntry {\n// do stuff\n} finally {\nchildSpan.end();\n}\n}\n</code></pre> <p>The OpenTelemetry API offers also an automated way to propagate the parent span on the current thread:</p> <pre><code>void parentTwo() {\nSpan parentSpan = tracer.spanBuilder(\"parent\").startSpan();\ntry(Scope scope = parentSpan.makeCurrent()) {\nchildTwo();\n} finally {\nparentSpan.end();\n}\n}\nvoid childTwo() {\nSpan childSpan = tracer.spanBuilder(\"child\")\n// NOTE: setParent(...) is not required;\n// `Span.current()` is automatically added as the parent\n.startSpan();\ntry(Scope scope = childSpan.makeCurrent()) {\n// do stuff\n} finally {\nchildSpan.end();\n}\n}\n</code></pre> <p>To link spans from remote processes, it is sufficient to set the Remote Context as parent.</p> <pre><code>Span childRemoteParent = tracer.spanBuilder(\"Child\").setParent(remoteContext).startSpan();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#get-the-current-span","title":"Get the current span","text":"<p>Sometimes it's helpful to do something with the current/active span at a particular point in program execution.</p> <pre><code>Span span = Span.current()\n</code></pre> <p>And if you want the current span for a particular <code>Context</code> object:</p> <pre><code>Span span = Span.fromContext(context)\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#span-attributes","title":"Span Attributes","text":"<p>In OpenTelemetry spans can be created freely and it's up to the implementor to annotate them with attributes specific to the represented operation. Attributes provide additional context on a span about the specific operation it tracks, such as results or operation properties.</p> <pre><code>Span span = tracer.spanBuilder(\"/resource/path\").setSpanKind(SpanKind.CLIENT).startSpan();\nspan.setAttribute(\"http.method\", \"GET\");\nspan.setAttribute(\"http.url\", url.toString());\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#semantic-attributes","title":"Semantic Attributes","text":"<p>There are semantic conventions for spans representing operations in well-known protocols like HTTP or database calls. Semantic conventions for these spans are defined in the specification at Trace Semantic Conventions.</p> <p>First add the semantic conventions as a dependency to your application:</p>"},{"location":"docs/instrumentation/java/manual/#maven_1","title":"Maven","text":"<pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-semconv&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#gradle_1","title":"Gradle","text":"<pre><code>dependencies {\nimplementation(\"io.opentelemetry:opentelemetry-semconv\")\n}\n</code></pre> <p>Finally, you can update your file to include semantic attributes:</p> <pre><code>Span span = tracer.spanBuilder(\"/resource/path\").setSpanKind(SpanKind.CLIENT).startSpan();\nspan.setAttribute(SemanticAttributes.HTTP_METHOD, \"GET\");\nspan.setAttribute(SemanticAttributes.HTTP_URL, url.toString());\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#create-spans-with-events","title":"Create Spans with events","text":"<p>Spans can be annotated with named events (called Span Events) that can carry zero or more Span Attributes, each of which itself is a key:value map paired automatically with a timestamp.</p> <pre><code>span.addEvent(\"Init\");\n...\nspan.addEvent(\"End\");\n</code></pre> <pre><code>Attributes eventAttributes = Attributes.of(\nAttributeKey.stringKey(\"key\"), \"value\",\nAttributeKey.longKey(\"result\"), 0L);\nspan.addEvent(\"End Computation\", eventAttributes);\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#create-spans-with-links","title":"Create Spans with links","text":"<p>A Span may be linked to zero or more other Spans that are causally related via a Span Link. Links can be used to represent batched operations where a Span was initiated by multiple initiating Spans, each representing a single incoming item being processed in the batch.</p> <pre><code>Span child = tracer.spanBuilder(\"childWithLink\")\n.addLink(parentSpan1.getSpanContext())\n.addLink(parentSpan2.getSpanContext())\n.addLink(parentSpan3.getSpanContext())\n.addLink(remoteSpanContext)\n.startSpan();\n</code></pre> <p>For more details how to read context from remote processes, see Context Propagation.</p>"},{"location":"docs/instrumentation/java/manual/#set-span-status","title":"Set span status","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - <code>SpanStatus.Error</code>. In rare scenarios, you could override the <code>Error</code> status with <code>OK</code>, but don't set <code>OK</code> on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>Span span = tracer.spanBuilder(\"my span\").startSpan();\n// put the span into the current Context\ntry (Scope scope = span.makeCurrent()) {\n// do something\n} catch (Throwable t) {\nspan.setStatus(StatusCode.ERROR, \"Something bad happened!\");\nthrow t;\n} finally {\nspan.end(); // Cannot set a span after this call\n}\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#record-exceptions-in-spans","title":"Record exceptions in spans","text":"<p>It can be a good idea to record exceptions when they happen. It's recommended to do this in conjunction with setting span status.</p> <pre><code>Span span = tracer.spanBuilder(\"my span\").startSpan();\n// put the span into the current Context\ntry (Scope scope = span.makeCurrent()) {\n// do something\n} catch (Throwable throwable) {\nspan.setStatus(StatusCode.ERROR, \"Something bad happened!\");\nspan.recordException(throwable);\n} finally {\nspan.end(); // Cannot set a span after this call\n}\n</code></pre> <p>This will capture things like the current stack trace in the span.</p>"},{"location":"docs/instrumentation/java/manual/#context-propagation","title":"Context Propagation","text":"<p>OpenTelemetry provides a text-based approach to propagate context to remote services using the W3C Trace Context HTTP headers.</p> <p>The following presents an example of an outgoing HTTP request using <code>HttpURLConnection</code>.</p> <pre><code>// Tell OpenTelemetry to inject the context in the HTTP headers\nTextMapSetter&lt;HttpURLConnection&gt; setter =\nnew TextMapSetter&lt;HttpURLConnection&gt;() {\n@Override\npublic void set(HttpURLConnection carrier, String key, String value) {\n// Insert the context as Header\ncarrier.setRequestProperty(key, value);\n}\n};\nURL url = new URL(\"http://127.0.0.1:8080/resource\");\nSpan outGoing = tracer.spanBuilder(\"/resource\").setSpanKind(SpanKind.CLIENT).startSpan();\ntry (Scope scope = outGoing.makeCurrent()) {\n// Use the Semantic Conventions.\n// (Note that to set these, Span does not *need* to be the current instance in Context or Scope.)\noutGoing.setAttribute(SemanticAttributes.HTTP_METHOD, \"GET\");\noutGoing.setAttribute(SemanticAttributes.HTTP_URL, url.toString());\nHttpURLConnection transportLayer = (HttpURLConnection) url.openConnection();\n// Inject the request with the *current*  Context, which contains our current Span.\nopenTelemetry.getPropagators().getTextMapPropagator().inject(Context.current(), transportLayer, setter);\n// Make outgoing call\n} finally {\noutGoing.end();\n}\n...\n</code></pre> <p>Similarly, the text-based approach can be used to read the W3C Trace Context from incoming requests. The following presents an example of processing an incoming HTTP request using HttpExchange.</p> <pre><code>TextMapGetter&lt;HttpExchange&gt; getter =\nnew TextMapGetter&lt;&gt;() {\n@Override\npublic String get(HttpExchange carrier, String key) {\nif (carrier.getRequestHeaders().containsKey(key)) {\nreturn carrier.getRequestHeaders().get(key).get(0);\n}\nreturn null;\n}\n@Override\npublic Iterable&lt;String&gt; keys(HttpExchange carrier) {\nreturn carrier.getRequestHeaders().keySet();\n}\n};\n...\npublic void handle(HttpExchange httpExchange) {\n// Extract the SpanContext and other elements from the request.\nContext extractedContext = openTelemetry.getPropagators().getTextMapPropagator()\n.extract(Context.current(), httpExchange, getter);\ntry (Scope scope = extractedContext.makeCurrent()) {\n// Automatically use the extracted SpanContext as parent.\nSpan serverSpan = tracer.spanBuilder(\"GET /resource\")\n.setSpanKind(SpanKind.SERVER)\n.startSpan();\ntry {\n// Add the attributes defined in the Semantic Conventions\nserverSpan.setAttribute(SemanticAttributes.HTTP_METHOD, \"GET\");\nserverSpan.setAttribute(SemanticAttributes.HTTP_SCHEME, \"http\");\nserverSpan.setAttribute(SemanticAttributes.HTTP_HOST, \"localhost:8080\");\nserverSpan.setAttribute(SemanticAttributes.HTTP_TARGET, \"/resource\");\n// Serve the request\n...\n} finally {\nserverSpan.end();\n}\n}\n}\n</code></pre> <p>The following code presents an example to read the W3C Trace Context from incoming request, add spans, and further propagate the context. The example utilizes HttpHeaders to fetch the traceparent header for context propagation.</p> <pre><code>TextMapGetter&lt;HttpHeaders&gt; getter =\nnew TextMapGetter&lt;HttpHeaders&gt;() {\n@Override\npublic String get(HttpHeaders headers, String s) {\nassert headers != null;\nreturn headers.getHeaderString(s);\n}\n@Override\npublic Iterable&lt;String&gt; keys(HttpHeaders headers) {\nList&lt;String&gt; keys = new ArrayList&lt;&gt;();\nMultivaluedMap&lt;String, String&gt; requestHeaders = headers.getRequestHeaders();\nrequestHeaders.forEach((k, v) -&gt;{\nkeys.add(k);\n});\n}\n};\nTextMapSetter&lt;HttpURLConnection&gt; setter =\nnew TextMapSetter&lt;HttpURLConnection&gt;() {\n@Override\npublic void set(HttpURLConnection carrier, String key, String value) {\n// Insert the context as Header\ncarrier.setRequestProperty(key, value);\n}\n};\n//...\npublic void handle(&lt;Library Specific Annotation&gt; HttpHeaders headers){\nContext extractedContext = opentelemetry.getPropagators().getTextMapPropagator()\n.extract(Context.current(), headers, getter);\ntry (Scope scope = extractedContext.makeCurrent()) {\n// Automatically use the extracted SpanContext as parent.\nSpan serverSpan = tracer.spanBuilder(\"GET /resource\")\n.setSpanKind(SpanKind.SERVER)\n.startSpan();\ntry(Scope ignored = serverSpan.makeCurrent()) {\n// Add the attributes defined in the Semantic Conventions\nserverSpan.setAttribute(SemanticAttributes.HTTP_METHOD, \"GET\");\nserverSpan.setAttribute(SemanticAttributes.HTTP_SCHEME, \"http\");\nserverSpan.setAttribute(SemanticAttributes.HTTP_HOST, \"localhost:8080\");\nserverSpan.setAttribute(SemanticAttributes.HTTP_TARGET, \"/resource\");\nHttpURLConnection transportLayer = (HttpURLConnection) url.openConnection();\n// Inject the request with the *current*  Context, which contains our current Span.\nopenTelemetry.getPropagators().getTextMapPropagator().inject(Context.current(), transportLayer, setter);\n// Make outgoing call\n}finally {\nserverSpan.end();\n}\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#metrics","title":"Metrics","text":"<p>Spans provide detailed information about your application, but produce data that is proportional to the load on the system. In contrast, metrics combine individual measurements into aggregations, and produce data which is constant as a function of system load. The aggregations lack details required to diagnose low level issues, but complement spans by helping to identify trends and providing application runtime telemetry.</p> <p>The metrics API defines a variety of instruments. Instruments record measurements, which are aggregated by the metrics SDK and eventually exported out of process. Instruments come in synchronous and asynchronous varieties. Synchronous instruments record measurements as they happen. Asynchronous instrument register a callback, which is invoked once per collection, and which records measurements at that point in time. The following instruments are available:</p> <ul> <li><code>LongCounter</code>/<code>DoubleCounter</code>: records only positive values, with synchronous   and asynchronous options. Useful for counting things, such as the number of   bytes sent over a network. Counter measurements are aggregated to   always-increasing monotonic sums by default.</li> <li><code>LongUpDownCounter</code>/<code>DoubleUpDownCounter</code>: records positive and negative   values, with synchronous and asynchronous options. Useful for counting things   that go up and down, like the size of a queue. Up down counter measurements   are aggregated to non-monotonic sums by default.</li> <li><code>LongGauge</code>/<code>DoubleGauge</code>: measures an instantaneous value with an   asynchronous callback. Useful for recording values that can't be merged across   attributes, like CPU utilization percentage. Gauge measurements are aggregated   as gauges by default.</li> <li><code>LongHistogram</code>/<code>DoubleHistogram</code>: records measurements that are most useful   to analyze as a histogram distribution. No asynchronous option is available.   Useful for recording things like the duration of time spent by an HTTP server   processing a request. Histogram measurements are aggregated to explicit bucket   histograms by default.</li> </ul> <p>Note: The asynchronous varieties of counter and up down counter assume that the registered callback is observing the cumulative sum. For example, if you register an asynchronous counter whose callback records bytes sent over a network, it must record the cumulative sum of all bytes sent over the network, rather than trying to compute and record the difference since last call.</p> <p>All metrics can be annotated with attributes: additional qualifiers that help describe what subdivision of the measurements the metric represents.</p> <p>The following is an example of counter usage:</p> <pre><code>OpenTelemetry openTelemetry = // obtain instance of OpenTelemetry\n// Gets or creates a named meter instance\nMeter meter = openTelemetry.meterBuilder(\"instrumentation-library-name\")\n.setInstrumentationVersion(\"1.0.0\")\n.build();\n// Build counter e.g. LongCounter\nLongCounter counter = meter\n.counterBuilder(\"processed_jobs\")\n.setDescription(\"Processed jobs\")\n.setUnit(\"1\")\n.build();\n// It is recommended that the API user keep a reference to Attributes they will record against\nAttributes attributes = Attributes.of(stringKey(\"Key\"), \"SomeWork\");\n// Record data\ncounter.add(123, attributes);\n</code></pre> <p>The following is an example of usage of an asynchronous instrument:</p> <pre><code>// Build an asynchronous instrument, e.g. Gauge\nmeter\n.gaugeBuilder(\"cpu_usage\")\n.setDescription(\"CPU Usage\")\n.setUnit(\"ms\")\n.buildWithCallback(measurement -&gt; {\nmeasurement.record(getCpuUsage(), Attributes.of(stringKey(\"Key\"), \"SomeWork\"));\n});\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#logs","title":"Logs","text":"<p>Logs are distinct from Metrics and Tracing in that there is no user-facing logs API. Instead, there is tooling to bridge logs from existing popular log frameworks (e.g. SLF4j, JUL, Logback, Log4j) into the OpenTelemetry ecosystem.</p> <p>The two typical workflows discussed below each cater to different application requirements.</p>"},{"location":"docs/instrumentation/java/manual/#direct-to-collector","title":"Direct to collector","text":"<p>In the direct to collector workflow, logs are emitted directly from an application to a collector using a network protocol (e.g. OTLP). This workflow is simple to set up as it doesn't require any additional log forwarding components, and allows an application to easily emit structured logs that conform to the log data model. However, the overhead required for applications to queue and export logs to a network location may not be suitable for all applications.</p> <p>To use this workflow:</p> <ul> <li>Install appropriate Log Appender.</li> <li>Configure the OpenTelemetry Log SDK to export log records to   desired target destination (the collector or   other).</li> </ul>"},{"location":"docs/instrumentation/java/manual/#log-appenders","title":"Log appenders","text":"<p>A log appender bridges logs from a log framework into the OpenTelemetry Log SDK using the Logs Bridge API. Log appenders are available for various popular java log frameworks:</p> <ul> <li>Log4j2 Appender</li> <li>Logback Appender</li> </ul> <p>The links above contain full usage and installation documentation, but installation is generally as follows:</p> <ul> <li>Add required dependency via gradle or maven.</li> <li>Extend the application's log configuration (i.e. <code>logback.xml</code>, <code>log4j.xml</code>,   etc) to include a reference to the OpenTelemetry log appender.</li> <li>Optionally configure the log framework to determine which logs (i.e. filter     by severity or logger name) are passed to the appender.</li> <li>Optionally configure the appender to indicate how logs are mapped to     OpenTelemetry Log Records (i.e. capture thread information, context data,     markers, etc).</li> </ul> <p>Log appenders automatically include the trace context in log records, enabling log correlation with traces.</p> <p>The Log Appender example demonstrates setup for a variety of scenarios.</p>"},{"location":"docs/instrumentation/java/manual/#via-file-or-stdout","title":"Via file or stdout","text":"<p>In the file or stdout workflow, logs are written to files or standout output. Another component (e.g. FluentBit) is responsible for reading / tailing the logs, parsing them to more structured format, and forwarding them a target, such as the collector. This workflow may be preferable in situations where application requirements do not permit additional overhead from direct to collector. However, it requires that all log fields required down stream are encoded into the logs, and that the component reading the logs parse the data into the log data model. The installation and configuration of log forwarding components is outside the scope of this document.</p> <p>Log correlation with traces is available by installing log context instrumentation.</p>"},{"location":"docs/instrumentation/java/manual/#log-context-instrumentation","title":"Log context instrumentation","text":"<p>OpenTelemetry provides components which enrich log context with trace context for various popular java log frameworks:</p> <ul> <li>Log4j context data instrumentation</li> <li>Logback MDC instrumentation</li> </ul> <p>This links above contain full usage and installation documentation, but installation is generally as follows:</p> <ul> <li>Add required dependency via gradle or maven.</li> <li>Extend the application's log configuration (i.e. <code>logback.xml</code> or <code>log4j.xml</code>,   etc) to reference the trace context fields in the log pattern.</li> </ul>"},{"location":"docs/instrumentation/java/manual/#sdk-configuration","title":"SDK Configuration","text":"<p>The configuration examples reported in this document only apply to the SDK provided by <code>opentelemetry-sdk</code>. Other implementation of the API might provide different configuration mechanisms.</p>"},{"location":"docs/instrumentation/java/manual/#tracing-sdk","title":"Tracing SDK","text":"<p>The application has to install a span processor with an exporter and may customize the behavior of the OpenTelemetry SDK.</p> <p>For example, a basic configuration instantiates the SDK tracer provider and sets to export the traces to a logging stream.</p> <pre><code>SdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n.addSpanProcessor(BatchSpanProcessor.builder(LoggingSpanExporter.create()).build())\n.build();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#sampler","title":"Sampler","text":"<p>It is not always feasible to trace and export every user request in an application. In order to strike a balance between observability and expenses, traces can be sampled.</p> <p>The OpenTelemetry SDK offers four samplers out of the box:</p> <ul> <li>AlwaysOnSampler which samples every trace regardless of upstream sampling   decisions.</li> <li>AlwaysOffSampler which doesn't sample any trace, regardless of upstream   sampling decisions.</li> <li>ParentBased which uses the parent span to make sampling decisions, if   present.</li> <li>TraceIdRatioBased which samples a configurable percentage of traces, and   additionally samples any trace that was sampled upstream.</li> </ul> <p>Additional samplers can be provided by implementing the <code>io.opentelemetry.sdk.trace.Sampler</code> interface.</p> <pre><code>SdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n.setSampler(Sampler.alwaysOn())\n//or\n.setSampler(Sampler.alwaysOff())\n//or\n.setSampler(Sampler.traceIdRatioBased(0.5))\n.build();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#span-processor","title":"Span Processor","text":"<p>Different Span processors are offered by OpenTelemetry. The <code>SimpleSpanProcessor</code> immediately forwards ended spans to the exporter, while the <code>BatchSpanProcessor</code> batches them and sends them in bulk. Multiple Span processors can be configured to be active at the same time using the <code>MultiSpanProcessor</code>.</p> <pre><code>SdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n.addSpanProcessor(SimpleSpanProcessor.create(LoggingSpanExporter.create()))\n.addSpanProcessor(BatchSpanProcessor.builder(LoggingSpanExporter.create()).build())\n.build();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#exporter","title":"Exporter","text":"<p>Span processors are initialized with an exporter which is responsible for sending the telemetry data a particular backend. OpenTelemetry offers five exporters out of the box:</p> <ul> <li><code>InMemorySpanExporter</code>: keeps the data in memory, useful for testing and   debugging.</li> <li>Jaeger Exporter: prepares and sends the collected telemetry data to a Jaeger   backend via gRPC. Varieties include <code>JaegerGrpcSpanExporter</code> and   <code>JaegerThriftSpanExporter</code>.</li> <li><code>ZipkinSpanExporter</code>: prepares and sends the collected telemetry data to a   Zipkin backend via the Zipkin APIs.</li> <li>Logging Exporter: saves the telemetry data into log streams. Varieties include   <code>LoggingSpanExporter</code> and <code>OtlpJsonLoggingSpanExporter</code>.</li> <li>OpenTelemetry Protocol Exporter: sends the data in OTLP to the OpenTelemetry   Collector or other OTLP receivers. Varieties include <code>OtlpGrpcSpanExporter</code>   and <code>OtlpHttpSpanExporter</code>.</li> </ul> <p>Other exporters can be found in the OpenTelemetry Registry.</p> <pre><code>ManagedChannel jaegerChannel = ManagedChannelBuilder.forAddress(\"localhost\", 3336)\n.usePlaintext()\n.build();\nJaegerGrpcSpanExporter jaegerExporter = JaegerGrpcSpanExporter.builder()\n.setEndpoint(\"localhost:3336\")\n.setTimeout(30, TimeUnit.SECONDS)\n.build();\nSdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n.addSpanProcessor(BatchSpanProcessor.builder(jaegerExporter).build())\n.build();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#metrics-sdk","title":"Metrics SDK","text":"<p>The application has to install a metric reader with an exporter, and may further customize the behavior of the OpenTelemetry SDK.</p> <p>For example, a basic configuration instantiates the SDK meter provider and sets to export the metrics to a logging stream.</p> <pre><code>SdkMeterProvider meterProvider = SdkMeterProvider.builder()\n.registerMetricReader(PeriodicMetricReader.builder(LoggingMetricExporter.create()).build())\n.build();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#metric-reader","title":"Metric Reader","text":"<p>Metric readers read aggregated metrics.</p> <pre><code>SdkMeterProvider meterProvider = SdkMeterProvider.builder()\n.registerMetricReader(...)\n.build();\n</code></pre> <p>OpenTelemetry provides a variety of metric readers out of the box:</p> <ul> <li><code>PeriodicMetricReader</code>: reads metrics on a configurable interval and pushes to   a <code>MetricExporter</code>.</li> <li><code>InMemoryMetricReader</code>: reads metrics into memory, useful for debugging and   testing.</li> <li><code>PrometheusHttpServer</code> (alpha): an HTTP server that reads metrics and   serializes to Prometheus text format.</li> </ul> <p>Custom metric reader implementations are not currently supported.</p>"},{"location":"docs/instrumentation/java/manual/#exporter_1","title":"Exporter","text":"<p>The <code>PeriodicMetricReader</code> is paired with a metric exporter, which is responsible for sending the telemetry data to a particular backend. OpenTelemetry provides the following exporters out of the box:</p> <ul> <li><code>InMemoryMetricExporter</code>: keeps the data in memory, useful for testing and   debugging.</li> <li>Logging Exporter: saves the telemetry data into log streams. Varieties include   <code>LoggingMetricExporter</code> and <code>OtlpJsonLoggingMetricExporter</code>.</li> <li>OpenTelemetry Protocol Exporter: sends the data in OTLP to the OpenTelemetry   Collector or other OTLP receivers. Varieties include <code>OtlpGrpcMetricExporter</code>   and <code>OtlpHttpMetricExporter</code>.</li> </ul> <p>Other exporters can be found in the OpenTelemetry Registry.</p>"},{"location":"docs/instrumentation/java/manual/#views","title":"Views","text":"<p>Views provide a mechanism for controlling how measurements are aggregated into metrics. They consist of an <code>InstrumentSelector</code> and a <code>View</code>. The instrument selector consists of a series of options for selecting which instruments the view applies to. Instruments can be selected by a combination of name, type, meter name, meter version, and meter schema url. The view describes how measurement should be aggregated. The view can change the name, description, the aggregation, and define the set of attribute keys that should be retained.</p> <pre><code>SdkMeterProvider meterProvider = SdkMeterProvider.builder()\n.registerView(\nInstrumentSelector.builder()\n.setName(\"my-counter\") // Select instrument(s) called \"my-counter\"\n.build(),\nView.builder()\n.setName(\"new-counter-name\") // Change the name to \"new-counter-name\"\n.build())\n.registerMetricReader(...)\n.build()\n</code></pre> <p>Every instrument has a default view, which retains the original name, description, and attributes, and has a default aggregation that is based on the type of instrument. When a registered view matches an instrument, the default view is replaced by the registered view. Additional registered views that match the instrument are additive, and result in multiple exported metrics for the instrument.</p>"},{"location":"docs/instrumentation/java/manual/#logs-sdk","title":"Logs SDK","text":"<p>The logs SDK dictates how logs are processed when using the direct to collector workflow. No log SDK is needed when using the log forwarding workflow.</p> <p>The typical log SDK configuration installs a log record processor and exporter. For example, the following installs the BatchLogRecordProcessor, which periodically exports to a network location via the OtlpGrpcLogRecordExporter:</p> <pre><code>SdkLoggerProvider loggerProvider = SdkLoggerProvider.builder()\n.addLogRecordProcessor(\nBatchLogRecordProcessor.builder(\nOtlpGrpcLogRecordExporter.builder()\n.setEndpoint(\"http://localhost:4317\")\n.build())\n.build())\n.build();\n</code></pre> <p>See releases for log specific artifact coordinates.</p>"},{"location":"docs/instrumentation/java/manual/#logrecord-processor","title":"LogRecord Processor","text":"<p>LogRecord processors process LogRecords emitted by log appenders.</p> <p>OpenTelemetry provides the following LogRecord processors out of the box:</p> <ul> <li><code>BatchLogRecordProcessor</code>: periodically sends batches of LogRecords to a   LogRecordExporter.</li> <li><code>SimpleLogRecordProcessor</code>: immediately sends each LogRecord to a   LogRecordExporter.</li> </ul> <p>Custom LogRecord processors are supported by implementing the <code>LogRecordProcessor</code> interface. Common use cases include enriching the LogRecords with contextual data like baggage, or filtering / obfuscating sensitive data.</p>"},{"location":"docs/instrumentation/java/manual/#logrecord-exporter","title":"LogRecord Exporter","text":"<p><code>BatchLogRecordProcessor</code> and <code>SimpleLogRecordProcessor</code> are paired with <code>LogRecordExporter</code>, which is responsible for sending telemetry data to a particular backend. OpenTelemetry provides the following exporters out of the box:</p> <ul> <li>OpenTelemetry Protocol Exporter: sends the data in OTLP to the OpenTelemetry   Collector or other OTLP receivers. Varieties include   <code>OtlpGrpcLogRecordExporter</code> and <code>OtlpHttpLogRecordExporter</code>.</li> <li><code>InMemoryLogRecordExporter</code>: keeps the data in memory, useful for testing and   debugging.</li> <li>Logging Exporter: saves the telemetry data into log streams. Varieties include   <code>SystemOutLogRecordExporter</code> and <code>OtlpJsonLoggingLogRecordExporter</code>. Note:   <code>OtlpJsonLoggingLogRecordExporter</code> logs to JUL, and may cause infinite loops   (i.e. JUL -&gt; SLF4J -&gt; Logback -&gt; OpenTelemetry Appender -&gt; OpenTelemetry Log   SDK -&gt; JUL) if not carefully configured.</li> </ul> <p>Custom exporters are supported by implementing the <code>LogRecordExporter</code> interface.</p>"},{"location":"docs/instrumentation/java/manual/#auto-configuration","title":"Auto Configuration","text":"<p>Instead of manually creating the <code>OpenTelemetry</code> instance by using the SDK builders directly from your code, it is also possible to use the SDK auto-configuration extension through the <code>opentelemetry-sdk-extension-autoconfigure</code> module.</p> <p>This module is made available by adding the following dependency to your application.</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-sdk-extension-autoconfigure&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>It allows you to auto-configure the OpenTelemetry SDK based on a standard set of supported environment variables and system properties. Each environment variable has a corresponding system property named the same way but as lower case and using the <code>.</code> (dot) character instead of the <code>_</code> (underscore) as separator.</p> <p>The logical service name can be specified via the <code>OTEL_SERVICE_NAME</code> environment variable (or <code>otel.service.name</code> system property).</p> <p>The traces, metrics or logs exporters can be set via the <code>OTEL_TRACES_EXPORTER</code>, <code>OTEL_METRICS_EXPORTER</code> and <code>OTEL_LOGS_EXPORTER</code> environment variables. For example <code>OTEL_TRACES_EXPORTER=jaeger</code> configures your application to use the Jaeger exporter. The corresponding Jaeger exporter library has to be provided in the classpath of the application as well.</p> <p>It's also possible to set up the propagators via the <code>OTEL_PROPAGATORS</code> environment variable, like for example using the <code>tracecontext</code> value to use W3C Trace Context.</p> <p>For more details, see all the supported configuration options in the module's README.</p> <p>The SDK auto-configuration has to be initialized from your code in order to allow the module to go through the provided environment variables (or system properties) and set up the <code>OpenTelemetry</code> instance by using the builders internally.</p> <pre><code>OpenTelemetrySdk sdk = AutoConfiguredOpenTelemetrySdk.initialize()\n.getOpenTelemetrySdk();\n</code></pre> <p>When environment variables or system properties are not sufficient, you can use some extension points provided through the auto-configure SPI and several methods in the <code>AutoConfiguredOpenTelemetrySdk</code> class.</p> <p>Following an example with a code snippet for adding an additional custom span processor.</p> <pre><code>AutoConfiguredOpenTelemetrySdk.builder()\n.addTracerProviderCustomizer(\n(sdkTracerProviderBuilder, configProperties) -&gt;\nsdkTracerProviderBuilder.addSpanProcessor(\nnew SpanProcessor() { /* implementation omitted for brevity */ }))\n.build();\n</code></pre>"},{"location":"docs/instrumentation/java/manual/#sdk-logging-and-error-handling","title":"SDK Logging and Error Handling","text":"<p>OpenTelemetry uses java.util.logging to log information about OpenTelemetry, including errors and warnings about misconfigurations or failures exporting data.</p> <p>By default, log messages are handled by the root handler in your application. If you have not installed a custom root handler for your application, logs of level <code>INFO</code> or higher are sent to the console by default.</p> <p>You may want to change the behavior of the logger for OpenTelemetry. For example, you can reduce the logging level to output additional information when debugging, increase the level for a particular class to ignore errors coming from that class, or install a custom handler or filter to run custom code whenever OpenTelemetry logs a particular message.</p>"},{"location":"docs/instrumentation/java/manual/#examples","title":"Examples","text":"<pre><code>## Turn off all OpenTelemetry logging\nio.opentelemetry.level = OFF\n</code></pre> <pre><code>## Turn off logging for just the BatchSpanProcessor\nio.opentelemetry.sdk.trace.export.BatchSpanProcessor.level = OFF\n</code></pre> <pre><code>## Log \"FINE\" messages for help in debugging\nio.opentelemetry.level = FINE\n## Sets the default ConsoleHandler's logger's level\n## Note this impacts the logging outside of OpenTelemetry as well\njava.util.logging.ConsoleHandler.level = FINE\n</code></pre> <p>For more fine-grained control and special case handling, custom handlers and filters can be specified with code.</p> <pre><code>// Custom filter which does not log errors that come from the export\npublic class IgnoreExportErrorsFilter implements Filter {\npublic boolean isLoggable(LogRecord record) {\nreturn !record.getMessage().contains(\"Exception thrown by the export\");\n}\n}\n</code></pre> <pre><code>## Registering the custom filter on the BatchSpanProcessor\nio.opentelemetry.sdk.trace.export.BatchSpanProcessor = io.opentelemetry.extension.logging.IgnoreExportErrorsFilter\n</code></pre>"},{"location":"docs/instrumentation/java/automatic/_index/","title":"Automatic Instrumentation","text":"<p>Automatic instrumentation with Java uses a Java agent JAR that can be attached to any Java 8+ application. It dynamically injects bytecode to capture telemetry from many popular libraries and frameworks. It can be used to capture telemetry data at the \"edges\" of an app or service, such as inbound requests, outbound HTTP calls, database calls, and so on. To learn how to manually instrument your service or app code, see Manual instrumentation.</p>"},{"location":"docs/instrumentation/java/automatic/_index/#setup","title":"Setup","text":"<ol> <li>Download opentelemetry-javaagent.jar from Releases of the     <code>opentelemetry-java-instrumentation</code> repo and place the JAR in your     preferred directory. The JAR file contains the agent and instrumentation     libraries.</li> <li> <p>Add <code>-javaagent:path/to/opentelemetry-javaagent.jar</code> and other config to     your JVM startup arguments and launch your app:</p> <ul> <li>Directly on the startup command:</li> </ul> <pre><code>java -javaagent:path/to/opentelemetry-javaagent.jar -Dotel.service.name=your-service-name -jar myapp.jar\n</code></pre> <ul> <li>Via the <code>JAVA_TOOL_OPTIONS</code> and other environment variables:</li> </ul> <pre><code>export JAVA_TOOL_OPTIONS=\"-javaagent:path/to/opentelemetry-javaagent.jar\"\nexport OTEL_SERVICE_NAME=\"your-service-name\"\njava -jar myapp.jar\n</code></pre> </li> </ol>"},{"location":"docs/instrumentation/java/automatic/_index/#configuring-the-agent","title":"Configuring the agent","text":"<p>The agent is highly configurable.</p> <p>One option is to pass configuration properties via the <code>-D</code> flag. In this example, a service name and Zipkin exporter for traces are configured:</p> <pre><code>java -javaagent:path/to/opentelemetry-javaagent.jar \\\n-Dotel.service.name=your-service-name \\\n-Dotel.traces.exporter=zipkin \\\n-jar myapp.jar\n</code></pre> <p>You can also use environment variables to configure the agent:</p> <pre><code>OTEL_SERVICE_NAME=your-service-name \\\nOTEL_TRACES_EXPORTER=zipkin \\\njava -javaagent:path/to/opentelemetry-javaagent.jar \\\n-jar myapp.jar\n</code></pre> <p>You can also supply a Java properties file and load configuration values from there:</p> <pre><code>java -javaagent:path/to/opentelemetry-javaagent.jar \\\n-Dotel.javaagent.configuration-file=path/to/properties/file.properties \\\n-jar myapp.jar\n</code></pre> <p>or</p> <pre><code>OTEL_JAVAAGENT_CONFIGURATION_FILE=path/to/properties/file.properties \\\njava -javaagent:path/to/opentelemetry-javaagent.jar \\\n-jar myapp.jar\n</code></pre> <p>To see the full range of configuration options, see Agent Configuration.</p>"},{"location":"docs/instrumentation/java/automatic/_index/#supported-libraries-frameworks-application-services-and-jvms","title":"Supported libraries, frameworks, application services, and JVMs","text":"<p>The Java agent ships with instrumentation libraries for many popular components. For the full list, see Supported libraries, frameworks, application services, and JVMs.</p>"},{"location":"docs/instrumentation/java/automatic/_index/#troubleshooting","title":"Troubleshooting","text":"<p>You can pass the <code>-Dotel.javaagent.debug=true</code> parameter to the agent to see debug logs. Note that these are quite verbose.</p>"},{"location":"docs/instrumentation/java/automatic/_index/#next-steps","title":"Next steps","text":"<p>After you have automatic instrumentation configured for your app or service, you might want to annotate selected methods or add manual instrumentation to collect custom telemetry data.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/","title":"Agent Configuration","text":""},{"location":"docs/instrumentation/java/automatic/agent-config/#sdk-autoconfiguration","title":"SDK Autoconfiguration","text":"<p>The SDK's autoconfiguration module is used for basic configuration of the agent. Read the docs to find settings such as configuring export or sampling.</p> <p>Here are some quick links into those docs for the configuration options for specific portions of the SDK &amp; agent:</p> <ul> <li>Exporters</li> <li>OTLP exporter (both span and metric exporters)</li> <li>Jaeger exporter</li> <li>Zipkin exporter</li> <li>Prometheus exporter</li> <li>Logging exporter</li> <li>Trace context propagation</li> <li>OpenTelemetry Resource and service name</li> <li>Batch span processor</li> <li>Sampler</li> <li>Span limits</li> <li>Using SPI to further configure the SDK</li> </ul>"},{"location":"docs/instrumentation/java/automatic/agent-config/#configuring-the-agent","title":"Configuring the agent","text":"<p>The agent can consume configuration from one or more of the following sources (ordered from highest to lowest priority):</p> <ul> <li>system properties</li> <li>environment variables</li> <li>the configuration file</li> <li>properties provided by the   <code>AutoConfigurationCustomizer#addPropertiesSupplier()</code>   function; using the   <code>AutoConfigurationCustomizerProvider</code>   SPI</li> </ul>"},{"location":"docs/instrumentation/java/automatic/agent-config/#configuring-with-environment-variables","title":"Configuring with Environment Variables","text":"<p>In some environments, configuring via Environment Variables is more preferred. Any setting configurable with a System Property can also be configured with an Environment Variable. Many settings below include both options, but where they don't apply the following steps to determine the correct name mapping of the desired System Property:</p> <ul> <li>Convert the System Property to uppercase.</li> <li>Replace all <code>.</code> and <code>-</code> characters with <code>_</code>.</li> </ul> <p>For example <code>otel.instrumentation.common.default-enabled</code> would convert to <code>OTEL_INSTRUMENTATION_COMMON_DEFAULT_ENABLED</code>.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#configuration-file","title":"Configuration file","text":"<p>You can provide a path to agent configuration file by setting the following property:</p> <p>{{% config_option name=\"otel.javaagent.configuration-file\" %}} Path to valid Java properties file which contains the agent configuration. {{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#extensions","title":"Extensions","text":"<p>You can enable extensions by setting the following property:</p> <p>{{% config_option name=\"otel.javaagent.extensions\" %}}</p> <p>Path to an extension jar file or folder, containing jar files. If pointing to a folder, every jar file in that folder will be treated as separate, independent extension.</p> <p>{{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#javaagent-logging-output","title":"Javaagent logging output","text":"<p>The agent's logging output can be configured by setting the following property:</p> <p>{{% config_option name=\"otel.javaagent.logging\" %}}</p> <p>The javaagent logging mode. The following 3 modes are supported:</p> <ul> <li><code>simple</code>: The agent will print out its logs using the standard error stream.   Only <code>INFO</code> or higher logs will be printed. This is the default javaagent   logging mode.</li> <li><code>none</code>: The agent will not log anything - not even its own version.</li> <li><code>application</code>: The agent will attempt to redirect its own logs to the   instrumented application's slf4j logger. This works the best for simple   one-jar applications that do not use multiple classloaders; Spring Boot apps   are supported as well. The javaagent output logs can be further configured   using the instrumented application's logging configuration (e.g. <code>logback.xml</code>   or <code>log4j2.xml</code>). Make sure to test that this mode works for your   application before running it in a production environment.</li> </ul> <p>{{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#common-instrumentation-configuration","title":"Common instrumentation configuration","text":"<p>Common settings that apply to multiple instrumentations at once.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#peer-service-name","title":"Peer service name","text":"<p>The peer service name is the name of a remote service to which a connection is made. It corresponds to <code>service.name</code> in the resource for the local service.</p> <p>{{% config_option name=\"otel.instrumentation.common.peer-service-mapping\" %}}</p> <p>Used to specify a mapping from host names or IP addresses to peer services, as a comma-separated list of <code>&lt;host_or_ip&gt;=&lt;user_assigned_name&gt;</code> pairs. The peer service is added as an attribute to a span whose host or IP address match the mapping.</p> <p>For example, if set to the following:</p> <pre><code>1.2.3.4=cats-service,dogs-abcdef123.serverlessapis.com=dogs-api\n</code></pre> <p>Then, requests to <code>1.2.3.4</code> will have a <code>peer.service</code> attribute of <code>cats-service</code> and requests to <code>dogs-abcdef123.serverlessapis.com</code> will have an attribute of <code>dogs-api</code>.</p> <p>{{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#db-statement-sanitization","title":"DB statement sanitization","text":"<p>The agent sanitizes all database queries/statements before setting the <code>db.statement</code> semantic attribute. All values (strings, numbers) in the query string are replaced with a question mark (<code>?</code>).</p> <p>Note: JDBC bind parameters are not captured in <code>db.statement</code>. See the corresponding issue if you are looking to capture bind parameters.</p> <p>Examples:</p> <ul> <li>SQL query <code>SELECT a from b where password=\"secret\"</code> will appear as   <code>SELECT a from b where password=?</code> in the exported span;</li> <li>Redis command <code>HSET map password \"secret\"</code> will appear as   <code>HSET map password ?</code> in the exported span.</li> </ul> <p>This behavior is turned on by default for all database instrumentations. Use the following property to disable it:</p> <p>{{% config_option   name=\"otel.instrumentation.common.db-statement-sanitizer.enabled\"   default=true %}} Enables the DB statement sanitization. {{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#capturing-http-request-and-response-headers","title":"Capturing HTTP request and response headers","text":"<p>You can configure the agent to capture predefined HTTP headers as span attributes, according to the semantic convention. Use the following properties to define which HTTP headers you want to capture:</p> <p>{{% config_option name=\"otel.instrumentation.http.capture-headers.client.request\" %}} A comma-separated list of HTTP header names. HTTP client instrumentations will capture HTTP request header values for all configured header names. {{% /config_option %}}</p> <p>{{% config_option name=\"otel.instrumentation.http.capture-headers.client.response\" %}} A comma-separated list of HTTP header names. HTTP client instrumentations will capture HTTP response header values for all configured header names. {{% /config_option %}}</p> <p>{{% config_option name=\"otel.instrumentation.http.capture-headers.server.request\" %}} A comma-separated list of HTTP header names. HTTP server instrumentations will capture HTTP request header values for all configured header names. {{% /config_option %}}</p> <p>{{% config_option name=\"otel.instrumentation.http.capture-headers.server.response\" %}} A comma-separated list of HTTP header names. HTTP server instrumentations will capture HTTP response header values for all configured header names. {{% /config_option %}}</p> <p>These configuration options are supported by all HTTP client and server instrumentations.</p> <p>Note: The property/environment variable names listed in the table are still experimental, and thus are subject to change.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#capturing-servlet-request-parameters","title":"Capturing servlet request parameters","text":"<p>You can configure the agent to capture predefined HTTP request parameter as span attributes for requests that are handled by Servlet API. Use the following property to define which servlet request parameters you want to capture:</p> <p>{{% config_option name=\"otel.instrumentation.servlet.experimental.capture-request-parameters\" %}} A comma-separated list of request parameter names. {{% /config_option %}}</p> <p>Note: The property/environment variable names listed in the table are still experimental, and thus are subject to change.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#capturing-consumer-message-receive-telemetry-in-messaging-instrumentations","title":"Capturing consumer message receive telemetry in messaging instrumentations","text":"<p>You can configure the agent to capture the consumer message receive telemetry in messaging instrumentation. Use the following property to enable it:</p> <p>{{% config_option   name=\"otel.instrumentation.messaging.experimental.receive-telemetry.enabled\"   default=false %}} Enables the consumer message receive telemetry. {{% /config_option %}}</p> <p>Note that this will cause the consumer side to start a new trace, with only a span link connecting it to the producer trace.</p> <p>Note: The property/environment variable names listed in the table are still experimental, and thus are subject to change.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#suppressing-specific-auto-instrumentation","title":"Suppressing specific auto-instrumentation","text":""},{"location":"docs/instrumentation/java/automatic/agent-config/#disabling-the-agent-entirely","title":"Disabling the agent entirely","text":"<p>You can disable the agent using <code>-Dotel.javaagent.enabled=false</code> (or using the equivalent environment variable <code>OTEL_JAVAAGENT_ENABLED=false</code>).</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#enable-only-specific-instrumentation","title":"Enable only specific instrumentation","text":"<p>You can disable all default auto instrumentation and selectively re-enable individual instrumentation. This may be desirable to reduce startup overhead or to have more control of which instrumentation is applied.</p> <ul> <li>Disable all instrumentation in the agent using   <code>-Dotel.instrumentation.common.default-enabled=false</code> (or using the equivalent   environment variable <code>OTEL_INSTRUMENTATION_COMMON_DEFAULT_ENABLED=false</code>).</li> <li>Enable each desired instrumentation individually using   <code>-Dotel.instrumentation.[name].enabled=true</code> (or using the equivalent   environment variable <code>OTEL_INSTRUMENTATION_[NAME]_ENABLED</code>) where <code>[name]</code>   (<code>[NAME]</code>) is the corresponding instrumentation <code>name</code> below.</li> </ul> <p>Note: Some instrumentation relies on other instrumentation to function properly. When selectively enabling instrumentation, be sure to enable the transitive dependencies too. Determining this dependency relationship is left as an exercise to the user.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#enable-manual-instrumentation-only","title":"Enable manual instrumentation only","text":"<p>You can suppress all auto instrumentations but have support for manual instrumentation with <code>@WithSpan</code> and normal API interactions by using <code>-Dotel.instrumentation.common.default-enabled=false -Dotel.instrumentation.opentelemetry-api.enabled=true -Dotel.instrumentation.opentelemetry-instrumentation-annotations.enabled=true</code></p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#suppressing-specific-agent-instrumentation","title":"Suppressing specific agent instrumentation","text":"<p>You can suppress agent instrumentation of specific libraries by using <code>-Dotel.instrumentation.[name].enabled=false</code> (or using the equivalent environment variable <code>OTEL_INSTRUMENTATION_[NAME]_ENABLED</code>) where <code>name</code> (<code>NAME</code>) is the corresponding instrumentation <code>name</code>:</p> Library/Framework Instrumentation name Additional methods tracing <code>methods</code> Additional tracing annotations <code>external-annotations</code> Akka Actor <code>akka-actor</code> Akka HTTP <code>akka-http</code> Apache Axis2 <code>axis2</code> Apache Camel <code>camel</code> Apache Cassandra <code>cassandra</code> Apache CXF <code>cxf</code> Apache DBCP <code>apache-dbcp</code> Apache Dubbo <code>apache-dubbo</code> Apache Geode <code>geode</code> Apache HttpAsyncClient <code>apache-httpasyncclient</code> Apache HttpClient <code>apache-httpclient</code> Apache Kafka <code>kafka</code> Apache MyFaces <code>jsf-myfaces</code> Apache Pulsar <code>pulsar</code> Apache RocketMQ <code>rocketmq-client</code> Apache Struts 2 <code>struts</code> Apache Tapestry <code>tapestry</code> Apache Tomcat <code>tomcat</code> Apache Wicket <code>wicket</code> Armeria <code>armeria</code> AsyncHttpClient (AHC) <code>async-http-client</code> AWS Lambda <code>aws-lambda</code> AWS SDK <code>aws-sdk</code> Azure SDK <code>azure-core</code> Couchbase <code>couchbase</code> C3P0 <code>c3p0</code> Dropwizard Views <code>dropwizard-views</code> Dropwizard Metrics <code>dropwizard-metrics</code> Eclipse Grizzly <code>grizzly</code> Eclipse Jersey <code>jersey</code> Eclipse Jetty <code>jetty</code> Eclipse Jetty HTTP Client <code>jetty-httpclient</code> Eclipse Metro <code>metro</code> Eclipse Mojarra <code>jsf-mojarra</code> Eclipse Vert.x HttpClient <code>vertx-http-client</code> Eclipse Vert.x Kafka Client <code>vertx-kafka-client</code> Eclipse Vert.x RxJava <code>vertx-rx-java</code> Eclipse Vert.x Web <code>vertx-web</code> Elasticsearch client <code>elasticsearch-transport</code> Elasticsearch REST client <code>elasticsearch-rest</code> Google Guava <code>guava</code> Google HTTP client <code>google-http-client</code> Google Web Toolkit <code>gwt</code> Grails <code>grails</code> GraphQL Java <code>graphql-java</code> GRPC <code>grpc</code> Hibernate <code>hibernate</code> HikariCP <code>hikaricp</code> Java HTTP Client <code>java-http-client</code> Java <code>HttpURLConnection</code> <code>http-url-connection</code> Java JDBC <code>jdbc</code> Java JDBC <code>DataSource</code> <code>jdbc-datasource</code> Java RMI <code>rmi</code> Java Runtime <code>runtime-metrics</code> Java Servlet <code>servlet</code> java.util.concurrent <code>executors</code> java.util.logging <code>java-util-logging</code> JAX-RS (Client) <code>jaxrs-client</code> JAX-RS (Server) <code>jaxrs</code> JAX-WS <code>jaxws</code> JBoss Logging Appender <code>jboss-logmanager-appender</code> JBoss Logging MDC <code>jboss-logmanager-mdc</code> JMS <code>jms</code> Jodd HTTP <code>jodd-http</code> JSP <code>jsp</code> K8s Client <code>kubernetes-client</code> kotlinx.coroutines <code>kotlinx-coroutines</code> Log4j Appender <code>log4j-appender</code> Log4j MDC (1.x) <code>log4j-mdc</code> Log4j Context Data (2.x) <code>log4j-context-data</code> Logback Appender <code>logback-appender</code> Logback MDC <code>logback-mdc</code> Micrometer <code>micrometer</code> MongoDB <code>mongo</code> Netflix Hystrix <code>hystrix</code> Netty <code>netty</code> OkHttp <code>okhttp</code> OpenLiberty <code>liberty</code> OpenTelemetry Extension Annotations <code>opentelemetry-extension-annotations</code> OpenTelemetry Instrumentation Annotations <code>opentelemetry-instrumentation-annotations</code> OpenTelemetry API <code>opentelemetry-api</code> Oracle UCP <code>oracle-ucp</code> OSHI (Operating System and Hardware Information) <code>oshi</code> Play Framework <code>play</code> Play WS HTTP Client <code>play-ws</code> Quartz <code>quartz</code> R2DBC <code>r2dbc</code> RabbitMQ Client <code>rabbitmq</code> Ratpack <code>ratpack</code> ReactiveX RxJava <code>rxjava</code> Reactor <code>reactor</code> Reactor Netty <code>reactor-netty</code> Redis Jedis <code>jedis</code> Redis Lettuce <code>lettuce</code> Rediscala <code>rediscala</code> Redisson <code>redisson</code> Restlet <code>restlet</code> Scala ForkJoinPool <code>scala-fork-join</code> Spark Web Framework <code>spark</code> Spring Batch <code>spring-batch</code> Spring Core <code>spring-core</code> Spring Data <code>spring-data</code> Spring JMS <code>spring-jms</code> Spring Integration <code>spring-integration</code> Spring Kafka <code>spring-kafka</code> Spring RabbitMQ <code>spring-rabbit</code> Spring RMI <code>spring-rmi</code> Spring Scheduling <code>spring-scheduling</code> Spring Web <code>spring-web</code> Spring WebFlux <code>spring-webflux</code> Spring Web MVC <code>spring-webmvc</code> Spring Web Services <code>spring-ws</code> Spymemcached <code>spymemcached</code> Tomcat JDBC <code>tomcat-jdbc</code> Twilio SDK <code>twilio</code> Twitter Finatra <code>finatra</code> Undertow <code>undertow</code> Vaadin <code>vaadin</code> Vibur DBCP <code>vibur-dbcp</code> ZIO <code>zio</code> <p>Note: When using environment variables, dashes (<code>-</code>) should be converted to underscores (<code>_</code>). For example, to suppress traces from <code>akka-actor</code> library, set <code>OTEL_INSTRUMENTATION_AKKA_ACTOR_ENABLED</code> to <code>false</code>.</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#suppressing-controller-andor-view-spans","title":"Suppressing controller and/or view spans","text":"<p>Some instrumentations (e.g. Spring Web MVC instrumentation) produce SpanKind.Internal spans to capture the controller and/or view execution. These spans can be suppressed using the configuration settings below, without suppressing the entire instrumentation which would also disable the instrumentation's capturing of <code>http.route</code> and associated span name on the parent SpanKind.Server span.</p> <p>{{% config_option   name=\"otel.instrumentation.common.experimental.controller-telemetry.enabled\"   default=true %}} Enables the controller telemetry. {{% /config_option %}}</p> <p>{{% config_option   name=\"otel.instrumentation.common.experimental.view-telemetry.enabled\"   default=true %}} Enables the view telemetry. {{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/agent-config/#instrumentation-span-suppression-behavior","title":"Instrumentation span suppression behavior","text":"<p>Some libraries that this agent instruments in turn use lower-level libraries, that are also instrumented. This would normally result in nested spans containing duplicate telemetry data. For example:</p> <ul> <li>Spans produced by the Reactor Netty HTTP client instrumentation would have   duplicate HTTP client spans produced by the Netty instrumentation;</li> <li>Dynamo DB spans produced by the AWS SDK instrumentation would have children   HTTP client spans produced by its internal HTTP client library (which is also   instrumented);</li> <li>Spans produced by the Tomcat instrumentation would have duplicate HTTP server   spans produced by the generic Servlet API instrumentation.</li> </ul> <p>The javaagent prevents these situations by detecting and suppressing nested spans that duplicate telemetry data. The suppression behavior can be configured using the following configuration option:</p> <p>{{% config_option name=\"otel.instrumentation.experimental.span-suppression-strategy\" %}}</p> <p>The javaagent span suppression strategy. The following 3 strategies are supported:</p> <ul> <li><code>semconv</code>: The agent will suppress duplicate semantic conventions. This is the   default behavior of the javaagent.</li> <li><code>span-kind</code>: The agent will suppress spans with the same kind (except   <code>INTERNAL</code>).</li> <li><code>none</code>: The agent will not suppress anything at all. We do not recommend   using this option for anything other than debug purposes, as it generates lots   of duplicate telemetry data.</li> </ul> <p>{{% /config_option %}}</p> <p>For example, suppose we instrument a database client which internally uses the Reactor Netty HTTP client; which in turn uses Netty.</p> <p>Using the default <code>semconv</code> suppression strategy would result in 2 nested <code>CLIENT</code> spans:</p> <ul> <li><code>CLIENT</code> span with database client semantic attributes emitted by the database   client instrumentation;</li> <li><code>CLIENT</code> span with HTTP client semantic attributes emitted by the Reactor   Netty instrumentation.</li> </ul> <p>The Netty instrumentation would be suppressed, as it duplicates the Reactor Netty HTTP client instrumentation.</p> <p>Using the suppression strategy <code>span-kind</code> would result in just one span:</p> <ul> <li><code>CLIENT</code> span with database client semantic attributes emitted by the database   client instrumentation.</li> </ul> <p>Both Reactor Netty and Netty instrumentations would be suppressed, as they also emit <code>CLIENT</code> spans.</p> <p>Finally, using the suppression strategy <code>none</code> would result in 3 spans:</p> <ul> <li><code>CLIENT</code> span with database client semantic attributes emitted by the database   client instrumentation;</li> <li><code>CLIENT</code> span with HTTP client semantic attributes emitted by the Reactor   Netty instrumentation;</li> <li><code>CLIENT</code> span with HTTP client semantic attributes emitted by the Netty   instrumentation.</li> </ul>"},{"location":"docs/instrumentation/java/automatic/annotations/","title":"Annotations","text":"<p>For most users, the out-of-the-box instrumentation is completely sufficient and nothing more has to be done. Sometimes, however, users wish to create spans for their own custom code without doing too much code change.</p>"},{"location":"docs/instrumentation/java/automatic/annotations/#dependencies","title":"Dependencies","text":"<p>You'll need to add a dependency on the <code>opentelemetry-instrumentation-annotations</code> library to use the <code>@WithSpan</code> annotation.</p>"},{"location":"docs/instrumentation/java/automatic/annotations/#maven","title":"Maven","text":"<pre><code>&lt;dependencies&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;io.opentelemetry.instrumentation&lt;/groupId&gt;\n&lt;artifactId&gt;opentelemetry-instrumentation-annotations&lt;/artifactId&gt;\n&lt;version&gt;{{% param javaInstrumentationVersion %}}&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>"},{"location":"docs/instrumentation/java/automatic/annotations/#gradle","title":"Gradle","text":"<pre><code>dependencies {\nimplementation('io.opentelemetry.instrumentation:opentelemetry-instrumentation-annotations:{{% param javaInstrumentationVersion %}}')\n}\n</code></pre>"},{"location":"docs/instrumentation/java/automatic/annotations/#creating-spans-around-methods-with-withspan","title":"Creating spans around methods with <code>@WithSpan</code>","text":"<p>To create a span corresponding to one of your method, annotate the method with <code>@WithSpan</code>.</p> <pre><code>import io.opentelemetry.instrumentation.annotations.WithSpan;\npublic class MyClass {\n@WithSpan\npublic void myMethod() {\n&lt;...&gt;\n}\n}\n</code></pre> <p>Each time the application invokes the annotated method, it creates a span that denotes its duration and provides any thrown exceptions. By default, the span name will be <code>&lt;className&gt;.&lt;methodName&gt;</code>, unless a name is provided as an argument to the annotation.</p> <p>If the return type of the method annotated by <code>@WithSpan</code> is one of the future- or promise-like types listed below, then the span will not be ended until the future completes.</p> <ul> <li>java.util.concurrent.CompletableFuture</li> <li>java.util.concurrent.CompletionStage</li> <li>com.google.common.util.concurrent.ListenableFuture</li> <li>org.reactivestreams.Publisher</li> <li>reactor.core.publisher.Mono</li> <li>reactor.core.publisher.Flux</li> <li>io.reactivex.Completable</li> <li>io.reactivex.Maybe</li> <li>io.reactivex.Single</li> <li>io.reactivex.Observable</li> <li>io.reactivex.Flowable</li> <li>io.reactivex.parallel.ParallelFlowable</li> </ul>"},{"location":"docs/instrumentation/java/automatic/annotations/#adding-attributes-to-the-span-with-spanattribute","title":"Adding attributes to the span with <code>@SpanAttribute</code>","text":"<p>When a span is created for an annotated method the values of the arguments to the method invocation can be automatically added as attributes to the created span by annotating the method parameters with the <code>@SpanAttribute</code> annotation.</p> <pre><code>import io.opentelemetry.instrumentation.annotations.SpanAttribute;\nimport io.opentelemetry.instrumentation.annotations.WithSpan;\npublic class MyClass {\n@WithSpan\npublic void myMethod(@SpanAttribute(\"parameter1\") String parameter1,\n@SpanAttribute(\"parameter2\") long parameter2) {\n&lt;...&gt;\n}\n}\n</code></pre> <p>Unless specified as an argument to the annotation, the attribute name will be derived from the formal parameter names if they are compiled into the <code>.class</code> files by passing the <code>-parameters</code> option to the <code>javac</code> compiler.</p>"},{"location":"docs/instrumentation/java/automatic/annotations/#suppressing-withspan-instrumentation","title":"Suppressing <code>@WithSpan</code> instrumentation","text":"<p>Suppressing <code>@WithSpan</code> is useful if you have code that is over-instrumented using <code>@WithSpan</code> and you want to suppress some of them without modifying the code.</p> <p>{{% config_option   name=\"otel.instrumentation.opentelemetry-instrumentation-annotations.exclude-methods\" %}} Suppress <code>@WithSpan</code> instrumentation for specific methods. Format is <code>my.package.MyClass1[method1,method2];my.package.MyClass2[method3]</code>. {{% /config_option %}}</p>"},{"location":"docs/instrumentation/java/automatic/annotations/#creating-spans-around-methods-with-otelinstrumentationmethodsinclude","title":"Creating spans around methods with <code>otel.instrumentation.methods.include</code>","text":"<p>In cases where you are unable to modify the code, you can still configure the javaagent to capture spans around specific methods.</p> <p>{{% config_option name=\"otel.instrumentation.methods.include\" %}} Add instrumentation for specific methods in lieu of <code>@WithSpan</code>. Format is <code>my.package.MyClass1[method1,method2];my.package.MyClass2[method3]</code>. {{% /config_option %}}</p> <p>If a method is overloaded (appears more than once on the same class with the same name but different parameters), all versions of the method will be instrumented.</p>"},{"location":"docs/instrumentation/java/automatic/annotations/#next-steps","title":"Next steps","text":"<p>Beyond the use of annotations, the OpenTelemetry API allows you to obtain a tracer that can be used for Manual Instrumentation and execute code within the scope of that span.</p>"},{"location":"docs/instrumentation/java/automatic/extensions/","title":"Extensions","text":""},{"location":"docs/instrumentation/java/automatic/extensions/#introduction","title":"Introduction","text":"<p>Extensions are designed to override or customize the instrumentation provided by the upstream agent without having to create a new OpenTelemetry distribution or alter the agent code in any way.</p> <p>Consider an instrumented database client that creates a span per database call and extracts data from the database connection to provide span attributes. The following are sample use cases for that scenario that can be solved by using extensions:</p> <ul> <li>\"I don't want this span at all\":</li> </ul> <p>Create an extension to disable selected instrumentation by providing new   default settings.</p> <ul> <li>\"I want to edit some attributes that don't depend on any db connection   instance\":</li> </ul> <p>Create an extension that provide a custom <code>SpanProcessor</code>.</p> <ul> <li>\"I want to edit some attributes and their values depend on a specific db   connection instance\":</li> </ul> <p>Create an extension with new instrumentation which injects its own advice into   the same method as the original one. You can use the <code>order</code> method to ensure   it runs after the original instrumentation and augment the current span with   new information.</p> <ul> <li>\"I want to remove some attributes\":</li> </ul> <p>Create an extension with a custom exporter or use the attribute filtering   functionality in the OpenTelemetry Collector.</p> <ul> <li>\"I don't like the OTel spans. I want to modify them and their lifecycle\":</li> </ul> <p>Create an extension that disables existing instrumentation and replace it with   new one that injects <code>Advice</code> into the same (or a better) method as the   original instrumentation. You can write your <code>Advice</code> for this and use the   existing <code>Tracer</code> directly or extend it. As you have your own <code>Advice</code>, you   can control which <code>Tracer</code> you use.</p>"},{"location":"docs/instrumentation/java/automatic/extensions/#extension-examples","title":"Extension examples","text":"<p>To get a demonstration how to create an extension for the OpenTelemetry Java instrumentation agent, build and run the extension project.</p>"},{"location":"docs/instrumentation/js/_index/","title":"JavaScript","text":"<p>{{% lang_instrumentation_index_head js /%}}</p>"},{"location":"docs/instrumentation/js/_index/#further-reading","title":"Further Reading","text":"<ul> <li>OpenTelemetry for JavaScript on GitHub</li> <li>Getting Started</li> <li>SDK and API Reference</li> </ul>"},{"location":"docs/instrumentation/js/context/","title":"Context","text":"<p>In order for OpenTelemetry to work, it must store and propagate important telemetry data. For example, when a request is received and a span is started it must be available to a component which creates its child span. To solve this problem, OpenTelemetry stores the span in the Context. This document describes the OpenTelemetry context API for JavaScript and how it is used.</p> <p>More information:</p> <ul> <li>Context specification</li> <li>Context API reference</li> </ul>"},{"location":"docs/instrumentation/js/context/#context-manager","title":"Context Manager","text":"<p>The context API depends on a context manager to work. The examples in this document will assume you have already configured a context manager. Typically the context manager is provided by your SDK, however it is possible to register one directly like this:</p> <pre><code>import * as api from '@opentelemetry/api';\nimport { AsyncHooksContextManager } from '@opentelemetry/context-async-hooks';\nconst contextManager = new AsyncHooksContextManager();\ncontextManager.enable();\napi.context.setGlobalContextManager(contextManager);\n</code></pre>"},{"location":"docs/instrumentation/js/context/#root-context","title":"Root Context","text":"<p>The <code>ROOT_CONTEXT</code> is the empty context. If no context is active, the <code>ROOT_CONTEXT</code> is active. Active context is explained below Active Context.</p>"},{"location":"docs/instrumentation/js/context/#context-keys","title":"Context Keys","text":"<p>Context entries are key-value pairs. Keys can be created by calling <code>api.createContextKey(description)</code>.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key1 = api.createContextKey('My first key');\nconst key2 = api.createContextKey('My second key');\n</code></pre>"},{"location":"docs/instrumentation/js/context/#basic-operations","title":"Basic Operations","text":""},{"location":"docs/instrumentation/js/context/#get-entry","title":"Get Entry","text":"<p>Entries are accessed using the <code>context.getValue(key)</code> method.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key = api.createContextKey('some key');\n// ROOT_CONTEXT is the empty context\nconst ctx = api.ROOT_CONTEXT;\nconst value = ctx.getValue(key);\n</code></pre>"},{"location":"docs/instrumentation/js/context/#set-entry","title":"Set Entry","text":"<p>Entries are created by using the <code>context.setValue(key, value)</code> method. Setting a context entry creates a new context with all the entries of the previous context, but with the new entry. Setting a context entry does not modify the previous context.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key = api.createContextKey('some key');\nconst ctx = api.ROOT_CONTEXT;\n// add a new entry\nconst ctx2 = ctx.setValue(key, 'context 2');\n// ctx2 contains the new entry\nconsole.log(ctx2.getValue(key)); // \"context 2\"\n// ctx is unchanged\nconsole.log(ctx.getValue(key)); // undefined\n</code></pre>"},{"location":"docs/instrumentation/js/context/#delete-entry","title":"Delete Entry","text":"<p>Entries are removed by calling <code>context.deleteValue(key)</code>. Deleting a context entry creates a new context with all the entries of the previous context, but without the entry identified by the key. Deleting a context entry does not modify the previous context.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key = api.createContextKey('some key');\nconst ctx = api.ROOT_CONTEXT;\nconst ctx2 = ctx.setValue(key, 'context 2');\n// remove the entry\nconst ctx3 = ctx.deleteValue(key);\n// ctx3 does not contain the entry\nconsole.log(ctx3.getValue(key)); // undefined\n// ctx2 is unchanged\nconsole.log(ctx2.getValue(key)); // \"context 2\"\n// ctx is unchanged\nconsole.log(ctx.getValue(key)); // undefined\n</code></pre>"},{"location":"docs/instrumentation/js/context/#active-context","title":"Active Context","text":"<p>IMPORTANT: This assumes you have configured a Context Manager. Without one, <code>api.context.active()</code> will ALWAYS return the <code>ROOT_CONTEXT</code>.</p> <p>The active context is the context which is returned by <code>api.context.active()</code>. The context object contains entries which allow tracing components which are tracing a single thread of execution to communicate with each other and ensure the trace is successfully created. For example, when a span is created it may be added to the context. Later, when another span is created it may use the span from the context as its parent span. This is accomplished through the use of mechanisms like async_hooks or AsyncLocalStorage in node, or zone.js on the web in order to propagate the context through a single execution. If no context is active, the <code>ROOT_CONTEXT</code> is returned, which is just the empty context object.</p>"},{"location":"docs/instrumentation/js/context/#get-active-context","title":"Get Active Context","text":"<p>The active context is the context which is returned by <code>api.context.active()</code>.</p> <pre><code>import * as api from '@opentelemetry/api';\n// Returns the active context\n// If no context is active, the ROOT_CONTEXT is returned\nconst ctx = api.context.active();\n</code></pre>"},{"location":"docs/instrumentation/js/context/#set-active-context","title":"Set Active Context","text":"<p>A context can be made active by use of <code>api.context.with(ctx, callback)</code>. During execution of the <code>callback</code>, the context passed to <code>with</code> will be returned by <code>context.active</code>.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key = api.createContextKey('Key to store a value');\nconst ctx = api.context.active();\napi.context.with(ctx.setValue(key, 'context 2'), async () =&gt; {\n// \"context 2\" is active\nconsole.log(api.context.active().getValue(key)); // \"context 2\"\n});\n</code></pre> <p>The return value of <code>api.context.with(context, callback)</code> is the return value of the callback. The callback is always called synchronously.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst name = await api.context.with(api.context.active(), async () =&gt; {\nconst row = await db.getSomeValue();\nreturn row['name'];\n});\nconsole.log(name); // name returned by the db\n</code></pre> <p>Active context executions may be nested.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key = api.createContextKey('Key to store a value');\nconst ctx = api.context.active();\n// No context is active\nconsole.log(api.context.active().getValue(key)); // undefined\napi.context.with(ctx.setValue(key, 'context 2'), () =&gt; {\n// \"context 2\" is active\nconsole.log(api.context.active().getValue(key)); // \"context 2\"\napi.context.with(ctx.setValue(key, 'context 3'), () =&gt; {\n// \"context 3\" is active\nconsole.log(api.context.active().getValue(key)); // \"context 3\"\n});\n// \"context 2\" is active\nconsole.log(api.context.active().getValue(key)); // \"context 2\"\n});\n// No context is active\nconsole.log(api.context.active().getValue(key)); // undefined\n</code></pre>"},{"location":"docs/instrumentation/js/context/#example","title":"Example","text":"<p>This more complex example illustrates how the context is not modified, but new context objects are created.</p> <pre><code>import * as api from '@opentelemetry/api';\nconst key = api.createContextKey('Key to store a value');\nconst ctx = api.context.active(); // Returns ROOT_CONTEXT when no context is active\nconst ctx2 = ctx.setValue(key, 'context 2'); // does not modify ctx\nconsole.log(ctx.getValue(key)); //? undefined\nconsole.log(ctx2.getValue(key)); //? \"context 2\"\nconst ret = api.context.with(ctx2, () =&gt; {\nconst ctx3 = api.context.active().setValue(key, 'context 3');\nconsole.log(api.context.active().getValue(key)); //? \"context 2\"\nconsole.log(ctx.getValue(key)); //? undefined\nconsole.log(ctx2.getValue(key)); //? \"context 2\"\nconsole.log(ctx3.getValue(key)); //? \"context 3\"\napi.context.with(ctx3, () =&gt; {\nconsole.log(api.context.active().getValue(key)); //? \"context 3\"\n});\nconsole.log(api.context.active().getValue(key)); //? \"context 2\"\nreturn 'return value';\n});\n// The value returned by the callback is returned to the caller\nconsole.log(ret); //? \"return value\"\n</code></pre>"},{"location":"docs/instrumentation/js/examples/","title":"Examples","text":"<p>Here are some of the resources for OpenTelemetry instrumentation examples.</p>"},{"location":"docs/instrumentation/js/examples/#core-examples","title":"Core Examples","text":"<p>The repository of the JavaScript version of OpenTelemetry holds some examples of how to run real application with OpenTelemetry JavaScript.</p>"},{"location":"docs/instrumentation/js/examples/#plugin-package-examples","title":"Plugin &amp; Package Examples","text":"<p>Many of the packages and plugins at the contributions repository for OpenTelemetry JavaScript come with an usage example. You can find them in the examples folder.</p>"},{"location":"docs/instrumentation/js/examples/#community-resources","title":"Community Resources","text":"<p>The nodejs-opentelemetry-tempo project illustrates the use of OpenTelemetry (through automatic and manual instrumentation) involving microservices with DB interactions. It uses the following:</p> <ul> <li>Prometheus, for monitoring and alerting</li> <li>Loki, for distributed logging</li> <li>Tempo, for distributed tracing</li> <li>Grafana for visualization</li> </ul> <p>For more details, visit the project repository.</p>"},{"location":"docs/instrumentation/js/exporters/","title":"Exporters","text":"<p>In order to visualize and analyze your traces, you will need to export them to a backend such as Jaeger or Zipkin. OpenTelemetry JS provides exporters for some common open source backends.</p> <p>Below you will find some introductions on how to set up backends and the matching exporters.</p>"},{"location":"docs/instrumentation/js/exporters/#otlp-endpoint","title":"OTLP endpoint","text":"<p>To send trace data to a OTLP endpoint (like the collector or Jaeger) you'll want to use an exporter package, such as <code>@opentelemetry/exporter-trace-otlp-proto</code>:</p> <pre><code>npm install --save @opentelemetry/exporter-trace-otlp-proto \\\n@opentelemetry/exporter-metrics-otlp-proto\n</code></pre> <p>Next, configure the exporter to point at an OTLP endpoint. For example you can update <code>instrumentation.ts|js</code> from the Getting Started like the following:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab Typescript &gt;}} /tracing.ts/ import * as opentelemetry from \"opentelemetry/sdk-node\"; import {   getNodeAutoInstrumentations, } from \"opentelemetry/auto-instrumentations-node\"; import {   OTLPTraceExporter, } from \"opentelemetry/exporter-trace-otlp-proto\"; import {   OTLPMetricExporter } from \"opentelemetry/exporter-metrics-otlp-proto\"; import {   PeriodicExportingMetricReader } from \"opentelemetry/sdk-metrics\";</p> <p>const sdk = new opentelemetry.NodeSDK({   traceExporter: new OTLPTraceExporter({     // optional - default url is http://localhost:4318/v1/traces     url: \"/v1/traces\",     // optional - collection of custom headers to be sent with each request, empty by default     headers: {},   }),   metricReader: new PeriodicExportingMetricReader({     exporter: new OTLPMetricExporter({       url: '/v1/metrics', // url is optional and can be omitted - default is http://localhost:4318/v1/metrics       headers: {}, // an optional object containing custom headers to be sent with each request     }),   }),   instrumentations: [getNodeAutoInstrumentations()], }); sdk.start(); {{&lt; /tab &gt;}} <p>{{&lt; tab JavaScript &gt;}} /tracing.js/ const opentelemetry = require(\"opentelemetry/sdk-node\"); const {   getNodeAutoInstrumentations, } = require(\"opentelemetry/auto-instrumentations-node\"); const {   OTLPTraceExporter, } = require(\"opentelemetry/exporter-trace-otlp-proto\"); const {   OTLPMetricExporter } = require(\"opentelemetry/exporter-metrics-otlp-proto\"); const {   PeriodicExportingMetricReader } = require('opentelemetry/sdk-metrics');</p> <p>const sdk = new opentelemetry.NodeSDK({   traceExporter: new OTLPTraceExporter({     // optional - default url is http://localhost:4318/v1/traces     url: \"/v1/traces\",     // optional - collection of custom headers to be sent with each request, empty by default     headers: {},   }),   metricReader: new PeriodicExportingMetricReader({     exporter: new OTLPMetricExporter({       url: '/v1/metrics', // url is optional and can be omitted - default is http://localhost:4318/v1/metrics       headers: {}, // an optional object containing custom headers to be sent with each request       concurrencyLimit: 1, // an optional limit on pending requests     }),   }),   instrumentations: [getNodeAutoInstrumentations()], }); sdk.start(); {{&lt; /tab &gt;}} <p>{{&lt; /tabpane&gt;}}</p> <p>To try out the <code>OTLPTraceExporter</code> quickly, you can run Jaeger in a docker container:</p> <pre><code>docker run -d --name jaeger \\\n-e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n-e COLLECTOR_OTLP_ENABLED=true \\\n-p 6831:6831/udp \\\n-p 6832:6832/udp \\\n-p 5778:5778 \\\n-p 16686:16686 \\\n-p 4317:4317 \\\n-p 4318:4318 \\\n-p 14250:14250 \\\n-p 14268:14268 \\\n-p 14269:14269 \\\n-p 9411:9411 \\\njaegertracing/all-in-one:latest\n</code></pre>"},{"location":"docs/instrumentation/js/exporters/#usage-with-the-webtracer","title":"Usage with the WebTracer","text":"<p>When you use the OTLP exporter in a browser-based application, you need to note that:</p> <ol> <li>Using gRPC &amp; http/proto for exporting is not supported</li> <li>Content Security Policies (CSPs) of your website might block your exports</li> <li>Cross-Origin Resource Sharing (CORS) headers might not allow your exports    to be sent</li> <li>You might need to expose your collector to the public internet</li> </ol> <p>Below you will find instructions to use the right exporter, to configure your CSPs and CORS headers and what precautions you have to take when exposing your collector.</p>"},{"location":"docs/instrumentation/js/exporters/#use-otlp-exporter-with-httpjson","title":"Use OTLP exporter with HTTP/JSON","text":"<p>OpenTelemetry Collector Exporter with gRPC and OpenTelemetry Collector Exporter with protobuf do only work with Node.js, therefore you are limited to use the OpenTelemetry Collector Exporter with HTTP.</p> <p>Make sure that the receiving end of your exporter (collector or observability backend) does support <code>http/json</code>, and that you are exporting your data to the right endpoint, i.e., make sure that your port is set to <code>4318</code>.</p>"},{"location":"docs/instrumentation/js/exporters/#configure-csps","title":"Configure CSPs","text":"<p>If your website is making use of Content Security Policies (CSPs), make sure that the domain of your OTLP endpoint is included. If your collector endpoint is <code>https://collector.example.com:4318/v1/traces</code>, add the following directive:</p> <pre><code>connect-src collector.example.com:4318/v1/traces\n</code></pre> <p>If your CSP is not including the OTLP endpoint, you will see an error message, stating that the request to your endpoint is violating the CSP directive.</p>"},{"location":"docs/instrumentation/js/exporters/#configure-cors-headers","title":"Configure CORS headers","text":"<p>If your website and collector are hosted at a different origin, your browser might block the requests going out to your collector. You need to configure special headers for Cross-Origin Resource Sharing (CORS).</p> <p>The OpenTelemetry collector provides a feature for http-based receivers to add the required headers to allow the receiver to accept traces from a web browser:</p> <pre><code>receivers:\notlp:\nprotocols:\nhttp:\ninclude_metadata: true\ncors:\nallowed_origins:\n- https://foo.bar.com\n- https://*.test.com\nallowed_headers:\n- Example-Header\nmax_age: 7200\n</code></pre>"},{"location":"docs/instrumentation/js/exporters/#securely-expose-your-collector","title":"Securely expose your collector","text":"<p>To receive telemetry from a web application you need to allow the browsers of your end-users to send data to your collector. If your web application is accessible from the public internet, you also have to make your collector accessible for everyone.</p> <p>It is recommended that you do not expose your collector directly, but that you put a reverse proxy (NGINX, Apache HTTP Server, ...) in front of it. The reverse proxy can take care of SSL-offloading, setting the right CORS headers, and many other features specific to web applications.</p> <p>Below you will find a configuration for the popular NGINX web server to get you started:</p> <pre><code>server {\nlisten 80 default_server;\nserver_name _;\nlocation / {\n# Take care of preflight requests\nif ($request_method = 'OPTIONS') {\nadd_header 'Access-Control-Max-Age' 1728000;\nadd_header 'Access-Control-Allow-Origin' 'name.of.your.website.example.com' always;\nadd_header 'Access-Control-Allow-Headers' 'Accept,Accept-Language,Content-Language,Content-Type' always;\nadd_header 'Access-Control-Allow-Credentials' 'true' always;\nadd_header 'Content-Type' 'text/plain charset=UTF-8';\nadd_header 'Content-Length' 0;\nreturn 204;\n}\nadd_header 'Access-Control-Allow-Origin' 'name.of.your.website.example.com' always;\nadd_header 'Access-Control-Allow-Credentials' 'true' always;\nadd_header 'Access-Control-Allow-Headers' 'Accept,Accept-Language,Content-Language,Content-Type' always;\nproxy_http_version 1.1;\nproxy_set_header Host $host;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_pass http://collector:4318;\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/js/exporters/#zipkin","title":"Zipkin","text":"<p>To set up Zipkin as quickly as possible, run it in a docker container:</p> <pre><code>docker run --rm -d -p 9411:9411 --name zipkin openzipkin/zipkin\n</code></pre> <p>Install the exporter package as a dependency for your application:</p> <pre><code>npm install --save @opentelemetry/exporter-zipkin\n</code></pre> <p>Update your OpenTelemetry configuration to use the exporter and to send data to your Zipkin backend:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab Typescript &gt;}} import { ZipkinExporter } from \"opentelemetry/exporter-zipkin\"; import { BatchSpanProcessor } from \"opentelemetry/sdk-trace-base\";</p> <p>provider.addSpanProcessor(new BatchSpanProcessor(new ZipkinExporter())); {{&lt; /tab&gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const { ZipkinExporter } = require(\"opentelemetry/exporter-zipkin\"); const { BatchSpanProcessor } = require(\"opentelemetry/sdk-trace-base\");</p> <p>provider.addSpanProcessor(new BatchSpanProcessor(new ZipkinExporter())); {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p>"},{"location":"docs/instrumentation/js/libraries/","title":"Using instrumentation libraries","text":"<p>You can use instrumentation libraries in order to generate telemetry data for a library or framework.</p> <p>For example, the instrumentation library for Express will automatically create spans based on the inbound HTTP requests.</p>"},{"location":"docs/instrumentation/js/libraries/#setup","title":"Setup","text":"<p>Each instrumentation library is an NPM package, and installation is typically done like so:</p> <pre><code>npm install &lt;name-of-package&gt;\n</code></pre> <p>It is typically then registered at application startup time, such as when creating a TracerProvider.</p>"},{"location":"docs/instrumentation/js/libraries/#nodejs","title":"Node.js","text":""},{"location":"docs/instrumentation/js/libraries/#node-autoinstrumentation-package","title":"Node autoinstrumentation package","text":"<p>OpenTelemetry also defines the auto-instrumentations-node metapackage that bundles all Node.js-based instrumentation libraries into a single package. It's a convenient way to add automatically-generated telemetry for all your libraries with minimal effort.</p> <p>To use the package, first install it:</p> <pre><code>npm install @opentelemetry/auto-instrumentations-node\n</code></pre> <p>Then in your tracing initialization code, use <code>registerInstrumentations</code>:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} /* tracing.ts */</p> <p>// Import dependencies import { getNodeAutoInstrumentations } from \"opentelemetry/auto-instrumentations-node\"; import opentelemetry from \"opentelemetry/api\"; import { Resource } from \"opentelemetry/resources\"; import { SemanticResourceAttributes } from \"opentelemetry/semantic-conventions\"; import { NodeTracerProvider } from \"opentelemetry/sdk-trace-node\"; import { registerInstrumentations } from \"opentelemetry/instrumentation\"; import { ConsoleSpanExporter, BatchSpanProcessor } from \"opentelemetry/sdk-trace-base\";</p> <p>// This registers all instrumentation packages registerInstrumentations({   instrumentations: [     getNodeAutoInstrumentations()   ], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new NodeTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} /* tracing.js */</p> <p>// Require dependencies const { getNodeAutoInstrumentations } = require(\"opentelemetry/auto-instrumentations-node\"); const opentelemetry = require(\"opentelemetry/api\"); const { Resource } = require(\"opentelemetry/resources\"); const { SemanticResourceAttributes } = require(\"opentelemetry/semantic-conventions\"); const { NodeTracerProvider } = require(\"opentelemetry/sdk-trace-node\"); const { registerInstrumentations } = require(\"opentelemetry/instrumentation\"); const { ConsoleSpanExporter, BatchSpanProcessor } = require(\"opentelemetry/sdk-trace-base\");</p> <p>// This registers all instrumentation packages registerInstrumentations({   instrumentations: [     getNodeAutoInstrumentations()   ], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new NodeTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/libraries/#using-individual-instrumentation-packages","title":"Using individual instrumentation packages","text":"<p>If you don't wish to use a metapackage, perhaps to decrease your dependency graph size, you can install and register individual instrumentation packages.</p> <p>For example, here's how you can install and register only the instrumentation-express and instrumentation-http packages to instrument inbound and outbound HTTP traffic.</p> <pre><code>npm install --save @opentelemetry/instrumentation-http @opentelemetry/instrumentation-express\n</code></pre> <p>And then register each instrumentation library:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} /* tracing.ts */</p> <p>// Import dependencies import { HttpInstrumentation } from \"opentelemetry/instrumentation-http\"; import { ExpressInstrumentation } from \"opentelemetry/instrumentation-express\"; import opentelemetry from \"opentelemetry/api\"; import { Resource } from \"opentelemetry/resources\"; import { SemanticResourceAttributes } from \"opentelemetry/semantic-conventions\"; import { NodeTracerProvider } from \"opentelemetry/sdk-trace-node\"; import { registerInstrumentations } from \"opentelemetry/instrumentation\"; import { ConsoleSpanExporter, BatchSpanProcessor } from \"opentelemetry/sdk-trace-base\";</p> <p>// This registers all instrumentation packages registerInstrumentations({   instrumentations: [     // Express instrumentation expects HTTP layer to be instrumented     new HttpInstrumentation(),     new ExpressInstrumentation(),   ], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new NodeTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} /* tracing.js */</p> <p>// Require dependencies const { HttpInstrumentation } = require(\"opentelemetry/instrumentation-http\"); const { ExpressInstrumentation } = require(\"opentelemetry/instrumentation-express\"); const opentelemetry = require(\"opentelemetry/api\"); const { Resource } = require(\"opentelemetry/resources\"); const { SemanticResourceAttributes } = require(\"opentelemetry/semantic-conventions\"); const { NodeTracerProvider } = require(\"opentelemetry/sdk-trace-node\"); const { registerInstrumentations } = require(\"opentelemetry/instrumentation\"); const { ConsoleSpanExporter, BatchSpanProcessor } = require(\"opentelemetry/sdk-trace-base\");</p> <p>// This registers all instrumentation packages registerInstrumentations({   instrumentations: [     // Express instrumentation expects HTTP layer to be instrumented     new HttpInstrumentation(),     new ExpressInstrumentation(),   ], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new NodeTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/libraries/#configuring-instrumentation-libraries","title":"Configuring instrumentation libraries","text":"<p>Some instrumentation libraries offer additional configuration options.</p> <p>For example, Express instrumentation offers ways to ignore specified middleware or enrich spans created automatically with a request hook.</p> <p>You'll need to refer to each instrumentation library's documentation for advanced configuration.</p>"},{"location":"docs/instrumentation/js/libraries/#available-instrumentation-libraries","title":"Available instrumentation libraries","text":"<p>A full list of instrumentation libraries produced by OpenTelemetry is available from the opentelemetry-js-contrib repository.</p> <p>You can also find more instrumentations available in the registry.</p>"},{"location":"docs/instrumentation/js/libraries/#next-steps","title":"Next steps","text":"<p>After you have set up instrumentation libraries, you may want to add manual instrumentation to collect custom telemetry data.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p>"},{"location":"docs/instrumentation/js/manual/","title":"Manual","text":"<p>Manual instrumentation is the process of adding observability code to your application.</p>"},{"location":"docs/instrumentation/js/manual/#tracing","title":"Tracing","text":""},{"location":"docs/instrumentation/js/manual/#initialize-tracing","title":"Initialize Tracing","text":"<p>To start tracing, you'll need to have an initialized <code>TracerProvider</code> that will let you create a <code>Tracer</code>.</p> <p>If a <code>TracerProvider</code> is not created, the OpenTelemetry APIs for tracing will use a no-op implementation and fail to generate data.</p>"},{"location":"docs/instrumentation/js/manual/#nodejs","title":"Node.js","text":"<p>To initialize tracing with the Node.js SDK, first ensure you have the SDK package and OpenTelemetry API installed:</p> <pre><code>npm install \\\n@opentelemetry/api \\\n@opentelemetry/resources \\\n@opentelemetry/semantic-conventions \\\n@opentelemetry/sdk-trace-node \\\n@opentelemetry/instrumentation\n</code></pre> <p>Next, create a separate <code>tracing.js|ts</code> file that has all the SDK initialization code in it:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} /tracing.ts/ import { BatchSpanProcessor, ConsoleSpanExporter } from \"opentelemetry/sdk-trace-base\"; import { Resource } from \"opentelemetry/resources\"; import { SemanticResourceAttributes } from \"opentelemetry/semantic-conventions\"; import { NodeTracerProvider } from \"opentelemetry/sdk-trace-node\"; import { registerInstrumentations } from \"opentelemetry/instrumentation\";</p> <p>// Optionally register instrumentation libraries registerInstrumentations({   instrumentations: [], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new NodeTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} /tracing.js/ const { Resource } = require(\"opentelemetry/resources\"); const { SemanticResourceAttributes } = require(\"opentelemetry/semantic-conventions\"); const { NodeTracerProvider } = require(\"opentelemetry/sdk-trace-node\"); const { registerInstrumentations } = require(\"opentelemetry/instrumentation\"); const { ConsoleSpanExporter, BatchSpanProcessor } = require(\"opentelemetry/sdk-trace-base\");</p> <p>// Optionally register instrumentation libraries registerInstrumentations({   instrumentations: [], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new NodeTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane&gt;}}</p> <p>Next, ensure that <code>tracing.js|ts</code> is required in your node invocation. This is also required if you're registering instrumentation libraries. For example:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} ts-node --require ./tracing.ts  {{&lt; /tab &gt;}} <p>{{&lt; tab JavaScript &gt;}} node --require ./tracing.js  {{&lt; /tab &gt;}} <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/manual/#browser","title":"Browser","text":"<p>First, ensure you've got the right packages:</p> <pre><code>npm install \\\n@opentelemetry/api \\\n@opentelemetry/resources \\\n@opentelemetry/semantic-conventions \\\n@opentelemetry/sdk-trace-web \\\n@opentelemetry/instrumentation\n</code></pre> <p>Create a <code>tracing.js|ts</code> file that initialized the Web SDK, creates a <code>TracerProvider</code>, and exports a <code>Tracer</code>.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import { Resource } from \"opentelemetry/resources\"; import { SemanticResourceAttributes } from \"opentelemetry/semantic-conventions\"; import { WebTracerProvider } from \"opentelemetry/sdk-trace-web\"; import { registerInstrumentations } from \"opentelemetry/instrumentation\"; import { BatchSpanProcessor, ConsoleSpanExporter } from \"opentelemetry/sdk-trace-base\";</p> <p>// Optionally register automatic instrumentation libraries registerInstrumentations({   instrumentations: [], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new WebTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const opentelemetry = require(\"opentelemetry/api\"); const { Resource } = require(\"opentelemetry/resources\"); const { SemanticResourceAttributes } = require(\"opentelemetry/semantic-conventions\"); const { WebTracerProvider } = require(\"opentelemetry/sdk-trace-web\"); const { registerInstrumentations } = require(\"opentelemetry/instrumentation\"); const { ConsoleSpanExporter, BatchSpanProcessor } = require(\"opentelemetry/sdk-trace-base\");</p> <p>// Optionally register automatic instrumentation libraries registerInstrumentations({   instrumentations: [], });</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const provider = new WebTracerProvider({     resource: resource, }); const exporter = new ConsoleSpanExporter(); const processor = new BatchSpanProcessor(exporter); provider.addSpanProcessor(processor);</p> <p>provider.register(); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane&gt;}}</p> <p>You'll need to bundle this file with your web application to be able to use tracing throughout the rest of your web application.</p>"},{"location":"docs/instrumentation/js/manual/#picking-the-right-span-processor","title":"Picking the right span processor","text":"<p>By default, the Node SDK uses the <code>BatchSpanProcessor</code>, and this span processor is also chosen in the Web SDK example. The <code>BatchSpanProcessor</code> processes spans in batches before they are exported. This is usually the right processor to use for an application.</p> <p>In contrast, the <code>SimpleSpanProcessor</code> processes spans as they are created. This means that if you create 5 spans, each will be processed and exported before the next span is created in code. This can be helpful in scenarios where you do not want to risk losing a batch, or if you're experimenting with OpenTelemetry in development. However, it also comes with potentially significant overhead, especially if spans are being exported over a network - each time a call to create a span is made, it would be processed and sent over a network before your app's execution could continue.</p> <p>In most cases, stick with <code>BatchSpanProcessor</code> over <code>SimpleSpanProcessor</code>.</p>"},{"location":"docs/instrumentation/js/manual/#acquiring-a-tracer","title":"Acquiring a tracer","text":"<p>Anywhere in your application where you write manual tracing code should call <code>getTracer</code> to acquire a tracer. For example:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import opentelemetry from \"opentelemetry/api\"; //...</p> <p>const tracer = opentelemetry.trace.getTracer(   'my-service-tracer' );</p> <p>// You can now use a 'tracer' to do tracing! {{&lt; /tab &gt;}} {{&lt; tab JavaScript &gt;}} const opentelemetry = require(\"opentelemetry/api\"); //...</p> <p>const tracer = opentelemetry.trace.getTracer(   'my-service-tracer' );</p> <p>// You can now use a 'tracer' to do tracing! {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>It's generally recommended to call <code>getTracer</code> in your app when you need it rather than exporting the <code>tracer</code> instance to the rest of your app. This helps avoid trickier application load issues when other required dependencies are involved.</p>"},{"location":"docs/instrumentation/js/manual/#create-spans","title":"Create spans","text":"<p>Now that you have a <code>Tracer</code> initialized, you can create <code>Span</code>s.</p> <pre><code>// Create a span. A span must be closed.\ntracer.startActiveSpan('main', (span) =&gt; {\nfor (let i = 0; i &lt; 10; i += 1) {\nconsole.log(i);\n}\n// Be sure to end the span!\nspan.end();\n});\n</code></pre> <p>The above code sample shows how to create an active span, which is the most common kind of span to create.</p>"},{"location":"docs/instrumentation/js/manual/#create-nested-spans","title":"Create nested spans","text":"<p>Nested spans let you track work that's nested in nature. For example, the <code>doWork</code> function below represents a nested operation. The following sample creates a nested span that tracks the <code>doWork</code> function:</p> <pre><code>const mainWork = () =&gt; {\ntracer.startActiveSpan('main', (parentSpan) =&gt; {\nfor (let i = 0; i &lt; 3; i += 1) {\ndoWork(i);\n}\n// Be sure to end the parent span!\nparentSpan.end();\n});\n};\nconst doWork = (i) =&gt; {\ntracer.startActiveSpan(`doWork:${i}`, (span) =&gt; {\n// simulate some random work.\nfor (let i = 0; i &lt;= Math.floor(Math.random() * 40000000); i += 1) {\n// empty\n}\n// Make sure to end this child span! If you don't,\n// it will continue to track work beyond 'doWork'!\nspan.end();\n});\n};\n</code></pre> <p>This code will create 3 child spans that have <code>parentSpan</code>'s span ID as their parent IDs.</p>"},{"location":"docs/instrumentation/js/manual/#create-independent-spans","title":"Create independent spans","text":"<p>The previous examples showed how to create an active span. In some cases, you'll want to create inactive spans that are siblings of one another rather than being nested.</p> <pre><code>const doWork = () =&gt; {\nconst span1 = tracer.startSpan('work-1');\n// do some work\nconst span2 = tracer.startSpan('work-2');\n// do some more work\nconst span3 = tracer.startSpan('work-3');\n// do even more work\nspan1.end();\nspan2.end();\nspan3.end();\n};\n</code></pre> <p>In this example, <code>span1</code>, <code>span2</code>, and <code>span3</code> are sibling spans and none of them are considered the currently active span. They share the same parent rather than being nested under one another.</p> <p>This arrangement can be helpful if you have units of work that are grouped together but are conceptually independent from one another.</p>"},{"location":"docs/instrumentation/js/manual/#get-the-current-span","title":"Get the current span","text":"<p>Sometimes it's helpful to do something with the current/active span at a particular point in program execution.</p> <pre><code>const activeSpan = opentelemetry.trace.getActiveSpan();\n// do something with the active span, optionally ending it if that is appropriate for your use case.\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#get-a-span-from-context","title":"Get a span from context","text":"<p>It can also be helpful to get the span from a given context that isn't necessarily the active span.</p> <pre><code>const ctx = getContextFromSomewhere();\nconst span = opentelemetry.trace.getSpan(ctx);\n// do something with the acquired span, optionally ending it if that is appropriate for your use case.\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#attributes","title":"Attributes","text":"<p>Attributes let you attach key/value pairs to a <code>Span</code> so it carries more information about the current operation that it's tracking.</p> <pre><code>tracer.startActiveSpan('app.new-span', (span) =&gt; {\n// do some work...\n// Add an attribute to the span\nspan.setAttribute('attribute1', 'value1');\nspan.end();\n});\n</code></pre> <p>You can also add attributes to a span as it's created:</p> <pre><code>tracer.startActiveSpan(\n'app.new-span',\n{ attributes: { attribute1: 'value1' } },\n(span) =&gt; {\n// do some work...\nspan.end();\n}\n);\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#semantic-attributes","title":"Semantic Attributes","text":"<p>There are semantic conventions for spans representing operations in well-known protocols like HTTP or database calls. Semantic conventions for these spans are defined in the specification at Trace Semantic Conventions. In the simple example of this guide the source code attributes can be used.</p> <p>First add the semantic conventions as a dependency to your application:</p> <pre><code>npm install --save @opentelemetry/semantic-conventions\n</code></pre> <p>Add the following to the top of your application file:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import { SemanticAttributes } from \"opentelemetry/semantic-conventions\"; {{&lt; /tab &gt;}} {{&lt; tab JavaScript &gt;}} const { SemanticAttributes } = require('opentelemetry/semantic-conventions'); {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>Finally, you can update your file to include semantic attributes:</p> <pre><code>const doWork = () =&gt; {\ntracer.startActiveSpan('app.doWork', (span) =&gt; {\nspan.setAttribute(SemanticAttributes.CODE_FUNCTION, 'doWork');\nspan.setAttribute(SemanticAttributes.CODE_FILEPATH, __filename);\n// Do some work...\nspan.end();\n});\n};\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#span-events","title":"Span events","text":"<p>A Span Event is a human-readable message on an <code>Span</code> that represents a discrete event with no duration that can be tracked by a single time stamp. You can think of it like a primitive log.</p> <pre><code>span.addEvent('Doing something');\nconst result = doWork();\n</code></pre> <p>You can also create Span Events with additional Attributes:</p> <pre><code>span.addEvent('some log', {\n'log.severity': 'error',\n'log.message': 'Data not found',\n'request.id': requestId,\n});\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#span-links","title":"Span links","text":"<p><code>Span</code>s can be created with zero or more <code>Link</code>s to other Spans that are causally related. A common scenario is to correlate one or more traces with the current span.</p> <pre><code>const someFunction = (spanToLinkFrom) =&gt; {\nconst options = {\nlinks: [\n{\ncontext: spanToLinkFrom.spanContext()\n}\n]\n};\ntracer.startActiveSpan('app.someFunction', options: options, span =&gt; {\n// Do some work...\nspan.end();\n});\n}\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#span-status","title":"Span Status","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - <code>SpanStatusCode.ERROR</code>.</p> <p>The status can be set at any time before the span is finished:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import opentelemetry, { SpanStatusCode } from \"opentelemetry/api\";</p> <p>// ...</p> <p>tracer.startActiveSpan('app.doWork', span =&gt; {   for (let i = 0; i &lt;= Math.floor(Math.random() * 40000000); i += 1) {     if (i &gt; 10000) {       span.setStatus({         code: SpanStatusCode.ERROR,         message: 'Error'       });     }   }</p> <p>span.end(); }); {{&lt; /tab &gt;}} {{&lt; tab JavaScript &gt;}} const opentelemetry = require(\"opentelemetry/api\");</p> <p>// ...</p> <p>tracer.startActiveSpan('app.doWork', span =&gt; {   for (let i = 0; i &lt;= Math.floor(Math.random() * 40000000); i += 1) {     if (i &gt; 10000) {       span.setStatus({         code: opentelemetry.SpanStatusCode.ERROR,         message: 'Error'       });     }   }</p> <p>span.end(); }); {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>By default, the status for all spans is <code>Unset</code> rather than <code>Ok</code>. It is typically the job of another component in your telemetry pipeline to interpret the <code>Unset</code> status of a span, so it's best not to override this unless you're explicitly tracking an error.</p>"},{"location":"docs/instrumentation/js/manual/#recording-exceptions","title":"Recording exceptions","text":"<p>It can be a good idea to record exceptions when they happen. It's recommended to do this in conjunction with setting span status.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import opentelemetry, { SpanStatusCode } from \"opentelemetry/api\";</p> <p>// ...</p> <p>try {   doWork(); } catch (ex) {   span.recordException(ex);   span.setStatus({ code: SpanStatusCode.ERROR }); } {{&lt; /tab &gt;}} {{&lt; tab JavaScript &gt;}} const opentelemetry = require(\"opentelemetry/api\");</p> <p>// ...</p> <p>try {   doWork(); } catch (ex) {   span.recordException(ex);   span.setStatus({ code: opentelemetry.SpanStatusCode.ERROR }); } {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p>"},{"location":"docs/instrumentation/js/manual/#using-sdk-trace-base-and-manually-propagating-span-context","title":"Using <code>sdk-trace-base</code> and manually propagating span context","text":"<p>In some cases, you may not be able to use either the Node.js SDK nor the Web SDK. The biggest difference, aside from initialization code, is that you'll have to manually set spans as active in the current context to be able to create nested spans.</p>"},{"location":"docs/instrumentation/js/manual/#initializing-tracing-with-sdk-trace-base","title":"Initializing tracing with <code>sdk-trace-base</code>","text":"<p>Initializing tracing is similar to how you'd do it with Node.js or the Web SDK.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import opentelemetry from \"opentelemetry/api\"; import {   BasicTracerProvider,   BatchSpanProcessor,   ConsoleSpanExporter } from \"opentelemetry/sdk-trace-base\";</p> <p>const provider = new BasicTracerProvider();</p> <p>// Configure span processor to send spans to the exporter provider.addSpanProcessor(new BatchSpanProcessor(new ConsoleSpanExporter())); provider.register();</p> <p>// This is what we'll access in all instrumentation code const tracer = opentelemetry.trace.getTracer(   'example-basic-tracer-node' ); {{&lt; /tab &gt;}} {{&lt; tab JavaScript &gt;}} const opentelemetry = require(\"opentelemetry/api\"); const {   BasicTracerProvider,   ConsoleSpanExporter,   BatchSpanProcessor, } = require(\"opentelemetry/sdk-trace-base\");</p> <p>const provider = new BasicTracerProvider();</p> <p>// Configure span processor to send spans to the exporter provider.addSpanProcessor(new BatchSpanProcessor(new ConsoleSpanExporter())); provider.register();</p> <p>// This is what we'll access in all instrumentation code const tracer = opentelemetry.trace.getTracer(     'example-basic-tracer-node' ); {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>Like the other examples in this document, this exports a tracer you can use throughout the app.</p>"},{"location":"docs/instrumentation/js/manual/#creating-nested-spans-with-sdk-trace-base","title":"Creating nested spans with <code>sdk-trace-base</code>","text":"<p>To create nested spans, you need to set whatever the currently-created span is as the active span in the current context. Don't bother using <code>startActiveSpan</code> because it won't do this for you.</p> <pre><code>const mainWork = () =&gt; {\nconst parentSpan = tracer.startSpan('main');\nfor (let i = 0; i &lt; 3; i += 1) {\ndoWork(parentSpan, i);\n}\n// Be sure to end the parent span!\nparentSpan.end();\n};\nconst doWork = (parent, i) =&gt; {\n// To create a child span, we need to mark the current (parent) span as the active span\n// in the context, then use the resulting context to create a child span.\nconst ctx = opentelemetry.trace.setSpan(\nopentelemetry.context.active(),\nparent\n);\nconst span = tracer.startSpan(`doWork:${i}`, undefined, ctx);\n// simulate some random work.\nfor (let i = 0; i &lt;= Math.floor(Math.random() * 40000000); i += 1) {\n// empty\n}\n// Make sure to end this child span! If you don't,\n// it will continue to track work beyond 'doWork'!\nspan.end();\n};\n</code></pre> <p>All other APIs behave the same when you use <code>sdk-trace-base</code> compared with the Node.js or Web SDKs.</p>"},{"location":"docs/instrumentation/js/manual/#metrics","title":"Metrics","text":"<p>To start metrics, you'll need to have an initialized <code>MeterProvider</code> that lets you create a <code>Meter</code>. <code>Meter</code>s let you create <code>Instrument</code>s that you can use to create different kinds of metrics. OpenTelemetry JavaScript currently supports the following <code>Instrument</code>s:</p> <ul> <li>Counter, a synchronous instrument which supports non-negative increments</li> <li>Asynchronous Counter, a asynchronous instrument which supports non-negative   increments</li> <li>Histogram, a synchronous instrument which supports arbitrary values that are   statistically meaningful, such as histograms, summaries or percentile</li> <li>Asynchronous Gauge, an asynchronous instrument which supports non-additive   values, such as room temperature</li> <li>UpDownCounter, a synchronous instrument which supports increments and   decrements, such as number of active requests</li> <li>Asynchronous UpDownCounter, an asynchronous instrument which supports   increments and decrements</li> </ul> <p>For more on synchronous and asynchronous instruments, and which kind is best suited for your use case, see Supplementary Guidelines.</p> <p>If a <code>MeterProvider</code> is not created either by an instrumentation library or manually, the OpenTelemetry Metrics API will use a no-op implementation and fail to generate data.</p>"},{"location":"docs/instrumentation/js/manual/#initialize-metrics","title":"Initialize Metrics","text":"<p>To initialize metrics, make sure you have the right packages installed:</p> <pre><code>npm install \\\n@opentelemetry/api \\\n@opentelemetry/resources \\\n@opentelemetry/semantic-conventions \\\n@opentelemetry/sdk-metrics \\\n@opentelemetry/instrumentation\n</code></pre> <p>Next, create a separate <code>instrumentation.js|ts</code> file that has all the SDK initialization code in it:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import opentelemetry from \"opentelemetry/api\"; import {   ConsoleMetricExporter,   MeterProvider,   PeriodicExportingMetricReader } from \"opentelemetry/sdk-metrics\"; import { Resource } from \"opentelemetry/resources\"; import { SemanticResourceAttributes } from \"opentelemetry/semantic-conventions\";</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const metricReader = new PeriodicExportingMetricReader({     exporter: new ConsoleMetricExporter(),</p> <pre><code>// Default is 60000ms (60 seconds). Set to 3 seconds for demonstrative purposes only.\nexportIntervalMillis: 3000,\n</code></pre> <p>});</p> <p>const myServiceMeterProvider = new MeterProvider({   resource: resource, });</p> <p>myServiceMeterProvider.addMetricReader(metricReader);</p> <p>// Set this MeterProvider to be global to the app being instrumented. opentelemetry.metrics.setGlobalMeterProvider(myServiceMeterProvider) {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const opentelemetry = require('opentelemetry/api') const {     MeterProvider,     PeriodicExportingMetricReader,     ConsoleMetricExporter   } = require('opentelemetry/sdk-metrics'); const { Resource } = require('opentelemetry/resources'); const { SemanticResourceAttributes } = require('opentelemetry/semantic-conventions');</p> <p>const resource =   Resource.default().merge(     new Resource({       [SemanticResourceAttributes.SERVICE_NAME]: \"service-name-here\",       [SemanticResourceAttributes.SERVICE_VERSION]: \"0.1.0\",     })   );</p> <p>const metricReader = new PeriodicExportingMetricReader({     exporter: new ConsoleMetricExporter(),</p> <pre><code>// Default is 60000ms (60 seconds). Set to 3 seconds for demonstrative purposes only.\nexportIntervalMillis: 3000,\n</code></pre> <p>});</p> <p>const myServiceMeterProvider = new MeterProvider({   resource: resource, });</p> <p>myServiceMeterProvider.addMetricReader(metricReader);</p> <p>// Set this MeterProvider to be global to the app being instrumented. opentelemetry.metrics.setGlobalMeterProvider(myServiceMeterProvider) {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>You'll need to <code>--require</code> this file when you run your app, such as:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} ts-node --require ./instrumentation.ts  {{&lt; /tab &gt;}} <p>{{&lt; tab JavaScript &gt;}} node --require ./instrumentation.js  {{&lt; /tab &gt;}} <p>{{&lt; /tabpane &gt;}}</p> <p>Now that a <code>MeterProvider</code> is configured, you can acquire a <code>Meter</code>.</p>"},{"location":"docs/instrumentation/js/manual/#acquiring-a-meter","title":"Acquiring a Meter","text":"<p>Anywhere in your application where you have manually instrumented code you can call <code>getMeter</code> to acquire a meter. For example:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import opentelemetry from \"opentelemetry/api\";</p> <p>const myMeter = opentelemetry.metrics.getMeter(   'my-service-meter' );</p> <p>// You can now use a 'meter' to create instruments! {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const opentelemetry = require('opentelemetry/api')</p> <p>const myMeter = opentelemetry.metrics.getMeter(   'my-service-meter' );</p> <p>// You can now use a 'meter' to create instruments! {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p> <p>It\u2019s generally recommended to call <code>getMeter</code> in your app when you need it rather than exporting the meter instance to the rest of your app. This helps avoid trickier application load issues when other required dependencies are involved.</p>"},{"location":"docs/instrumentation/js/manual/#synchronous-and-asynchronous-instruments","title":"Synchronous and asynchronous instruments","text":"<p>OpenTelemetry instruments are either synchronous or asynchronous (observable).</p> <p>Synchronous instruments take a measurement when they are called. The measurement is done as another call during program execution, just like any other function call. Periodically, the aggregation of these measurements is exported by a configured exporter. Because measurements are decoupled from exporting values, an export cycle may contain zero or multiple aggregated measurements.</p> <p>Asynchronous instruments, on the other hand, provide a measurement at the request of the SDK. When the SDK exports, a callback that was provided to the instrument on creation is invoked. This callback provides the SDK with a measurement that is immediately exported. All measurements on asynchronous instruments are performed once per export cycle.</p> <p>Asynchronous instruments are useful in several circumstances, such as:</p> <ul> <li>When updating a counter is not computationally cheap, and thus you don't want   the currently executing thread to have to wait for that measurement</li> <li>Observations need to happen at frequencies unrelated to program execution   (i.e., they cannot be accurately measured when tied to a request lifecycle)</li> <li>There is no value from knowing the precise timestamp of increments</li> </ul> <p>In cases like these, it's often better to observe a cumulative value directly, rather than aggregate a series of deltas in post-processing (the synchronous example). Take note of the use of <code>observe</code> rather than <code>add</code> in the appropriate code examples below.</p>"},{"location":"docs/instrumentation/js/manual/#using-counters","title":"Using Counters","text":"<p>Counters can by used to measure a non-negative, increasing value.</p> <pre><code>const counter = myMeter.createCounter('events.counter');\n//...\ncounter.add(1);\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#using-updown-counters","title":"Using UpDown Counters","text":"<p>UpDown counters can increment and decrement, allowing you to observe a cumulative value that goes up or down.</p> <pre><code>const counter = myMeter.createUpDownCounter('events.counter');\n//...\ncounter.add(1);\n//...\ncounter.add(-1);\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#using-histograms","title":"Using Histograms","text":"<p>Histograms are used to measure a distribution of values over time.</p> <p>For example, here's how you might report a distribution of response times for an API route with Express:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}} {{&lt; tab TypeScript &gt;}} import express from \"express\";</p> <p>const app = express();</p> <p>app.get('/', (_req, _res) =&gt; {   const histogram = myMeter.createHistogram(\"task.duration\");   const startTime = new Date().getTime()</p> <p>// do some work in an API call</p> <p>const endTime = new Date().getTime()   const executionTime = endTime - startTime</p> <p>// Record the duration of the task operation   histogram.record(executionTime) }); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const express = require('express');</p> <p>const app = express();</p> <p>app.get('/', (_req, _res) =&gt; {   const histogram = myMeter.createHistogram(\"task.duration\");   const startTime = new Date().getTime()</p> <p>// do some work in an API call</p> <p>const endTime = new Date().getTime()   const executionTime = endTime - startTime</p> <p>// Record the duration of the task operation   histogram.record(executionTime) }); {{&lt; /tab &gt;}} {{&lt; /tabpane&gt;}}</p>"},{"location":"docs/instrumentation/js/manual/#using-observable-async-counters","title":"Using Observable (Async) Counters","text":"<p>Observable counters can be used to measure an additive, non-negative, monotonically increasing value.</p> <pre><code>let events = [];\nconst addEvent = (name) =&gt; {\nevents = append(events, name);\n};\nconst counter = myMeter.createObservableCounter('events.counter');\ncounter.addCallback((result) =&gt; {\nresult.observe(len(events));\n});\n//... calls to addEvent\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#using-observable-async-updown-counters","title":"Using Observable (Async) UpDown Counters","text":"<p>Observable UpDown counters can increment and decrement, allowing you to measure an additive, non-negative, non-monotonically increasing cumulative value.</p> <pre><code>let events = [];\nconst addEvent = (name) =&gt; {\nevents = append(events, name);\n};\nconst removeEvent = () =&gt; {\nevents.pop();\n};\nconst counter = myMeter.createObservableUpDownCounter('events.counter');\ncounter.addCallback((result) =&gt; {\nresult.observe(len(events));\n});\n//... calls to addEvent and removeEvent\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#using-observable-async-gauges","title":"Using Observable (Async) Gauges","text":"<p>Observable Gauges should be used to measure non-additive values.</p> <pre><code>let temperature = 32;\nconst gauge = myMeter.createObservableGauge('temperature.gauge');\ngauge.addCallback((result) =&gt; {\nresult.observe(temperature);\n});\n//... temperature variable is modified by a sensor\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#describing-instruments","title":"Describing instruments","text":"<p>When you create instruments like counters, histograms, etc. you can give them a description.</p> <pre><code>const httpServerResponseDuration = myMeter.createHistogram(\n'http.server.duration',\n{\ndescription: 'A distribution of the HTTP server response times',\nunit: 'milliseconds',\nvalueType: ValueType.INT,\n}\n);\n</code></pre> <p>In JavaScript, each configuration type means the following:</p> <ul> <li><code>description</code> - a human-readable description for the instrument</li> <li><code>unit</code> - The description of the unit of measure that the value is intended to   represent. For example, <code>milliseconds</code> to measure duration, or <code>bytes</code> to   count number of bytes.</li> <li><code>valueType</code> - The kind of numeric value used in measurements.</li> </ul> <p>It's generally recommended to describe each instrument you create.</p>"},{"location":"docs/instrumentation/js/manual/#adding-attributes","title":"Adding attributes","text":"<p>You can add Attributes to metrics when they are generated.</p> <pre><code>const counter = myMeter.createCounter('my.counter');\ncounter.add(1, { 'some.optional.attribute': 'some value' });\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#configure-metric-views","title":"Configure Metric Views","text":"<p>A Metric View provides developers with the ability to customize metrics exposed by the Metrics SDK.</p>"},{"location":"docs/instrumentation/js/manual/#selectors","title":"Selectors","text":"<p>To instantiate a view, one must first select a target instrument. The following are valid selectors for metrics:</p> <ul> <li><code>instrumentType</code></li> <li><code>instrumentName</code></li> <li><code>meterName</code></li> <li><code>meterVersion</code></li> <li><code>meterSchemaUrl</code></li> </ul> <p>Selecting by <code>instrumentName</code> (of type string) has support for wildcards, so you can select all instruments using <code>*</code> or select all instruments whose name starts with <code>http</code> by using <code>http*</code>.</p>"},{"location":"docs/instrumentation/js/manual/#examples","title":"Examples","text":"<p>Filter attributes on all metric types:</p> <pre><code>const limitAttributesView = new View({\n// only export the attribute 'environment'\nattributeKeys: ['environment'],\n// apply the view to all instruments\ninstrumentName: '*',\n});\n</code></pre> <p>Drop all instruments with the meter name <code>pubsub</code>:</p> <pre><code>const dropView = new View({\naggregation: new DropAggregation(),\nmeterName: 'pubsub',\n});\n</code></pre> <p>Define explicit bucket sizes for the Histogram named <code>http.server.duration</code>:</p> <pre><code>const histogramView = new View({\naggregation: new ExplicitBucketHistogramAggregation([\n0, 1, 5, 10, 15, 20, 25, 30,\n]),\ninstrumentName: 'http.server.duration',\ninstrumentType: InstrumentType.HISTOGRAM,\n});\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#attach-to-meter-provider","title":"Attach to meter provider","text":"<p>Once views have been configured, attach them to the corresponding meter provider:</p> <pre><code>const meterProvider = new MeterProvider({\nviews: [limitAttributesView, dropView, histogramView],\n});\n</code></pre>"},{"location":"docs/instrumentation/js/manual/#next-steps","title":"Next steps","text":"<p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p>"},{"location":"docs/instrumentation/js/propagation/","title":"Propagation","text":"<p>Propagation is the mechanism that moves data between services and processes. Although not limited to tracing, it is what allows traces to build causal information about a system across services that are arbitrarily distributed across process and network boundaries.</p>"},{"location":"docs/instrumentation/js/propagation/#context-propagation-with-libraries","title":"Context propagation with libraries","text":"<p>For the vast majority of use cases, context propagation is done with instrumentation libraries.</p> <p>For example, if you have several Node.js services that communicate over HTTP, you can use the <code>express</code> and <code>http</code> instrumentation libraries to automatically propagate trace context across services for you.</p> <p>It is highly recommend that you use instrumentation libraries to propagate context. Although it is possible to propagate context manually, if your system uses libraries to communicate between services, use a matching instrumentation library to propagate context.</p> <p>Refer to Libraries to learn more about instrumentation libraries and how to use them.</p>"},{"location":"docs/instrumentation/js/propagation/#manual-w3c-trace-context-propagation","title":"Manual W3C Trace Context Propagation","text":"<p>In some cases, it is not possible to propagate context with an instrumentation library. There may not be an instrumentation library that matches a library you're using to have services communicate with one another. Or you many have requirements that instrumentation libraries cannot fulfill, even if they exist.</p> <p>When you must propagate context manually, you can use the context api.</p> <p>The following generic example demonstrates how you can propagate trace context manually.</p> <p>First, on the sending service, you'll need to inject the current <code>context</code>:</p> <pre><code>// Sending service\nimport { context, propagation, trace } from '@opentelemetry/api';\nconst output = {};\n// Serialize the traceparent and tracestate from context into\n// an output object.\n//\n// This example uses the active trace context, but you can\n// use whatever context is appropriate to your scenario.\npropagation.inject(context.active(), output);\nconst { traceparent, tracestate } = output;\n// You can then pass the traceparent and tracestate\n// data to whatever mechanism you use to propagate\n// across services.\n</code></pre> <p>On the receiving service, you'll need to extract <code>context</code> (for example, from parsed HTTP headers) and then set them as the current trace context.</p> <pre><code>// Receiving service\nimport { context, propagation, trace } from '@opentelemetry/api';\n// Assume \"input\" is an object with 'traceparent' &amp; 'tracestate' keys\nconst input = {};\n// Extracts the 'traceparent' and 'tracestate' data into a context object.\n//\n// You can then treat this context as the active context for your\n// traces.\nlet activeContext = propagation.extract(context.active(), input);\nlet tracer = trace.getTracer('app-name');\nlet span = tracer.startSpan(\nspanName,\n{\nattributes: {},\n},\nactiveContext\n);\n// Set the created span as active in the deserialized context.\ntrace.setSpan(activeContext, span);\n</code></pre> <p>From there, when you have a deserialized active context, you can create spans that will be a part of the same trace from the other service.</p> <p>You can also use the Context API to modify or set the deserialized context in other ways.</p>"},{"location":"docs/instrumentation/js/resources/","title":"Resources","text":"<p>A resource represents the entity producing telemetry as resource attributes. For example, a process producing telemetry that is running in a container on Kubernetes has a Pod name, a namespace, and possibly a deployment name. All three of these attributes can be included in the resource.</p> <p>In your observability backend, you can use resource information to better investigate interesting behavior. For example, if your trace or metrics data indicate latency in your system, you can narrow it down to a specific container, pod, or Kubernetes deployment.</p> <p>Below you will find some introductions on how to set up resource detection with the Node.js SDK.</p>"},{"location":"docs/instrumentation/js/resources/#setup","title":"Setup","text":"<p>Follow the instructions in the Getting Started - Node.js, so that you have the files <code>package.json</code>, <code>app.js</code> and <code>tracing.js</code>.</p>"},{"location":"docs/instrumentation/js/resources/#process-environment-resource-detection","title":"Process &amp; Environment Resource Detection","text":"<p>Out of the box, the Node.js SDK detects process and process runtime resources and takes attributes from the environment variable <code>OTEL_RESOURCE_ATTRIBUTES</code>. You can verify what it detects by turning on diagnostic logging in <code>tracing.js</code>:</p> <pre><code>// For troubleshooting, set the log level to DiagLogLevel.DEBUG\ndiag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);\n</code></pre> <p>Run the application with some values set to <code>OTEL_RESOURCE_ATTRIBUTES</code>, e.g. we set the <code>host.name</code> to identify the Host:</p> <pre><code>$ env OTEL_RESOURCE_ATTRIBUTES=\"host.name=localhost\" \\\nnode --require ./tracing.js app.js\n@opentelemetry/api: Registered a global for diag v1.2.0.\n...\nListening for requests on http://localhost:8080\nEnvDetector found resource. Resource { attributes: { 'host.name': 'localhost' } }\nProcessDetector found resource. Resource {\n  attributes: {\n    'process.pid': 12345,\n    'process.executable.name': 'node',\n    'process.command': '/app.js',\n    'process.command_line': '/bin/node /app.js',\n    'process.runtime.version': '16.17.0',\n    'process.runtime.name': 'nodejs',\n    'process.runtime.description': 'Node.js'\n  }\n}\n...\n</code></pre>"},{"location":"docs/instrumentation/js/resources/#adding-resources-with-environment-variables","title":"Adding resources with environment variables","text":"<p>In the above example, the SDK detected the process and also added the <code>host.name=localhost</code> attribute set via the environment variable automatically.</p> <p>Below you will find instructions to get resources detected automatically for you. However, you might run into the situation that no detector exists for the resource you need. In that case you can use the environment <code>OTEL_RESOURCE_ATTRIBUTES</code> to inject whatever you need. For example the following script adds Service, Host and OS resource attributes:</p> <pre><code>$ env OTEL_RESOURCE_ATTRIBUTES=\"service.name=app.js,service.namespace=tutorial,service.version=1.0,service.instance.id=`uuidgen`,host.name=${HOSTNAME:},host.type=`uname -m`,os.name=`uname -s`,os.version=`uname -r`\" \\\nnode --require ./tracing.js app.js\n...\nEnvDetector found resource. Resource {\n  attributes: {\n    'service.name': 'app.js',\n    'service.namespace': 'tutorial',\n    'service.version': '1.0',\n    'service.instance.id': '46D99F44-27AB-4006-9F57-3B7C9032827B',\n    'host.name': 'myhost',\n    'host.type': 'arm64',\n    'os.name': 'linux',\n    'os.version': '6.0'\n  }\n}\n...\n</code></pre>"},{"location":"docs/instrumentation/js/resources/#adding-resources-in-code","title":"Adding resources in code","text":"<p>Custom resources can also be configured in your code. The <code>NodeSDK</code> provides a configuration option, where you can set them. For example you can update the <code>tracing.js</code> like the following to have <code>service.*</code> attributes set:</p> <pre><code>...\nconst { Resource } = require('@opentelemetry/resources');\nconst { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');\n...\nconst sdk = new opentelemetry.NodeSDK({\n...\nresource: new Resource({\n[ SemanticResourceAttributes.SERVICE_NAME ]: \"yourServiceName\",\n[ SemanticResourceAttributes.SERVICE_NAMESPACE ]: \"yourNameSpace\",\n[ SemanticResourceAttributes.SERVICE_VERSION ]: \"1.0\",\n[ SemanticResourceAttributes.SERVICE_INSTANCE_ID ]: \"my-instance-id-1\",\n})\n...\n});\n...\n</code></pre> <p>Note: If you set your resource attributes via environment variable and code, the values set via the environment variable take precedence.</p>"},{"location":"docs/instrumentation/js/resources/#container-resource-detection","title":"Container Resource Detection","text":"<p>Use the same setup (<code>package.json</code>, <code>app.js</code> and <code>tracing.js</code> with debugging turned on) and <code>Dockerfile</code> with the following content in the same directory:</p> <pre><code>FROM node:latest\nWORKDIR /usr/src/app\nCOPY package.json ./\nRUN npm install\nCOPY . .\nEXPOSE 8080\nCMD [ \"node\", \"--require\", \"./tracing.js\", \"app.js\" ]\n</code></pre> <p>To make sure that you can stop your docker container with Ctrl + C (<code>SIGINT</code>) add the following to the bottom of <code>app.js</code>:</p> <pre><code>process.on('SIGINT', function () {\nprocess.exit();\n});\n</code></pre> <p>To get the id of your container detected automatically for you, install the following additional dependency:</p> <pre><code>npm install @opentelemetry/resource-detector-docker\n</code></pre> <p>Next, update your <code>tracing.js</code> like the following:</p> <pre><code>const opentelemetry = require('@opentelemetry/sdk-node');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\nconst { diag, DiagConsoleLogger, DiagLogLevel } = require('@opentelemetry/api');\nconst {\ndockerCGroupV1Detector,\n} = require('@opentelemetry/resource-detector-docker');\n// For troubleshooting, set the log level to DiagLogLevel.DEBUG\ndiag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);\nconst sdk = new opentelemetry.NodeSDK({\ntraceExporter: new opentelemetry.tracing.ConsoleSpanExporter(),\ninstrumentations: [getNodeAutoInstrumentations()],\nresourceDetectors: [dockerCGroupV1Detector],\n});\nsdk.start();\n</code></pre> <p>Build your docker image:</p> <pre><code>docker build . -t nodejs-otel-getting-started\n</code></pre> <p>Run your docker container:</p> <pre><code>$ docker run --rm -p 8080:8080 nodejs-otel-getting-started\n@opentelemetry/api: Registered a global for diag v1.2.0.\n...\nListening for requests on http://localhost:8080\nDockerCGroupV1Detector found resource. Resource {\nattributes: {\n'container.id': 'fffbeaf682f32ef86916f306ff9a7f88cc58048ab78f7de464da3c320ldb5c54'\n}\n}\n</code></pre> <p>The detector has extracted the <code>container.id</code> for you. However you might recognize that in this example, the process attributes and the attributes set via an environment variable are missing! To resolve this, when you set the <code>resourceDetectors</code> list you also need to specify the <code>envDetector</code> and <code>processDetector</code> detectors:</p> <pre><code>const opentelemetry = require('@opentelemetry/sdk-node');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\nconst { diag, DiagConsoleLogger, DiagLogLevel } = require('@opentelemetry/api');\nconst {\ndockerCGroupV1Detector,\n} = require('@opentelemetry/resource-detector-docker');\nconst { envDetector, processDetector } = require('@opentelemetry/resources');\n// For troubleshooting, set the log level to DiagLogLevel.DEBUG\ndiag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);\nconst sdk = new opentelemetry.NodeSDK({\ntraceExporter: new opentelemetry.tracing.ConsoleSpanExporter(),\ninstrumentations: [getNodeAutoInstrumentations()],\n// Make sure to add all detectors you need here!\nresourceDetectors: [envDetector, processDetector, dockerCGroupV1Detector],\n});\nsdk.start();\n</code></pre> <p>Rebuild your image and run your container once again:</p> <pre><code>docker run --rm -p 8080:8080 nodejs-otel-getting-started\n@opentelemetry/api: Registered a global for diag v1.2.0.\n...\nListening for requests on http://localhost:8080\nEnvDetector found resource. Resource { attributes: {} }\nProcessDetector found resource. Resource {\nattributes: {\n'process.pid': 1,\n    'process.executable.name': 'node',\n    'process.command': '/usr/src/app/app.js',\n    'process.command_line': '/usr/local/bin/node /usr/src/app/app.js',\n    'process.runtime.version': '18.9.0',\n    'process.runtime.name': 'nodejs',\n    'process.runtime.description': 'Node.js'\n}\n}\nDockerCGroupV1Detector found resource. Resource {\nattributes: {\n'container.id': '654d0670317b9a2d3fc70cbe021c80ea15339c4711fb8e8b3aa674143148d84e'\n}\n}\n...\n</code></pre>"},{"location":"docs/instrumentation/js/resources/#next-steps","title":"Next steps","text":"<p>There are more resource detectors you can add to your configuration, for example to get details about your Cloud environment or Deployment. You will find a list here.</p>"},{"location":"docs/instrumentation/js/sampling/","title":"Sampling","text":"<p>Sampling is a process that restricts the amount of traces that are generated by a system. The JavaScript SDK offers several head samplers.</p>"},{"location":"docs/instrumentation/js/sampling/#default-behavior","title":"Default behavior","text":"<p>By default, all spans are sampled, and thus, 100% of traces are sampled. If you do not need to manage data volume, don't bother setting a sampler.</p>"},{"location":"docs/instrumentation/js/sampling/#traceidratiobasedsampler","title":"TraceIDRatioBasedSampler","text":"<p>When sampling, the most common head sampler to use is the TraceIdRatioBasedSampler. It deterministically samples a percentage of traces that you pass in as a parameter.</p>"},{"location":"docs/instrumentation/js/sampling/#environment-variables","title":"Environment Variables","text":"<p>You can configure the TraceIdRatioBasedSampler with environment variables:</p> <pre><code>export OTEL_TRACES_SAMPLER=\"traceidratio\"\nexport OTEL_TRACES_SAMPLER_ARG=\"0.1\"\n</code></pre> <p>This tells the SDK to sample spans such that only 10% of traces get created.</p>"},{"location":"docs/instrumentation/js/sampling/#nodejs","title":"Node.js","text":"<p>You can also configure the TraceIdRatioBasedSampler in code. Here's an example for Node.js:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} import { TraceIdRatioBasedSampler } from 'opentelemetry/sdk-trace-node';</p> <p>const samplePercentage = 0.1;</p> <p>const sdk = new NodeSDK({   // Other SDK configuration parameters go here   sampler: new TraceIdRatioBasedSampler(samplePercentage), }); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const { TraceIdRatioBasedSampler } = require('opentelemetry/sdk-trace-node');</p> <p>const samplePercentage = 0.1;</p> <p>const sdk = new NodeSDK({   // Other SDK configuration parameters go here   sampler: new TraceIdRatioBasedSampler(samplePercentage), }); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/sampling/#browser","title":"Browser","text":"<p>You can also configure the TraceIdRatioBasedSampler in code. Here's an example for browser apps:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} import { WebTracerProvider, TraceIdRatioBasedSampler } from 'opentelemetry/sdk-trace-web';</p> <p>const samplePercentage = 0.1;</p> <p>const provider = new WebTracerProvider({     sampler: new TraceIdRatioBasedSampler(samplePercentage), }); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} const { WebTracerProvider, TraceIdRatioBasedSampler } = require('opentelemetry/sdk-trace-web');</p> <p>const samplePercentage = 0.1;</p> <p>const provider = new WebTracerProvider({     sampler: new TraceIdRatioBasedSampler(samplePercentage), }); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/serverless/","title":"Serverless","text":"<p>This guide shows how to get started with tracing serverless functions using OpenTelemetry instrumentation libraries.</p>"},{"location":"docs/instrumentation/js/serverless/#aws-lambda","title":"AWS Lambda","text":"<p>The following show how to use Lambda wrappers with OpenTelemetry to instrument AWS Lambda functions and send traces to a configured backend.</p> <p>If you are interested in a plug and play user experience, see OpenTelemetry Lambda Layers.</p>"},{"location":"docs/instrumentation/js/serverless/#dependencies","title":"Dependencies","text":"<p>First, create an empty package.json:</p> <pre><code>npm init -y\n</code></pre> <p>Then install the required dependencies:</p> <pre><code>npm install \\\n@opentelemetry/api \\\n@opentelemetry/auto-instrumentations-node \\\n@opentelemetry/exporter-trace-otlp-http \\\n@opentelemetry/instrumentation \\\n@opentelemetry/sdk-trace-base \\\n@opentelemetry/sdk-trace-node\n</code></pre>"},{"location":"docs/instrumentation/js/serverless/#aws-lambda-wrapper-code","title":"AWS Lambda wrapper code","text":"<p>This file contains all the OpenTelemetry logic, which enables tracing. Save the following code as <code>lambda-wrapper.js</code>.</p> <pre><code>/* lambda-wrapper.js */\nconst api = require('@opentelemetry/api');\nconst { BatchSpanProcessor } = require('@opentelemetry/sdk-trace-base');\nconst {\nOTLPTraceExporter,\n} = require('@opentelemetry/exporter-trace-otlp-http');\nconst { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');\nconst { registerInstrumentations } = require('@opentelemetry/instrumentation');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\napi.diag.setLogger(new api.DiagConsoleLogger(), api.DiagLogLevel.ALL);\nconst provider = new NodeTracerProvider();\nconst collectorOptions = {\nurl: '&lt;backend_url&gt;',\n};\nconst spanProcessor = new BatchSpanProcessor(\nnew OTLPTraceExporter(collectorOptions)\n);\nprovider.addSpanProcessor(spanProcessor);\nprovider.register();\nregisterInstrumentations({\ninstrumentations: [\ngetNodeAutoInstrumentations({\n'@opentelemetry/instrumentation-aws-lambda': {\ndisableAwsContextPropagation: true,\n},\n}),\n],\n});\n</code></pre> <p>Replace <code>&lt;backend_url&gt;</code> with the URL of your favorite backend to export all traces to it. If you don't have one setup already, you can check out Jaeger or Zipkin.</p> <p>Note that <code>disableAwsContextPropagation</code> is set to true. The reason for this is that the Lambda instrumentation tries to use the X-Ray context headers by default, unless active tracing is enabled for this function, this results in a non-sampled context, which creates a <code>NonRecordingSpan</code>.</p> <p>More details can be found in the instrumentation documentation.</p>"},{"location":"docs/instrumentation/js/serverless/#aws-lambda-function-handler","title":"AWS Lambda function handler","text":"<p>Now that you have a Lambda wrapper, create a simple handler that serves as a Lambda function. Save the following code as <code>handler.js</code>.</p> <pre><code>/* handler.js */\n'use strict';\nconst https = require('https');\nfunction getRequest() {\nconst url = 'https://opentelemetry.io/';\nreturn new Promise((resolve, reject) =&gt; {\nconst req = https.get(url, (res) =&gt; {\nresolve(res.statusCode);\n});\nreq.on('error', (err) =&gt; {\nreject(new Error(err));\n});\n});\n}\nexports.handler = async (event) =&gt; {\ntry {\nconst result = await getRequest();\nreturn {\nstatusCode: result,\n};\n} catch (error) {\nreturn {\nstatusCode: 400,\nbody: error.message,\n};\n}\n};\n</code></pre>"},{"location":"docs/instrumentation/js/serverless/#deployment","title":"Deployment","text":"<p>There are multiple ways of deploying your Lambda function:</p> <ul> <li>AWS Console</li> <li>AWS CLI</li> <li>Serverless Framework</li> <li>Terraform</li> </ul> <p>Here we will be using Serverless Framework, more details can be found in the Setting Up Serverless Framework guide.</p> <p>Create a file called <code>serverless.yml</code>:</p> <pre><code>service: lambda-otel-native\nframeworkVersion: '3'\nprovider:\nname: aws\nruntime: nodejs14.x\nregion: '&lt;your-region&gt;'\nenvironment:\nNODE_OPTIONS: --require lambda-wrapper\nfunctions:\nlambda-otel-test:\nhandler: handler.hello\n</code></pre> <p>For OpenTelemetry to work properly, <code>lambda-wrapper.js</code> must be included before any other file: the <code>NODE_OPTIONS</code> setting ensures this.</p> <p>Note if you are not using Serverless Framework to deploy your Lambda function, you must manually add this environment variable using the AWS Console UI.</p> <p>Finally, run the following command to deploy the project to AWS:</p> <pre><code>serverless deploy\n</code></pre> <p>You can now invoke the newly deployed Lambda function by using the AWS Console UI. You should expect to see spans related to the invocation of the Lambda function.</p>"},{"location":"docs/instrumentation/js/serverless/#visiting-the-backend","title":"Visiting the backend","text":"<p>You should now be able to view traces produced by OpenTelemetry from your Lambda function in the backend!</p>"},{"location":"docs/instrumentation/js/serverless/#gcp-function","title":"GCP function","text":"<p>The following shows how to instrument HTTP triggered function using the Google Cloud Platform (GCP) UI.</p>"},{"location":"docs/instrumentation/js/serverless/#creating-function","title":"Creating function","text":"<p>Login to GCP and create or select a project where your function should be placed. In the side menu go to Serverless and select Cloud Functions. Next, click on Create Function, and select 2nd generation for your environment, provide a function name and select your region.</p>"},{"location":"docs/instrumentation/js/serverless/#setup-environment-variable-for-otelwrapper","title":"Setup environment variable for otelwrapper","text":"<p>If closed, open the Runtime, build, connections and security settings menu and scroll down and add the environment variable <code>NODE_OPTIONS</code> with the following value:</p> <pre><code>--require ./otelwrapper.js\n</code></pre>"},{"location":"docs/instrumentation/js/serverless/#select-runtime","title":"Select runtime","text":"<p>On the next screen (Code), select Node.js version 16 for your runtime.</p>"},{"location":"docs/instrumentation/js/serverless/#establish-otel-wrapper","title":"Establish OTel wrapper","text":"<p>Create a new file called <code>otelwrapper.js</code>, that will be used to instrument your service. Please make sure that you provide a <code>SERVICE_NAME</code> and that you set the <code>&lt;address for your backend&gt;</code>.</p> <pre><code>/* otelwrapper.js */\nconst { Resource } = require('@opentelemetry/resources');\nconst {\nSemanticResourceAttributes,\n} = require('@opentelemetry/semantic-conventions');\nconst api = require('@opentelemetry/api');\nconst { BatchSpanProcessor } = require('@opentelemetry/sdk-trace-base');\nconst {\nOTLPTraceExporter,\n} = require('@opentelemetry/exporter-trace-otlp-http');\nconst { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');\nconst { registerInstrumentations } = require('@opentelemetry/instrumentation');\nconst {\ngetNodeAutoInstrumentations,\n} = require('@opentelemetry/auto-instrumentations-node');\nconst providerConfig = {\nresource: new Resource({\n[SemanticResourceAttributes.SERVICE_NAME]: '&lt;your function name&gt;',\n}),\n};\napi.diag.setLogger(new api.DiagConsoleLogger(), api.DiagLogLevel.ALL);\nconst provider = new NodeTracerProvider(providerConfig);\nconst collectorOptions = {\nurl: '&lt;address for your backend&gt;',\n};\nconst spanProcessor = new BatchSpanProcessor(\nnew OTLPTraceExporter(collectorOptions)\n);\nprovider.addSpanProcessor(spanProcessor);\nprovider.register();\nregisterInstrumentations({\ninstrumentations: [getNodeAutoInstrumentations()],\n});\n</code></pre>"},{"location":"docs/instrumentation/js/serverless/#establish-packagejson","title":"Establish package.json","text":"<p>Add the following content to your package.json:</p> <pre><code>{\n\"dependencies\": {\n\"@google-cloud/functions-framework\": \"^3.0.0\",\n\"@opentelemetry/api\": \"^1.3.0\",\n\"@opentelemetry/auto-instrumentations-node\": \"^0.35.0\",\n\"@opentelemetry/exporter-trace-otlp-http\": \"^0.34.0\",\n\"@opentelemetry/instrumentation\": \"^0.34.0\",\n\"@opentelemetry/sdk-node\": \"^0.34.0\",\n\"@opentelemetry/sdk-trace-base\": \"^1.8.0\",\n\"@opentelemetry/sdk-trace-node\": \"^1.8.0\",\n\"@opentelemetry/resources\": \"^1.8.0\",\n\"@opentelemetry/semantic-conventions\": \"^1.8.0\"\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/js/serverless/#add-http-call-to-function","title":"Add HTTP call to function","text":"<p>The following code makes a call to the OpenTelemetry web site to demonstrate an outbound call.</p> <pre><code>/* index.js */\nconst functions = require('@google-cloud/functions-framework');\nconst https = require('https');\nfunctions.http('helloHttp', (req, res) =&gt; {\nlet url = 'https://opentelemetry.io/';\nhttps\n.get(url, (response) =&gt; {\nres.send(`Response ${response.body}!`);\n})\n.on('error', (e) =&gt; {\nres.send(`Error ${e}!`);\n});\n});\n</code></pre>"},{"location":"docs/instrumentation/js/serverless/#backend","title":"Backend","text":"<p>If you run OTel collector in GCP VM you are likely to need to create VPC access connector to be able to send traces.</p>"},{"location":"docs/instrumentation/js/serverless/#deploy","title":"Deploy","text":"<p>Select Deploy in UI and await deployment to be ready.</p>"},{"location":"docs/instrumentation/js/serverless/#testing","title":"Testing","text":"<p>You can test the function using cloud shell from test tab.</p>"},{"location":"docs/instrumentation/js/automatic/_index/","title":"Automatic Instrumentation","text":"<p>Automatic instrumentation provides a way to instrument any Node.js application and capture telemetry data from many popular libraries and frameworks without any code changes.</p>"},{"location":"docs/instrumentation/js/automatic/_index/#setup","title":"Setup","text":"<p>Run the following commands to install the appropriate packages.</p> <pre><code>npm install --save @opentelemetry/api\nnpm install --save @opentelemetry/auto-instrumentations-node\n</code></pre> <p>The <code>@opentelemetry/api</code> and <code>@opentelemetry/auto-instrumentations-node</code> packages install the API, SDK, and the instrumentation tools.</p>"},{"location":"docs/instrumentation/js/automatic/_index/#configuring-the-module","title":"Configuring the module","text":"<p>The module is highly configurable.</p> <p>One option is to configure the module by way of using <code>env</code> to set environment variables from the CLI:</p> <pre><code>env OTEL_TRACES_EXPORTER=otlp OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=your-endpoint \\\nnode --require @opentelemetry/auto-instrumentations-node/register app.js\n</code></pre> <p>Alternatively, you can use <code>export</code> to set environment variables:</p> <pre><code>export OTEL_TRACES_EXPORTER=\"otlp\"\nexport OTEL_METRICS_EXPORTER=\"otlp\"\nexport OTEL_EXPORTER_OTLP_ENDPOINT=\"your-endpoint\"\nexport OTEL_NODE_RESOURCE_DETECTORS=\"env,host,os\"\nexport OTEL_SERVICE_NAME=\"your-service-name\"\nexport NODE_OPTIONS=\"--require @opentelemetry/auto-instrumentations-node/register\"\nnode app.js\n</code></pre> <p>By default, all SDK resource detectors are used. You can use the environment variable <code>OTEL_NODE_RESOURCE_DETECTORS</code> to enable only certain detectors, or completely disable them.</p> <p>To see the full range of configuration options, see Module Configuration.</p>"},{"location":"docs/instrumentation/js/automatic/_index/#supported-libraries-and-frameworks","title":"Supported libraries and frameworks","text":"<p>A number of popular Node.js libraries are auto-instrumented. For the full list, see Supported instrumentation.</p>"},{"location":"docs/instrumentation/js/automatic/_index/#troubleshooting","title":"Troubleshooting","text":"<p>You can set the log level by setting the <code>OTEL_LOG_LEVEL</code> environment variable to one of the following:</p> <ul> <li><code>none</code></li> <li><code>error</code></li> <li><code>warn</code></li> <li><code>info</code></li> <li><code>debug</code></li> <li><code>verbose</code></li> <li><code>all</code></li> <li>The default level is <code>info</code>.</li> </ul> <p>NOTES:</p> <ul> <li>In a production environment, it is recommended to set <code>OTEL_LOG_LEVEL</code> to   info.</li> <li>Logs are always sent to console, no matter the environment, or debug level.</li> <li>Debug logs are extremely verbose and can negatively impact the performance   of your application. Enable debug logging only when needed.</li> </ul>"},{"location":"docs/instrumentation/js/automatic/module-config/","title":"Automatic Instrumentation Configuration","text":"<p>This module is highly configurable by setting environment variables. Many aspects of the auto instrumentation's behavior can be configured for your needs, such as resource detectors, exporters, trace context propagation headers, and more.</p>"},{"location":"docs/instrumentation/js/automatic/module-config/#sdk-and-exporter-configuration","title":"SDK and exporter configuration","text":"<p>SDK and exporter configuration can be set using environment variables. More information can be found here.</p>"},{"location":"docs/instrumentation/js/automatic/module-config/#sdk-resource-detector-configuration","title":"SDK resource detector configuration","text":"<p>By default, the module will enable all SDK resource detectors. You can use the <code>OTEL_NODE_RESOURCE_DETECTORS</code> environment variable to enable only certain detectors, or completely disable them:</p> <ul> <li><code>env</code></li> <li><code>host</code></li> <li><code>os</code></li> <li><code>process</code></li> <li><code>container</code></li> <li><code>alibaba</code></li> <li><code>aws</code></li> <li><code>gcp</code></li> <li><code>all</code> - enables all resource detectors</li> <li><code>none</code> - disables resource detection</li> </ul> <p>For example, to only enable the <code>env</code> and <code>host</code> detectors, you can set:</p> <pre><code>OTEL_NODE_RESOURCE_DETECTORS=env,host\n</code></pre>"},{"location":"docs/instrumentation/js/getting-started/_index/","title":"Getting Started","text":"<p>These two guides for Node.js and the browser use simple examples in javascript to get you started with OpenTelemetry. Both will show you the following steps:</p> <ul> <li>Install the required OpenTelemetry libraries</li> <li>Initialize a global tracer</li> <li>Initialize and register a   span exporter</li> </ul>"},{"location":"docs/instrumentation/js/getting-started/browser/","title":"Browser","text":"<p>While this guide uses the example application presented below, the steps to instrument your own application should be similar.</p>"},{"location":"docs/instrumentation/js/getting-started/browser/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have the following installed locally:</p> <ul> <li>Node.js</li> <li>TypeScript, if you will be using   TypeScript.</li> </ul>"},{"location":"docs/instrumentation/js/getting-started/browser/#example-application","title":"Example Application","text":"<p>This is a very simple guide, if you'd like to see more complex examples go to examples/opentelemetry-web.</p> <p>Copy the following file into an empty directory and call it <code>index.html</code>.</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n&lt;meta charset=\"utf-8\" /&gt;\n&lt;title&gt;Document Load Instrumentation Example&lt;/title&gt;\n&lt;base href=\"/\" /&gt;\n&lt;!--\n      https://www.w3.org/TR/trace-context/\n      Set the `traceparent` in the server's HTML template code. It should be\n      dynamically generated server side to have the server's request trace Id,\n      a parent span Id that was set on the server's request span, and the trace\n      flags to indicate the server's sampling decision\n      (01 = sampled, 00 = notsampled).\n      '{version}-{traceId}-{spanId}-{sampleDecision}'\n    --&gt;\n&lt;meta\nname=\"traceparent\"\ncontent=\"00-ab42124a3c573678d4d8b21ba52df3bf-d21f7bc17caa5aba-01\"\n/&gt;\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    Example of using Web Tracer with document load instrumentation with console\n    exporter and collector exporter\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"docs/instrumentation/js/getting-started/browser/#installation","title":"Installation","text":"<p>To create traces in the browser, you will need <code>@opentelemetry/sdk-trace-web</code>, and the instrumentation <code>@opentelemetry/instrumentation-document-load</code>:</p> <pre><code>npm init -y\nnpm install @opentelemetry/api \\\n@opentelemetry/sdk-trace-web \\\n@opentelemetry/instrumentation-document-load \\\n@opentelemetry/context-zone\n</code></pre>"},{"location":"docs/instrumentation/js/getting-started/browser/#initialization-and-configuration","title":"Initialization and Configuration","text":"<p>If you are coding in TypeScript, then run the following command:</p> <pre><code>tsc --init\n</code></pre> <p>Then acquire parcel, which will (among other things) let you work in Typescript.</p> <pre><code>npm install --save-dev parcel\n</code></pre> <p>Create an empty code file named <code>document-load</code> with a <code>.ts</code> or <code>.js</code> extension, as appropriate, based on the language you've chosen to write your app in. Add the following code to your HTML right before the <code>&lt;/body&gt;</code> closing tag:</p> <p>{{&lt; tabpane lang=html persistLang=false &gt;}} {{&lt; tab TypeScript &gt;}}</p> <p>{{&lt; /tab &gt;}} {{&lt; tab JavaScript &gt;}}</p> <p>{{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p> <p>We will add some code that will trace the document load timings and output those as OpenTelemetry Spans.</p>"},{"location":"docs/instrumentation/js/getting-started/browser/#creating-a-tracer-provider","title":"Creating a Tracer Provider","text":"<p>Add the following code to the <code>document-load.ts|js</code> to create a tracer provider, which brings the instrumentation to trace document load:</p> <pre><code>/* document-load.ts|js file - the code snippet is the same for both the languages */\nimport { WebTracerProvider } from '@opentelemetry/sdk-trace-web';\nimport { DocumentLoadInstrumentation } from '@opentelemetry/instrumentation-document-load';\nimport { ZoneContextManager } from '@opentelemetry/context-zone';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\nconst provider = new WebTracerProvider();\nprovider.register({\n// Changing default contextManager to use ZoneContextManager - supports asynchronous operations - optional\ncontextManager: new ZoneContextManager(),\n});\n// Registering instrumentations\nregisterInstrumentations({\ninstrumentations: [new DocumentLoadInstrumentation()],\n});\n</code></pre> <p>Now build the app with parcel:</p> <pre><code>npx parcel index.html\n</code></pre> <p>and open the development webserver (e.g. at <code>http://localhost:1234</code>) to see if your code works.</p> <p>There will be no output of traces yet, for this we need to add an exporter.</p>"},{"location":"docs/instrumentation/js/getting-started/browser/#creating-an-exporter","title":"Creating an Exporter","text":"<p>In the following example, we will use the <code>ConsoleSpanExporter</code> which prints all spans to the console.</p> <p>In order to visualize and analyze your traces, you will need to export them to a tracing backend. Follow these instructions for setting up a backend and exporter.</p> <p>You may also want to use the <code>BatchSpanProcessor</code> to export spans in batches in order to more efficiently use resources.</p> <p>To export traces to the console, modify <code>document-load.ts|js</code> so that it matches the following code snippet:</p> <pre><code>/* document-load.ts|js file - the code is the same for both the languages */\nimport {\nConsoleSpanExporter,\nSimpleSpanProcessor,\n} from '@opentelemetry/sdk-trace-base';\nimport { WebTracerProvider } from '@opentelemetry/sdk-trace-web';\nimport { DocumentLoadInstrumentation } from '@opentelemetry/instrumentation-document-load';\nimport { ZoneContextManager } from '@opentelemetry/context-zone';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\nconst provider = new WebTracerProvider();\nprovider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));\nprovider.register({\n// Changing default contextManager to use ZoneContextManager - supports asynchronous operations - optional\ncontextManager: new ZoneContextManager(),\n});\n// Registering instrumentations\nregisterInstrumentations({\ninstrumentations: [new DocumentLoadInstrumentation()],\n});\n</code></pre> <p>Now, rebuild your application and open the browser again. In the console of the developer toolbar you should see some traces being exported:</p> <pre><code>{\n\"traceId\": \"ab42124a3c573678d4d8b21ba52df3bf\",\n\"parentId\": \"cfb565047957cb0d\",\n\"name\": \"documentFetch\",\n\"id\": \"5123fc802ffb5255\",\n\"kind\": 0,\n\"timestamp\": 1606814247811266,\n\"duration\": 9390,\n\"attributes\": {\n\"component\": \"document-load\",\n\"http.response_content_length\": 905\n},\n\"status\": {\n\"code\": 0\n},\n\"events\": [\n{\n\"name\": \"fetchStart\",\n\"time\": [1606814247, 811266158]\n},\n{\n\"name\": \"domainLookupStart\",\n\"time\": [1606814247, 811266158]\n},\n{\n\"name\": \"domainLookupEnd\",\n\"time\": [1606814247, 811266158]\n},\n{\n\"name\": \"connectStart\",\n\"time\": [1606814247, 811266158]\n},\n{\n\"name\": \"connectEnd\",\n\"time\": [1606814247, 811266158]\n},\n{\n\"name\": \"requestStart\",\n\"time\": [1606814247, 819101158]\n},\n{\n\"name\": \"responseStart\",\n\"time\": [1606814247, 819791158]\n},\n{\n\"name\": \"responseEnd\",\n\"time\": [1606814247, 820656158]\n}\n]\n}\n</code></pre>"},{"location":"docs/instrumentation/js/getting-started/browser/#add-instrumentations","title":"Add Instrumentations","text":"<p>If you want to instrument AJAX requests, User Interactions and others, you can register additional instrumentations for those:</p> <pre><code>registerInstrumentations({\ninstrumentations: [\nnew UserInteractionInstrumentation(),\nnew XMLHttpRequestInstrumentation(),\n],\n});\n</code></pre>"},{"location":"docs/instrumentation/js/getting-started/browser/#meta-packages-for-web","title":"Meta Packages for Web","text":"<p>To leverage the most common instrumentations all in one you can simply use the OpenTelemetry Meta Packages for Web</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/","title":"Node.js","text":"<p>This page will show you how to get started with OpenTelemetry in Node.js.</p> <p>You will learn how you can instrument a simple application automatically, in such a way that traces, metrics and logs are emitted to the console.</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have the following installed locally:</p> <ul> <li>Node.js</li> <li>TypeScript, if you will be using   TypeScript.</li> </ul>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#example-application","title":"Example Application","text":"<p>The following example uses a basic Express application. If you are not using Express, that's ok \u2014 you can use OpenTelemetry JavaScript with other web frameworks as well, such as Koa and Nest.JS. For a complete list of libraries for supported frameworks, see the registry.</p> <p>For more elaborate examples, see examples.</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#dependencies","title":"Dependencies","text":"<p>To begin, set up an empty <code>package.json</code> in a new directory:</p> <pre><code>npm init -y\n</code></pre> <p>Next, install Express dependencies.</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} npm install typescript \\   ts-node \\   types/node \\   express \\   types/express {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} npm install express {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#create-and-launch-an-http-server","title":"Create and launch an HTTP Server","text":"<p>Create a file named <code>app.ts</code> (or <code>app.js</code> if not using typescript) and add the following code to it:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} /app.ts/ import express, { Express } from \"express\";</p> <p>const PORT: number = parseInt(process.env.PORT || \"8080\"); const app: Express = express();</p> <p>function getRandomNumber(min: number, max: number) {   return Math.floor(Math.random() * (max - min) + min); }</p> <p>app.get(\"/rolldice\", (req, res) =&gt; {   res.send(getRandomNumber(1, 6).toString()); });</p> <p>app.listen(PORT, () =&gt; {   console.log(<code>Listening for requests on http://localhost:${PORT}</code>); }); {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} /app.js/ const express = require(\"express\");</p> <p>const PORT = parseInt(process.env.PORT || \"8080\"); const app = express();</p> <p>function getRandomNumber(min, max) {   return Math.floor(Math.random() * (max - min) + min); }</p> <p>app.get(\"/rolldice\", (req, res) =&gt; {   res.send(getRandomNumber(1, 6).toString()); });</p> <p>app.listen(PORT, () =&gt; {   console.log(<code>Listening for requests on http://localhost:${PORT}</code>); }); {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane&gt;}}</p> <p>Run the application with the following command and open http://localhost:8080/rolldice in your web browser to ensure it is working.</p> <p>{{&lt; tabpane lang=console persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} $ npx ts-node app.ts Listening for requests on http://localhost:8080 {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} $ node app.js Listening for requests on http://localhost:8080 {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#instrumentation","title":"Instrumentation","text":"<p>The following shows how to install, initialize, and run an application instrumented with OpenTelemetry.</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#dependencies_1","title":"Dependencies","text":"<p>First, install the Node SDK and autoinstrumentations package.</p> <p>The Node SDK lets you initialize OpenTelemetry with several configuration defaults that are correct for the majority of use cases.</p> <p>The <code>auto-instrumentations-node</code> package installs instrumentation packages that will automatically create spans corresponding to code called in libraries. In this case, it provides instrumentation for Express, letting the example app automatically create spans for each incoming request.</p> <pre><code>npm install @opentelemetry/sdk-node \\\n@opentelemetry/api \\\n@opentelemetry/auto-instrumentations-node \\\n@opentelemetry/sdk-metrics\n</code></pre> <p>To find all autoinstrumentation modules, you can look at the registry.</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#setup","title":"Setup","text":"<p>The instrumentation setup and configuration must be run before your application code. One tool commonly used for this task is the --require flag.</p> <p>Create a file named <code>instrumentation.ts</code> (or <code>instrumentation.js</code> if not using typescript) , which will contain your instrumentation setup code.</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} /instrumentation.ts/ import { NodeSDK } from 'opentelemetry/sdk-node'; import { ConsoleSpanExporter } from 'opentelemetry/sdk-trace-node'; import { getNodeAutoInstrumentations } from 'opentelemetry/auto-instrumentations-node'; import { PeriodicExportingMetricReader, ConsoleMetricExporter } from 'opentelemetry/sdk-metrics';</p> <p>const sdk = new NodeSDK({   traceExporter: new ConsoleSpanExporter(),   metricReader: new PeriodicExportingMetricReader({     exporter: new ConsoleMetricExporter()   }),   instrumentations: [getNodeAutoInstrumentations()] });</p> <p>sdk   .start()</p> <p>{{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} /instrumentation.js/ // Require dependencies const { NodeSDK } = require('opentelemetry/sdk-node'); const { ConsoleSpanExporter } = require('opentelemetry/sdk-trace-node'); const { getNodeAutoInstrumentations } = require('opentelemetry/auto-instrumentations-node'); const { PeriodicExportingMetricReader, ConsoleMetricExporter } = require('opentelemetry/sdk-metrics');</p> <p>const sdk = new NodeSDK({   traceExporter: new ConsoleSpanExporter(),   metricReader: new PeriodicExportingMetricReader({     exporter: new ConsoleMetricExporter()   }),   instrumentations: [getNodeAutoInstrumentations()] });</p> <p>sdk   .start() {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#run-the-instrumented-app","title":"Run the instrumented app","text":"<p>Now you can run your application as you normally would, but you can use the <code>--require</code> flag to load the instrumentation before the application code.</p> <p>{{&lt; tabpane lang=console persistLang=false &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} $ npx ts-node --require ./instrumentation.ts app.ts Listening for requests on http://localhost:8080 {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} $ node --require ./instrumentation.js app.js Listening for requests on http://localhost:8080 {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <p>Open http://localhost:8080/rolldice in your web browser and reload the page a few times. After a while you should see the spans printed in the console by the <code>ConsoleSpanExporter</code>.</p> View example output <pre><code>{\n\"traceId\": \"3f1fe6256ea46d19ec3ca97b3409ad6d\",\n\"parentId\": \"f0b7b340dd6e08a7\",\n\"name\": \"middleware - query\",\n\"id\": \"41a27f331c7bfed3\",\n\"kind\": 0,\n\"timestamp\": 1624982589722992,\n\"duration\": 417,\n\"attributes\": {\n\"http.route\": \"/\",\n\"express.name\": \"query\",\n\"express.type\": \"middleware\"\n},\n\"status\": { \"code\": 0 },\n\"events\": []\n}\n{\n\"traceId\": \"3f1fe6256ea46d19ec3ca97b3409ad6d\",\n\"parentId\": \"f0b7b340dd6e08a7\",\n\"name\": \"middleware - expressInit\",\n\"id\": \"e0ed537a699f652a\",\n\"kind\": 0,\n\"timestamp\": 1624982589725778,\n\"duration\": 673,\n\"attributes\": {\n\"http.route\": \"/\",\n\"express.name\": \"expressInit\",\n\"express.type\": \"middleware\"\n},\n\"status\": { code: 0 },\n\"events\": []\n}\n{\n\"traceId\": \"3f1fe6256ea46d19ec3ca97b3409ad6d\",\n\"parentId\": \"f0b7b340dd6e08a7\",\n\"name\": \"request handler - /\",\n\"id\": \"8614a81e1847b7ef\",\n\"kind\": 0,\n\"timestamp\": 1624982589726941,\n\"duration\": 21,\n\"attributes\": {\n\"http.route\": \"/\",\n\"express.name\": \"/\",\n\"express.type\": \"request_handler\"\n},\n\"status\": { code: 0 },\n\"events\": []\n}\n{\n\"traceId\": \"3f1fe6256ea46d19ec3ca97b3409ad6d\",\n\"parentId\": undefined,\n\"name\": \"GET /\",\n\"id\": \"f0b7b340dd6e08a7\",\n\"kind\": 1,\n\"timestamp\": 1624982589720260,\n\"duration\": 11380,\n\"attributes\": {\n\"http.url\": \"http://localhost:8080/\",\n\"http.host\": \"localhost:8080\",\n\"net.host.name\": \"localhost\",\n\"http.method\": \"GET\",\n\"http.route\": \"\",\n\"http.target\": \"/\",\n\"http.user_agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\",\n\"http.flavor\": \"1.1\",\n\"net.transport\": \"ip_tcp\",\n\"net.host.ip\": \"::1\",\n\"net.host.port\": 8080,\n\"net.peer.ip\": \"::1\",\n\"net.peer.port\": 61520,\n\"http.status_code\": 304,\n\"http.status_text\": \"NOT MODIFIED\"\n},\n\"status\": { \"code\": 1 },\n\"events\": []\n}\n</code></pre> <p>The generated span tracks the lifetime of a request to the <code>/rolldice</code> route.</p> <p>Send a few more requests to the endpoint. After a moment, you'll see metrics in the console output, such as the following:</p> View example output <pre><code>{\n  descriptor: {\n    name: 'http.server.duration',\n    type: 'HISTOGRAM',\n    description: 'measures the duration of the inbound HTTP requests',\n    unit: 'ms',\n    valueType: 1\n},\n  dataPointType: 0,\n  dataPoints: [\n{\n      attributes: [Object],\n      startTime: [Array],\n      endTime: [Array],\n      value: [Object]\n}\n]\n}\n{\n  descriptor: {\n    name: 'http.client.duration',\n    type: 'HISTOGRAM',\n    description: 'measures the duration of the outbound HTTP requests',\n    unit: 'ms',\n    valueType: 1\n},\n  dataPointType: 0,\n  dataPoints: []\n}\n{\n  descriptor: {\n    name: 'db.client.connections.usage',\n    type: 'UP_DOWN_COUNTER',\n    description: 'The number of connections that are currently in the state referenced by the attribute \"state\".',\n    unit: '{connections}',\n    valueType: 1\n},\n  dataPointType: 3,\n  dataPoints: []\n}\n{\n  descriptor: {\n    name: 'http.server.duration',\n    type: 'HISTOGRAM',\n    description: 'measures the duration of the inbound HTTP requests',\n    unit: 'ms',\n    valueType: 1\n},\n  dataPointType: 0,\n  dataPoints: [\n{\n      attributes: [Object],\n      startTime: [Array],\n      endTime: [Array],\n      value: [Object]\n}\n]\n}\n{\n  descriptor: {\n    name: 'http.client.duration',\n    type: 'HISTOGRAM',\n    description: 'measures the duration of the outbound HTTP requests',\n    unit: 'ms',\n    valueType: 1\n},\n  dataPointType: 0,\n  dataPoints: []\n}\n{\n  descriptor: {\n    name: 'db.client.connections.usage',\n    type: 'UP_DOWN_COUNTER',\n    description: 'The number of connections that are currently in the state referenced by the attribute \"state\".',\n    unit: '{connections}',\n    valueType: 1\n},\n  dataPointType: 3,\n  dataPoints: []\n}\n{\n  descriptor: {\n    name: 'http.server.duration',\n    type: 'HISTOGRAM',\n    description: 'measures the duration of the inbound HTTP requests',\n    unit: 'ms',\n    valueType: 1\n},\n  dataPointType: 0,\n  dataPoints: [\n{\n      attributes: [Object],\n      startTime: [Array],\n      endTime: [Array],\n      value: [Object]\n}\n]\n}\n{\n  descriptor: {\n    name: 'http.client.duration',\n    type: 'HISTOGRAM',\n    description: 'measures the duration of the outbound HTTP requests',\n    unit: 'ms',\n    valueType: 1\n},\n  dataPointType: 0,\n  dataPoints: []\n}\n{\n  descriptor: {\n    name: 'db.client.connections.usage',\n    type: 'UP_DOWN_COUNTER',\n    description: 'The number of connections that are currently in the state referenced by the attribute \"state\".',\n    unit: '{connections}',\n    valueType: 1\n},\n  dataPointType: 3,\n  dataPoints: []\n}\n</code></pre>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#next-steps","title":"Next Steps","text":"<p>Enrich your instrumentation generated automatically with manual instrumentation of your own codebase. This gets you customized observability data.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p>"},{"location":"docs/instrumentation/js/getting-started/nodejs/#troubleshooting","title":"Troubleshooting","text":"<p>Did something go wrong? You can enable diagnostic logging to validate that OpenTelemetry is initialized correctly:</p> <p>{{&lt; tabpane langEqualsHeader=true &gt;}}</p> <p>{{&lt; tab TypeScript &gt;}} /instrumentation.ts/ import { diag, DiagConsoleLogger, DiagLogLevel } from 'opentelemetry/api';</p> <p>// For troubleshooting, set the log level to DiagLogLevel.DEBUG diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.INFO);</p> <p>// const sdk = new NodeSDK({... {{&lt; /tab &gt;}}</p> <p>{{&lt; tab JavaScript &gt;}} /instrumentation.js/ // Require dependencies const { diag, DiagConsoleLogger, DiagLogLevel } = require('opentelemetry/api');</p> <p>// For troubleshooting, set the log level to DiagLogLevel.DEBUG diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.INFO);</p> <p>// const sdk = new NodeSDK({... {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p>"},{"location":"docs/instrumentation/net/_index/","title":".NET","text":"<p>{{% lang_instrumentation_index_head dotnet %}}</p> <p>* While the OpenTelemetryLoggerProvider (i.e integration with ILogger) is stable, the OTLP Log Exporter is still non-stable.</p> <p>{{% /lang_instrumentation_index_head %}}</p>"},{"location":"docs/instrumentation/net/_index/#version-support","title":"Version Support","text":"<p>OpenTelemetry for .NET supports all officially supported versions of .NET Core and .NET Framework except for .NET Framework 3.5 SP1.</p>"},{"location":"docs/instrumentation/net/_index/#repositories","title":"Repositories","text":"<p>OpenTelemetry .NET consists of the following repositories:</p> <ul> <li>OpenTelemetry .NET</li> <li>OpenTelemetry .NET Contrib</li> <li>OpenTelemetry .NET Automatic Instrumentation</li> </ul>"},{"location":"docs/instrumentation/net/automatic/","title":"Automatic Instrumentation","text":"<p>You can use automatic instrumentation to initialize signal providers and generate telemetry data for supported instrumented libraries without modifying the application's source code.</p> <p>Here you can find the latest release of OpenTelemetry .NET Automatic Instrumentation.</p> <p>You can find the documentation in the project's repository.</p>"},{"location":"docs/instrumentation/net/automatic/#next-steps","title":"Next steps","text":"<p>After you have set up the automatic instrumentation, you may want to add manual instrumentation to collect custom telemetry data.</p> <p>If you do not want to rely on automatic instrumentation, which is currently in beta, you may want to use instrumentation libraries explicitly instead.</p>"},{"location":"docs/instrumentation/net/exporters/","title":"Exporters","text":"<p>In order to visualize and analyze your traces and metrics, you will need to export them to a backend.</p>"},{"location":"docs/instrumentation/net/exporters/#console-exporter","title":"Console exporter","text":"<p>The console exporter is useful for development and debugging tasks, and is the simplest to set up.</p> <pre><code>dotnet add package OpenTelemetry.Exporter.Console\ndotnet add package OpenTelemetry.Extensions.Hosting\n</code></pre> <p>If you're using ASP.NET Core, configure the exporter in your ASP.NET Core services:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddOpenTelemetry().WithTracing(b =&gt;\n{\nb.AddConsoleExporter()\n// The rest of your setup code goes here too\n});\n</code></pre> <p>Otherwise, configure the exporter when creating a tracer provider:</p> <pre><code>using var tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddConsoleExporter()\n// Other setup code, like setting a resource goes here too\n.Build();\n</code></pre>"},{"location":"docs/instrumentation/net/exporters/#otlp-endpoint","title":"OTLP endpoint","text":"<p>To send trace data to an OTLP endpoint (like the collector or Jaeger) you'll want to configure an OTLP exporter that sends to your endpoint.</p> <pre><code>dotnet add package OpenTelemetry.Exporter.OpenTelemetryProtocol\ndotnet add package OpenTelemetry.Extensions.Hosting\n</code></pre> <p>If you're using ASP.NET Core, configure the exporter in your ASP.NET Core services:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(b =&gt;\n{\nb.AddOtlpExporter()\n// The rest of your setup code goes here too\n});\n</code></pre> <p>This will, by default, send traces using gRPC to http://localhost:4317, to customize this to use HTTP and the protobuf format, you can add options like this:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(b =&gt;\n{\nb\n.AddOtlpExporter(opt =&gt;\n{\nopt.Endpoint = new Uri(\"your-endpoint-here\");\nopt.Protocol = OtlpExportProtocol.HttpProtobuf;\n})\n// The rest of your setup code goes here too\n});\n</code></pre> <p>Otherwise, configure the exporter when creating a tracer provider:</p> <pre><code>using var tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddOtlpExporter(opt =&gt;\n{\nopt.Endpoint = new Uri(\"your-endpoint-here\");\nopt.Protocol = OtlpExportProtocol.HttpProtobuf;\n})\n// Other setup code, like setting a resource goes here too\n.Build();\n</code></pre> <p>Use environment variables to set values like headers and an endpoint URL for production.</p>"},{"location":"docs/instrumentation/net/exporters/#note-for-net-core-31-and-below-and-grpc","title":"Note for .NET Core 3.1 and below and gRPC","text":"<p>Note: Versions below .NET 6 are not officially supported by opentelemetry-dotnet, therefore this section is here to help, but may not work as the library progresses.</p> <p>If you're not using ASP.NET Core gRPC and you are running on .NET Core 3.x, you'll need to add the following at application startup</p> <pre><code>AppContext.SetSwitch(\"System.Net.Http.SocketsHttpHandler.Http2UnencryptedSupport\", true);\n</code></pre> <p>If you are using .NET 5 or higher, the previous code sample is not required.</p>"},{"location":"docs/instrumentation/net/exporters/#jaeger","title":"Jaeger","text":"<p>To try out the OTLP exporter, you can run Jaeger as an OTLP endpoint and for trace visualization in a docker container:</p> <pre><code>docker run -d --name jaeger \\\n-e COLLECTOR_OTLP_ENABLED=true \\\n-p 16686:16686 \\\n-p 4317:4317 \\\n-p 4318:4318 \\\njaegertracing/all-in-one:latest\n</code></pre>"},{"location":"docs/instrumentation/net/exporters/#zipkin","title":"Zipkin","text":"<p>If you are using Zipkin to visualize trace data, you'll need to set it up first. This is how to run it in a docker container:</p> <pre><code>docker run --rm -d -p 9411:9411 --name zipkin openzipkin/zipkin\n</code></pre> <p>Next, install the Zipkin exporter package:</p> <pre><code>dotnet add package OpenTelemetry.Exporter.Zipkin\ndotnet add package OpenTelemetry.Extensions.Hosting\n</code></pre> <p>If you're using ASP.NET Core, configure the exporter in your ASP.NET Core services:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(b =&gt;\n{\nb.AddZipkinExporter(o =&gt;\n{\no.Endpoint = new Uri(\"your-zipkin-uri-here\");\n})\n// The rest of your setup code goes here too\n});\n</code></pre> <p>Otherwise, configure the exporter when creating a tracer provider:</p> <pre><code>using var tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddZipkinExporter(o =&gt;\n{\no.Endpoint = new Uri(\"your-zipkin-uri-here\");\n})\n// Other setup code, like setting a resource goes here too\n.Build();\n</code></pre>"},{"location":"docs/instrumentation/net/exporters/#prometheus-experimental","title":"Prometheus (Experimental)","text":"<p>*Note: this is experimental and dependent on the OpenTelemetry specification to be made stable before it will be a released package. For now, we recommend using the OTLP exporter and using the OpenTelemetry Collector to send metrics to Prometheus*</p> <p>If you're using Prometheus to visualize metrics data, you'll need to set it up first. Here's how to do it using a docker container:</p> <p>First, you'll need a <code>prometheus.yml</code> file to configure your Prometheus backend, such as the following:</p> <pre><code>global:\n  scrape_interval: 1s\n  evaluation_interval: 1s\n\nscrape_configs:\n  - job_name: prometheus\n    static_configs:\n      - targets: [localhost:9090]\n</code></pre> <p>Next, run the following docker command to set up Prometheus:</p> <pre><code>docker run \\\n-p 9090:9090 \\\n-v ${PWD}/prometheus.yml:/etc/prometheus/prometheus.yml \\\nprom/prometheus\n</code></pre> <p>Next, install the Prometheus exporter:</p>"},{"location":"docs/instrumentation/net/exporters/#aspnet","title":"ASP.NET","text":"<pre><code>dotnet add package OpenTelemetry.Exporter.Prometheus.AspNetCore --version 1.4.0-rc.4\ndotnet add package OpenTelemetry.Extensions.Hosting\n</code></pre> <p>If you're using ASP.NET Core, configure the exporter in your ASP.NET Core services:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddOpenTelemetry()\n.WithMetrics(b =&gt; b.AddPrometheusExporter());\n</code></pre> <p>You'll then need to add the endpoint so that Prometheus can scrape your site. You can do this using the <code>IAppBuilder</code> extension like this:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\n// .. Setup\nvar app = builder.Build();\napp.UseOpenTelemetryPrometheusScrapingEndpoint();\nawait app.RunAsync();\n</code></pre>"},{"location":"docs/instrumentation/net/exporters/#non-aspnet-core","title":"Non-ASP.NET Core","text":"<p>For applications not using ASP.NET Core, you can use the <code>HttpListener</code> version which is available in a different package:</p> <pre><code>dotnet add package OpenTelemetry.Exporter.Prometheus.HttpListener --version 1.4.0-rc.4\n</code></pre> <p>Then this is setup directly on the <code>MeterProviderBuilder</code>:</p> <pre><code>var meterProvider = Sdk.CreateMeterProviderBuilder()\n.AddMeter(MyMeter.Name)\n.AddPrometheusHttpListener(\noptions =&gt; options.UriPrefixes = new string[] { \"http://localhost:9090/\" })\n.Build();\n</code></pre> <p>Finally, register the Prometheus scraping middleware using the <code>UseOpenTelemetryPrometheusScrapingEndpoint</code> extension method on <code>IApplicationBuilder</code> :</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\nvar app = builder.Build();\napp.UseOpenTelemetryPrometheusScrapingEndpoint();\n</code></pre> <p>Further details on configuring the Prometheus exporter can be found here.</p>"},{"location":"docs/instrumentation/net/exporters/#next-steps","title":"Next steps","text":"<p>To ensure you're getting the most data as easily as possible, install instrumentation libraries to generate observability data.</p> <p>Additionally, enriching your codebase with manual instrumentation gives you customized observability data.</p> <p>You can also check the automatic instrumentation for .NET, which is currently in beta.</p>"},{"location":"docs/instrumentation/net/getting-started/","title":"Getting Started","text":"<p>OpenTelemetry for .NET is unique among OpenTelemetry implementations, as it is integrated with the .NET <code>System.Diagnostics</code> library. At a high level, you can think of OpenTelemetry for .NET as a bridge between the telemetry available through <code>System.Diagnostics</code> and the greater OpenTelemetry ecosystem, such as OpenTelemetry Protocol (OTLP) and the OpenTelemetry Collector.</p>"},{"location":"docs/instrumentation/net/getting-started/#aspnet-core","title":"ASP.NET Core","text":"<p>The following example demonstrates using Instrumentation Libraries and manual instrumentation via an ASP.NET Core app.</p> <p>First, create your basic ASP.NET Core site:</p> <pre><code>dotnet new mvc\n</code></pre> <p>Next, Add the Core OpenTelemetry packages</p> <pre><code>dotnet add package OpenTelemetry.Exporter.Console\ndotnet add package OpenTelemetry.Extensions.Hosting\n</code></pre> <p>Now let's add the instrumentation packages for ASP.NET Core. This will give us some automatic spans for each HTTP request to our app.</p> <pre><code>dotnet add package OpenTelemetry.Instrumentation.AspNetCore --prerelease\n</code></pre> <p>Note that as the Semantic Conventions for attribute names are not currently stable the instrumentation package is currently not in a released state. That doesn't mean that the functionality itself is not stable. This means that you need to use the <code>--prerelease</code> flag, or install a specific version of the package</p>"},{"location":"docs/instrumentation/net/getting-started/#setup","title":"Setup","text":"<p>Next, we need to add OpenTelemetry to our Service Collection in <code>Program.cs</code> so that its listening correctly.</p> <pre><code>using System.Diagnostics;\nusing OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\nvar builder = WebApplication.CreateBuilder(args);\n// .. other setup\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(tracerProviderBuilder =&gt;\ntracerProviderBuilder\n.AddSource(DiagnosticsConfig.ActivitySource.Name)\n.ConfigureResource(resource =&gt; resource\n.AddService(DiagnosticsConfig.ServiceName))\n.AddAspNetCoreInstrumentation()\n.AddConsoleExporter());\n// ... other setup\npublic static class DiagnosticsConfig\n{\npublic const string ServiceName = \"MyService\";\npublic static ActivitySource ActivitySource = new ActivitySource(ServiceName);\n}\n</code></pre> <p>At this stage, you should be able to run your site, and see a Console output similar to this:</p> <p>Note: an <code>Activity</code> in .NET is analogous to a Span in OpenTelemetry terminology</p> View example output <pre><code>Activity.TraceId:            54d084eba205a7a39398df4642be8f4a\nActivity.SpanId:             aca5e39a86a17d59\nActivity.TraceFlags:         Recorded\nActivity.ActivitySourceName: Microsoft.AspNetCore\nActivity.DisplayName:        /\nActivity.Kind:               Server\nActivity.StartTime:          2023-02-21T12:19:28.2499974Z\nActivity.Duration:           00:00:00.3106744\nActivity.Tags:\n    net.host.name: localhost\n    net.host.port: 5123\n    http.method: GET\n    http.scheme: http\n    http.target: /\n    http.url: http://localhost:5123/\n    http.flavor: 1.1\n    http.user_agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.50\n    http.status_code: 200\nResource associated with Activity:\n    service.name: MyService\n    service.instance.id: 2c7ca153-e460-4643-b550-7c08487a4c0c\n</code></pre>"},{"location":"docs/instrumentation/net/getting-started/#manual-instrumentation","title":"Manual Instrumentation","text":"<p>Next, add tracing via the <code>System.Diagnostics</code> API.</p> <p>Paste the following code into your <code>HomeController</code>'s <code>Index</code> action:</p> <pre><code>public IActionResult Index()\n{\n// Track work inside of the request\nusing var activity = DiagnosticsConfig.ActivitySource.StartActivity(\"SayHello\");\nactivity?.SetTag(\"foo\", 1);\nactivity?.SetTag(\"bar\", \"Hello, World!\");\nactivity?.SetTag(\"baz\", new int[] { 1, 2, 3 });\nreturn View();\n}\n</code></pre> <p>When you run the app and navigate to the <code>/</code> route, you'll see output about spans similar to the following:</p> View example output <pre><code>Activity.TraceId:            47d25efc8b5e9184ce57e692f5f65465\nActivity.SpanId:             bb864adcf4592f54\nActivity.TraceFlags:         Recorded\nActivity.ParentSpanId:       acbff23f5ad721ff\nActivity.ActivitySourceName: MyService\nActivity.DisplayName:        SayHello\nActivity.Kind:               Internal\nActivity.StartTime:          2023-02-21T12:27:41.9596458Z\nActivity.Duration:           00:00:00.0005683\nActivity.Tags:\n    foo: 1\n    bar: Hello, World!\n    baz: [1,2,3]\nResource associated with Activity:\n    service.name: MyService\n    service.instance.id: 2b07a9ca-29c4-4e01-b0ed-929184b32192\n</code></pre> <p>You'll notice the <code>Activity</code> objects from ASP.NET Core alongside the <code>Activity</code> we created manually in our controller action.</p>"},{"location":"docs/instrumentation/net/getting-started/#metrics","title":"Metrics","text":"<p>Next we'll add the ASP.NET Core automatically generated metrics to the app.</p> <pre><code>using OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\nusing OpenTelemetry.Metrics;\nvar builder = WebApplication.CreateBuilder(args);\n// .. other setup\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(/*  .. tracing setup */ )\n.WithMetrics(metricsProviderBuilder =&gt;\nmetricsProviderBuilder\n.ConfigureResource(resource =&gt; resource\n.AddService(DiagnosticsConfig.ServiceName))\n.AddAspNetCoreInstrumentation()\n.AddConsoleExporter());\n// .. other setup\n</code></pre> <p>If you run your application now, you'll see a series of metrics output to the console. like this.</p> View example output <pre><code>Export http.server.duration, Measures the duration of inbound HTTP requests., Unit: ms, Meter: OpenTelemetry.Instrumentation.AspNetCore/1.0.0.0\n(2023-02-21T12:38:57.0187781Z, 2023-02-21T12:44:16.9651349Z] http.flavor: 1.1 http.method: GET http.route: {controller=Home}/{action=Index}/{id?} http.scheme: http http.status_code: 200 net.host.name: localhost net.host.port: 5123 Histogram\nValue: Sum: 373.4504 Count: 1 Min: 373.4504 Max: 373.4504\n(-Infinity,0]:0\n(0,5]:0\n(5,10]:0\n(10,25]:0\n(25,50]:0\n(50,75]:0\n(75,100]:0\n(100,250]:0\n(250,500]:1\n(500,750]:0\n(750,1000]:0\n(1000,2500]:0\n(2500,5000]:0\n(5000,7500]:0\n(7500,10000]:0\n(10000,+Infinity]:0\n</code></pre>"},{"location":"docs/instrumentation/net/getting-started/#manual-metrics","title":"Manual Metrics","text":"<p>Next, add some manual metrics to the app. This will initialize a Meter to create a counter in code.</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\n// .. other setup\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(/*  .. tracing setup */ )\n.WithMetrics(metricsProviderBuilder =&gt;\nmetricsProviderBuilder\n.AddMeter(DiagnosticsConfig.Meter.Name)\n// .. more metrics\n);\npublic static class DiagnosticsConfig\n{\npublic const string ServiceName = \"MyService\";\n// .. other config\npublic static Meter Meter = new(ServiceName);\npublic static Counter&lt;long&gt; RequestCounter =\nMeter.CreateCounter&lt;long&gt;(\"app.request_counter\");\n}\n</code></pre> <p>Now we can increment the counter in our <code>Index</code> action.</p> <pre><code>    public IActionResult Index()\n{\n// do other stuff\nDiagnosticsConfig.RequestCounter.Add(1,\nnew(\"Action\", nameof(Index)),\nnew(\"Controller\", nameof(HomeController)));\nreturn View();\n}\n</code></pre> <p>You'll notice here that we're also adding Tags (OpenTelemetry Attributes) to our request counter that distinguishes it from other requests. You should now see an output like this.</p> View example output <pre><code>Export app.request_counter, Meter: MyService\n(2023-02-21T13:11:28.7265324Z, 2023-02-21T13:11:48.7074259Z] Action: Index Controller: HomeController LongSum\nValue: 1\n</code></pre> <p>Tip: if you comment out the <code>.AddAspNetCoreInstrumentation()</code> line in <code>Program.cs</code> you'll be able to see the output better.</p>"},{"location":"docs/instrumentation/net/getting-started/#send-data-to-a-collector","title":"Send data to a collector","text":"<p>The OpenTelemetry Collector is a vital component of most production deployments. A collector is most beneficial in the following situations, among others:</p> <ul> <li>A single telemetry sink shared by multiple services, to reduce overhead of   switching exporters</li> <li>Aggregate traces across multiple services, running on multiple hosts</li> <li>A central place to process traces prior to exporting them to a backend</li> </ul>"},{"location":"docs/instrumentation/net/getting-started/#configure-and-run-a-local-collector","title":"Configure and run a local collector","text":"<p>First, save the following collector configuration code to a file in the <code>/tmp/</code> directory:</p> <pre><code># /tmp/otel-collector-config.yaml\nreceivers:\notlp:\nprotocols:\nhttp:\ngrpc:\nexporters:\nlogging:\nloglevel: debug\nprocessors:\nbatch:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [logging]\nprocessors: [batch]\nmetrics:\nreceivers: [otlp]\nexporters: [logging]\nprocessors: [batch]\n</code></pre> <p>Then run the docker command to acquire and run the collector based on this configuration:</p> <pre><code>docker run -p 4317:4317 \\\n-v /tmp/otel-collector-config.yaml:/etc/otel-collector-config.yaml \\\notel/opentelemetry-collector:latest \\\n--config=/etc/otel-collector-config.yaml\n</code></pre> <p>You will now have an collector instance running locally.</p>"},{"location":"docs/instrumentation/net/getting-started/#modify-the-code-to-export-spans-via-otlp","title":"Modify the code to export spans via OTLP","text":"<p>The next step is to modify the code to send spans to the collector via OTLP instead of the console.</p> <p>First, add the following package:</p> <pre><code>dotnet add package OpenTelemetry.Exporter.OpenTelemetryProtocol\n</code></pre> <p>Next, using the ASP.NET Core code from earlier, replace the console exporter with an OTLP exporter:</p> <pre><code>builder.Services.AddOpenTelemetry()\n.WithTracing(tracerProviderBuilder =&gt;\ntracerProviderBuilder\n// .. other config\n.AddOtlpExporter())\n.WithMetrics(metricsProviderBuilder =&gt;\nmetricsProviderBuilder\n// .. other config\n.AddOtlpExporter());\n</code></pre> <p>By default, it will send spans to <code>localhost:4317</code>, which is what the collector is listening on if you've followed the step above.</p>"},{"location":"docs/instrumentation/net/getting-started/#run-the-application","title":"Run the application","text":"<p>Run the application like before:</p> <pre><code>dotnet run\n</code></pre> <p>Now, telemetry will be output by the collector process.</p>"},{"location":"docs/instrumentation/net/getting-started/#next-steps","title":"Next steps","text":"<p>To ensure you're getting the most data as easily as possible, install instrumentation libraries to generate observability data.</p> <p>Additionally, enriching your codebase with manual instrumentation gives you customized observability data.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p> <p>You can also check the automatic instrumentation for .NET, which is currently in beta.</p>"},{"location":"docs/instrumentation/net/libraries/","title":"Using instrumentation libraries","text":"<p>You can use instrumentation libraries in order to generate telemetry data for a particular instrumented library.</p> <p>For example, the instrumentation library for ASP.NET Core will automatically create spans and metrics based on the inbound HTTP requests.</p>"},{"location":"docs/instrumentation/net/libraries/#setup","title":"Setup","text":"<p>Each instrumentation library is a NuGet package, and installing them is typically done like so:</p> <pre><code>dotnet add package OpenTelemetry.Instrumentation.{library-name-or-type}\n</code></pre> <p>It is typically then registered at application startup time, such as when creating a TracerProvider.</p>"},{"location":"docs/instrumentation/net/libraries/#note-on-versioning","title":"Note on Versioning","text":"<p>The Semantic Conventions (Standards) for attribute names are not currently stable therefore the instrumentation package is currently not in a released state. That doesn't mean that the functionality itself is not stable, only that the names of some of the attributes may change in the future, some may be added, some may be removed. This means that you need to use the <code>--prerelease</code> flag, or install a specific version of the package</p>"},{"location":"docs/instrumentation/net/libraries/#example-with-aspnet-core-and-httpclient","title":"Example with ASP.NET Core and HttpClient","text":"<p>As an example, here's how you can instrument inbound and output requests from an ASP.NET Core app.</p> <p>First, get the appropriate packages of OpenTelemetry Core:</p> <pre><code>dotnet add package OpenTelemetry\ndotnet add package OpenTelemetry.Extensions.Hosting\ndotnet add package OpenTelemetry.Exporter.Console\n</code></pre> <p>Then you can install the Instrumentation packages</p> <pre><code>dotnet add package OpenTelemetry.Instrumentation.AspNetCore --prerelease\ndotnet add package OpenTelemetry.Instrumentation.Http --prerelease\n</code></pre> <p>Next, configure each instrumentation library at startup and use them!</p> <pre><code>using OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\nvar builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(b =&gt;\n{\nb\n.AddHttpClientInstrumentation()\n.AddAspNetCoreInstrumentation();\n});\nvar app = builder.Build();\nvar httpClient = new HttpClient();\napp.MapGet(\"/hello\", async () =&gt;\n{\nvar html = await httpClient.GetStringAsync(\"https://example.com/\");\nif (string.IsNullOrWhiteSpace(html))\n{\nreturn \"Hello, World!\";\n}\nelse\n{\nreturn \"Hello, World!\";\n}\n});\napp.Run();\n</code></pre> <p>When you run this code and access the <code>/hello</code> endpoint, the instrumentation libraries will:</p> <ul> <li>Start a new trace</li> <li>Generate a span representing the request made to the endpoint</li> <li>Generate a child span representing the HTTP GET made to <code>https://example.com/</code></li> </ul> <p>If you add more instrumentation libraries, then you get more spans for each of those.</p>"},{"location":"docs/instrumentation/net/libraries/#available-instrumentation-libraries","title":"Available instrumentation libraries","text":"<p>A full list of instrumentation libraries produced by OpenTelemetry is available from the opentelemetry-dotnet repository.</p> <p>You can also find more instrumentations available in the registry.</p>"},{"location":"docs/instrumentation/net/libraries/#next-steps","title":"Next steps","text":"<p>After you have set up instrumentation libraries, you may want to add manual instrumentation to collect custom telemetry data.</p> <p>If you are using .NET Framework 4.x instead of modern .NET, refer to the .NET Framework docs to configure OpenTelemetry and instrumentation libraries on .NET Framework.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p> <p>You can also check the automatic instrumentation for .NET, which is currently in beta.</p>"},{"location":"docs/instrumentation/net/manual/","title":"Manual Instrumentation","text":"<p>Manual instrumentation is the process of adding observability code to your application.</p>"},{"location":"docs/instrumentation/net/manual/#a-note-on-terminology","title":"A note on terminology","text":"<p>.NET is different from other languages/runtimes that support OpenTelemetry. The Tracing API is implemented by the System.Diagnostics API, repurposing existing constructs like <code>ActivitySource</code> and <code>Activity</code> to be OpenTelemetry-compliant under the covers.</p> <p>However, there are parts of the OpenTelemetry API and terminology that .NET developers must still know to be able to instrument their applications, which are covered here as well as the <code>System.Diagnostics</code> API.</p> <p>If you prefer to use OpenTelemetry APIs instead of <code>System.Diagnostics</code> APIs, you can refer to the OpenTelemetry API Shim docs for tracing.</p>"},{"location":"docs/instrumentation/net/manual/#initializing-tracing","title":"Initializing tracing","text":"<p>There are two main ways to initialize tracing, depending on whether you're using a console app or something that's ASP.NET Core-based.</p>"},{"location":"docs/instrumentation/net/manual/#console-app","title":"Console app","text":"<p>To start tracing in a console app, you need to create a tracer provider.</p> <p>First, ensure that you have the right packages:</p> <pre><code>dotnet add package OpenTelemetry\ndotnet add package OpenTelemetry.Exporter.Console\n</code></pre> <p>And then use code like this at the beginning of your program, during any important startup operations.</p> <pre><code>using OpenTelemetry;\nusing OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\n// ...\nvar serviceName = \"MyServiceName\";\nvar serviceVersion = \"1.0.0\";\nusing var tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddSource(serviceName)\n.ConfigureResource(resource =&gt;\nresource.AddService(\nserviceName: serviceName,\nserviceVersion: serviceVersion))\n.AddConsoleExporter()\n.Build();\n// ...\n</code></pre> <p>This is also where you can configure instrumentation libraries.</p> <p>Note that this sample uses the Console Exporter. If you are exporting to another endpoint, you'll have to use a different exporter.</p>"},{"location":"docs/instrumentation/net/manual/#aspnet-core","title":"ASP.NET Core","text":"<p>To start tracing in an ASP.NET Core-based app, use the OpenTelemetry extensions for ASP.NET Core setup.</p> <p>First, ensure that you have the right packages:</p> <pre><code>dotnet add package OpenTelemetry\ndotnet add package OpenTelemetry.Extensions.Hosting\ndotnet add package OpenTelemetry.Exporter.Console\n</code></pre> <p>Then you can install the Instrumentation package</p> <pre><code>dotnet add package OpenTelemetry.Instrumentation.AspNetCore --prerelease\n</code></pre> <p>Note that the <code>--prerelease</code> flag is required for all instrumentation packages because they are all dependent on naming conventions for attributes/labels (Semantic Conventions) that aren't yet classed as stable.</p> <p>Next, configure it in your ASP.NET Core startup routine where you have access to an <code>IServiceCollection</code>.</p> <pre><code>using OpenTelemetry;\nusing OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\n// Define some important constants and the activity source.\n// These can come from a config file, constants file, etc.\nvar serviceName = \"MyCompany.MyProduct.MyService\";\nvar serviceVersion = \"1.0.0\";\nvar builder = WebApplication.CreateBuilder(args);\n// Configure important OpenTelemetry settings, the console exporter\nbuilder.Services.AddOpenTelemetry()\n.WithTracing(b =&gt;\n{\nb\n.AddConsoleExporter()\n.AddSource(serviceName)\n.ConfigureResource(resource =&gt;\nresource.AddService(\nserviceName: serviceName,\nserviceVersion: serviceVersion))\n});\n</code></pre> <p>This is also where you can configure instrumentation libraries.</p> <p>Note that this sample uses the Console Exporter. If you are exporting to another endpoint, you'll have to use a different exporter.</p>"},{"location":"docs/instrumentation/net/manual/#setting-up-an-activitysource","title":"Setting up an ActivitySource","text":"<p>Once tracing is initialized, you can configure an <code>ActivitySource</code>, which will be how you trace operations with <code>Activity</code>s.</p> <p>Typically, an <code>ActivitySource</code> is instantiated once per app/service that is being instrumented, so it's a good idea to instantiate it once in a shared location. It is also typically named the same as the Service Name.</p> <pre><code>using System.Diagnostics;\npublic static class Telemetry\n{\n//...\n// Name it after the service name for your app.\n// It can come from a config file, constants file, etc.\npublic static readonly ActivitySource MyActivitySource = new(TelemetryConstants.ServiceName);\n//...\n}\n</code></pre> <p>You can instantiate several <code>ActivitySource</code>s if that suits your scenario, although it is generally sufficient to just have one defined per service.</p>"},{"location":"docs/instrumentation/net/manual/#creating-activities","title":"Creating Activities","text":"<p>To create an <code>Activity</code>, give it a name and create it from your <code>ActivitySource</code>.</p> <pre><code>using var myActivity = MyActivitySource.StartActivity(\"SayHello\");\n// do work that 'myActivity' will now track\n</code></pre>"},{"location":"docs/instrumentation/net/manual/#creating-nested-activities","title":"Creating nested Activities","text":"<p>If you have a distinct sub-operation you'd like to track as a part of another one, you can create activities to represent the relationship.</p> <pre><code>public static void ParentOperation()\n{\nusing var parentActivity = MyActivitySource.StartActivity(\"ParentActivity\");\n// Do some work tracked by parentActivity\nChildOperation();\n// Finish up work tracked by parentActivity again\n}\npublic static void ChildOperation()\n{\nusing var childActivity = MyActivitySource.StartActivity(\"ChildActivity\");\n// Track work in ChildOperation with childActivity\n}\n</code></pre> <p>When you view spans in a trace visualization tool, <code>ChildActivity</code> will be tracked as a nested operation under <code>ParentActivity</code>.</p>"},{"location":"docs/instrumentation/net/manual/#nested-activities-in-the-same-scope","title":"Nested Activities in the same scope","text":"<p>You may wish to create a parent-child relationship in the same scope. Although possible, this is generally not recommended because you need to be careful to end any nested <code>Activity</code> when you expect it to end.</p> <pre><code>public static void DoWork()\n{\nusing var parentActivity = MyActivitySource.StartActivity(\"ParentActivity\");\n// Do some work tracked by parentActivity\nusing (var childActivity = MyActivitySource.StartActivity(\"ChildActivity\"))\n{\n// Do some \"child\" work in the same function\n}\n// Finish up work tracked by parentActivity again\n}\n</code></pre> <p>In the preceding example, <code>childActivity</code> is ended because the scope of the <code>using</code> block is explicitly defined, rather than scoped to <code>DoWork</code> itself like <code>parentActivity</code>.</p>"},{"location":"docs/instrumentation/net/manual/#creating-independent-activities","title":"Creating independent Activities","text":"<p>The previous examples showed how to create Activities that follow a nested hierarchy. In some cases, you'll want to create independent Activities that are siblings of the same root rather than being nested.</p> <pre><code>public static void DoWork()\n{\nusing var parent = MyActivitySource.StartActivity(\"parent\");\nusing (var child1 = DemoSource.StartActivity(\"child1\"))\n{\n// Do some work that 'child1' tracks\n}\nusing (var child2 = DemoSource.StartActivity(\"child2\"))\n{\n// Do some work that 'child2' tracks\n}\n// 'child1' and 'child2' both share 'parent' as a parent, but are independent\n// from one another\n}\n</code></pre>"},{"location":"docs/instrumentation/net/manual/#creating-new-root-activities","title":"Creating new root Activities","text":"<p>If you wish to create a new root Activity, you'll need to \"de-parent\" from the current activity.</p> <pre><code>public static void DoWork()\n{\nvar previous = Activity.Current;\nActivity.Current = null;\nvar newRoot = source.StartActivity(\"NewRoot\");\n// Re-set the previous Current Activity so the trace isn't messed up\nActivity.Current = previous;\n}\n</code></pre>"},{"location":"docs/instrumentation/net/manual/#get-the-current-activity","title":"Get the current Activity","text":"<p>Sometimes it's helpful to access whatever the current <code>Activity</code> is at a point in time so you can enrich it with more information.</p> <pre><code>var activity = Activity.Current;\n// may be null if there is none\n</code></pre> <p>Note that <code>using</code> is not used in the prior example. Doing so will end current <code>Activity</code>, which is not likely to be desired.</p>"},{"location":"docs/instrumentation/net/manual/#add-tags-to-an-activity","title":"Add tags to an Activity","text":"<p>Tags (the equivalent of <code>Attributes</code> in OpenTelemetry) let you attach key/value pairs to an <code>Activity</code> so it carries more information about the current operation that it's tracking.</p> <pre><code>using var myActivity = MyActivitySource.StartActivity(\"SayHello\");\nactivity?.SetTag(\"operation.value\", 1);\nactivity?.SetTag(\"operation.name\", \"Saying hello!\");\nactivity?.SetTag(\"operation.other-stuff\", new int[] { 1, 2, 3 });\n</code></pre> <p>We recommend that all Tag names are defined in constants rather than defined inline as this provides both consistency and also discoverability.</p>"},{"location":"docs/instrumentation/net/manual/#adding-events","title":"Adding events","text":"<p>An event is a human-readable message on an <code>Activity</code> that represents \"something happening\" during its lifetime.</p> <pre><code>using var myActivity = MyActivitySource.StartActivity(\"SayHello\");\n// ...\nmyActivity?.AddEvent(new(\"Gonna try it!\"));\n// ...\nmyActivity?.AddEvent(new(\"Did it!\"));\n</code></pre> <p>Events can also be created with a timestamp and a collection of Tags.</p> <pre><code>using var myActivity = MyActivitySource.StartActivity(\"SayHello\");\n// ...\nmyActivity?.AddEvent(new(\"Gonna try it!\", DateTimeOffset.Now));\n// ...\nvar eventTags = new Dictionary&lt;string, object?&gt;\n{\n{ \"foo\", 1 },\n{ \"bar\", \"Hello, World!\" },\n{ \"baz\", new int[] { 1, 2, 3 } }\n};\nmyActivity?.AddEvent(new(\"Gonna try it!\", DateTimeOffset.Now, new(eventTags)));\n</code></pre>"},{"location":"docs/instrumentation/net/manual/#adding-links","title":"Adding links","text":"<p>An <code>Activity</code> can be created with zero or more <code>ActivityLink</code>s that are causally related.</p> <pre><code>// Get a context from somewhere, perhaps it's passed in as a parameter\nvar activityContext = Activity.Current!.Context;\nvar links = new List&lt;ActivityLink&gt;\n{\nnew ActivityLink(activityContext)\n};\nusing var anotherActivity =\nMyActivitySource.StartActivity(\nActivityKind.Internal,\nname: \"anotherActivity\",\nlinks: links);\n// do some work\n</code></pre>"},{"location":"docs/instrumentation/net/manual/#set-activity-status","title":"Set Activity status","text":"<p>A status can be set on an activity, typically used to specify that an activity has not completed successfully - <code>ActivityStatusCode.Error</code>. In rare scenarios, you could override the <code>Error</code> status with <code>Ok</code>, but don't set <code>Ok</code> on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>using var myActivity = MyActivitySource.StartActivity(\"SayHello\");\ntry\n{\n// do something\n}\ncatch (Exception ex)\n{\nmyActivity.SetStatus(ActivityStatusCode.Error, \"Something bad happened!\");\n}\n</code></pre>"},{"location":"docs/instrumentation/net/manual/#next-steps","title":"Next steps","text":"<p>After you've set up manual instrumentation, you may want to use instrumentation libraries. As the name suggests, they will instrument relevant libraries you're using and generate spans (activities) for things like inbound and outbound HTTP requests and more.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p> <p>You can also check the automatic instrumentation for .NET, which is currently in beta.</p>"},{"location":"docs/instrumentation/net/netframework/","title":".NET Framework instrumentation configuration","text":"<p>OpenTelemetry supports both .NET and .NET Framework (an older Windows-based .NET implementation).</p> <p>If you're already using the modern, cross-platform implementation of .NET, you can skip this article.</p>"},{"location":"docs/instrumentation/net/netframework/#aspnet-initialization","title":"ASP.NET Initialization","text":"<p>Initialization for ASP.NET is a little different than for ASP.NET Core.</p> <p>First, install the following NuGet packages:</p> <ul> <li>OpenTelemetry.Instrumentation.AspNet</li> <li>OpenTelemetry.Extensions.Hosting</li> </ul> <p>Next, modify your <code>Web.Config</code> file to add a required HttpModule:</p> <pre><code>&lt;system.webServer&gt;\n&lt;modules&gt;\n&lt;add\nname=\"TelemetryHttpModule\"\ntype=\"OpenTelemetry.Instrumentation.AspNet.TelemetryHttpModule,\n                OpenTelemetry.Instrumentation.AspNet.TelemetryHttpModule\"\npreCondition=\"integratedMode,managedHandler\" /&gt;\n&lt;/modules&gt;\n&lt;/system.webServer&gt;\n</code></pre> <p>Finally, initialize ASP.NET instrumentation in your <code>Global.asax.cs</code> file along with other OpenTelemetry initialization:</p> <pre><code>using OpenTelemetry;\nusing OpenTelemetry.Trace;\npublic class WebApiApplication : HttpApplication\n{\nprivate TracerProvider _tracerProvider;\nprotected void Application_Start()\n{\n_tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddAspNetInstrumentation()\n// Other configuration, like adding an exporter and setting resources\n.AddConsoleExporter()\n.AddSource(\"my-service-name\")\n.SetResourceBuilder(\nResourceBuilder.CreateDefault()\n.AddService(serviceName: \"my-service-name\", serviceVersion: \"1.0.0\"))\n.Build();\n}\nprotected void Application_End()\n{\n_tracerProvider?.Dispose();\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/net/netframework/#advanced-aspnet-configuration","title":"Advanced ASP.NET configuration","text":"<p>ASP.NET instrumentation can be configured to change the default behavior.</p>"},{"location":"docs/instrumentation/net/netframework/#filter","title":"Filter","text":"<p>ASP.NET instrumentation collects all incoming HTTP requests by default. However, you can filter incoming requests by using the <code>Filter</code> method in <code>AspNetInstrumentationOptions</code>. This works similar to a LINQ <code>Where</code> clause, where only requests that match a condition will be collected.</p> <p>The following code snippet shows how to use <code>Filter</code> to only allow GET requests.</p> <pre><code>this.tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddAspNetInstrumentation(\n(options) =&gt; options.Filter =\n(httpContext) =&gt;\n{\n// only collect telemetry about HTTP GET requests\nreturn httpContext.Request.HttpMethod.Equals(\"GET\");\n})\n.Build();\n</code></pre> <p>Filtering happens at an early stage, and is different from Sampling, which occurs after data has been collected. Filtering will limit what gets collected in the first place.</p>"},{"location":"docs/instrumentation/net/netframework/#enrich","title":"Enrich","text":"<p>If you have data that you'd like to have added to every <code>Activity</code> that's generated by OpenTelemetry, you can use the <code>Enrich</code> method.</p> <p>The <code>Enrich</code> action is called only when <code>activity.IsAllDataRequested</code> is <code>true</code>. It contains the <code>Activity</code> created, the name of the event, and the raw object</p> <p>The following code snippet shows how to add additional tags using <code>Enrich</code>.</p> <pre><code>this.tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddAspNetInstrumentation((options) =&gt; options.Enrich\n= (activity, eventName, rawObject) =&gt;\n{\nif (eventName.Equals(\"OnStartActivity\"))\n{\nif (rawObject is HttpRequest httpRequest)\n{\nactivity?.SetTag(\"physicalPath\", httpRequest.PhysicalPath);\n}\n}\nelse if (eventName.Equals(\"OnStopActivity\"))\n{\nif (rawObject is HttpResponse httpResponse)\n{\nactivity?.SetTag(\"responseType\", httpResponse.ContentType);\n}\n}\n})\n.Build();\n</code></pre> <p>See Add tags to an Activity for annotating trace data more generally.</p>"},{"location":"docs/instrumentation/net/netframework/#recordexception","title":"RecordException","text":"<p>ASP.NET instrumentation automatically sets a given <code>Activity</code>'s status to <code>Error</code> if an unhandled exception is thrown.</p> <p>You can also set the <code>RecordException</code> property to <code>true</code>, which will store an exception on the <code>Activity</code> itself as an <code>ActivityEvent</code>.</p>"},{"location":"docs/instrumentation/net/netframework/#next-steps","title":"Next steps","text":"<p>After you have observability generated automatically with instrumentation libraries, you may want to add manual instrumentation to collect custom telemetry data.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p> <p>You can also check the automatic instrumentation for .NET, which is currently in beta.</p>"},{"location":"docs/instrumentation/net/resources/","title":"Resources","text":"<p>A resource represents the entity producing telemetry as resource attributes. For example, a process producing telemetry that is running in a container on Kubernetes has a Pod name, a namespace, and possibly a deployment name. All three of these attributes can be included in the resource.</p> <p>In your observability backend, you can use resource information to better investigate interesting behavior. For example, if your trace or metrics data indicate latency in your system, you can narrow it down to a specific container, pod, or Kubernetes deployment.</p>"},{"location":"docs/instrumentation/net/resources/#setup","title":"Setup","text":"<p>Follow the instructions in the Getting Started, so that you have a running .NET app exporting data to the console.</p>"},{"location":"docs/instrumentation/net/resources/#adding-resources-with-environment-variables","title":"Adding resources with environment variables","text":"<p>You can use the <code>OTEL_RESOURCE_ATTRIBUTES</code> environment variable to inject resources into your application. The .NET SDK will automatically detect these resources.</p> <p>The following example adds Service, Host and OS resource attributes via environment variables, running unix programs like <code>uname</code> to generate the resource data.</p> <pre><code>$ env OTEL_RESOURCE_ATTRIBUTES=\"service.name=resource-tutorial-dotnet,service.namespace=tutorial,service.version=1.0,service.instance.id=`uuidgen`,host.name=`HOSTNAME`,host.type=`uname -m`,os.name=`uname -s`,os.version=`uname -r`\" dotnet run\n\nActivity.TraceId:          d1cbb7787440cc95b325835cb2ff8018\nActivity.SpanId:           2ca007300fcb3068\nActivity.TraceFlags:           Recorded\nActivity.ActivitySourceName: tutorial-dotnet\nActivity.DisplayName: SayHello\nActivity.Kind:        Internal\nActivity.StartTime:   2022-10-02T13:31:12.0175090Z\nActivity.Duration:    00:00:00.0003920\nActivity.Tags:\n    foo: 1\n    bar: Hello, World!\n    baz: [1,2,3]\nResource associated with Activity:\n    service.name: resource-tutorial-dotnet\n    service.namespace: tutorial\n    service.version: 1.0\n    service.instance.id: 93B14BAD-813D-48EE-9FB1-2ADFD07C5E78\n    host.name: myhost\n    host.type: arm64\n    os.name: Darwin\n    os.version: 21.6.0\n</code></pre>"},{"location":"docs/instrumentation/net/resources/#adding-resources-in-code","title":"Adding resources in code","text":"<p>You can also add custom resources in code by attaching them to a <code>ResourceBuilder</code>.</p> <p>The following example builds on the getting started sample and adds two custom resources, <code>environment.name</code> and <code>team.name</code> in code:</p> <pre><code>using System.Diagnostics;\nusing System.Collections.Generic;\nusing OpenTelemetry;\nusing OpenTelemetry.Trace;\nusing OpenTelemetry.Resources;\nvar serviceName = \"resource-tutorial-dotnet\";\nvar serviceVersion = \"1.0\";\nvar resourceBuilder =\nResourceBuilder\n.CreateDefault()\n.AddService(serviceName: serviceName, serviceVersion: serviceVersion)\n.AddAttributes(new Dictionary&lt;string, object&gt;\n{\n[\"environment.name\"] = \"production\",\n[\"team.name\"] = \"backend\"\n});\nvar sourceName = \"tutorial-dotnet\";\nusing var tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddSource(sourceName)\n.SetResourceBuilder(resourceBuilder)\n.AddConsoleExporter()\n.Build();\nvar MyActivitySource = new ActivitySource(sourceName);\nusing var activity = MyActivitySource.StartActivity(\"SayHello\");\nactivity?.SetTag(\"foo\", 1);\nactivity?.SetTag(\"bar\", \"Hello, World!\");\nactivity?.SetTag(\"baz\", new int[] { 1, 2, 3 });\n</code></pre> <p>In this example, the <code>service.name</code> and <code>service.version</code> values are set in code as well. Additionally, <code>service.instance.id</code> gets a default value.</p> <p>If you run the same command as in Adding resources with environment variables, but this time without <code>service.name</code> <code>service.version</code>, and <code>service.instance.id</code>, you'll see the <code>environment.name</code> and <code>team.name</code> resources in the resource list:</p> <pre><code>$ env OTEL_RESOURCE_ATTRIBUTES=\"service.namespace=tutorial,host.name=`HOSTNAME`,host.type=`uname -m`,os.name=`uname -s`,os.version=`uname -r`\" dotnet run\n\nActivity.TraceId:          d1cbb7787440cc95b325835cb2ff8018\nActivity.SpanId:           2ca007300fcb3068\nActivity.TraceFlags:           Recorded\nActivity.ActivitySourceName: tutorial-dotnet\nActivity.DisplayName: SayHello\nActivity.Kind:        Internal\nActivity.StartTime:   2022-10-02T13:31:12.0175090Z\nActivity.Duration:    00:00:00.0003920\nActivity.Tags:\n    foo: 1\n    bar: Hello, World!\n    baz: [1,2,3]\nResource associated with Activity:\n    environment.name: production\n    team.name: backend\n    service.name: resource-tutorial-dotnet\n    service.namespace: tutorial\n    service.version: 1.0\n    service.instance.id: 28976A1C-BF02-43CA-BAE0-6E0564431462\n    host.name: pcarter\n    host.type: arm64\n    os.name: Darwin\n    os.version: 21.6.0\n</code></pre> <p>Note: If you set resource attributes with both environment variables and code, the values in code take precedence.</p>"},{"location":"docs/instrumentation/net/resources/#next-steps","title":"Next steps","text":"<p>There are more resource detectors you can add to your configuration, for example to get details about your Cloud environment or Deployment.</p>"},{"location":"docs/instrumentation/net/shim/","title":"OpenTelemetry Tracing Shim","text":"<p>.NET is different from other languages/runtimes that support OpenTelemetry. Tracing is implemented by the System.Diagnostics API, repurposing older constructs like <code>ActivitySource</code> and <code>Activity</code> to be OpenTelemetry-compliant under the covers.</p> <p>OpenTelemetry for .NET also provides an API shim on top of the System.Diagnostics- based implementation. This shim is helpful if you're working with other languages and OpenTelemetry in the same codebase, or if you prefer to use terminology consistent with the OpenTelemetry spec.</p>"},{"location":"docs/instrumentation/net/shim/#initializing-tracing","title":"Initializing tracing","text":"<p>There are two main ways to initialize tracing, depending on whether you're using a console app or something that's ASP.NET Core-based.</p>"},{"location":"docs/instrumentation/net/shim/#console-app","title":"Console app","text":"<p>To start tracing in a console app, you need to create a tracer provider.</p> <p>First, ensure that you have the right packages:</p> <pre><code>dotnet add package OpenTelemetry\ndotnet add package OpenTelemetry.Exporter.Console\n</code></pre> <p>And then use code like this at the beginning of your program, during any important startup operations.</p> <pre><code>using OpenTelemetry;\nusing OpenTelemetry.Trace;\nusing OpenTelemetry.Resources;\n// ...\nvar serviceName = \"MyServiceName\";\nvar serviceVersion = \"1.0.0\";\nusing var tracerProvider = Sdk.CreateTracerProviderBuilder()\n.AddSource(serviceName)\n.SetResourceBuilder(\nResourceBuilder.CreateDefault()\n.AddService(serviceName: serviceName, serviceVersion: serviceVersion))\n.AddConsoleExporter()\n.Build();\n//...\n</code></pre> <p>This is also where you can configure instrumentation libraries.</p> <p>Note that this sample uses the Console Exporter. If you are exporting to another endpoint, you'll have to use a different exporter.</p>"},{"location":"docs/instrumentation/net/shim/#aspnet-core","title":"ASP.NET Core","text":"<p>To start tracing in an ASP.NET Core-based app, use the OpenTelemetry extensions for ASP.NET Core setup.</p> <p>First, ensure that you have the right packages:</p> <pre><code>dotnet add package OpenTelemetry --prerelease\ndotnet add package OpenTelemetry.Instrumentation.AspNetCore --prerelease\ndotnet add package OpenTelemetry.Extensions.Hosting --prerelease\ndotnet add package OpenTelemetry.Exporter.Console --prerelease\n</code></pre> <p>And then configure it in your ASP.NET Core startup routine where you have access to an <code>IServiceCollection</code>.</p> <pre><code>using OpenTelemetry.Resources;\nusing OpenTelemetry.Trace;\n// These can come from a config file, constants file, etc.\nvar serviceName = \"MyCompany.MyProduct.MyService\";\nvar serviceVersion = \"1.0.0\";\nvar builder = WebApplication.CreateBuilder(args);\n// Configure important OpenTelemetry settings, the console exporter, and instrumentation library\nbuilder.Services.AddOpenTelemetry().WithTracing(tcb =&gt;\n{\ntcb\n.AddSource(serviceName)\n.SetResourceBuilder(\nResourceBuilder.CreateDefault()\n.AddService(serviceName: serviceName, serviceVersion: serviceVersion))\n.AddAspNetCoreInstrumentation()\n.AddConsoleExporter();\n});\n</code></pre> <p>In the preceding example, a <code>Tracer</code> corresponding to the service is injected during setup. This lets you get access to an instance in your endpoint mapping (or controllers if you're using an older version of .NET).</p> <p>It's not required to inject a service-level tracer, nor does it improve performance either. You will need to decide where you'll want your tracer instance to live, though.</p> <p>This is also where you can configure instrumentation libraries.</p> <p>Note that this sample uses the Console Exporter. If you are exporting to another endpoint, you'll have to use a different exporter.</p>"},{"location":"docs/instrumentation/net/shim/#setting-up-a-tracer","title":"Setting up a tracer","text":"<p>Once tracing is initialized, you can configure a <code>Tracer</code>, which will be how you trace operations with <code>Span</code>s.</p> <p>Typically, a <code>Tracer</code> is instantiated once per app/service that is being instrumented, so it's a good idea to instantiate it once in a shared location. It is also typically named the same as the Service Name.</p>"},{"location":"docs/instrumentation/net/shim/#injecting-a-tracer-with-aspnet-core","title":"Injecting a tracer with ASP.NET Core","text":"<p>ASP.NET Core generally encourages injecting instances of long-lived objects like <code>Tracer</code>s during setup.</p> <pre><code>using OpenTelemetry.Trace;\nvar builder = WebApplication.CreateBuilder(args);\n// ...\nbuilder.Services.AddSingleton(TracerProvider.Default.GetTracer(serviceName));\n// ...\nvar app = builder.Build();\n// ...\napp.MapGet(\"/hello\", (Tracer tracer) =&gt;\n{\nusing var span = tracer.StartActiveSpan(\"hello-span\");\n// do stuff\n});\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#acquiring-a-tracer-from-a-tracerprovider","title":"Acquiring a tracer from a TracerProvider","text":"<p>If you're not using ASP.NET Core or would rather not inject an instance of a <code>Tracer</code>, create one from your instantiated <code>TracerProvider</code>:</p> <pre><code>// ...\nvar tracer = tracerProvider.GetTracer(serviceName);\n// Assign it somewhere globally\n//...\n</code></pre> <p>You'll likely want to assign this <code>Tracer</code> instance to a variable in a central location so that you have access to it throughout your service.</p> <p>You can instantiate as many <code>Tracer</code>s as you'd like per service, although it's generally sufficient to just have one defined per service.</p>"},{"location":"docs/instrumentation/net/shim/#creating-spans","title":"Creating Spans","text":"<p>To create a span, give it a name and create it from your <code>Tracer</code>.</p> <pre><code>using var span = MyTracer.StartActiveSpan(\"SayHello\");\n// do work that 'span' will now track\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#creating-nested-spans","title":"Creating nested Spans","text":"<p>If you have a distinct sub-operation you'd like to track as a part of another one, you can create spans to represent the relationship.</p> <pre><code>public static void ParentOperation(Tracer tracer)\n{\nusing var parentSpan = tracer.StartActiveSpan(\"parent-span\");\n// Do some work tracked by parentSpan\nChildOperation(tracer);\n// Finish up work tracked by parentSpan again\n}\npublic static void ChildOperation(Tracer tracer)\n{\nusing var childSpan = tracer.StartActiveSpan(\"child-span\");\n// Track work in ChildOperation with childSpan\n}\n</code></pre> <p>When you view spans in a trace visualization tool, <code>child-span</code> will be tracked as a nested operation under <code>parent-span\"</code>.</p>"},{"location":"docs/instrumentation/net/shim/#nested-spans-in-the-same-scope","title":"Nested Spans in the same scope","text":"<p>You may wish to create a parent-child relationship in the same scope. Although possible, this is generally not recommended because you need to be careful to end any nested <code>TelemetrySpan</code> when you expect it to end.</p> <pre><code>public static void DoWork(Tracer tracer)\n{\nusing var parentSpan = tracer.StartActiveSpan(\"parent-span\");\n// Do some work tracked by parentSpan\nusing (var childSpan = tracer.StartActiveSpan(\"child-span\"))\n{\n// Do some \"child\" work in the same function\n}\n// Finish up work tracked by parentSpan again\n}\n</code></pre> <p>In the preceding example, <code>childSpan</code> is ended because the scope of the <code>using</code> block is explicitly defined, rather than scoped to <code>DoWork</code> itself like <code>parentSpan</code>.</p>"},{"location":"docs/instrumentation/net/shim/#creating-independent-spans","title":"Creating independent Spans","text":"<p>The previous examples showed how to create Spans that follow a nested hierarchy. In some cases, you'll want to create independent Spans that are siblings of the same root rather than being nested.</p> <pre><code>public static void DoWork(Tracer tracer)\n{\nusing var parent = tracer.StartSpan(\"parent\");\n// 'parent' will be the shared parent of both 'child1' and 'child2'\nusing (var child1 = tracer.StartSpan(\"child1\"))\n{\n// do some work that 'child1' tracks\n}\nusing (var child2 = tracer.StartSpan(\"child2\"))\n{\n// do some work that 'child2' tracks\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#creating-new-root-spans","title":"Creating new root Spans","text":"<p>You can also create new root spans that are completely detached from the current trace.</p> <pre><code>public static void DoWork(Tracer tracer)\n{\nusing var newRoot = tracer.StartRootSpan(\"newRoot\");\n}\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#get-the-current-span","title":"Get the current Span","text":"<p>Sometimes it's helpful to access whatever the current <code>TelemetrySpan</code> is at a point in time so you can enrich it with more information.</p> <pre><code>var span = Tracer.CurrentSpan;\n// do cool stuff!\n</code></pre> <p>Note that <code>using</code> is not used in the prior example. Doing so will end current <code>TelemetrySpan</code> when it goes out of scope, which is unlikely to be desired behavior.</p>"},{"location":"docs/instrumentation/net/shim/#add-attributes-to-a-span","title":"Add Attributes to a Span","text":"<p>Attributes let you attach key/value pairs to a <code>TelemetrySpan</code> so it carries more information about the current operation that it's tracking.</p> <pre><code>using var span = tracer.StartActiveSpan(\"SayHello\");\nspan.SetAttribute(\"operation.value\", 1);\nspan.SetAttribute(\"operation.name\", \"Saying hello!\");\nspan.SetAttribute(\"operation.other-stuff\", new int[] { 1, 2, 3 });\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#adding-events","title":"Adding events","text":"<p>An event is a human-readable message on an <code>TelemetrySpan</code> that represents \"something happening\" during its lifetime. You can think of it like a primitive log.</p> <pre><code>using var span = tracer.StartActiveSpan(\"SayHello\");\n// ...\nspan.AddEvent(\"Doing something...\");\n// ...\nspan.AddEvent(\"Dit it!\");\n</code></pre> <p>Events can also be created with a timestamp and a collection of attributes.</p> <pre><code>using var span = tracer.StartActiveSpan(\"SayHello\");\n// ...\nspan.AddEvent(\"event-message\");\nspan.AddEvent(\"event-message2\", DateTimeOffset.Now);\n// ...\nvar attributeData = new Dictionary&lt;string, object&gt;\n{\n{\"foo\", 1 },\n{ \"bar\", \"Hello, World!\" },\n{ \"baz\", new int[] { 1, 2, 3 } }\n};\nspan.AddEvent(\"asdf\", DateTimeOffset.Now, new(attributeData));\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#adding-links","title":"Adding links","text":"<p>A <code>TelemetrySpan</code> can be created with zero or more <code>Link</code>s that are causally related.</p> <pre><code>// Get a context from somewhere, perhaps it's passed in as a parameter\nvar ctx = span.Context;\nvar links = new List&lt;Link&gt;\n{\nnew(ctx)\n};\nusing var span = tracer.StartActiveSpan(\"another-span\", links: links);\n// do some work\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#set-span-status","title":"Set span status","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - <code>Status.Error</code>. In rare scenarios, you could override the <code>Error</code> status with <code>Ok</code>, but don't set <code>Ok</code> on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>using var span = tracer.StartActiveSpan(\"SayHello\");\ntry\n{\n// do something\n}\ncatch (Exception ex)\n{\nspan.SetStatus(Status.Error, \"Something bad happened!\");\n}\n</code></pre>"},{"location":"docs/instrumentation/net/shim/#record-exceptions-in-spans","title":"Record exceptions in spans","text":"<p>It can be a good idea to record exceptions when they happen. It's recommended to do this in conjunction with setting span status.</p> <pre><code>using var span = tracer.StartActiveSpan(\"SayHello\");\ntry\n{\n// do something\n}\ncatch (Exception ex)\n{\nspan.SetStatus(Status.Error, \"Something bad happened!\");\nspan.RecordException(ex)\n}\n</code></pre> <p>This will capture things like the current stack trace as attributes in the span.</p>"},{"location":"docs/instrumentation/net/shim/#next-steps","title":"Next steps","text":"<p>After you've setup manual instrumentation, you may want to use instrumentation libraries. Instrumentation libraries will instrument relevant libraries you're using and generate data for things like inbound and outbound HTTP requests and more.</p> <p>You'll also want to configure an appropriate exporter to export your telemetry data to one or more telemetry backends.</p>"},{"location":"docs/instrumentation/other/_index/","title":"Other languages","text":"<p>Implementing the OpenTelemetry specification is not limited to the languages you will find in our documentation. OpenTelemetry is designed in a way that it is possible to implement it in every language you like.</p> <p>For some languages, unofficial implementations exist -- you can find them in the registry. If you know about an implementation not listed there, please add it to the registry.</p> <p>The OpenTelemetry community is open to maintain implementations for additional languages and with that make them \"official\" parts of the OpenTelemetry projects. For that you can raise an issue and gauge interest in the formation of a special interest group for your language.</p> <p>For the following languages a request to create a SIG exists:</p> <ul> <li>Lua</li> <li>Perl</li> <li>Julia</li> </ul>"},{"location":"docs/instrumentation/php/_index/","title":"PHP","text":"<p>{{% lang_instrumentation_index_head php /%}}</p>"},{"location":"docs/instrumentation/php/_index/#further-reading","title":"Further Reading","text":"<ul> <li>OpenTelemetry for PHP on GitHub</li> <li>Installation</li> <li>Examples</li> </ul>"},{"location":"docs/instrumentation/php/_index/#requirements","title":"Requirements","text":"<p>OpenTelemetry for PHP requires a minimum PHP version of 7.4, and auto-instrumentation requires version 8.0+.</p>"},{"location":"docs/instrumentation/php/_index/#dependencies","title":"Dependencies","text":"<p>Some of the <code>SDK</code> and <code>Contrib</code> packages have a dependency on both a HTTP Factories (PSR17) and a php-http/async-client implementation. You can find appropriate composer packages implementing given standards on packagist.org.</p> <p>See http-factory-implementations to find a <code>PSR17 (HTTP factories)</code> implementation, and async-client-implementations to find a <code>php-http/async-client</code> implementation.</p>"},{"location":"docs/instrumentation/php/_index/#optional-php-extensions","title":"Optional PHP extensions","text":"Extension Purpose ext-grpc Required to use gRPC as a transport for the OTLP exporter ext-mbstring More performant than the fallback, <code>symfony/polyfill-mbstring</code> ext-zlib If you want to compress exported data ext-ffi Fiber-based context storage ext-protobuf Significant performance improvement for otlp+protobuf exporting"},{"location":"docs/instrumentation/php/_index/#ext-ffi","title":"ext-ffi","text":"<p>Fibers support can be enabled by setting the <code>OTEL_PHP_FIBERS_ENABLED</code> environment variable to <code>true</code>. Using fibers with non-<code>CLI</code> SAPIs may require preloading of bindings. One way to achieve this is setting <code>ffi.preload</code> to <code>src/Context/fiber/zend_observer_fiber.h</code> and setting <code>opcache.preload</code> to <code>vendor/autoload.php</code>.</p>"},{"location":"docs/instrumentation/php/_index/#ext-protobuf","title":"ext-protobuf","text":"<p>The native protobuf library is significantly slower than the extension. We strongly encourage the use of the extension.</p>"},{"location":"docs/instrumentation/php/_index/#setup","title":"Setup","text":"<p>OpenTelemetry for PHP is distributed via packagist, in a number of packages. We recommend that you install only the packages that you need, which as a minimum is usually <code>API</code>, <code>Context</code>, <code>SDK</code> and an exporter.</p> <p>We strongly encourage that your code only depend on classes and interfaces in the <code>API</code> package.</p>"},{"location":"docs/instrumentation/php/automatic/","title":"Automatic Instrumentation","text":"<p>Automatic instrumentation with PHP requires at least PHP 8.0, and the OpenTelemetry PHP extension. The extension allows developers code to hook into classes and methods, and execute userland code before and after the hooked method runs.</p>"},{"location":"docs/instrumentation/php/automatic/#example","title":"Example","text":"<pre><code>&lt;?php\nOpenTelemetry\\Instrumentation\\hook(\n'class': DemoClass::class,\n'function': 'run',\n'pre': static function (DemoClass $demo, array $params, string $class, string $function, ?string $filename, ?int $lineno) {\nstatic $instrumentation;\n$instrumentation ??= new CachedInstrumentation('example');\n$span = $instrumentation-&gt;tracer()-&gt;spanBuilder($class)-&gt;startSpan();\nContext::storage()-&gt;attach($span-&gt;storeInContext(Context::getCurrent()));\n},\n'post': static function (DemoClass $demo, array $params, $returnValue, ?Throwable $exception) {\n$scope = Context::storage()-&gt;scope();\n$scope-&gt;detach();\n$span = Span::fromContext($scope-&gt;context());\nif ($exception) {\n$span-&gt;recordException($exception);\n$span-&gt;setStatus(StatusCode::STATUS_ERROR);\n}\n$span-&gt;end();\n}\n);\n$demo = new DemoClass();\n$demo-&gt;run();\n</code></pre> <p>Here, we provide <code>pre</code> and <code>post</code> functions, which are executed before and after <code>DemoClass::run</code>. The <code>pre</code> function starts and activates a span, and the <code>post</code> function ends it. If an exception was thrown by <code>DemoClass::run()</code>, the <code>post</code> function will record it, without affecting exception propagation.</p>"},{"location":"docs/instrumentation/php/automatic/#installation","title":"Installation","text":"<p>The extension can be installed via pecl, pickle or php-extension-installer (docker specific).</p> <ol> <li>Setup development environment. Installing from source requires proper    development environment and some dependencies:</li> </ol> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab \"Linux (apt)\" &gt;}}sudo apt-get install gcc make autoconf{{&lt; /tab &gt;}}</p> <p>{{&lt; tab \"MacOS (homebrew)\" &gt;}}brew install gcc make autoconf{{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <ol> <li>Build/install the extension. With your environment set up you can install the    extension:</li> </ol> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab pecl &gt;}}pecl install opentelemetry-beta{{&lt; /tab &gt;}}</p> <p>{{&lt; tab pickle &gt;}} php pickle.phar install --source https://github.com/open-telemetry/opentelemetry-php-instrumentation.git#1.0.0beta2 {{&lt; /tab &gt;}}</p> <p>{{&lt; tab \"php-extension-installer (docker)\" &gt;}} install-php-extensions opentelemetry {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <ol> <li>Add the extension to your <code>php.ini</code> file:</li> </ol> <pre><code>[opentelemetry]\nextension=opentelemetry.so\n</code></pre> <ol> <li>Verify that the extension is installed and enabled:</li> </ol> <pre><code>php -m | grep opentelemetry\n</code></pre>"},{"location":"docs/instrumentation/php/automatic/#zero-code-configuration-for-automatic-instrumentation","title":"Zero-code configuration for automatic instrumentation","text":"<p>When used in conjunction with the OpenTelemetry SDK, you can use environment variables or <code>php.ini</code> to configure auto-instrumentation:</p> <pre><code>OTEL_PHP_AUTOLOAD_ENABLED=true \\\nOTEL_SERVICE_NAME=your-service-name \\\nOTEL_TRACES_EXPORTER=otlp \\\nOTEL_EXPORTER_OTLP_PROTOCOL=grpc \\\nOTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4317 \\\nOTEL_PROPAGATORS=baggage,tracecontext \\\nphp myapp.php\n</code></pre>"},{"location":"docs/instrumentation/php/automatic/#manual-setup-for-automatic-instrumentation","title":"Manual setup for automatic instrumentation","text":"<pre><code>&lt;?php\nOpenTelemetry\\API\\Common\\Instrumentation\\Globals::registerInitializer(function (Configurator $configurator) {\n$propagator = TraceContextPropagator::getInstance();\n$spanProcessor = new BatchSpanProcessor(/*params*/);\n$tracerProvider = (new TracerProviderBuilder())\n-&gt;addSpanProcessor($spanProcessor)\n-&gt;setSampler(new ParentBased(new AlwaysOnSampler()))\n-&gt;build();\nShutdownHandler::register([$tracerProvider, 'shutdown']);\nreturn $configurator\n-&gt;withTracerProvider($tracerProvider)\n-&gt;withPropagator($propagator);\n});\n//instrumentation libraries can access the configured providers (or a no-op implementation) via `Globals`\n$tracer = Globals::tracerProvider()-&gt;getTracer('example');\n//or, via CachedInstrumentation\n$instrumentation = new CachedInstrumentation('example');\n$tracerProvider = $instrumentation-&gt;tracer();\n</code></pre>"},{"location":"docs/instrumentation/php/automatic/#supported-libraries-and-frameworks","title":"Supported libraries and frameworks","text":"<p>Automatic Instrumentation comes with a number of instrumentation libraries for commonly used PHP libraries. For the full list, see instrumentation libraries on packagist.</p>"},{"location":"docs/instrumentation/php/automatic/#next-steps","title":"Next steps","text":"<p>After you have automatic instrumentation configured for your app or service, you might want to add manual instrumentation to collect custom telemetry data.</p>"},{"location":"docs/instrumentation/php/exporters/","title":"Exporters","text":"<p>In order to visualize and analyze your telemetry, you will need to export it to a backend. OpenTelemetry PHP provides exporters for some common open source backends.</p>"},{"location":"docs/instrumentation/php/exporters/#otlp","title":"OTLP","text":"<p>To send trace data to a OTLP endpoint (like the collector or Jaeger) you'll need to use the <code>open-telemetry/exporter-otlp</code> package:</p> <pre><code>composer require open-telemetry/exporter-otlp\n</code></pre> <p>If you use gRPC, you will also need to install the <code>open-telemetry/transport-grpc</code> package:</p> <pre><code>composer require open-telemetry/transport-grpc\n</code></pre> <p>Next, configure the exporter with an OTLP endpoint. For example, you can update <code>GettingStarted.php</code> from Getting Started like the following:</p> <p>{{&lt; tabpane &gt;}} {{&lt; tab gRPC &gt;}} use OpenTelemetry\\API\\Common\\Signal\\Signals; use OpenTelemetry\\Contrib\\Grpc\\GrpcTransportFactory; use OpenTelemetry\\Contrib\\Otlp\\OtlpUtil; use OpenTelemetry\\Contrib\\Otlp\\SpanExporter; use OpenTelemetry\\SDK\\Trace\\SpanProcessor\\SimpleSpanProcessor; use OpenTelemetry\\SDK\\Trace\\TracerProvider;</p> <p>$transport = (new GrpcTransportFactory())-&gt;create('http://collector:4317' . OtlpUtil::method(Signals::TRACE)); \\(exporter = new SpanExporter(\\)transport); {{&lt; /tab &gt;}} {{&lt; tab protobuf &gt;}} use OpenTelemetry\\Contrib\\Otlp\\OtlpHttpTransportFactory; use OpenTelemetry\\Contrib\\Otlp\\SpanExporter; use OpenTelemetry\\SDK\\Trace\\SpanProcessor\\SimpleSpanProcessor; use OpenTelemetry\\SDK\\Trace\\TracerProvider;</p> <p>$transport = (new OtlpHttpTransportFactory())-&gt;create('http://collector:4318/v1/traces', 'application/x-protobuf'); \\(exporter = new SpanExporter(\\)transport); {{&lt; /tab&gt;}} {{&lt; tab json &gt;}} use OpenTelemetry\\Contrib\\Otlp\\OtlpHttpTransportFactory; use OpenTelemetry\\Contrib\\Otlp\\SpanExporter; use OpenTelemetry\\SDK\\Trace\\SpanProcessor\\SimpleSpanProcessor; use OpenTelemetry\\SDK\\Trace\\TracerProvider;</p> <p>$transport = (new OtlpHttpTransportFactory())-&gt;create('http://collector:4318/v1/traces', 'application/json'); \\(exporter = new SpanExporter(\\)transport); {{&lt; /tab &gt;}} {{&lt; tab nd-json &gt;}} /* newline-delimited JSON */ use OpenTelemetry\\Contrib\\Otlp\\OtlpHttpTransportFactory; use OpenTelemetry\\Contrib\\Otlp\\SpanExporter; use OpenTelemetry\\SDK\\Trace\\SpanProcessor\\SimpleSpanProcessor; use OpenTelemetry\\SDK\\Trace\\TracerProvider;</p> <p>$transport = (new OtlpHttpTransportFactory())-&gt;create('http://collector:4318/v1/traces', 'application/x-ndjson'); \\(exporter = new SpanExporter(\\)transport); {{&lt; /tab &gt;}} {{&lt; /tabpane &gt;}}</p> <p>Then, register the exporter in a tracer provider:</p> <pre><code>$tracerProvider =  new TracerProvider(\n   new SimpleSpanProcessor($exporter)\n);\n$tracer = $tracerProvider-&gt;getTracer('io.opentelemetry.contrib.php');\n</code></pre> <p>To try out the example locally, you can run Jaeger in a docker container:</p> <pre><code>docker run -d --name jaeger \\\n-e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n-e COLLECTOR_OTLP_ENABLED=true \\\n-p 6831:6831/udp \\\n-p 6832:6832/udp \\\n-p 5778:5778 \\\n-p 16686:16686 \\\n-p 4317:4317 \\\n-p 4318:4318 \\\n-p 14250:14250 \\\n-p 14268:14268 \\\n-p 14269:14269 \\\n-p 9411:9411 \\\njaegertracing/all-in-one:latest\n</code></pre>"},{"location":"docs/instrumentation/php/exporters/#zipkin","title":"Zipkin","text":"<p>If you're using Zipkin to visualize traces, you'll need to set it up first. Here's how to run it locally in a docker container.</p> <pre><code>docker run --rm -d -p 9411:9411 --name zipkin openzipkin/zipkin\n</code></pre> <p>Install the exporter package as a dependency for your application:</p> <pre><code>composer require open-telemetry/exporter-zipkin\n</code></pre> <p>Update the example to use the Zipkin exporter and to send data to your zipkin backend:</p> <pre><code>$transport = PsrTransportFactory::discover()-&gt;create('http://zipkin:9411/api/v2/spans', 'application/json');\n$zipkinExporter = new ZipkinExporter($transport);\n$tracerProvider =  new TracerProvider(\n    new SimpleSpanProcessor($zipkinExporter)\n);\n$tracer = $tracerProvider-&gt;getTracer('io.opentelemetry.contrib.php');\n</code></pre>"},{"location":"docs/instrumentation/php/exporters/#minimizing-export-delays","title":"Minimizing export delays","text":"<p>Most PHP runtimes are synchronous and blocking. Sending telemetry data can delay HTTP responses being received by your users.</p> <p>If you are using <code>fastcgi</code>, you could issue a call to <code>fastcgi_finish_request()</code> after sending a user response, which means that delays in sending telemetry data will not hold up request processing.</p> <p>To minimize the impact of slow transport of telemetry data, particularly for external or cloud-based backends, you should consider using a local OpenTelemetry Collector. A local collector can quickly accept, then batch and send all of your telemetry to the backend. Such a setup will make your system more robust and scalable.</p>"},{"location":"docs/instrumentation/php/getting-started/","title":"Getting Started","text":"<p>This page will show you how to get started with OpenTelemetry in PHP.</p> <p>You will learn how you can instrument a simple PHP application automatically, in such a way that traces, metrics and logs are emitted to the console.</p>"},{"location":"docs/instrumentation/php/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have the following installed locally: open source</p> <ul> <li>PHP 8.0+</li> <li>PECL</li> <li>composer</li> </ul> <p>Before you get started make sure that you have both available in your shell:</p> <pre><code>$ php -v\n$ composer -v\n</code></pre>"},{"location":"docs/instrumentation/php/getting-started/#example-application","title":"Example Application","text":"<p>The following example uses a basic Slim application. If you are not using Slim, that's ok \u2014 you can use OpenTelemetry PHP with other web frameworks as well, such as Wordpress, Symfony and Laravel. For a complete list of libraries for supported frameworks, see the registry.</p>"},{"location":"docs/instrumentation/php/getting-started/#dependencies","title":"Dependencies","text":"<p>In an empty directory create a minimal <code>composer.json</code> file in your directory:</p> <pre><code>echo '{\"require\": {}, \"minimum-stability\": \"beta\", \"config\": {\"allow-plugins\": {\"php-http/discovery\": true}}}' &gt; composer.json\n</code></pre> <p>In an empty directory create a minimal <code>composer.json</code> file in your directory:</p> <pre><code>composer require slim/slim:\"4.*\"\ncomposer require slim/psr7\n</code></pre>"},{"location":"docs/instrumentation/php/getting-started/#create-and-launch-an-http-server","title":"Create and launch an HTTP Server","text":"<p>In that same directory, create a file called <code>index.php</code></p>"},{"location":"docs/instrumentation/php/getting-started/#export-to-console","title":"Export to Console","text":"<p>In your directory create a file called <code>GettingStarted.php</code> with the following content:</p> <pre><code>&lt;?php\nuse Psr\\Http\\Message\\ResponseInterface as Response;\nuse Psr\\Http\\Message\\ServerRequestInterface as Request;\nuse Slim\\Factory\\AppFactory;\nrequire __DIR__ . '/vendor/autoload.php';\n$app = AppFactory::create();\n$app-&gt;get('/rolldice', function (Request $request, Response $response, $args) {\n$response-&gt;getBody()-&gt;write(strval(random_int(1,6)));\nreturn $response;\n});\n$app-&gt;run();\n</code></pre> <p>Run the application with the following command and open http://localhost:8080/rolldice in your web browser to ensure it is working.</p> <pre><code>php -S localhost:8080\n</code></pre>"},{"location":"docs/instrumentation/php/getting-started/#instrumentation","title":"Instrumentation","text":"<p>Next, you\u2019ll use the OpenTelemetry PHP extension to automatically instrument the application at launch time.</p> <ol> <li>Since the extension is built from source, you need to setup some build tools</li> </ol> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab \"Linux (apt)\" &gt;}}sudo apt-get install gcc make autoconf{{&lt; /tab &gt;}}</p> <p>{{&lt; tab \"MacOS (homebrew)\" &gt;}}brew install gcc make autoconf{{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane &gt;}}</p> <ol> <li>Build the extension with <code>PECL</code>:</li> </ol> <pre><code>$ pecl install opentelemetry-beta\n</code></pre> <p>{{% alert title=\"Note\" color=\"warning\" %}}If you want to pickle or the    docker-specific use php-extension-installer to build/install the extension,    read the instructions here. {{% /alert %}}</p> <ol> <li>Add the extension to your <code>php.ini</code> file:</li> </ol> <pre><code>[opentelemetry]\nextension=opentelemetry.so\n</code></pre> <ol> <li>Verify that the extension is installed and enabled:</li> </ol> <pre><code>$ php -m | grep opentelemetry\n</code></pre> <ol> <li>Add additional dependencies to your application, which are required for the    automatic instrumentation of your code:</li> </ol> <pre><code>$ composer require php-http/guzzle7-adapter open-telemetry/sdk open-telemetry/opentelemetry-auto-slim\n</code></pre> <p>With the OpenTelemetry PHP extension set up you can now run your application and automatically instrument it at launch time:</p> <pre><code>env OTEL_PHP_AUTOLOAD_ENABLED=true  OTEL_TRACES_EXPORTER=console OTEL_METRICS_EXPORTER=none OTEL_LOGS_EXPORTER=none php -S localhost:8080\n</code></pre> <p>Open http://localhost:8080/rolldice in your web browser and reload the page a few times. After a while you should see the spans printed to your console:</p> View example output <pre><code>[\n{\n\"name\": \"GET /rolldice\",\n\"context\": {\n\"trace_id\": \"16d7c6da7c021c574205736527816eb7\",\n\"span_id\": \"268e52331de62e33\",\n\"trace_state\": \"\"\n},\n\"resource\": {\n\"service.name\": \"__root__\",\n\"service.version\": \"1.0.0+no-version-set\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.language\": \"php\",\n\"telemetry.sdk.version\": \"1.0.0beta10\",\n\"telemetry.auto.version\": \"1.0.0beta5\",\n\"process.runtime.name\": \"cli-server\",\n\"process.runtime.version\": \"8.2.6\",\n\"process.pid\": 24435,\n\"process.executable.path\": \"/bin/php\",\n\"process.owner\": \"php\",\n\"os.type\": \"darwin\",\n\"os.description\": \"22.4.0\",\n\"os.name\": \"Darwin\",\n\"os.version\": \"Darwin Kernel Version 22.4.0: Mon Mar  6 20:59:28 PST 2023; root:xnu-8796.101.5~3/RELEASE_ARM64_T6000\",\n\"host.name\": \"OPENTELEMETRY-PHP\",\n\"host.arch\": \"arm64\"\n},\n\"parent_span_id\": \"\",\n\"kind\": \"KIND_SERVER\",\n\"start\": 1684749478068582482,\n\"end\": 1684749478072715774,\n\"attributes\": {\n\"code.function\": \"handle\",\n\"code.namespace\": \"Slim\\\\App\",\n\"code.filepath\": \"/vendor/slim/slim/Slim/App.php\",\n\"code.lineno\": 197,\n\"http.url\": \"http://localhost:8080/rolldice\",\n\"http.method\": \"GET\",\n\"http.request_content_length\": \"\",\n\"http.scheme\": \"http\",\n\"http.status_code\": 200,\n\"http.flavor\": \"1.1\",\n\"http.response_content_length\": \"\"\n},\n\"status\": {\n\"code\": \"Unset\",\n\"description\": \"\"\n},\n\"events\": [],\n\"links\": []\n}\n]\n</code></pre>"},{"location":"docs/instrumentation/php/getting-started/#whats-next","title":"What's next?","text":"<p>For more:</p> <ul> <li>Run this example with another exporter for telemetry data.</li> <li>Try automatic instrumentation on one of your own apps.</li> <li>Learn about manual instrumentation and try out more   examples.</li> </ul>"},{"location":"docs/instrumentation/php/manual/","title":"Manual Instrumentation","text":"<p>Libraries that want to export telemetry data using OpenTelemetry MUST only depend on the <code>opentelemetry-api</code> package and should never configure or depend on the OpenTelemetry SDK.</p> <p>The SDK configuration must be provided by Applications which should also depend on the <code>opentelemetry-sdk</code> package, or any other implementation of the OpenTelemetry API. This way, libraries will obtain a real implementation only if the user application is configured for it.</p>"},{"location":"docs/instrumentation/php/manual/#installation","title":"Installation","text":"<p>The following shows how to install, initialize, and run an application instrumented with OpenTelemetry.</p> <p>To use the OpenTelemetry SDK for PHP you need packages that satisfy the dependencies for <code>php-http/async-client-implementation</code> and <code>psr/http-factory-implementation</code>, for example the Guzzle 7 HTTP Adapter satisfies both:</p> <pre><code>composer require \"php-http/guzzle7-adapter\"\n</code></pre> <p>Now you can install the OpenTelemetry SDK:</p> <pre><code>composer require open-telemetry/sdk\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#tracing","title":"Tracing","text":""},{"location":"docs/instrumentation/php/manual/#setup","title":"Setup","text":"<p>The first step is to get a handle to an instance of the <code>OpenTelemetry</code> interface.</p> <p>If you are an application developer, you need to configure an instance of the <code>OpenTelemetry SDK</code> as early as possible in your application. This can be done using the <code>Sdk::builder()</code> method. The returned <code>SdkBuilder</code> instance gets the providers related to the signals, tracing and metrics, in order to build the <code>OpenTelemetry</code> instance.</p> <p>You can build the providers by using the <code>TracerProvider::builder()</code> and <code>MeterProvider::builder()</code> methods. It is also strongly recommended to define a <code>Resource</code> instance as a representation of the entity producing the telemetry; in particular the <code>service.name</code> attribute is the most important piece of telemetry source-identifying info.</p>"},{"location":"docs/instrumentation/php/manual/#example","title":"Example","text":"<pre><code>&lt;?php\n$resource = ResourceInfoFactory::defaultResource();\n$transport = (new GrpcTransportFactory())-&gt;create('http://collector:4317' . OtlpUtil::method(Signals::TRACE));\n$exporter = new SpanExporter($transport);\n$reader = new ExportingReader(\nnew MetricExporter(\nPsrTransportFactory::discover()-&gt;create('http://collector:4318/v1/metrics', 'application/x-protobuf')\n),\nClockFactory::getDefault()\n);\n$meterProvider = MeterProvider::builder()\n-&gt;setResource($resource)\n-&gt;addReader($reader)\n-&gt;build();\n$tracerProvider = TracerProvider::builder()\n-&gt;addSpanProcessor(\n(new BatchSpanProcessorBuilder($spanExporter))\n-&gt;setMeterProvider($meterProvider)\n-&gt;build()\n)\n-&gt;setResource($resource)\n-&gt;setSampler(new ParentBased(new AlwaysOnSampler()))\n-&gt;build();\nSdk::builder()\n-&gt;setTracerProvider($tracerProvider)\n-&gt;setMeterProvider($meterProvider)\n-&gt;setPropagator(TraceContextPropagator::getInstance())\n-&gt;setAutoShutdown(true)\n-&gt;buildAndRegisterGlobal();\n$instrumentation = new CachedInstrumentation('example');\n$tracer = $instrumentation-&gt;tracer();\n</code></pre> <p>It's important to run the tracer provider's <code>shutdown()</code> method when the PHP process ends, to enable flushing of any enqueued telemetry. The shutdown process is blocking, so consider running it in an async process. Otherwise, you can use the <code>ShutdownHandler</code> to register the shutdown function as part of PHP's shutdown process:</p> <pre><code>\\OpenTelemetry\\SDK\\Common\\Util\\ShutdownHandler::register([$tracerProvider, 'shutdown']);\n\\OpenTelemetry\\SDK\\Common\\Util\\ShutdownHandler::register([$meterProvider, 'shutdown']);\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#acquiring-a-tracer","title":"Acquiring a Tracer","text":"<p>To do Tracing you'll need to acquire a <code>Tracer</code>.</p> <p>Note: Methods of the OpenTelemetry SDK should never be called.</p> <p>First, a <code>Tracer</code> must be acquired, which is responsible for creating spans and interacting with the Context. A tracer is acquired by using the OpenTelemetry API specifying the name and version of the library instrumenting the instrumented library or application to be monitored. More information is available in the specification chapter Obtaining a Tracer.</p> <pre><code>$tracer = Globals::tracerProvider()-&gt;getTracer('instrumentation-library-name', '1.0.0');\n</code></pre> <p>Important: the \"name\" and optional version of the tracer are purely informational. All <code>Tracer</code>s that are created by a single <code>OpenTelemetry</code> instance will interoperate, regardless of name.</p>"},{"location":"docs/instrumentation/php/manual/#create-spans","title":"Create Spans","text":"<p>To create Spans, you only need to specify the name of the span. The start and end time of the span is automatically set by the OpenTelemetry SDK.</p> <pre><code>$span = $tracer-&gt;spanBuilder(\"my span\")-&gt;startSpan();\n// Make the span the current span\ntry {\n  $scope = $span-&gt;activate();\n  // In this scope, the span is the current/active span\n} finally {\n    $span-&gt;end();\n    $scope-&gt;detach();\n}\n</code></pre> <p>It's required to call <code>end()</code> to end the span, and you must <code>detach</code> the active scope if you have activated it.</p>"},{"location":"docs/instrumentation/php/manual/#create-nested-spans","title":"Create nested Spans","text":"<p>Most of the time, we want to correlate spans for nested operations. OpenTelemetry supports tracing within processes and across remote processes. For more details how to share context between remote processes, see Context Propagation.</p> <p>For a method <code>a</code> calling a method <code>b</code>, the spans could be manually linked in the following way:</p> <pre><code>  $parentSpan = $tracer-&gt;spanBuilder(\"parent\")-&gt;startSpan();\n  $scope = $parentSpan-&gt;activate();\n  try {\n    $child = $tracer-&gt;spanBuilder(\"child\")-&gt;startSpan();\n    //do stuff\n    $child-&gt;end();\n  } finally {\n    $parentSpan-&gt;end();\n    $scope-&gt;detach();\n  }\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#get-the-current-span","title":"Get the current span","text":"<p>Sometimes it's helpful to do something with the current/active span at a particular point in program execution.</p> <pre><code>$span = OpenTelemetry\\API\\Trace\\Span::getCurrent();\n</code></pre> <p>And if you want the current span for a particular <code>Context</code> object:</p> <pre><code>$span = OpenTelemetry\\API\\Trace\\Span::fromContext($context);\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#span-attributes","title":"Span Attributes","text":"<p>In OpenTelemetry spans can be created freely and it's up to the implementor to annotate them with attributes specific to the represented operation. Attributes provide additional context on a span about the specific operation it tracks, such as results or operation properties.</p> <pre><code>$span = $tracer-&gt;spanBuilder(\"/resource/path\")-&gt;setSpanKind(SpanKind::CLIENT)-&gt;startSpan();\n$span-&gt;setAttribute(\"http.method\", \"GET\");\n$span-&gt;setAttribute(\"http.url\", (string) $url);\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#create-spans-with-events","title":"Create Spans with events","text":"<p>Spans can be annotated with named events (called Span Events) that can carry zero or more Span Attributes, each of which itself is a key:value map paired automatically with a timestamp.</p> <pre><code>$span-&gt;addEvent(\"Init\");\n...\n$span-&gt;addEvent(\"End\");\n</code></pre> <pre><code>$eventAttributes = Attributes::create([\n    \"key\" =&gt; \"value\",\n    \"result\" =&gt; 3.14159;\n]);\n$span-&gt;addEvent(\"End Computation\", $eventAttributes);\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#create-spans-with-links","title":"Create Spans with links","text":"<p>A Span may be linked to zero or more other Spans that are causally related via a Span Link. Links can be used to represent batched operations where a Span was initiated by multiple initiating Spans, each representing a single incoming item being processed in the batch.</p> <pre><code>$span = $tracer-&gt;spanBuilder(\"span-with-links\")\n        -&gt;addLink($parentSpan1-&gt;getContext())\n        -&gt;addLink($parentSpan2-&gt;getContext())\n        -&gt;addLink($parentSpan3-&gt;getContext())\n        -&gt;addLink($remoteSpanContext)\n    -&gt;startSpan();\n</code></pre> <p>For more details how to read context from remote processes, see Context Propagation.</p>"},{"location":"docs/instrumentation/php/manual/#set-span-status-and-record-exceptions","title":"Set span status and record exceptions","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - <code>SpanStatus::ERROR</code>. In rare scenarios, you could override the <code>Error</code> status with <code>Ok</code>, but don't set <code>Ok</code> on successfully-completed spans.</p> <p>It can be a good idea to record exceptions when they happen. It's recommended to do this in conjunction with setting span status.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>$span = $tracer-&gt;spanBuilder(\"my-span\")-&gt;startSpan();\n$scope = $span-&gt;activate();\ntry {\n  // do something\n} catch (Throwable $t) {\n  $span-&gt;setStatus(StatusCode::STATUS_ERROR, \"Something bad happened!\");\n  $span-&gt;recordException($t); //This will capture things like the current stack trace in the span.\n  throw $t;\n} finally {\n  $span-&gt;end(); // Cannot modify span after this call\n  $scope-&gt;detach();\n}\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#sampler","title":"Sampler","text":"<p>It is not always feasible to trace and export every user request in an application. In order to strike a balance between observability and expenses, traces can be sampled.</p> <p>The OpenTelemetry SDK offers four samplers out of the box:</p> <ul> <li><code>AlwaysOnSampler</code> which samples every trace regardless of upstream sampling   decisions.</li> <li><code>AlwaysOffSampler</code> which doesn't sample any trace, regardless of upstream   sampling decisions.</li> <li><code>ParentBased</code> which uses the parent span to make sampling decisions, if   present.</li> <li><code>TraceIdRatioBased</code> which samples a configurable percentage of traces, and   additionally samples any trace that was sampled upstream.</li> </ul> <pre><code>$tracerProvider = TracerProvider::builder()\n  -&gt;setSampler(new AlwaysOnSampler())\n  //or\n  -&gt;setSampler(new AlwaysOffSampler())\n  //or\n  -&gt;setSampler(new TraceIdRatioBasedSampler(0.5))\n  -&gt;build();\n</code></pre> <p>Additional samplers can be provided by implementing <code>OpenTelemetry\\SDK\\Trace\\SamplerInterface</code>. An example of doing so would be to make sampling decisions based on attributes set at span creation time.</p>"},{"location":"docs/instrumentation/php/manual/#span-processor","title":"Span Processor","text":"<p>Different Span processors are offered by OpenTelemetry. The <code>SimpleSpanProcessor</code> immediately forwards ended spans to the exporter, while the <code>BatchSpanProcessor</code> batches them and sends them in bulk.</p> <pre><code>$tracerProvider = TracerProvider::builder()\n  -&gt;addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporterFactory()-&gt;create()))\n  -&gt;build();\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#transports","title":"Transports","text":"<p>All exporters require a <code>Transport</code>, which is responsible for the sending of telemetry data from an exporter:</p> <ul> <li><code>PsrTransport</code> - uses a PSR18 client to send data over HTTP</li> <li><code>StreamTransport</code> - uses a stream to send data</li> <li><code>GrpcTransport</code> - uses gRPC to send protobuf-encoded data</li> </ul>"},{"location":"docs/instrumentation/php/manual/#exporter","title":"Exporter","text":"<p>Span processors are initialized with an exporter which is responsible for sending the telemetry data to a particular backend:</p> <ul> <li><code>InMemory</code>: keeps the data in memory, useful for testing and debugging.</li> <li><code>Console</code>: sends the data to a stream such as <code>stdout</code> or <code>stderr</code></li> <li><code>Zipkin</code>: prepares and sends the collected telemetry data to a Zipkin backend   via the Zipkin APIs.</li> <li>Logging Exporter: saves the telemetry data into log streams.</li> <li>OpenTelemetry Protocol Exporter: sends the data in OTLP format to the   OpenTelemetry Collector or other OTLP receivers. The   underlying <code>Transport</code> can send:</li> <li>protobuf over HTTP</li> <li>protobuf over gRPC</li> <li>JSON over HTTP</li> </ul>"},{"location":"docs/instrumentation/php/manual/#logging-and-error-handling","title":"Logging and Error Handling","text":"<p>OpenTelemetry can be configured to use a PSR-3 logger to log information about OpenTelemetry, including errors and warnings about misconfigurations or failures exporting data:</p> <pre><code>$logger = new Psr3Logger(LogLevel::INFO);\nLoggerHolder::set($logger);\n</code></pre> <p>If no PSR-3 logger is provided, error messages will instead be recorded via <code>trigger_error</code> (at a level no higher than <code>E_USER_WARNING</code>).</p> <p>For more fine-grained control and special case handling, custom handlers and filters can be applied to the logger (if the logger offers this ability).</p>"},{"location":"docs/instrumentation/php/manual/#metrics","title":"Metrics","text":"<p>OpenTelemetry can be used to measure and record different types of metrics from an application, which can then be pushed to a metrics service such as the OpenTelemetry collector:</p> <ul> <li>counter</li> <li>async counter</li> <li>histogram</li> <li>async gauge</li> <li>up/down counter</li> <li>async up/down counter</li> </ul> <p>Meter types and usage are explained in the metrics concepts documentation.</p>"},{"location":"docs/instrumentation/php/manual/#setup_1","title":"Setup","text":"<p>First, create a <code>MeterProvider</code>:</p> <pre><code>$reader = new ExportingReader((new ConsoleMetricExporterFactory())-&gt;create());\n$meterProvider = MeterProvider::builder()\n    -&gt;addReader($reader)\n    -&gt;build();\n</code></pre> <p>You can now use the meter provider to retrieve meters.</p>"},{"location":"docs/instrumentation/php/manual/#synchronous-meters","title":"Synchronous meters","text":"<p>A synchronous meter must be manually adjusted as data changes:</p> <pre><code>$up_down = $meterProvider\n    -&gt;getMeter('my_up_down')\n    -&gt;createUpDownCounter('queued', 'jobs', 'The number of jobs enqueued');\n//jobs come in\n$up_down-&gt;add(2);\n//job completed\n$up_down-&gt;add(-1);\n//more jobs come in\n$up_down-&gt;add(2);\n$meterProvider-&gt;forceFlush();\n</code></pre> <p>Synchronous metrics are exported when <code>forceFlush()</code> and/or <code>shutdown()</code> are called on the meter provider.</p>"},{"location":"docs/instrumentation/php/manual/#asynchronous-meters","title":"Asynchronous meters","text":"<p>Async meters are <code>observable</code>, eg <code>ObservableGauge</code>. When registering an observable/async meter, you provide one or more callback functions. The callback functions will be called by a periodic exporting metric reader, for example based on an event-loop timer. The callback(s) are responsible for returning the latest data for the meter.</p> <p>In this example, the callbacks are executed when <code>$reader-&gt;collect()</code> is executed:</p> <pre><code>$queue = [\n    'job1',\n    'job2',\n    'job3',\n];\n$meterProvider\n    -&gt;getMeter('my_gauge')\n    -&gt;createObservableGauge('queued', 'jobs', 'The number of jobs enqueued')\n    -&gt;observe(static function (ObserverInterface $observer) use ($queue): void {\n        $observer-&gt;observe(count($queue));\n    });\n$reader-&gt;collect();\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#readers","title":"Readers","text":"<p>Currently we only have an <code>ExportingReader</code>, which is an implementation of the periodic exporting metric reader. When its <code>collect()</code> method is called, all associated asynchronous meters are observed, and metrics pushed to the exporter.</p>"},{"location":"docs/instrumentation/php/manual/#logging","title":"Logging","text":"<p>As logging is a mature and well-established function, the OpenTelemetry approach is a little different for this signal.</p> <p>The OpenTelemetry logger is not designed to be used directly, but rather to be integrated into existing logging libraries as a handler. In this way, you can choose to have some or all of your application logs sent to an OpenTelemetry-compatible service such as the collector.</p>"},{"location":"docs/instrumentation/php/manual/#setup_2","title":"Setup","text":"<p>You get a logger from a <code>LoggerProvider</code>. Log records get emitted via an <code>EventLogger</code>:</p> <pre><code>&lt;?php\n$loggerProvider = new LoggerProvider(\nnew SimpleLogsProcessor(\nnew ConsoleExporter()\n)\n);\n$logger = $loggerProvider-&gt;getLogger('demo', '1.0', 'http://schema.url', [/*attributes*/]);\n$eventLogger = new EventLogger($logger, 'my-domain');\n</code></pre> <p>Once configured, a <code>LogRecord</code> can be created and sent via the event logger's <code>logEvent</code>method:</p> <pre><code>$record = (new LogRecord('hello world'))\n    -&gt;setSeverityText('INFO')\n    -&gt;setAttributes([/*attributes*/]);\n$eventLogger-&gt;logEvent('foo', $record);\n</code></pre>"},{"location":"docs/instrumentation/php/manual/#integrations-for-3rd-party-logging-libraries","title":"Integrations for 3rd-party logging libraries","text":""},{"location":"docs/instrumentation/php/manual/#monolog","title":"Monolog","text":"<p>You can use the monolog handler to send monolog logs to an OpenTelemetry-capable receiver:</p> <pre><code>composer require open-telemetry/opentelemetry-logger-monolog\n</code></pre> <pre><code>$loggerProvider = new LoggerProvider(/*params*/);\n$handler = new \\OpenTelemetry\\Contrib\\Logs\\Monolog\\Handler(\n    $loggerProvider,\n    \\Psr\\Log\\LogLevel::ERROR,\n);\n$logger = new \\Monolog\\Logger('example', [$handler]);\n$logger-&gt;info('hello, world');\n$logger-&gt;error('oh no', [\n    'foo' =&gt; 'bar',\n    'exception' =&gt; new \\Exception('something went wrong'),\n]);\n$loggerProvider-&gt;shutdown();\n</code></pre>"},{"location":"docs/instrumentation/php/propagation/","title":"Propagation","text":"<p>Propagation is the mechanism that moves data between services and processes. Although not limited to tracing, it is what allows traces to build causal information about a system across services that are arbitrarily distributed across process and network boundaries.</p> <p>OpenTelemetry provides a text-based approach to propagate context to remote services using the W3C Trace Context HTTP headers.</p>"},{"location":"docs/instrumentation/php/propagation/#context-propagation-with-frameworks-and-libraries","title":"Context propagation with frameworks and libraries","text":"<p>Auto-instrumentation exists for some popular PHP frameworks (eg Symfony, Laravel, Slim) and HTTP libraries propagate context for incoming and outgoing HTTP requests.</p> <p>We highly recommend that you use auto-instrumentation or instrumentation libraries to propagate context. Although it is possible to propagate context manually, the PHP auto-instrumentation and instrumentation libraries are well-tested and easier to use.</p>"},{"location":"docs/instrumentation/php/propagation/#incoming","title":"Incoming","text":"<p>Auto-instrumentation for frameworks which implement the PSR-15 <code>RequestHandlerInterface</code> will automatically extract W3C tracecontext headers, create a root span, and set a remote parent for the root span.</p> <pre><code>composer require open-telemetry/opentelemetry-auto-psr15\n</code></pre>"},{"location":"docs/instrumentation/php/propagation/#outgoing","title":"Outgoing","text":"<p>PSR-18 auto-instrumentation will automatically apply W3C tracecontext headers to outgoing HTTP requests for any library which implements the PSR-18 interface.</p> <pre><code>open-telemetry/opentelemetry-auto-psr18\n</code></pre>"},{"location":"docs/instrumentation/php/propagation/#manual-w3c-trace-context-propagation","title":"Manual W3C Trace Context Propagation","text":"<p>In some cases, it is not possible to propagate context with an instrumentation library. There may not be an instrumentation library that matches a library you're using to have services communicate with one another. Or you many have requirements that instrumentation libraries cannot fulfill, even if they exist.</p> <p>When you must propagate context manually, you can use the context api.</p> <p>The following presents an example of an outgoing HTTP request:</p> <pre><code>$request = new Request('GET', 'http://localhost:8080/resource');\n$outgoing = $tracer-&gt;spanBuilder('/resource')-&gt;setSpanKind(SpanKind::CLIENT)-&gt;startSpan();\n$outgoing-&gt;setAttribute(TraceAttributes::HTTP_METHOD, $request-&gt;getMethod());\n$outgoing-&gt;setAttribute(TraceAttributes::HTTP_URL, (string) $request-&gt;getUri());\n$carrier = [];\nTraceContextPropagator::getInstance()-&gt;inject($carrier);\nforeach ($carrier as $name =&gt; $value) {\n    $request = $request-&gt;withAddedHeader($name, $value);\n}\ntry {\n    $response = $client-&gt;send($request);\n} finally {\n    $outgoing-&gt;end();\n}\n</code></pre> <p>Similarly, the text-based approach can be used to read the W3C Trace Context from incoming requests. The following presents an example of processing an incoming HTTP request:</p> <pre><code>$request = ServerRequestCreator::createFromGlobals();\n$context = TraceContextPropagator::getInstance()-&gt;extract($request-&gt;getHeaders());\n$root = $tracer-&gt;spanBuilder('HTTP ' . $request-&gt;getMethod())\n    -&gt;setStartTimestamp((int) ($request-&gt;getServerParams()['REQUEST_TIME_FLOAT'] * 1e9))\n    -&gt;setParent($context)\n    -&gt;setSpanKind(SpanKind::KIND_SERVER)\n    -&gt;startSpan();\n$scope = $root-&gt;activate();\ntry {\n    /* do stuff */\n} finally {\n    $root-&gt;end();\n    $scope-&gt;detach();\n}\n</code></pre>"},{"location":"docs/instrumentation/php/resources/","title":"Resources","text":"<p>A resource represents the entity producing telemetry as resource attributes. For example, a process producing telemetry that is running in a container on Kubernetes has a Pod name, a namespace, and possibly a deployment name. All three of these attributes can be included in the resource.</p> <p>In your observability backend, you can use resource information to better investigate interesting behavior. For example, if your trace or metrics data indicate latency in your system, you can narrow it down to a specific container, pod, or Kubernetes deployment.</p>"},{"location":"docs/instrumentation/php/resources/#resource-detection","title":"Resource Detection","text":"<p>The PHP SDK detects resources from a variety of sources, and by default will use all available resource detectors:</p> <ul> <li>environment (<code>OTEL_RESOURCE_ATTRIBUTES</code>, <code>OTEL_SERVICE_NAME</code>)</li> <li>host information</li> <li>host operating system</li> <li>current process</li> <li>runtime</li> </ul>"},{"location":"docs/instrumentation/php/resources/#disabling-resource-detection","title":"Disabling resource detection","text":"<p>By default, all SDK resource detectors are used, but you can use the environment variable <code>OTEL_PHP_RESOURCE_DETECTORS</code> to enable only certain detectors, or completely disable them:</p> <ul> <li><code>env</code></li> <li><code>host</code></li> <li><code>os</code></li> <li><code>process</code></li> <li><code>process_runtime</code></li> <li><code>sdk</code></li> <li><code>sdk_provided</code></li> <li><code>all</code> - enable all resource detectors</li> <li><code>none</code> - disable resource detection</li> </ul> <p>For example, to enable only the <code>env</code>, <code>host</code> and <code>sdk</code> detectors:</p> <pre><code>env OTEL_PHP_RESOURCE_DETECTORS=env,host,sdk \\\nphp example.php\n</code></pre>"},{"location":"docs/instrumentation/php/resources/#custom-resource-detectors","title":"Custom resource detectors","text":"<p>Resource detectors for generic platforms or vendor-specific environments can be installed as composer packages.</p> <p>For example, to install and enable the <code>container</code> resource detector:</p> <pre><code>composer require open-telemetry/detector-container\nenv OTEL_PHP_RESOURCE_DETECTORS=container \\\nphp example.php\n</code></pre> <p>Note that installed detectors are automatically included in the default <code>all</code> resource detector list.</p>"},{"location":"docs/instrumentation/php/resources/#adding-resources-with-environment-variables","title":"Adding resources with environment variables","text":"<p>If there is not an SDK detector for the resource you need, you can add arbitrary resources via the <code>OTEL_RESOURCE_ATTRIBUTES</code> environment variable, which is interpreted by the <code>env</code> detector. This variable takes a comma-separated list of key=value pairs, for example:</p> <pre><code>env OTEL_RESOURCE_ATTRIBUTES=\"service.name=my_service,service.namespace=demo,service.version=1.0,deployment.environment=development\" \\\nphp example.php\n</code></pre>"},{"location":"docs/instrumentation/php/resources/#adding-resources-in-code","title":"Adding resources in code","text":"<p>Custom resources can also be configured in your code. Here, the default resources (detected as described above) are merged with custom resources. The resources are then passed to the tracer provider, where they will be associated with all generated spans.</p> <pre><code>$resource = ResourceInfoFactory::defaultResource()-&gt;merge(ResourceInfo::create(Attributes::create([\n    ResourceAttributes::SERVICE_NAMESPACE =&gt; 'foo',\n    ResourceAttributes::SERVICE_NAME =&gt; 'bar',\n    ResourceAttributes::SERVICE_INSTANCE_ID =&gt; 1,\n    ResourceAttributes::SERVICE_VERSION =&gt; '0.1',\n    ResourceAttributes::DEPLOYMENT_ENVIRONMENT =&gt; 'development',\n])));\n$tracerProvider =  new TracerProvider(\n    new SimpleSpanProcessor(\n        (new ConsoleSpanExporterFactory())-&gt;create()\n    ),\n    null,\n    $resource\n);\n</code></pre>"},{"location":"docs/instrumentation/php/sdk/","title":"SDK","text":"<p>The OpenTelemetry SDK provides a working implementation of the API, and can be set up and configured in a number of ways.</p>"},{"location":"docs/instrumentation/php/sdk/#manual-setup","title":"Manual setup","text":"<p>Setting up an SDK manually gives you the most control over the SDK's configuration:</p> <pre><code>&lt;?php\n$exporter = new InMemoryExporter();\n$meterProvider = new NoopMeterProvider();\n$tracerProvider =  new TracerProvider(\nnew BatchSpanProcessor(\n$exporter,\nClockFactory::getDefault(),\n2048, //max queue size\n5000, //export timeout\n1024, //max batch size\ntrue, //autoflush\n$meterProvider\n)\n);\n</code></pre>"},{"location":"docs/instrumentation/php/sdk/#sdk-builder","title":"SDK Builder","text":"<p>The SDK builder provides a convenient interface to configure parts of the SDK. However, it doesn't support all of the features that manual setup does.</p> <pre><code>&lt;?php\n$spanExporter = new InMemoryExporter(); //mock exporter for demonstration purposes\n$meterProvider = MeterProvider::builder()\n-&gt;registerMetricReader(\nnew ExportingReader(new MetricExporter((new StreamTransportFactory())-&gt;create(STDOUT, 'application/x-ndjson'), /*Temporality::CUMULATIVE*/))\n)\n-&gt;build();\n$tracerProvider = TracerProvider::builder()\n-&gt;addSpanProcessor(\n(new BatchSpanProcessorBuilder($spanExporter))\n-&gt;setMeterProvider($meterProvider)\n-&gt;build()\n)\n-&gt;build();\n$loggerProvider = LoggerProvider::builder()\n-&gt;addLogRecordProcessor(\nnew SimpleLogsProcessor(\n(new ConsoleExporterFactory())-&gt;create()\n)\n)\n-&gt;setResource(ResourceInfo::create(Attributes::create(['foo' =&gt; 'bar'])))\n-&gt;build();\nSdk::builder()\n-&gt;setTracerProvider($tracerProvider)\n-&gt;setLoggerProvider($loggerProvider)\n-&gt;setMeterProvider($meterProvider)\n-&gt;setPropagator(TraceContextPropagator::getInstance())\n-&gt;setAutoShutdown(true)\n-&gt;buildAndRegisterGlobal();\n</code></pre>"},{"location":"docs/instrumentation/php/sdk/#autoloading","title":"Autoloading","text":"<p>If all configuration comes from environment variables (or <code>php.ini</code>), you can use SDK autoloading to automatically configure and globally register an SDK. The only requirement for this is that you set <code>OTEL_PHP_AUTOLOAD_ENABLED=true</code>, and provide any required/non-standard configuration as set out in sdk-configuration.</p> <p>For example:</p> <pre><code>OTEL_PHP_AUTOLOAD_ENABLED=true \\\nOTEL_EXPORTER_OTLP_PROTOCOL=grpc \\\nOTEL_EXPORTER_OTLP_ENDPOINT=http://collector:4317 \\\nphp example.php\n</code></pre> <pre><code>&lt;?php\nrequire 'vendor/autoload.php'; //sdk autoloading happens as part of composer initialization\n$tracer = OpenTelemetry\\API\\Common\\Instrumentation\\Globals::tracerProvider()-&gt;getTracer('name', 'version', 'schema.url', [/*attributes*/]);\n$meter = OpenTelemetry\\API\\Common\\Instrumentation\\Globals::meterProvider()-&gt;getTracer('name', 'version', 'schema.url', [/*attributes*/]);\n</code></pre> <p>SDK autoloading happens as part of the composer autoloader.</p> <p>{{% alert title=\"Important\" color=\"warning\" %}}The batch span and log processors emit metrics about their internal state, so ensure that you have a correctly configured metrics exporter. Alternatively, you can disable metrics by setting <code>OTEL_METRICS_EXPORTER=none</code>}</p>"},{"location":"docs/instrumentation/php/sdk/#configuration","title":"Configuration","text":"<p>The PHP SDK supports most of the available configurations. Our conformance to the specification is listed in the spec compliance matrix.</p> <p>There are also a number of PHP-specific configurations:</p> Name Default value Values Example Description OTEL_PHP_TRACES_PROCESSOR batch batch, simple simple Span processor selection OTEL_PHP_DETECTORS all env, host, os, process, process_runtime, sdk, sdk_provided, container env,os,process Resource detector selection OTEL_PHP_AUTOLOAD_ENABLED false true, false true Enable/disable SDK autoloading OTEL_PHP_DISABLED_INSTRUMENTATIONS [] Instrumentation name(s) psr15,psr18 Disable one or more installed auto-instrumentations <p>Configurations can be provided as environment variables, or via <code>php.ini</code> (or a file included by <code>php.ini</code>)</p>"},{"location":"docs/instrumentation/python/_index/","title":"Python","text":"<p>{{% lang_instrumentation_index_head python /%}}</p>"},{"location":"docs/instrumentation/python/_index/#version-support","title":"Version support","text":"<p>OpenTelemetry-Python supports Python 3.6 and higher.</p>"},{"location":"docs/instrumentation/python/_index/#installation","title":"Installation","text":"<p>The API and SDK packages are available on PyPI, and can be installed via pip:</p> <pre><code>pip install opentelemetry-api\npip install opentelemetry-sdk\n</code></pre> <p>In addition, there are several extension packages which can be installed separately as:</p> <pre><code>pip install opentelemetry-exporter-{exporter}\npip install opentelemetry-instrumentation-{instrumentation}\n</code></pre> <p>These are for exporter and instrumentation packages respectively. The Jaeger, Zipkin, Prometheus, OTLP and OpenCensus Exporters can be found in the exporter directory of the repository. Instrumentations and additional exporters can be found in the contrib repo instrumentation and exporter directories.</p>"},{"location":"docs/instrumentation/python/_index/#extensions","title":"Extensions","text":"<p>To find related projects like exporters, instrumentation libraries, tracer implementations, etc., visit the Registry.</p>"},{"location":"docs/instrumentation/python/_index/#installing-cutting-edge-packages","title":"Installing Cutting-edge Packages","text":"<p>There is some functionality that has not yet been released to PyPI. In that situation, you may want to install the packages directly from the repo. This can be done by cloning the repository and doing an editable install:</p> <pre><code>git clone https://github.com/open-telemetry/opentelemetry-python.git\ncd opentelemetry-python\npip install -e ./opentelemetry-api\npip install -e ./opentelemetry-sdk\n</code></pre>"},{"location":"docs/instrumentation/python/_index/#repositories-and-benchmarks","title":"Repositories and benchmarks","text":"<ul> <li>Main repo: opentelemetry-python</li> <li>Contrib repo: opentelemetry-python-contrib</li> </ul>"},{"location":"docs/instrumentation/python/cookbook/","title":"Cookbook","text":"<p>This page is a cookbook for common scenarios.</p>"},{"location":"docs/instrumentation/python/cookbook/#create-a-new-span","title":"Create a new span","text":"<pre><code>from opentelemetry import trace\ntracer = trace.get_tracer(\"my.tracer\")\nwith tracer.start_as_current_span(\"print\") as span:\nprint(\"foo\")\nspan.set_attribute(\"printed_string\", \"foo\")\n</code></pre>"},{"location":"docs/instrumentation/python/cookbook/#getting-and-modifying-a-span","title":"Getting and modifying a span","text":"<pre><code>from opentelemetry import trace\ncurrent_span = trace.get_current_span()\ncurrent_span.set_attribute(\"hometown\", \"seattle\")\n</code></pre>"},{"location":"docs/instrumentation/python/cookbook/#create-a-nested-span","title":"Create a nested span","text":"<pre><code>from opentelemetry import trace\nimport time\ntracer = trace.get_tracer(\"my.tracer\")\n# Create a new span to track some work\nwith tracer.start_as_current_span(\"parent\"):\ntime.sleep(1)\n# Create a nested span to track nested work\nwith tracer.start_as_current_span(\"child\"):\ntime.sleep(2)\n# the nested span is closed when it's out of scope\n# Now the parent span is the current span again\ntime.sleep(1)\n# This span is also closed when it goes out of scope\n</code></pre>"},{"location":"docs/instrumentation/python/cookbook/#capturing-baggage-at-different-contexts","title":"Capturing baggage at different contexts","text":"<pre><code>from opentelemetry import trace, baggage\ntracer = trace.get_tracer(\"my.tracer\")\nwith tracer.start_as_current_span(name=\"root span\") as root_span:\nparent_ctx = baggage.set_baggage(\"context\", \"parent\")\nwith tracer.start_as_current_span(\nname=\"child span\", context=parent_ctx\n) as child_span:\nchild_ctx = baggage.set_baggage(\"context\", \"child\")\nprint(baggage.get_baggage(\"context\", parent_ctx))\nprint(baggage.get_baggage(\"context\", child_ctx))\n</code></pre>"},{"location":"docs/instrumentation/python/cookbook/#manually-setting-span-context","title":"Manually setting span context","text":"<p>Usually your application or serving framework will take care of propagating your trace context for you. But in some cases, you may need to save your trace context (with <code>.inject</code>) and restore it elsewhere (with <code>.extract</code>) yourself.</p> <pre><code>from opentelemetry import trace, context\nfrom opentelemetry.trace import NonRecordingSpan, SpanContext, TraceFlags\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor\nfrom opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator\n# Set up a simple processor to write spans out to the console so we can see what's happening.\ntrace.set_tracer_provider(TracerProvider())\ntrace.get_tracer_provider().add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\ntracer = trace.get_tracer(\"my.tracer\")\n# A TextMapPropagator works with any dict-like object as its Carrier by default. You can also implement custom getters and setters.\nwith tracer.start_as_current_span('first-trace'):\ncarrier = {}\n# Write the current context into the carrier.\nTraceContextTextMapPropagator().inject(carrier)\n# The below might be in a different thread, on a different machine, etc.\n# As a typical example, it would be on a different microservice and the carrier would\n# have been forwarded via HTTP headers.\n# Extract the trace context from the carrier.\n# Here's what a typical carrier might look like, as it would have been injected above.\ncarrier = {'traceparent': '00-a9c3b99a95cc045e573e163c3ac80a77-d99d251a8caecd06-01'}\n# Then we use a propagator to get a context from it.\nctx = TraceContextTextMapPropagator().extract(carrier=carrier)\n# Instead of extracting the trace context from the carrier, if you have a SpanContext\n# object already you can get a trace context from it like this.\nspan_context = SpanContext(\ntrace_id=2604504634922341076776623263868986797,\nspan_id=5213367945872657620,\nis_remote=True,\ntrace_flags=TraceFlags(0x01)\n)\nctx = trace.set_span_in_context(NonRecordingSpan(span_context))\n# Now there are a few ways to make use of the trace context.\n# You can pass the context object when starting a span.\nwith tracer.start_as_current_span('child', context=ctx) as span:\nspan.set_attribute('primes', [2, 3, 5, 7])\n# Or you can make it the current context, and then the next span will pick it up.\n# The returned token lets you restore the previous context.\ntoken = context.attach(ctx)\ntry:\nwith tracer.start_as_current_span('child') as span:\nspan.set_attribute('evens', [2, 4, 6, 8])\nfinally:\ncontext.detach(token)\n</code></pre>"},{"location":"docs/instrumentation/python/cookbook/#using-multiple-tracer-providers-with-different-resource","title":"Using multiple tracer providers with different Resource","text":"<pre><code>from opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor\n# Global tracer provider which can be set only once\ntrace.set_tracer_provider(\nTracerProvider(resource=Resource.create({\"service.name\": \"service1\"}))\n)\ntrace.get_tracer_provider().add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\ntracer = trace.get_tracer(\"tracer.one\")\nwith tracer.start_as_current_span(\"some-name\") as span:\nspan.set_attribute(\"key\", \"value\")\nanother_tracer_provider = TracerProvider(\nresource=Resource.create({\"service.name\": \"service2\"})\n)\nanother_tracer_provider.add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\nanother_tracer = trace.get_tracer(\"tracer.two\", tracer_provider=another_tracer_provider)\nwith another_tracer.start_as_current_span(\"name-here\") as span:\nspan.set_attribute(\"another-key\", \"another-value\")\n</code></pre>"},{"location":"docs/instrumentation/python/distro/","title":"OpenTelemetry Distro","text":"<p>In order to make using OpenTelemetry and auto-instrumentation as quick as possible without sacrificing flexibility, OpenTelemetry distros provide a mechanism to automatically configure some of the more common options for users. By harnessing their power, users of OpenTelemetry can configure the components as they need. The <code>opentelemetry-distro</code> package provides some defaults to users looking to get started, it configures:</p> <ul> <li>the SDK TracerProvider</li> <li>a BatchSpanProcessor</li> <li>the OTLP <code>SpanExporter</code> to send data to an OpenTelemetry collector</li> </ul> <p>The package also provides a starting point for anyone interested in producing an alternative distro. The interfaces implemented by the package are loaded by the auto-instrumentation via the <code>opentelemetry_distro</code> and <code>opentelemetry_configurator</code> entry points to configure the application before any other code is executed.</p> <p>In order to automatically export data from OpenTelemetry to the OpenTelemetry collector, installing the package will set up all the required entry points.</p> <pre><code>$ pip install opentelemetry-distro[otlp] opentelemetry-instrumentation\n</code></pre> <p>Start the Collector locally to see data being exported. Write the following file:</p> <pre><code># /tmp/otel-collector-config.yaml\nreceivers:\notlp:\nprotocols:\ngrpc:\nhttp:\nexporters:\nlogging:\nloglevel: debug\nprocessors:\nbatch:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [logging]\nprocessors: [batch]\n</code></pre> <p>Then start the Docker container:</p> <pre><code>docker run -p 4317:4317 \\\n-v /tmp/otel-collector-config.yaml:/etc/otel-collector-config.yaml \\\notel/opentelemetry-collector:latest \\\n--config=/etc/otel-collector-config.yaml\n</code></pre> <p>The following code will create a span with no configuration.</p> <pre><code># no_configuration.py\nfrom opentelemetry import trace\nwith trace.get_tracer(\"my.tracer\").start_as_current_span(\"foo\"):\nwith trace.get_tracer(\"my.tracer\").start_as_current_span(\"bar\"):\nprint(\"baz\")\n</code></pre> <p>Lastly, run the <code>no_configuration.py</code> with the auto-instrumentation:</p> <pre><code>$ opentelemetry-instrument python no_configuration.py\n</code></pre> <p>The resulting span will appear in the output from the collector and look similar to this:</p> <pre><code>Resource labels:\n     -&gt; telemetry.sdk.language: STRING(python)\n     -&gt; telemetry.sdk.name: STRING(opentelemetry)\n     -&gt; telemetry.sdk.version: STRING(1.1.0)\n     -&gt; service.name: STRING(unknown_service)\nInstrumentationLibrarySpans #0\nInstrumentationLibrary __main__\nSpan #0\n    Trace ID       : db3c99e5bfc50ef8be1773c3765e8845\n    Parent ID      : 0677126a4d110cb8\n    ID             : 3163b3022808ed1b\n    Name           : bar\n    Kind           : SPAN_KIND_INTERNAL\n    Start time     : 2021-05-06 22:54:51.23063 +0000 UTC\n    End time       : 2021-05-06 22:54:51.230684 +0000 UTC\n    Status code    : STATUS_CODE_UNSET\n    Status message :\nSpan #1\n    Trace ID       : db3c99e5bfc50ef8be1773c3765e8845\n    Parent ID      :\n    ID             : 0677126a4d110cb8\n    Name           : foo\n    Kind           : SPAN_KIND_INTERNAL\n    Start time     : 2021-05-06 22:54:51.230549 +0000 UTC\n    End time       : 2021-05-06 22:54:51.230706 +0000 UTC\n    Status code    : STATUS_CODE_UNSET\n    Status message :\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/","title":"Exporters","text":"<p>In order to visualize and analyze your telemetry you will need to use an exporter.</p>"},{"location":"docs/instrumentation/python/exporters/#console-exporter","title":"Console exporter","text":"<p>The console exporter is useful for development and debugging tasks, and is the simplest to set up.</p>"},{"location":"docs/instrumentation/python/exporters/#trace","title":"Trace","text":"<pre><code>from opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\n# Service name is required for most backends,\n# and although it's not necessary for console export,\n# it's good to set service name anyways.\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\nprovider = TracerProvider(resource=resource)\nprocessor = BatchSpanProcessor(ConsoleSpanExporter())\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n# Merrily go about tracing!\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#metrics","title":"Metrics","text":"<p>Use a <code>PeriodicExportingMetricReader</code> to periodically print metrics to the console. <code>PeriodicExportingMetricReader</code> can be configured to export at a different interval, change the temporality for each instrument kind, or change the default aggregation for each instrument kind.</p>"},{"location":"docs/instrumentation/python/exporters/#temporality-presets","title":"Temporality Presets","text":"<p>There are temporality presets for each instrumentation kind. These presets can be set with the environment variable <code>OTEL_EXPORTER_METRICS_TEMPORALITY_PREFERENCE</code>, for example:</p> <pre><code>$ export OTEL_EXPORTER_METRICS_TEMPORALITY_PREFERENCE=\"DELTA\"\n</code></pre> <p>The default value for <code>OTEL_EXPORTER_METRICS_TEMPORALITY_PREFERENCE</code> is <code>\"CUMULATIVE\"</code>.</p> <p>The available values and their corresponding settings for this environment variable are:</p> <ul> <li> <p><code>CUMULATIVE</code></p> </li> <li> <p><code>Counter</code>: <code>CUMULATIVE</code></p> </li> <li><code>UpDownCounter</code>: <code>CUMULATIVE</code></li> <li><code>Histogram</code>: <code>CUMULATIVE</code></li> <li><code>ObservableCounter</code>: <code>CUMULATIVE</code></li> <li><code>ObservableUpDownCounter</code>: <code>CUMULATIVE</code></li> <li> <p><code>ObservableGauge</code>: <code>CUMULATIVE</code></p> </li> <li> <p><code>DELTA</code></p> </li> <li> <p><code>Counter</code>: <code>DELTA</code></p> </li> <li><code>UpDownCounter</code>: <code>CUMULATIVE</code></li> <li><code>Histogram</code>: <code>DELTA</code></li> <li><code>ObservableCounter</code>: <code>DELTA</code></li> <li><code>ObservableUpDownCounter</code>: <code>CUMULATIVE</code></li> <li> <p><code>ObservableGauge</code>: <code>CUMULATIVE</code></p> </li> <li> <p><code>LOWMEMORY</code></p> </li> <li><code>Counter</code>: <code>DELTA</code></li> <li><code>UpDownCounter</code>: <code>CUMULATIVE</code></li> <li><code>Histogram</code>: <code>DELTA</code></li> <li><code>ObservableCounter</code>: <code>CUMULATIVE</code></li> <li><code>ObservableUpDownCounter</code>: <code>CUMULATIVE</code></li> <li><code>ObservableGauge</code>: <code>CUMULATIVE</code></li> </ul> <p>Setting <code>OTEL_EXPORTER_METRICS_TEMPORALITY_PREFERENCE</code> to any other value than <code>CUMULATIVE</code>, <code>DELTA</code> or <code>LOWMEMORY</code> will log a warning and set this environment variable to <code>CUMULATIVE</code>.</p> <pre><code>from opentelemetry import metrics\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader, ConsoleMetricExporter\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\n# Service name is required for most backends,\n# and although it's not necessary for console export,\n# it's good to set service name anyways.\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\nreader = PeriodicExportingMetricReader(ConsoleMetricExporter())\nprovider = MeterProvider(resource=resource, metric_readers=[reader])\nmetrics.set_meter_provider(provider)\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#otlp-endpoint-or-collector","title":"OTLP endpoint or Collector","text":"<p>To send data to an OTLP endpoint or the OpenTelemetry Collector, you'll want to configure an OTLP exporter that sends to your endpoint.</p> <p>First, install an OTLP exporter:</p> <pre><code>$ pip install opentelemetry-exporter-otlp-proto-grpc\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#trace_1","title":"Trace","text":"<pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n# Service name is required for most backends\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\nprovider = TracerProvider(resource=resource)\nprocessor = BatchSpanProcessor(OTLPSpanExporter(endpoint=\"your-endpoint-here\"))\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n# Merrily go about tracing!\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#metrics_1","title":"Metrics","text":"<pre><code>from opentelemetry import metrics\nfrom opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\n# Service name is required for most backends\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\nreader = PeriodicExportingMetricReader(\nOTLPMetricExporter(endpoint=\"localhost:5555\")\n)\nprovider = MeterProvider(resource=resource, metric_readers=[reader])\nmetrics.set_meter_provider(provider)\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#using-http","title":"Using HTTP","text":"<p>If you'd prefer to use OTLP/HTTP with the binary-encoded protobuf format, you can install the package:</p> <pre><code>$ pip install opentelemetry-exporter-otlp-proto-http\n</code></pre> <p>Next, replace the import declarations with the following:</p> <pre><code>from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n</code></pre> <p>Finally, update your exporter endpoint if you're specifying it in code:</p> <pre><code>OTLPSpanExporter(endpoint=\"&lt;traces-endpoint&gt;/v1/traces\")\n</code></pre> <p>There is not currently an OTLP/HTTP metric exporter.</p>"},{"location":"docs/instrumentation/python/exporters/#jaeger","title":"Jaeger","text":"<p>If you are using Jaeger to visualize trace data, you'll need to set it up first. This is how to run it in a docker container:</p> <pre><code>$ docker run -d --name jaeger \\\n-e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n-p 5775:5775/udp \\\n-p 6831:6831/udp \\\n-p 6832:6832/udp \\\n-p 5778:5778 \\\n-p 16686:16686 \\\n-p 14268:14268 \\\n-p 14250:14250 \\\n-p 9411:9411 \\\njaegertracing/all-in-one:latest\n</code></pre> <p>Next, install the Jaeger exporter package:</p> <pre><code>$ pip install opentelemetry-exporter-jaeger\n</code></pre> <p>This will install packages for both:</p> <ul> <li><code>opentelemetry-exporter-jaeger-thrift</code></li> <li><code>opentelemetry-exporter-jaeger-proto-grpc</code></li> </ul> <p>You can use either to export your traces to Jaeger.</p> <p>Once the package is installed, you can configure the exporter when initializing tracing:</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\njaeger_exporter = JaegerExporter(\nagent_host_name=\"localhost\",\nagent_port=6831,\n)\nprovider = TracerProvider(resource=resource)\nprocessor = BatchSpanProcessor(jaeger_exporter)\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n# Merrily go about tracing!\n</code></pre> <p>The previous example uses thrift. To use protobuf, change the import declaration to:</p> <pre><code>from opentelemetry.exporter.jaeger.proto.grpc import JaegerExporter\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#zipkin","title":"Zipkin","text":"<p>If you are using Zipkin to visualize trace data, you'll need to set it up first. This is how to run it in a docker container:</p> <pre><code>$ docker run --rm -d -p 9411:9411 --name zipkin openzipkin/zipkin\n</code></pre> <p>Next, install the Zipkin exporter package:</p> <pre><code>$ pip install opentelemetry-exporter-zipkin-proto-http\n</code></pre> <p>Then you can configure the exporter when initializing tracing:</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.zipkin.proto.http import ZipkinExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\nzipkin_exporter = ZipkinExporter(endpoint=\"http://localhost:9411/api/v2/spans\")\nprovider = TracerProvider(resource=resource)\nprocessor = BatchSpanProcessor(zipkin_exporter)\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n# merrily go about tracing!\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#using-json","title":"Using JSON","text":"<p>If you'd prefer to use Thrift as the protocol, you can install the package:</p> <pre><code>$ pip install opentelemetry-exporter-zipkin-json\n</code></pre> <p>And replace the <code>ZipkinExporter</code> import declaration with the following:</p> <pre><code>from opentelemetry.exporter.zipkin.json import ZipkinExporter\n</code></pre>"},{"location":"docs/instrumentation/python/exporters/#prometheus","title":"Prometheus","text":"<p>If you are using Prometheus to collect metrics data, you'll need to set it up first.</p> <p>First create a config file:</p> <pre><code>$ cat &gt; prometheus.yml &lt;&lt;EOF\nscrape_configs:\n  - job_name: 'otel-python-demo'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:8000']\nEOF\n</code></pre> <p>Then start the Prometheus server in Docker:</p> <pre><code>$ docker run -d --rm \\\n--network=host \\\n-v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \\\nprom/prometheus\n</code></pre> <p>Next, install the Prometheus exporter package:</p> <pre><code>$ pip install opentelemetry-exporter-prometheus\n</code></pre> <p>Then you can configure the exporter when initializing metrics:</p> <pre><code>from prometheus_client import start_http_server\nfrom opentelemetry import metrics\nfrom opentelemetry.exporter.prometheus import PrometheusMetricReader\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\n# Service name is required for most backends\nresource = Resource(attributes={\nSERVICE_NAME: \"your-service-name\"\n})\n# Start Prometheus client\nstart_http_server(port=8000, addr=\"localhost\")\n# Initialize PrometheusMetricReader which pulls metrics from the SDK\n# on-demand to respond to scrape requests\nreader = PrometheusMetricReader()\nprovider = MeterProvider(resource=resource, metric_readers=[reader])\nmetrics.set_meter_provider(provider)\n</code></pre>"},{"location":"docs/instrumentation/python/getting-started/","title":"Getting Started","text":"<p>This page will show you how to get started with OpenTelemetry in Python.</p> <p>You will learn how you can instrument a simple application automatically, in such a way that traces, metrics and logs are emitted to the console.</p>"},{"location":"docs/instrumentation/python/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have the following installed locally:</p> <ul> <li>Python 3</li> </ul>"},{"location":"docs/instrumentation/python/getting-started/#example-application","title":"Example Application","text":"<p>The following example uses a basic Flask application. If you are not using Flask, that's ok \u2014 you can use OpenTelemetry Python with other web frameworks as well, such as Django and FastAPI. For a complete list of libraries for supported frameworks, see the registry.</p> <p>For more elaborate examples, see examples.</p>"},{"location":"docs/instrumentation/python/getting-started/#installation","title":"Installation","text":"<p>To begin, set up an environment in a new directory:</p> <pre><code>mkdir otel-getting-started\ncd otel-getting-started\npython3 -m venv .\nsource ./bin/activate\n</code></pre> <p>Now install Flask:</p> <pre><code>pip install flask\n</code></pre>"},{"location":"docs/instrumentation/python/getting-started/#create-and-launch-an-http-server","title":"Create and launch an HTTP Server","text":"<p>Create a file <code>app.py</code> and add the following code to it:</p> <pre><code>from random import randint\nfrom flask import Flask\napp = Flask(__name__)\n@app.route(\"/rolldice\")\ndef roll_dice():\nreturn str(do_roll())\ndef do_roll():\nreturn randint(1, 6)\n</code></pre> <p>Run the application with the following command and open http://localhost:8080/rolldice in your web browser to ensure it is working.</p> <pre><code>flask run -p 8080\n</code></pre>"},{"location":"docs/instrumentation/python/getting-started/#instrumentation","title":"Instrumentation","text":"<p>Automatic instrumentation will generate telemetry data on your behalf. There are several options you can take, covered in more detail in Automatic Instrumentation. Here we'll use the <code>opentelemetry-instrument</code> agent.</p> <p>Install the <code>opentelemetry-distro</code> package, which contains the OpenTelemetry API, SDK and also the tools <code>opentelemetry-bootstrap</code> and <code>opentelemetry-instrument</code> you will use below.</p> <pre><code>pip install opentelemetry-distro\n</code></pre> <p>Run the <code>opentelemetry-bootstrap</code> command:</p> <pre><code>opentelemetry-bootstrap -a install\n</code></pre> <p>This will install Flask instrumentation.</p>"},{"location":"docs/instrumentation/python/getting-started/#run-the-instrumented-app","title":"Run the instrumented app","text":"<p>You can now run your instrumented app with <code>opentelemetry-instrument</code> and have it print to the console for now:</p> <pre><code>opentelemetry-instrument \\\n--traces_exporter console \\\n--metrics_exporter console \\\n--logs_exporter console \\\nflask run -p 8080\n</code></pre> <p>Open http://localhost:8080/rolldice in your web browser and reload the page a few times. After a while you should see the spans printed in the console, such as the following:</p> View example output <pre><code>{\n\"name\": \"/rolldice\",\n\"context\": {\n\"trace_id\": \"0xdcd253b9501348b63369d83219da0b14\",\n\"span_id\": \"0x886c05bc23d2250e\",\n\"trace_state\": \"[]\"\n},\n\"kind\": \"SpanKind.SERVER\",\n\"parent_id\": null,\n\"start_time\": \"2022-04-27T23:53:11.533109Z\",\n\"end_time\": \"2022-04-27T23:53:11.534097Z\",\n\"status\": {\n\"status_code\": \"UNSET\"\n},\n\"attributes\": {\n\"http.method\": \"GET\",\n\"http.server_name\": \"127.0.0.1\",\n\"http.scheme\": \"http\",\n\"net.host.port\": 5000,\n\"http.host\": \"localhost:5000\",\n\"http.target\": \"/rolldice\",\n\"net.peer.ip\": \"127.0.0.1\",\n\"http.user_agent\": \"curl/7.68.0\",\n\"net.peer.port\": 52538,\n\"http.flavor\": \"1.1\",\n\"http.route\": \"/rolldice\",\n\"http.status_code\": 200\n},\n\"events\": [],\n\"links\": [],\n\"resource\": {\n\"attributes\": {\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"1.14.0\",\n\"telemetry.auto.version\": \"0.35b0\",\n\"service.name\": \"unknown_service\"\n},\n\"schema_url\": \"\"\n}\n}\n</code></pre> <p>The generated span tracks the lifetime of a request to the <code>/rolldice</code> route.</p> <p>Send a few more requests to the endpoint, and then either wait for a little bit or terminate the app and you'll see metrics in the console output, such as the following:</p> View example output <pre><code>{\n\"resource_metrics\": [\n{\n\"resource\": {\n\"attributes\": {\n\"service.name\": \"unknown_service\",\n\"telemetry.auto.version\": \"0.34b0\",\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"1.13.0\"\n},\n\"schema_url\": \"\"\n},\n\"schema_url\": \"\",\n\"scope_metrics\": [\n{\n\"metrics\": [\n{\n\"data\": {\n\"aggregation_temporality\": 2,\n\"data_points\": [\n{\n\"attributes\": {\n\"http.flavor\": \"1.1\",\n\"http.host\": \"localhost:5000\",\n\"http.method\": \"GET\",\n\"http.scheme\": \"http\",\n\"http.server_name\": \"127.0.0.1\"\n},\n\"start_time_unix_nano\": 1666077040061693305,\n\"time_unix_nano\": 1666077098181107419,\n\"value\": 0\n}\n],\n\"is_monotonic\": false\n},\n\"description\": \"measures the number of concurrent HTTP requests that are currently in-flight\",\n\"name\": \"http.server.active_requests\",\n\"unit\": \"requests\"\n},\n{\n\"data\": {\n\"aggregation_temporality\": 2,\n\"data_points\": [\n{\n\"attributes\": {\n\"http.flavor\": \"1.1\",\n\"http.host\": \"localhost:5000\",\n\"http.method\": \"GET\",\n\"http.scheme\": \"http\",\n\"http.server_name\": \"127.0.0.1\",\n\"http.status_code\": 200,\n\"net.host.port\": 5000\n},\n\"bucket_counts\": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n\"count\": 1,\n\"explicit_bounds\": [\n0, 5, 10, 25, 50, 75, 100, 250, 500, 1000\n],\n\"max\": 1,\n\"min\": 1,\n\"start_time_unix_nano\": 1666077040063027610,\n\"sum\": 1,\n\"time_unix_nano\": 1666077098181107419\n}\n]\n},\n\"description\": \"measures the duration of the inbound HTTP request\",\n\"name\": \"http.server.duration\",\n\"unit\": \"ms\"\n}\n],\n\"schema_url\": \"\",\n\"scope\": {\n\"name\": \"opentelemetry.instrumentation.flask\",\n\"schema_url\": \"\",\n\"version\": \"0.34b0\"\n}\n}\n]\n}\n]\n}\n</code></pre>"},{"location":"docs/instrumentation/python/getting-started/#add-manual-instrumentation-to-automatic-instrumentation","title":"Add manual instrumentation to automatic instrumentation","text":"<p>Automatic instrumentation captures telemetry at the edges of your systems, such as inbound and outbound HTTP requests, but it doesn't capture what's going on in your application. For that you'll need to write some manual instrumentation. Here's how you can easily link up manual instrumentation with automatic instrumentation.</p>"},{"location":"docs/instrumentation/python/getting-started/#traces","title":"Traces","text":"<p>First, modify <code>app.py</code> to include code that initializes a tracer and uses it to create a trace that's a child of the one that's automatically generated:</p> <pre><code># These are the necessary import declarations\nfrom opentelemetry import trace\nfrom random import randint\nfrom flask import Flask\n# Acquire a tracer\ntracer = trace.get_tracer(\"diceroller.tracer\")\napp = Flask(__name__)\n@app.route(\"/rolldice\")\ndef roll_dice():\nreturn str(do_roll())\ndef do_roll():\n# This creates a new span that's the child of the current one\nwith tracer.start_as_current_span(\"do_roll\") as rollspan:\nres = randint(1, 6)\nrollspan.set_attribute(\"roll.value\", res)\nreturn res\n</code></pre> <p>Now run the app again:</p> <pre><code>opentelemetry-instrument \\\n--traces_exporter console \\\n--metrics_exporter console \\\nflask run -p 8080\n</code></pre> <p>When you send a request to the server, you'll see two spans in the trace emitted to the console, and the one called <code>do_roll</code> registers its parent as the automatically created one:</p> View example output <pre><code>{\n\"name\": \"do_roll\",\n\"context\": {\n\"trace_id\": \"0x48da59d77e13beadd1a961dc8fcaa74e\",\n\"span_id\": \"0x40c38b50bc8da6b7\",\n\"trace_state\": \"[]\"\n},\n\"kind\": \"SpanKind.INTERNAL\",\n\"parent_id\": \"0x84f8c5d92970d94f\",\n\"start_time\": \"2022-04-28T00:07:55.892307Z\",\n\"end_time\": \"2022-04-28T00:07:55.892331Z\",\n\"status\": {\n\"status_code\": \"UNSET\"\n},\n\"attributes\": {\n\"roll.value\": 4\n},\n\"events\": [],\n\"links\": [],\n\"resource\": {\n\"attributes\": {\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"1.14.0\",\n\"telemetry.auto.version\": \"0.35b0\",\n\"service.name\": \"unknown_service\"\n},\n\"schema_url\": \"\"\n}\n}\n{\n\"name\": \"/rolldice\",\n\"context\": {\n\"trace_id\": \"0x48da59d77e13beadd1a961dc8fcaa74e\",\n\"span_id\": \"0x84f8c5d92970d94f\",\n\"trace_state\": \"[]\"\n},\n\"kind\": \"SpanKind.SERVER\",\n\"parent_id\": null,\n\"start_time\": \"2022-04-28T00:07:55.891500Z\",\n\"end_time\": \"2022-04-28T00:07:55.892552Z\",\n\"status\": {\n\"status_code\": \"UNSET\"\n},\n\"attributes\": {\n\"http.method\": \"GET\",\n\"http.server_name\": \"127.0.0.1\",\n\"http.scheme\": \"http\",\n\"net.host.port\": 5000,\n\"http.host\": \"localhost:5000\",\n\"http.target\": \"/rolldice\",\n\"net.peer.ip\": \"127.0.0.1\",\n\"http.user_agent\": \"curl/7.68.0\",\n\"net.peer.port\": 53824,\n\"http.flavor\": \"1.1\",\n\"http.route\": \"/rolldice\",\n\"http.status_code\": 200\n},\n\"events\": [],\n\"links\": [],\n\"resource\": {\n\"attributes\": {\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"1.14.0\",\n\"telemetry.auto.version\": \"0.35b0\",\n\"service.name\": \"unknown_service\"\n},\n\"schema_url\": \"\"\n}\n}\n</code></pre> <p>The <code>parent_id</code> of <code>do_roll</code> is the same is the <code>span_id</code> for <code>/rolldice</code>, indicating a parent-child relationship!</p>"},{"location":"docs/instrumentation/python/getting-started/#metrics","title":"Metrics","text":"<p>Now modify <code>app.py</code> to include code that initializes a meter and uses it to create a counter instrument which counts the number of rolls for each possible roll value:</p> <pre><code># These are the necessary import declarations\nfrom opentelemetry import trace\nfrom opentelemetry import metrics\nfrom random import randint\nfrom flask import Flask\ntracer = trace.get_tracer(\"diceroller.tracer\")\n# Acquire a meter.\nmeter = metrics.get_meter(\"diceroller.meter\")\n# Now create a counter instrument to make measurements with\nroll_counter = meter.create_counter(\n\"roll_counter\",\ndescription=\"The number of rolls by roll value\",\n)\napp = Flask(__name__)\n@app.route(\"/rolldice\")\ndef roll_dice():\nreturn str(do_roll())\ndef do_roll():\nwith tracer.start_as_current_span(\"do_roll\") as rollspan:\nres = randint(1, 6)\nrollspan.set_attribute(\"roll.value\", res)\n# This adds 1 to the counter for the given roll value\nroll_counter.add(1, {\"roll.value\": res})\nreturn res\n</code></pre> <p>Now run the app again:</p> <pre><code>opentelemetry-instrument \\\n--traces_exporter console \\\n--metrics_exporter console \\\nflask run -p 8080\n</code></pre> <p>When you send a request to the server, you'll see the roll counter metric emitted to the console, with separate counts for each roll value:</p> View example output <pre><code>{\n\"resource_metrics\": [\n{\n\"resource\": {\n\"attributes\": {\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"1.12.0rc1\",\n\"telemetry.auto.version\": \"0.31b0\",\n\"service.name\": \"unknown_service\"\n},\n\"schema_url\": \"\"\n},\n\"scope_metrics\": [\n{\n\"scope\": {\n\"name\": \"app\",\n\"version\": \"\",\n\"schema_url\": null\n},\n\"metrics\": [\n{\n\"name\": \"roll_counter\",\n\"description\": \"The number of rolls by roll value\",\n\"unit\": \"\",\n\"data\": {\n\"data_points\": [\n{\n\"attributes\": {\n\"roll.value\": 4\n},\n\"start_time_unix_nano\": 1654790325350232600,\n\"time_unix_nano\": 1654790332211598800,\n\"value\": 3\n},\n{\n\"attributes\": {\n\"roll.value\": 6\n},\n\"start_time_unix_nano\": 1654790325350232600,\n\"time_unix_nano\": 1654790332211598800,\n\"value\": 4\n},\n{\n\"attributes\": {\n\"roll.value\": 5\n},\n\"start_time_unix_nano\": 1654790325350232600,\n\"time_unix_nano\": 1654790332211598800,\n\"value\": 1\n},\n{\n\"attributes\": {\n\"roll.value\": 1\n},\n\"start_time_unix_nano\": 1654790325350232600,\n\"time_unix_nano\": 1654790332211598800,\n\"value\": 2\n},\n{\n\"attributes\": {\n\"roll.value\": 3\n},\n\"start_time_unix_nano\": 1654790325350232600,\n\"time_unix_nano\": 1654790332211598800,\n\"value\": 1\n}\n],\n\"aggregation_temporality\": 2,\n\"is_monotonic\": true\n}\n}\n],\n\"schema_url\": null\n}\n],\n\"schema_url\": \"\"\n}\n]\n}\n</code></pre>"},{"location":"docs/instrumentation/python/getting-started/#send-telemetry-to-an-opentelemetry-collector","title":"Send telemetry to an OpenTelemetry Collector","text":"<p>The OpenTelemetry Collector is a critical component of most production deployments. Some examples of when it's beneficial to use a collector:</p> <ul> <li>A single telemetry sink shared by multiple services, to reduce overhead of   switching exporters</li> <li>Aggregating traces across multiple services, running on multiple hosts</li> <li>A central place to process traces prior to exporting them to a backend</li> </ul> <p>Unless you have just a single service or are experimenting, you'll want to use a collector in production deployments.</p>"},{"location":"docs/instrumentation/python/getting-started/#configure-and-run-a-local-collector","title":"Configure and run a local collector","text":"<p>First, save the following collector configuration code to a file in the <code>/tmp/</code> directory:</p> <pre><code># /tmp/otel-collector-config.yaml\nreceivers:\notlp:\nprotocols:\ngrpc:\nexporters:\nlogging:\nloglevel: debug\nprocessors:\nbatch:\nservice:\npipelines:\ntraces:\nreceivers: [otlp]\nexporters: [logging]\nprocessors: [batch]\nmetrics:\nreceivers: [otlp]\nexporters: [logging]\nprocessors: [batch]\n</code></pre> <p>Then run the docker command to acquire and run the collector based on this configuration:</p> <pre><code>docker run -p 4317:4317 \\\n-v /tmp/otel-collector-config.yaml:/etc/otel-collector-config.yaml \\\notel/opentelemetry-collector:latest \\\n--config=/etc/otel-collector-config.yaml\n</code></pre> <p>You will now have an collector instance running locally, listening on port 4317.</p>"},{"location":"docs/instrumentation/python/getting-started/#modify-the-command-to-export-spans-and-metrics-via-otlp","title":"Modify the command to export spans and metrics via OTLP","text":"<p>The next step is to modify the command to send spans and metrics to the collector via OTLP instead of the console.</p> <p>To do this, install the OTLP exporter package:</p> <pre><code>pip install opentelemetry-exporter-otlp\n</code></pre> <p>The <code>opentelemetry-instrument</code> agent will detect the package you just installed and default to OTLP export when it's run next.</p>"},{"location":"docs/instrumentation/python/getting-started/#run-the-application","title":"Run the application","text":"<p>Run the application like before, but don't export to the console:</p> <pre><code>opentelemetry-instrument flask run -p 8080\n</code></pre> <p>By default, <code>opentelemetry-instrument</code> exports traces and metrics over OTLP/gRPC and will send them to <code>localhost:4317</code>, which is what the collector is listening on.</p> <p>When you access the <code>/rolldice</code> route now, you'll see output in the collector process instead of the flask process, which should look something like this:</p> View example output <pre><code>2022-06-09T20:43:39.915Z        DEBUG   loggingexporter/logging_exporter.go:51  ResourceSpans #0\nResource labels:\n     -&gt; telemetry.sdk.language: STRING(python)\n     -&gt; telemetry.sdk.name: STRING(opentelemetry)\n     -&gt; telemetry.sdk.version: STRING(1.12.0rc1)\n     -&gt; telemetry.auto.version: STRING(0.31b0)\n     -&gt; service.name: STRING(unknown_service)\nInstrumentationLibrarySpans #0\nInstrumentationLibrary app\nSpan #0\n    Trace ID       : 7d4047189ac3d5f96d590f974bbec20a\n    Parent ID      : 0b21630539446c31\n    ID             : 4d18cee9463a79ba\n    Name           : do_roll\n    Kind           : SPAN_KIND_INTERNAL\n    Start time     : 2022-06-09 20:43:37.390134089 +0000 UTC\n    End time       : 2022-06-09 20:43:37.390327687 +0000 UTC\n    Status code    : STATUS_CODE_UNSET\n    Status message :\nAttributes:\n     -&gt; roll.value: INT(5)\nInstrumentationLibrarySpans #1\nInstrumentationLibrary opentelemetry.instrumentation.flask 0.31b0\nSpan #0\n    Trace ID       : 7d4047189ac3d5f96d590f974bbec20a\n    Parent ID      :\n    ID             : 0b21630539446c31\n    Name           : /rolldice\n    Kind           : SPAN_KIND_SERVER\n    Start time     : 2022-06-09 20:43:37.388733595 +0000 UTC\n    End time       : 2022-06-09 20:43:37.390723792 +0000 UTC\n    Status code    : STATUS_CODE_UNSET\n    Status message :\nAttributes:\n     -&gt; http.method: STRING(GET)\n     -&gt; http.server_name: STRING(127.0.0.1)\n     -&gt; http.scheme: STRING(http)\n     -&gt; net.host.port: INT(5000)\n     -&gt; http.host: STRING(localhost:5000)\n     -&gt; http.target: STRING(/rolldice)\n     -&gt; net.peer.ip: STRING(127.0.0.1)\n     -&gt; http.user_agent: STRING(curl/7.82.0)\n     -&gt; net.peer.port: INT(53878)\n     -&gt; http.flavor: STRING(1.1)\n     -&gt; http.route: STRING(/rolldice)\n     -&gt; http.status_code: INT(200)\n\n2022-06-09T20:43:40.025Z        INFO    loggingexporter/logging_exporter.go:56  MetricsExporter {\"#metrics\": 1}\n2022-06-09T20:43:40.025Z        DEBUG   loggingexporter/logging_exporter.go:66  ResourceMetrics #0\nResource labels:\n     -&gt; telemetry.sdk.language: STRING(python)\n     -&gt; telemetry.sdk.name: STRING(opentelemetry)\n     -&gt; telemetry.sdk.version: STRING(1.12.0rc1)\n     -&gt; telemetry.auto.version: STRING(0.31b0)\n     -&gt; service.name: STRING(unknown_service)\nInstrumentationLibraryMetrics #0\nInstrumentationLibrary app\nMetric #0\nDescriptor:\n     -&gt; Name: roll_counter\n     -&gt; Description: The number of rolls by roll value\n     -&gt; Unit:\n     -&gt; DataType: Sum\n     -&gt; IsMonotonic: true\n     -&gt; AggregationTemporality: AGGREGATION_TEMPORALITY_CUMULATIVE\nNumberDataPoints #0\nData point attributes:\n     -&gt; roll.value: INT(5)\nStartTimestamp: 2022-06-09 20:43:37.390226915 +0000 UTC\nTimestamp: 2022-06-09 20:43:39.848587966 +0000 UTC\nValue: 1\n</code></pre>"},{"location":"docs/instrumentation/python/getting-started/#next-steps","title":"Next steps","text":"<p>There are several options available for automatic instrumentation and Python. See Automatic Instrumentation to learn about them and how to configure them.</p> <p>There's a lot more to manual instrumentation than just creating a child span. To learn details about initializing manual instrumentation and many more parts of the OpenTelemetry API you can use, see Manual Instrumentation.</p> <p>Finally, there are several options for exporting your telemetry data with OpenTelemetry. To learn how to export your data to a preferred backend, see Exporters.</p>"},{"location":"docs/instrumentation/python/manual/","title":"Manual Instrumentation","text":"<p>Manual instrumentation is the process of adding observability code to your application.</p>"},{"location":"docs/instrumentation/python/manual/#initializing-the-sdk","title":"Initializing the SDK","text":"<p>First, ensure you have the API and SDK packages:</p> <pre><code>pip install opentelemetry-api\npip install opentelemetry-sdk\n</code></pre> <p>To start tracing, you'll need to initialize a <code>TracerProvider</code> and optionally set it as the global default.</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import (\nBatchSpanProcessor,\nConsoleSpanExporter,\n)\nprovider = TracerProvider()\nprocessor = BatchSpanProcessor(ConsoleSpanExporter())\nprovider.add_span_processor(processor)\n# Sets the global default tracer provider\ntrace.set_tracer_provider(provider)\n# Creates a tracer from the global tracer provider\ntracer = trace.get_tracer(\"my.tracer.name\")\n</code></pre> <p>To start collecting metrics, you'll need to initialize a <code>MeterProvider</code> and optionally set it as the global default.</p> <pre><code>from opentelemetry import metrics\nfrom opentelemetry.sdk.metrics import MeterProvider\nfrom opentelemetry.sdk.metrics.export import (\nConsoleMetricExporter,\nPeriodicExportingMetricReader,\n)\nmetric_reader = PeriodicExportingMetricReader(ConsoleMetricExporter())\nprovider = MeterProvider(metric_readers=[metric_reader])\n# Sets the global default meter provider\nmetrics.set_meter_provider(provider)\n# Creates a meter from the global meter provider\nmeter = metrics.get_meter(\"my.meter.name\")\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#tracing","title":"Tracing","text":""},{"location":"docs/instrumentation/python/manual/#creating-spans","title":"Creating spans","text":"<p>To create a span, you'll typically want it to be started as the current span.</p> <pre><code>def do_work():\nwith tracer.start_as_current_span(\"span-name\") as span:\n# do some work that 'span' will track\nprint(\"doing some work...\")\n# When the 'with' block goes out of scope, 'span' is closed for you\n</code></pre> <p>You can also use <code>start_span</code> to create a span without making it the current span. This is usually done to track concurrent or asynchronous operations.</p>"},{"location":"docs/instrumentation/python/manual/#creating-nested-spans","title":"Creating nested spans","text":"<p>If you have a distinct sub-operation you'd like to track as a part of another one, you can create spans to represent the relationship:</p> <pre><code>def do_work():\nwith tracer.start_as_current_span(\"parent\") as parent:\n# do some work that 'parent' tracks\nprint(\"doing some work...\")\n# Create a nested span to track nested work\nwith tracer.start_as_current_span(\"child\") as child:\n# do some work that 'child' tracks\nprint(\"doing some nested work...\")\n# the nested span is closed when it's out of scope\n# This span is also closed when it goes out of scope\n</code></pre> <p>When you view spans in a trace visualization tool, <code>child</code> will be tracked as a nested span under <code>parent</code>.</p>"},{"location":"docs/instrumentation/python/manual/#creating-spans-with-decorators","title":"Creating spans with decorators","text":"<p>It's common to have a single span track the execution of an entire function. In that scenario, there is a decorator you can use to reduce code:</p> <pre><code>@tracer.start_as_current_span(\"do_work\")\ndef do_work():\nprint(\"doing some work...\")\n</code></pre> <p>Use of the decorator is equivalent to creating the span inside <code>do_work()</code> and ending it when <code>do_work()</code> is finished.</p> <p>To use the decorator, you must have a <code>tracer</code> instance available global to your function declaration.</p> <p>If you need to add attributes, events, or links then it's less convenient to use a decorator.</p>"},{"location":"docs/instrumentation/python/manual/#get-the-current-span","title":"Get the current span","text":"<p>Sometimes it's helpful to access whatever the current span is at a point in time so that you can enrich it with more information.</p> <pre><code>from opentelemetry import trace\ncurrent_span = trace.get_current_span()\n# enrich 'current_span' with some information\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#add-attributes-to-a-span","title":"Add attributes to a span","text":"<p>Attributes let you attach key/value pairs to a span so it carries more information about the current operation that it's tracking.</p> <pre><code>from opentelemetry import trace\ncurrent_span = trace.get_current_span()\ncurrent_span.set_attribute(\"operation.value\", 1)\ncurrent_span.set_attribute(\"operation.name\", \"Saying hello!\")\ncurrent_span.set_attribute(\"operation.other-stuff\", [1, 2, 3])\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#add-semantic-attributes","title":"Add semantic attributes","text":"<p>Semantic Attributes are pre-defined Attributes that are well-known naming conventions for common kinds of data. Using Semantic Attributes lets you normalize this kind of information across your systems.</p> <p>To use Semantic Attributes in Python, ensure you have the semantic conventions package:</p> <pre><code>pip install opentelemetry-semantic-conventions\n</code></pre> <p>Then you can use it in code:</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.semconv.trace import SpanAttributes\n// ...\ncurrent_span = trace.get_current_span()\ncurrent_span.set_attribute(SpanAttributes.HTTP_METHOD, \"GET\")\ncurrent_span.set_attribute(SpanAttributes.HTTP_URL, \"https://opentelemetry.io/\")\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#adding-events","title":"Adding events","text":"<p>An event is a human-readable message on a span that represents \"something happening\" during its lifetime. You can think of it as a primitive log.</p> <pre><code>from opentelemetry import trace\ncurrent_span = trace.get_current_span()\ncurrent_span.add_event(\"Gonna try it!\")\n# Do the thing\ncurrent_span.add_event(\"Did it!\")\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#adding-links","title":"Adding links","text":"<p>A span can be created with zero or more span links that causally link it to another span. A link needs a span context to be created.</p> <pre><code>from opentelemetry import trace\ntracer = trace.get_tracer(__name__)\nwith tracer.start_as_current_span(\"span-1\"):\n# Do something that 'span-1' tracks.\nctx = trace.get_current_span().get_span_context()\nlink_from_span_1 = trace.Link(ctx)\nwith tracer.start_as_current_span(\"span-2\", links=[link_from_span_1]):\n# Do something that 'span-2' tracks.\n# The link in 'span-2' is casually associated it with the 'span-1',\n# but it is not a child span.\npass\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#set-span-status","title":"Set span status","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - <code>StatusCode.ERROR</code>. In rare scenarios, you could override the Error status with <code>StatusCode.OK</code>, but don\u2019t set <code>StatusCode.OK</code> on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.trace import Status, StatusCode\ncurrent_span = trace.get_current_span()\ntry:\n# something that might fail\nexcept:\ncurrent_span.set_status(Status(StatusCode.ERROR))\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#record-exceptions-in-spans","title":"Record exceptions in spans","text":"<p>It can be a good idea to record exceptions when they happen. It\u2019s recommended to do this in conjunction with setting span status.</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.trace import Status, StatusCode\ncurrent_span = trace.get_current_span()\ntry:\n# something that might fail\n# Consider catching a more specific exception in your code\nexcept Exception as ex:\ncurrent_span.set_status(Status(StatusCode.ERROR))\ncurrent_span.record_exception(ex)\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#change-the-default-propagation-format","title":"Change the default propagation format","text":"<p>By default, OpenTelemetry Python will use the following propagation formats:</p> <ul> <li>W3C Trace Context</li> <li>W3C Baggage</li> </ul> <p>If you have a need to change the defaults, you can do so either via environment variables or in code:</p>"},{"location":"docs/instrumentation/python/manual/#using-environment-variables","title":"Using Environment Variables","text":"<p>You can set the <code>OTEL_PROPAGATORS</code> environment variable with a comma-separated list. Accepted values are:</p> <ul> <li><code>\"tracecontext\"</code>: W3C Trace Context</li> <li><code>\"baggage\"</code>: W3C Baggage</li> <li><code>\"b3\"</code>: B3 Single</li> <li><code>\"b3multi\"</code>: B3 Multi</li> <li><code>\"jaeger\"</code>: Jaeger</li> <li><code>\"xray\"</code>: AWS X-Ray (third party)</li> <li><code>\"ottrace\"</code>: OT Trace (third party)</li> <li><code>\"none\"</code>: No automatically configured propagator.</li> </ul> <p>The default configuration is equivalent to <code>OTEL_PROPAGATORS=\"tracecontext,baggage\"</code>.</p>"},{"location":"docs/instrumentation/python/manual/#using-sdk-apis","title":"Using SDK APIs","text":"<p>Alternatively, you can change the format in code.</p> <p>For example, if you need to use Zipkin's B3 propagation format instead, you can install the B3 package:</p> <pre><code>pip install opentelemetry-propagator-b3\n</code></pre> <p>And then set the B3 propagator in your tracing initialization code:</p> <pre><code>from opentelemetry.propagate import set_global_textmap\nfrom opentelemetry.propagators.b3 import B3Format\nset_global_textmap(B3Format())\n</code></pre> <p>Note that environment variables will override what's configured in code.</p>"},{"location":"docs/instrumentation/python/manual/#metrics","title":"Metrics","text":""},{"location":"docs/instrumentation/python/manual/#creating-and-using-synchronous-instruments","title":"Creating and using synchronous instruments","text":"<p>Instruments are used to make measurements of your application. Synchronous instruments are used inline with application/business processing logic, like when handling a request or calling another service.</p> <p>First, create your instrument. Instruments are generally created once at the module or class level and then used inline with business logic. This example uses a Counter instrument to count the number of work items completed:</p> <pre><code>work_counter = meter.create_counter(\n\"work.counter\", unit=\"1\", description=\"Counts the amount of work done\"\n)\n</code></pre> <p>Using the Counter's add operation, the code below increments the count by one, using the work item's type as an attribute.</p> <pre><code>def do_work(work_item):\n# count the work being doing\nwork_counter.add(1, {\"work.type\": work_item.work_type})\nprint(\"doing some work...\")\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#creating-and-using-asynchronous-instruments","title":"Creating and using asynchronous instruments","text":"<p>Asynchronous instruments give the user a way to register callback functions, which are invoked on demand to make measurements. This is useful to periodically measure a value that cannot be instrumented directly. Async instruments are created with zero or more callbacks which will be invoked during metric collection. Each callback accepts options from the SDK and returns its observations.</p> <p>This example uses an Asynchronous Gauge instrument to report the current config version provided by a configuration server by scraping an HTTP endpoint. First, write a callback to make observations:</p> <pre><code>from typing import Iterable\nfrom opentelemetry.metrics import CallbackOptions, Observation\ndef scrape_config_versions(options: CallbackOptions) -&gt; Iterable[Observation]:\nr = requests.get(\n\"http://configserver/version_metadata\", timeout=options.timeout_millis / 10**3\n)\nfor metadata in r.json():\nyield Observation(\nmetadata[\"version_num\"], {\"config.name\": metadata[\"version_num\"]}\n)\n</code></pre> <p>Note that OpenTelemetry will pass options to your callback containing a timeout. Callbacks should respect this timeout to avoid blocking indefinitely. Finally, create the instrument with the callback to register it:</p> <pre><code>meter.create_observable_gauge(\n\"config.version\",\ncallbacks=[scrape_config_versions],\ndescription=\"The active config version for each configuration\",\n)\n</code></pre>"},{"location":"docs/instrumentation/python/manual/#additional-references","title":"Additional References","text":"<ul> <li>Trace</li> <li>Trace Concepts</li> <li>Trace Specification</li> <li>Python Trace API Documentation</li> <li>Python Trace SDK Documentation</li> <li>Metrics</li> <li>Metrics Concepts</li> <li>Metrics Specification</li> <li>Python Metrics API Documentation</li> <li>Python Metrics SDK Documentation</li> </ul>"},{"location":"docs/instrumentation/python/mypy/","title":"Using mypy","text":"<p>If you're using mypy, you'll need to turn on namespace packages, otherwise <code>mypy</code> won't be able to run correctly.</p> <p>To turn on namespace packages, do one of the following:</p> <p>Add the following to your project configuration file:</p> <pre><code>[tool.mypy]\nnamespace_packages = true\n</code></pre> <p>Or, use a command-line switch:</p> <pre><code>mypy --namespace-packages\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/_index/","title":"Automatic Instrumentation","text":"<p>Automatic instrumentation with Python uses a Python agent that can be attached to any Python application. It dynamically injects bytecode to capture telemetry from many popular libraries and frameworks.</p>"},{"location":"docs/instrumentation/python/automatic/_index/#setup","title":"Setup","text":"<p>Run the following commands to install the appropriate packages.</p> <pre><code>pip install opentelemetry-distro \\\n    opentelemetry-exporter-otlp\nopentelemetry-bootstrap -a install\n</code></pre> <p>The <code>opentelemetry-distro</code> package installs the API, SDK, and the <code>opentelemetry-bootstrap</code> and <code>opentelemetry-instrument</code> tools.</p> <p>The <code>opentelemetry-bootstrap -a install</code> command reads through the list of packages installed in your active <code>site-packages</code> folder, and installs the corresponding instrumentation libraries for these packages, if applicable. For example, if you already installed the <code>flask</code> package, running <code>opentelemetry-bootstrap -a install</code> will install <code>opentelemetry-instrumentation-flask</code> for you.</p> <p>NOTE: If you leave out <code>-a install</code>, the command will simply list out the recommended auto-instrumentation packages to be installed. More information can be found here.</p>"},{"location":"docs/instrumentation/python/automatic/_index/#configuring-the-agent","title":"Configuring the agent","text":"<p>The agent is highly configurable.</p> <p>One option is to configure the agent by way of configuration properties from the CLI:</p> <pre><code>opentelemetry-instrument \\\n    --traces_exporter console,otlp \\\n    --metrics_exporter console \\\n    --service_name your-service-name \\\n    --exporter_otlp_endpoint 0.0.0.0:4317 \\\n    python myapp.py\n</code></pre> <p>Alternatively, you can use environment variables to configure the agent:</p> <pre><code>OTEL_SERVICE_NAME=your-service-name \\\nOTEL_TRACES_EXPORTER=console,otlp \\\nOTEL_METRICS_EXPORTER=console \\\nOTEL_EXPORTER_OTLP_TRACES_ENDPOINT=0.0.0.0:4317\nopentelemetry-instrument \\\n    python myapp.py\n</code></pre> <p>To see the full range of configuration options, see Agent Configuration.</p>"},{"location":"docs/instrumentation/python/automatic/_index/#supported-libraries-and-frameworks","title":"Supported libraries and frameworks","text":"<p>A number of popular Python libraries are auto-instrumented, including Flask and Django. You can find the full list here.</p>"},{"location":"docs/instrumentation/python/automatic/_index/#troubleshooting","title":"Troubleshooting","text":""},{"location":"docs/instrumentation/python/automatic/_index/#python-package-installation-failure","title":"Python package installation failure","text":"<p>The Python package installs require <code>gcc</code> and <code>gcc-c++</code>, which you may need to install if you\u2019re running a slim version of Linux (e.g., CentOS).</p> <p>CentOS:</p> <pre><code>yum -y install python3-devel\nyum -y install gcc-c++\n</code></pre> <p>Debian/Ubuntu:</p> <pre><code>apt install -y python3-dev\napt install -y build-essential\n</code></pre> <p>Alpine:</p> <pre><code>apk add python3-dev\napk add build-base\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/_index/#grpc-connectivity","title":"gRPC Connectivity","text":"<p>To debug Python gRPC connectivity issues, set the following gRPC debug environment variables:</p> <pre><code>export GRPC_VERBOSITY=debug\nexport GRPC_TRACE=http,call_error,connectivity_state\nopentelemetry-instrument python &lt;your_app&gt;.py\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/agent-config/","title":"Agent Configuration","text":"<p>The agent is highly configurable, either by:</p> <ul> <li>Passing configuration properties from the CLI</li> <li>Setting   environment variables</li> </ul>"},{"location":"docs/instrumentation/python/automatic/agent-config/#configuration-properties","title":"Configuration properties","text":"<p>Here's an example of agent configuration via configuration properties:</p> <pre><code>opentelemetry-instrument \\\n--traces_exporter console,otlp \\\n--metrics_exporter console \\\n--service_name your-service-name \\\n--exporter_otlp_endpoint 0.0.0.0:4317 \\\npython myapp.py\n</code></pre> <p>Here's an explanation of what each configuration does:</p> <ul> <li><code>traces_exporter</code> specifies which traces exporter to use. In this case, traces   are being exported to <code>console</code> (stdout) and with <code>otlp</code>. The <code>otlp</code> option   tells <code>opentelemetry-instrument</code> to send the traces to an endpoint that   accepts OTLP via gRPC. In order to use HTTP instead of gRPC, add   <code>--exporter_otlp_protocol http</code>. The full list of available options for   traces_exporter, see the Python contrib   OpenTelemetry Instrumentation.</li> <li><code>metrics_exporter</code> specifies which metrics exporter to use. In this case,   metrics are being exported to <code>console</code> (stdout). It is currently required for   your to specify a metrics exporter. If you aren't exporting metrics, specify   <code>none</code> as the value instead.</li> <li><code>service_name</code> sets the name of the service associated with your telemetry,   and is sent to your Observability backend.</li> <li><code>exporter_otlp_endpoint</code> sets the endpoint where telemetry is exported to. If   omitted, the default Collector endpoint will be used,   which is <code>0.0.0.0:4317</code> for gRPC and <code>0.0.0.0:4318</code> for HTTP.</li> <li><code>exporter_otlp_headers</code> is required depending on your chosen Observability   backend. More info exporter OTLP headers be found   here.</li> </ul>"},{"location":"docs/instrumentation/python/automatic/agent-config/#environment-variables","title":"Environment Variables","text":"<p>In some cases, configuring via environment variables is more preferred. Any setting configurable with a command-line argument can also be configured with an Environment Variable.</p> <p>You can apply the following steps to determine the correct name mapping of the desired configuration property:</p> <ul> <li>Convert the configuration property to uppercase.</li> <li>Prefix environment variable with <code>OTEL_</code></li> </ul> <p>For example, <code>exporter_otlp_endpoint</code> would convert to <code>OTEL_EXPORTER_OTLP_TRACES_ENDPOINT</code>.</p>"},{"location":"docs/instrumentation/python/automatic/agent-config/#python-specific-configuration","title":"Python-specific Configuration","text":"<p>There are some python specific configuration options you can set by prefixing environment variables with <code>OTEL_PYTHON_</code>.</p>"},{"location":"docs/instrumentation/python/automatic/agent-config/#excluded-urls","title":"Excluded URLs","text":"<p>Comma-separated regexes representing which URLs to exclude across all instrumentations:</p> <ul> <li><code>OTEL_PYTHON_EXCLUDED_URLS</code></li> </ul> <p>You can also exclude URLs for specific instrumentations by using a variable <code>OTEL_PYTHON_&lt;library&gt;_EXCLUDED_URLS</code>, where library is the uppercase version of one of the following: Django, Falcon, FastAPI, Flask, Pyramid, Requests, Starlette, Tornado, urllib, urllib3.</p> <p>Examples:</p> <pre><code>export OTEL_PYTHON_EXCLUDED_URLS=\"client/.*/info,healthcheck\"\nexport OTEL_PYTHON_URLLIB3_EXCLUDED_URLS=\"client/.*/info\"\nexport OTEL_PYTHON_REQUESTS_EXCLUDED_URLS=\"healthcheck\"\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/agent-config/#request-attribute-names","title":"Request Attribute Names","text":"<p>Comma-separated list of names that will be extracted from the request object and set as attributes on spans.</p> <ul> <li><code>OTEL_PYTHON_DJANGO_TRACED_REQUEST_ATTRS</code></li> <li><code>OTEL_PYTHON_FALCON_TRACED_REQUEST_ATTRS</code></li> <li><code>OTEL_PYTHON_TORNADO_TRACED_REQUEST_ATTRS</code></li> </ul> <p>Examples:</p> <pre><code>export OTEL_PYTHON_DJANGO_TRACED_REQUEST_ATTRS='path_info,content_type'\nexport OTEL_PYTHON_FALCON_TRACED_REQUEST_ATTRS='query_string,uri_template'\nexport OTEL_PYTHON_TORNADO_TRACED_REQUEST_ATTRS='uri,query'\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/agent-config/#logging","title":"Logging","text":"<p>There are some configuration options used to control the logs that are outputted.</p> <ul> <li><code>OTEL_PYTHON_LOG_CORRELATION</code>: to enable trace context injection into logs   (true, false)</li> <li><code>OTEL_PYTHON_LOG_FORMAT</code>: to instruct the instrumentation to use a custom   logging format</li> <li><code>OTEL_PYTHON_LOG_LEVEL</code>: to set a custom log level (info, error, debug,   warning)</li> </ul> <p>Examples:</p> <pre><code>export OTEL_PYTHON_LOG_CORRELATION=true\nexport OTEL_PYTHON_LOG_FORMAT=\"%(msg)s [span_id=%(span_id)s]\"\nexport OTEL_PYTHON_LOG_LEVEL=debug\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/agent-config/#other","title":"Other","text":"<p>There are some more configuration options that can be set that don't fall into a specific category.</p> <ul> <li><code>OTEL_PYTHON_DJANGO_INSTRUMENT</code>: set to <code>false</code> to disable the default enabled   state for the Django instrumentation</li> <li><code>OTEL_PYTHON_ELASTICSEARCH_NAME_PREFIX</code>: changes the default prefixes for   Elasticsearch operation names from \"Elasticsearch\" to whatever is used here</li> <li><code>OTEL_PYTHON_GRPC_EXCLUDED_SERVICES</code>: comma-separated list of specific   services to exclude for the gRPC instrumentation</li> <li><code>OTEL_PYTHON_ID_GENERATOR</code>: to specify which IDs generator to use for the   global Tracer Provider</li> <li><code>OTEL_PYTHON_INSTRUMENTATION_SANITIZE_REDIS</code>: to enable query sanitization</li> </ul> <p>Examples:</p> <pre><code>export OTEL_PYTHON_DJANGO_INSTRUMENT=false\nexport OTEL_PYTHON_ELASTICSEARCH_NAME_PREFIX=my-custom-prefix\nexport OTEL_PYTHON_GRPC_EXCLUDED_SERVICES=\"GRPCTestServer,GRPCHealthServer\"\nexport OTEL_PYTHON_ID_GENERATOR=xray\nexport OTEL_PYTHON_INSTRUMENTATION_SANITIZE_REDIS=true\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/agent-config/#disabling-specific-instrumentations","title":"Disabling Specific Instrumentations","text":"<p>The Python agent by default will detect a python program's packages and instrument any packages it can. This makes instrumentation easy, but can result in too much or unwanted data.</p> <p>You can omit specific packages from instrumentation by using the <code>OTEL_PYTHON_DISABLED_INSTRUMENTATIONS</code> environment variable. The environment variable can be set to a comma-separated list of package names to exclude from instrumentation.</p> <p>For example, if your Python program uses the <code>redis</code> and <code>kafka-python</code> packages, by default the agent will use the <code>opentelemetry-instrumentation-redis</code> and <code>opentelemetry-instrumentation-kafka-python</code> packages to instrument them. To disable this, you can set <code>OTEL_PYTHON_DISABLED_INSTRUMENTATIONS=redis,kafka-python</code>.</p>"},{"location":"docs/instrumentation/python/automatic/example/","title":"Auto-Instrumentation Example","text":"<p>This page demonstrates how to use Python auto-instrumentation in OpenTelemetry. The example is based on an OpenTracing example. You can download or view the source files used in this page from the <code>opentelemetry-python</code> repo.</p> <p>This example uses three different scripts. The main difference between them is how they are instrumented:</p> <ol> <li><code>server_manual.py</code> is instrumented manually.</li> <li><code>server_automatic.py</code> is instrumented automatically.</li> <li><code>server_programmatic.py</code> is instrumented programmatically.</li> </ol> <p>Programmatic instrumentation is a kind of instrumentation that requires minimal instrumentation code to be added to the application. Only some instrumentation libraries offer additional capabilities that give you greater control over the instrumentation process when used programmatically.</p> <p>Run the first script without the automatic instrumentation agent and second with the agent. They should both produce the same results, demonstrating that the automatic instrumentation agent does exactly the same thing as manual instrumentation.</p> <p>Automatic instrumentation utilizes monkey-patching to dynamically rewrite methods and classes at runtime through instrumentation libraries. This reduces the amount of work required to integrate OpenTelemetry into your application code. Below, you will see the difference between a Flask route instrumented manually, automatically and programmatically.</p>"},{"location":"docs/instrumentation/python/automatic/example/#manually-instrumented-server","title":"Manually instrumented server","text":"<p><code>server_manual.py</code></p> <pre><code>@app.route(\"/server_request\")\ndef server_request():\nwith tracer.start_as_current_span(\n\"server_request\",\ncontext=extract(request.headers),\nkind=trace.SpanKind.SERVER,\nattributes=collect_request_attributes(request.environ),\n):\nprint(request.args.get(\"param\"))\nreturn \"served\"\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/example/#automatically-instrumented-server","title":"Automatically-instrumented server","text":"<p><code>server_automatic.py</code></p> <pre><code>@app.route(\"/server_request\")\ndef server_request():\nprint(request.args.get(\"param\"))\nreturn \"served\"\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/example/#programmatically-instrumented-server","title":"Programmatically-instrumented server","text":"<p><code>server_programmatic.py</code></p> <pre><code>instrumentor = FlaskInstrumentor()\napp = Flask(__name__)\ninstrumentor.instrument_app(app)\n# instrumentor.instrument_app(app, excluded_urls=\"/server_request\")\n@app.route(\"/server_request\")\ndef server_request():\nprint(request.args.get(\"param\"))\nreturn \"served\"\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/example/#prepare","title":"Prepare","text":"<p>Execute the following example in a separate virtual environment. Run the following commands to prepare for auto-instrumentation:</p> <pre><code>$ mkdir auto_instrumentation\n$ virtualenv auto_instrumentation\n$ source auto_instrumentation/bin/activate\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/example/#install","title":"Install","text":"<p>Run the following commands to install the appropriate packages. The <code>opentelemetry-distro</code> package depends on a few others, like <code>opentelemetry-sdk</code> for custom instrumentation of your own code and <code>opentelemetry-instrumentation</code> which provides several commands that help automatically instrument a program.</p> <pre><code>$ pip install opentelemetry-distro\n$ pip install opentelemetry-instrumentation-flask\n$ pip install flask\n$ pip install requests\n</code></pre> <p>The examples that follow send instrumentation results to the console. Learn more about installing and configuring the OpenTelemetry Distro to send telemetry to other destinations, like an OpenTelemetry Collector.</p> <p>Note: To use automatic instrumentation through <code>opentelemetry-instrument</code>, you must configure it via environment variables or the command line. The agent creates a telemetry pipeline that cannot be modified other than through these means. If you need more customization for your telemetry pipelines, then you need to forego the agent and import the OpenTelemetry SDK and instrumentation libraries into your code and configure them there. You may also extend automatic instrumentation by importing the OpenTelemetry API. For more details, see the API reference.</p>"},{"location":"docs/instrumentation/python/automatic/example/#execute","title":"Execute","text":"<p>This section guides you through the manual process of instrumenting a server as well as the process of executing an automatically instrumented server.</p>"},{"location":"docs/instrumentation/python/automatic/example/#execute-the-manually-instrumented-server","title":"Execute the manually instrumented server","text":"<p>Execute the server in two separate consoles, one to run each of the scripts that make up this example:</p> <pre><code>$ source auto_instrumentation/bin/activate\n$ python server_manual.py\n</code></pre> <pre><code>$ source auto_instrumentation/bin/activate\n$ python client.py testing\n</code></pre> <p>The console running <code>server_manual.py</code> will display the spans generated by instrumentation as JSON. The spans should appear similar to the following example:</p> <pre><code>{\n\"name\": \"server_request\",\n\"context\": {\n\"trace_id\": \"0xfa002aad260b5f7110db674a9ddfcd23\",\n\"span_id\": \"0x8b8bbaf3ca9c5131\",\n\"trace_state\": \"{}\"\n},\n\"kind\": \"SpanKind.SERVER\",\n\"parent_id\": null,\n\"start_time\": \"2020-04-30T17:28:57.886397Z\",\n\"end_time\": \"2020-04-30T17:28:57.886490Z\",\n\"status\": {\n\"status_code\": \"OK\"\n},\n\"attributes\": {\n\"http.method\": \"GET\",\n\"http.server_name\": \"127.0.0.1\",\n\"http.scheme\": \"http\",\n\"host.port\": 8082,\n\"http.host\": \"localhost:8082\",\n\"http.target\": \"/server_request?param=testing\",\n\"net.peer.ip\": \"127.0.0.1\",\n\"net.peer.port\": 52872,\n\"http.flavor\": \"1.1\"\n},\n\"events\": [],\n\"links\": [],\n\"resource\": {\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"0.16b1\"\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/example/#execute-the-automatically-instrumented-server","title":"Execute the automatically-instrumented server","text":"<p>Stop the execution of <code>server_manual.py</code> by pressing Control+C and run the following command instead:</p> <pre><code>$ opentelemetry-instrument --traces_exporter console --metrics_exporter none python server_automatic.py\n</code></pre> <p>In the console where you previously executed <code>client.py</code>, run the following command again:</p> <pre><code>$ python client.py testing\n</code></pre> <p>The console running <code>server_automatic.py</code> will display the spans generated by instrumentation as JSON. The spans should appear similar to the following example:</p> <pre><code>{\n\"name\": \"server_request\",\n\"context\": {\n\"trace_id\": \"0x9f528e0b76189f539d9c21b1a7a2fc24\",\n\"span_id\": \"0xd79760685cd4c269\",\n\"trace_state\": \"{}\"\n},\n\"kind\": \"SpanKind.SERVER\",\n\"parent_id\": \"0xb4fb7eee22ef78e4\",\n\"start_time\": \"2020-04-30T17:10:02.400604Z\",\n\"end_time\": \"2020-04-30T17:10:02.401858Z\",\n\"status\": {\n\"status_code\": \"OK\"\n},\n\"attributes\": {\n\"http.method\": \"GET\",\n\"http.server_name\": \"127.0.0.1\",\n\"http.scheme\": \"http\",\n\"host.port\": 8082,\n\"http.host\": \"localhost:8082\",\n\"http.target\": \"/server_request?param=testing\",\n\"net.peer.ip\": \"127.0.0.1\",\n\"net.peer.port\": 48240,\n\"http.flavor\": \"1.1\",\n\"http.route\": \"/server_request\",\n\"http.status_text\": \"OK\",\n\"http.status_code\": 200\n},\n\"events\": [],\n\"links\": [],\n\"resource\": {\n\"telemetry.sdk.language\": \"python\",\n\"telemetry.sdk.name\": \"opentelemetry\",\n\"telemetry.sdk.version\": \"0.16b1\",\n\"service.name\": \"\"\n}\n}\n</code></pre> <p>You can see that both outputs are the same because automatic instrumentation does exactly what manual instrumentation does.</p>"},{"location":"docs/instrumentation/python/automatic/example/#execute-the-programmatically-instrumented-server","title":"Execute the programmatically-instrumented server","text":"<p>It is also possible to use the instrumentation libraries (such as <code>opentelemetry-instrumentation-flask</code>) by themselves which may have an advantage of customizing options. However, by choosing to do this it means you forego using auto-instrumentation by starting your application with <code>opentelemetry-instrument</code> as this is mutually exclusive.</p> <p>Execute the server just like you would do for manual instrumentation, in two separate consoles, one to run each of the scripts that make up this example:</p> <pre><code>source auto_instrumentation/bin/activate\npython server_programmatic.py\n</code></pre> <pre><code>source auto_instrumentation/bin/activate\npython client.py testing\n</code></pre> <p>The results should be the same as running with manual instrumentation.</p>"},{"location":"docs/instrumentation/python/automatic/example/#using-programmatic-instrumentation-features","title":"Using programmatic-instrumentation features","text":"<p>Some instrumentation libraries include features that allow for more precise control while instrumenting programmatically, the instrumentation library for Flask is one of them.</p> <p>This example has a line commented out, change it like this:</p> <pre><code># instrumentor.instrument_app(app)\ninstrumentor.instrument_app(app, excluded_urls=\"/server_request\")\n</code></pre> <p>After running the example again, no instrumentation should appear on the server side. This is because or the <code>excluded_urls</code> option passed to <code>instrument_app</code> that effectively stops the <code>server_request</code> function from being instrumented as its URL matches the regular expression passed to <code>excluded_urls</code>.</p>"},{"location":"docs/instrumentation/python/automatic/example/#instrumentation-while-debugging","title":"Instrumentation while debugging","text":"<p>The debug mode can be enabled in the Flask app like this:</p> <pre><code>if __name__ == \"__main__\":\napp.run(port=8082, debug=True)\n</code></pre> <p>The debug mode can break instrumentation from happening because it enables a reloader. To run instrumentation while the debug mode is enabled, set the <code>use_reloader</code> option to <code>False</code>:</p> <pre><code>if __name__ == \"__main__\":\napp.run(port=8082, debug=True, use_reloader=False)\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/example/#configure","title":"Configure","text":"<p>The auto instrumentation can consume configuration from environment variables.</p>"},{"location":"docs/instrumentation/python/automatic/example/#capture-http-request-and-response-headers","title":"Capture HTTP request and response headers","text":"<p>You can capture predefined HTTP headers as span attributes, according to the semantic convention.</p> <p>To define which HTTP headers you want to capture, provide a comma-separated list of HTTP header names via the environment variables <code>OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST</code> and <code>OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_RESPONSE</code>, e.g.:</p> <pre><code>$ export OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_REQUEST=\"Accept-Encoding,User-Agent,Referer\"\n$ export OTEL_INSTRUMENTATION_HTTP_CAPTURE_HEADERS_SERVER_RESPONSE=\"Last-Modified,Content-Type\"\n$ opentelemetry-instrument --traces_exporter console --metrics_exporter none python app.py\n</code></pre> <p>These configuration options are supported by the following HTTP instrumentations:</p> <ul> <li>Django</li> <li>Falcon</li> <li>FastAPI</li> <li>Pyramid</li> <li>Starlette</li> <li>Tornado</li> <li>WSGI</li> </ul> <p>If those headers are available, they will be included in your span:</p> <pre><code>{\n\"attributes\": {\n\"http.request.header.user-agent\": [\n\"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)\"\n],\n\"http.request.header.accept_encoding\": [\"gzip, deflate, br\"],\n\"http.response.header.last_modified\": [\"2022-04-20 17:07:13.075765\"],\n\"http.response.header.content_type\": [\"text/html; charset=utf-8\"]\n}\n}\n</code></pre>"},{"location":"docs/instrumentation/python/automatic/operator/","title":"Using the OpenTelemetry Operator to Inject Auto-Instrumentation","text":"<p>If you run your Python service in Kubernetes, you can take advantage of the OpenTelemetry Operator to inject auto-instrumentation without having to modify each of your services directly. See the OpenTelemetry Operator Auto-instrumentation docs for more details.</p>"},{"location":"docs/instrumentation/ruby/_index/","title":"Ruby","text":"<p>{{% lang_instrumentation_index_head ruby /%}}</p>"},{"location":"docs/instrumentation/ruby/_index/#whos-using-opentelemetry-ruby","title":"Who's using OpenTelemetry Ruby?","text":"<p>OpenTelemetry Ruby is in use by a number of companies, including:</p> <ul> <li>Heroku</li> <li>GitHub</li> <li>Fulcrum</li> <li>Puppet</li> <li>Shopify</li> <li>TableCheck</li> <li>Dropbox DocSend</li> </ul> <p>If you would like to add your name to this list, submit a pull request.</p>"},{"location":"docs/instrumentation/ruby/_index/#repository","title":"Repository","text":"<ul> <li>OpenTelemetry for Ruby repository</li> </ul>"},{"location":"docs/instrumentation/ruby/automatic/","title":"Automatic instrumentation","text":"<p>Automatic instrumentation in ruby is done via instrumentation packages, and most commonly, the <code>opentelemetry-instrumentation-all</code> package. These are called Instrumentation Libraries.</p> <p>For example, if you are using Rails and enable instrumentation, your running Rails app will automatically generate telemetry data for inbound requests to your controllers.</p>"},{"location":"docs/instrumentation/ruby/automatic/#configuring-all-instrumentation-libraries","title":"Configuring all instrumentation libraries","text":"<p>The recommended way to use instrumentation libraries is to use the <code>opentelemetry-instrumentation-all</code> package:</p> <pre><code>gem 'opentelemetry-sdk'\ngem 'opentelemetry-exporter-otlp'\ngem 'opentelemetry-instrumentation-all'\n</code></pre> <p>and configure it early in your application lifecycle. See the example below using a Rails initializer:</p> <pre><code># config/initializers/opentelemetry.rb\nrequire 'opentelemetry/sdk'\nrequire 'opentelemetry/exporter/otlp'\nrequire 'opentelemetry/instrumentation/all'\nOpenTelemetry::SDK.configure do |c|\nc.service_name = '&lt;YOUR_SERVICE_NAME&gt;'\nc.use_all() # enables all instrumentation!\nend\n</code></pre> <p>This will install all instrumentation libraries and enable the ones that match up to libraries you're using in your app.</p>"},{"location":"docs/instrumentation/ruby/automatic/#overriding-configuration-for-specific-instrumentation-libraries","title":"Overriding configuration for specific instrumentation libraries","text":"<p>If you are enabling all instrumentation but want to override the configuration for a specific one, call <code>use_all</code> with a configuration map parameter, where the key represents the library, and the value is its specific configuration parameter.</p> <p>For example, here's how you can install all instrumentations except the <code>Redis</code> instrumentation into your app:</p> <pre><code>require 'opentelemetry/sdk'\nrequire 'opentelemetry/instrumentation/all'\nOpenTelemetry::SDK.configure do |c|\nconfig = {'OpenTelemetry::Instrumentation::Redis' =&gt; { enabled: false }}\nc.use_all(config)\nend\n</code></pre> <p>To override more instrumentation, add another entry in the <code>config</code> map.</p>"},{"location":"docs/instrumentation/ruby/automatic/#configuring-specific-instrumentation-libraries","title":"Configuring specific instrumentation libraries","text":"<p>If you prefer more selectively installing and using only specific instrumentation libraries, you can do that too. For example, here's how to use only <code>Sinatra</code> and <code>Faraday</code>, with <code>Faraday</code> being configured with an additional configuration parameter.</p> <p>First, install the specific instrumentation libraries you know you want to use:</p> <pre><code>gem install opentelemetry-instrumentation-sinatra\ngem install opentelemetry-instrumentation-faraday\n</code></pre> <p>Then configure them:</p> <pre><code>require 'opentelemetry/sdk'\n# install all compatible instrumentation with default configuration\nOpenTelemetry::SDK.configure do |c|\nc.use 'OpenTelemetry::Instrumentation::Sinatra'\nc.use 'OpenTelemetry::Instrumentation::Faraday', { opt: 'value' }\nend\n</code></pre>"},{"location":"docs/instrumentation/ruby/automatic/#next-steps","title":"Next steps","text":"<p>Instrumentation libraries are the easiest way to generate lots of useful telemetry data about your ruby apps. But they don't generate data specific to your application's logic! To do that, you'll need to enrich the automatic instrumentation from instrumentation libraries with manual instrumentation.</p>"},{"location":"docs/instrumentation/ruby/exporters/","title":"Exporters","text":"<p>In order to visualize and analyze your traces, you will need to export them to a backend such as Jaeger or Zipkin. OpenTelemetry Ruby provides exporters for some common open source backends.</p> <p>Below you will find some introductions on how to set up backends and the matching exporters.</p>"},{"location":"docs/instrumentation/ruby/exporters/#otlp-endpoint","title":"OTLP endpoint","text":"<p>To send trace data to a OTLP endpoint (like the collector or Jaeger) you'll want to use an exporter package, such as <code>opentelemetry-exporter-otlp</code>:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab bundler &gt;}} bundle add opentelemetry-exporter-otlp {{&lt; /tab &gt;}}</p> <p>{{&lt; tab gem &gt;}} gem install opentelemetry-exporter-otlp {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane&gt;}}</p> <p>Next, configure the exporter to point at an OTLP endpoint. For example you can update <code>config/initializers/opentelemetry.rb</code> from the Getting Started by adding <code>require 'opentelemetry-exporter-otlp'</code> to the code:</p> <pre><code># config/initializers/opentelemetry.rb\nrequire 'opentelemetry/sdk'\nrequire 'opentelemetry/instrumentation/all'\nrequire 'opentelemetry-exporter-otlp'\nOpenTelemetry::SDK.configure do |c|\nc.service_name = 'dice-ruby'\nc.use_all() # enables all instrumentation!\nend\n</code></pre> <p>If you now run your application it will use OTLP to export traces:</p> <pre><code>rails server -p 8080\n</code></pre> <p>By default traces are sent to an OTLP endpoint listening on localhost:4318. You can change the endpoint by setting the <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> accordingly:</p> <pre><code>env OTEL_EXPORTER_OTLP_ENDPOINT=\"http://localhost:4318/v1/traces\" rails server -p 8080\n</code></pre> <p>To try out the OTLP exporter quickly and see your traces visualized at the receiving end, you can run Jaeger in a docker container:</p> <pre><code>docker run -d --name jaeger \\\n-e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n-e COLLECTOR_OTLP_ENABLED=true \\\n-p 6831:6831/udp \\\n-p 6832:6832/udp \\\n-p 5778:5778 \\\n-p 16686:16686 \\\n-p 4317:4317 \\\n-p 4318:4318 \\\n-p 14250:14250 \\\n-p 14268:14268 \\\n-p 14269:14269 \\\n-p 9411:9411 \\\njaegertracing/all-in-one:latest\n</code></pre>"},{"location":"docs/instrumentation/ruby/exporters/#zipkin","title":"Zipkin","text":"<p>To set up Zipkin as quickly as possible, run it in a docker container:</p> <pre><code>docker run --rm -d -p 9411:9411 --name zipkin openzipkin/zipkin\n</code></pre> <p>Install the exporter package as a dependency for your application:</p> <p>{{&lt; tabpane lang=shell persistLang=false &gt;}}</p> <p>{{&lt; tab bundle &gt;}} bundle add opentelemetry-exporter-zipkin {{&lt; /tab &gt;}}</p> <p>{{&lt; tab gem &gt;}} gem install opentelemetry-exporter-zipkin {{&lt; /tab &gt;}}</p> <p>{{&lt; /tabpane&gt;}}</p> <p>Update your OpenTelemetry configuration to use the exporter and to send data to your Zipkin backend:</p> <pre><code># config/initializers/opentelemetry.rb\nrequire 'opentelemetry/sdk'\nrequire 'opentelemetry/instrumentation/all'\nrequire 'opentelemetry-exporter-zipkin'\nOpenTelemetry::SDK.configure do |c|\nc.service_name = 'dice-ruby'\nc.use_all() # enables all instrumentation!\nend\n</code></pre> <p>If you now run your application, set the environment variable <code>OTEL_TRACES_EXPORTER</code> to zipkin:</p> <pre><code>env OTEL_TRACES_EXPORTER=zipkin rails server\n</code></pre> <p>By default traces are sent to a Zipkin endpoint listening on port localhost:9411. You can change the endpoint by setting the <code>OTEL_EXPORTER_ZIPKIN_ENDPOINT</code> accordingly:</p> <pre><code>env OTEL_EXPORTER_OTLP_ENDPOINT=\"http://localhost:9411\" rails server\n</code></pre>"},{"location":"docs/instrumentation/ruby/getting-started/","title":"Getting Started","text":"<p>This page will show you how to get started with OpenTelemetry in Ruby.</p> <p>You will learn how you can instrument a simple application automatically, in such a way that traces, metrics and logs are emitted to the console.</p>"},{"location":"docs/instrumentation/ruby/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have the following installed locally:</p> <ul> <li>MRI Ruby &gt;= <code>3.0</code>, jruby &gt;= <code>9.3.2.0</code>, or truffleruby &gt;= 22.1</li> <li>Bundler</li> </ul> <p>{{% alert  title=\"Warning\" color=\"warning\" %}} <code>jruby</code> only targets compatibility with MRI Ruby 2.6.8, which is EOL. This project does not officially support MRI Ruby 2.6.8, and provides <code>jruby</code> support on a best-effort basis until the <code>jruby</code> project supports compatibility with more modern Ruby runtimes.</p> <p>While tested, support for <code>truffleruby</code> is on a best-effort basis at this time. {{% /alert %}}</p>"},{"location":"docs/instrumentation/ruby/getting-started/#example-application","title":"Example Application","text":"<p>The following example uses a basic Rails application. If you are not using Rails, that's ok \u2014 you can use OpenTelemetry Ruby with other web frameworks as well, such as Sinatra and Rack. For a complete list of libraries for supported frameworks, see the registry.</p> <p>For more elaborate examples, see examples.</p>"},{"location":"docs/instrumentation/ruby/getting-started/#dependencies","title":"Dependencies","text":"<p>To begin, install rails:</p> <pre><code>gem install rails\n</code></pre>"},{"location":"docs/instrumentation/ruby/getting-started/#create-the-application","title":"Create the application","text":"<p>Create a new api-only application called <code>dice-ruby</code> and change into the newly created folder <code>dice-ruby</code></p> <pre><code>rails new --api dice-ruby\ncd dice-ruby\n</code></pre> <p>Create a controller for rolling a dice:</p> <pre><code>rails generate controller dice\n</code></pre> <p>This will create a file called <code>app/controllers/dice_controller.rb</code>. Open that file in your preferred editor and update it with the following code:</p> <pre><code>class DiceController &lt; ApplicationController\ndef roll\nrender json: (rand(6) + 1).to_s\nend\nend\n</code></pre> <p>Next, open the <code>config/routes.rb</code> file and add the following code:</p> <pre><code>Rails.application.routes.draw do\nget 'rolldice', to: 'dice#roll'\nend\n</code></pre> <p>Run the application with the following command and open http://localhost:8080/rolldice in your web browser to ensure it is working.</p> <pre><code>rails server -p 8080\n</code></pre> <p>If everything works fine you should see a number between 1 and 6 returned to you. You can now stop the application and instrument it using OpenTelemetry.</p>"},{"location":"docs/instrumentation/ruby/getting-started/#instrumentation","title":"Instrumentation","text":"<p>Install the <code>opentelemetry-sdk</code> and <code>opentelemetry-instrumentation-all</code> packages:</p> <pre><code>bundle add opentelemetry-sdk opentelemetry-instrumentation-all\n</code></pre> <p>The inclusion of <code>opentelemetry-instrumentation-all</code> provides instrumentations for Rails, Sinatra, several HTTP libraries, and more.</p> <p>For Rails applications, the usual way to initialize OpenTelemetry is in a Rails initializer. For other Ruby services, perform this initialization as early as possible in the start-up process.</p> <p>Create a file named <code>config/initializers/opentelemetry.rb</code> with the following code:</p> <pre><code># config/initializers/opentelemetry.rb\nrequire 'opentelemetry/sdk'\nrequire 'opentelemetry/instrumentation/all'\nOpenTelemetry::SDK.configure do |c|\nc.service_name = 'dice-ruby'\nc.use_all() # enables all instrumentation!\nend\n</code></pre> <p>The call <code>c.use_all()</code> enables all instrumentations in the <code>instrumentation/all</code> package. If you have more advanced configuration needs, see configuring specific instrumentation libraries.</p>"},{"location":"docs/instrumentation/ruby/getting-started/#run-the-instrumented-app","title":"Run the instrumented app","text":"<p>You can now run your instrumented app and have it print to the console for now:</p> <pre><code>env OTEL_TRACES_EXPORTER=console rails server -p 8080\n</code></pre> <p>Open http://localhost:8080/rolldice in your web browser and reload the page a few times. You should see the spans printed in the console, such as the following:</p> <pre><code>#&lt;struct OpenTelemetry::SDK::Trace::SpanData\nname=\"DiceController#roll\",\nkind=:server,\nstatus=#&lt;OpenTelemetry::Trace::Status:0x000000010587fc48 @code=1, @description=\"\"&gt;,\nparent_span_id=\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\",\ntotal_recorded_attributes=8,\ntotal_recorded_events=0,\ntotal_recorded_links=0,\nstart_timestamp=1683555544407294000,\nend_timestamp=1683555544464308000,\nattributes=\n{\"http.method\"=&gt;\"GET\",\n\"http.host\"=&gt;\"localhost:8080\",\n\"http.scheme\"=&gt;\"http\",\n\"http.target\"=&gt;\"/rolldice\",\n\"http.user_agent\"=&gt;\"curl/7.87.0\",\n\"code.namespace\"=&gt;\"DiceController\",\n\"code.function\"=&gt;\"roll\",\n\"http.status_code\"=&gt;200},\nlinks=nil,\nevents=nil,\nresource=\n#&lt;OpenTelemetry::SDK::Resources::Resource:0x000000010511d1f8\n@attributes=\n{\"service.name\"=&gt;\"&lt;YOUR_SERVICE_NAME&gt;\",\n\"process.pid\"=&gt;83900,\n\"process.command\"=&gt;\"bin/rails\",\n\"process.runtime.name\"=&gt;\"ruby\",\n\"process.runtime.version\"=&gt;\"3.2.2\",\n\"process.runtime.description\"=&gt;\"ruby 3.2.2 (2023-03-30 revision e51014f9c0) [arm64-darwin22]\",\n\"telemetry.sdk.name\"=&gt;\"opentelemetry\",\n\"telemetry.sdk.language\"=&gt;\"ruby\",\n\"telemetry.sdk.version\"=&gt;\"1.2.0\"}&gt;,\ninstrumentation_scope=#&lt;struct OpenTelemetry::SDK::InstrumentationScope name=\"OpenTelemetry::Instrumentation::Rack\", version=\"0.23.0\"&gt;,\nspan_id=\"\\xA7\\xF0\\x9B#\\b[\\xE4I\",\ntrace_id=\"\\xF3\\xDC\\b8\\x91h\\xB0\\xDF\\xDEn*CH\\x9Blf\",\ntrace_flags=#&lt;OpenTelemetry::Trace::TraceFlags:0x00000001057b7b08 @flags=1&gt;,\ntracestate=#&lt;OpenTelemetry::Trace::Tracestate:0x00000001057b67f8 @hash={}&gt;&gt;\n</code></pre>"},{"location":"docs/instrumentation/ruby/getting-started/#what-next","title":"What next?","text":"<p>Adding tracing to a single service is a great first step. OpenTelemetry provides a few more features that will allow you gain even deeper insights!</p> <ul> <li>Exporters allow you to export your data to a preferred backend.</li> <li>Context propagation is perhaps one of the most powerful concepts in   OpenTelemetry because it will upgrade your single service trace into a   distributed trace, which makes it possible for OpenTelemetry vendors to   visualize a request from end-to-end across process and network boundaries.</li> <li>Span events allow you to add a human-readable message on a span that   represents \"something happening\" during its lifetime.</li> <li>Manual instrumentation will give provide you the ability to enrich   your traces with domain specific data.</li> </ul>"},{"location":"docs/instrumentation/ruby/manual/","title":"Manual Instrumentation","text":"<p>Auto-instrumentation is the easiest way to get started with instrumenting your code, but in order to get the most insight into your system, you should add manual instrumentation where appropriate. To do this, use the OpenTelemetry SDK to access the currently executing span and add attributes to it, and/or to create new spans.</p>"},{"location":"docs/instrumentation/ruby/manual/#initializing-the-sdk","title":"Initializing the SDK","text":"<p>First, ensure you have the SDK package installed:</p> <pre><code>gem install opentelemetry-sdk\n</code></pre> <p>Then include configuration code that runs when your program initializes. Make sure that <code>service.name</code> is set by configuring a service name.</p>"},{"location":"docs/instrumentation/ruby/manual/#acquiring-a-tracer","title":"Acquiring a Tracer","text":"<p>To begin tracing, you will need to ensure you have an initialized <code>Tracer</code> that comes from a <code>TracerProvider</code>.</p> <p>The easiest and most common way to do this is to use the globally-registered TracerProvider. If you are using instrumentation libraries, such as in a Rails app, then one will be registered for you.</p> <pre><code># If in a rails app, this lives in config/initializers/opentelemetry.rb\nrequire \"opentelemetry/sdk\"\nOpenTelemetry::SDK.configure do |c|\nc.service_name = '&lt;YOUR_SERVICE_NAME&gt;'\nend\n# 'Tracer' can be used throughout your code now\nMyAppTracer = OpenTelemetry.tracer_provider.tracer('&lt;YOUR_TRACER_NAME&gt;')\n</code></pre> <p>With a <code>Tracer</code> acquired, you can manually trace code.</p>"},{"location":"docs/instrumentation/ruby/manual/#tracing","title":"Tracing","text":""},{"location":"docs/instrumentation/ruby/manual/#get-the-current-span","title":"Get the current span","text":"<p>It's very common to add information to the current span somewhere within your program. To do so, you can get the current span and add attributes to it.</p> <pre><code>require \"opentelemetry/sdk\"\ndef track_extended_warranty(extended_warranty)\n# Get the current span\ncurrent_span = OpenTelemetry::Trace.current_span\n# And add useful stuff to it!\ncurrent_span.add_attributes({\n\"com.extended_warranty.id\" =&gt; extended_warranty.id,\n\"com.extended_warranty.timestamp\" =&gt; extended_warranty.timestamp\n})\nend\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#creating-new-spans","title":"Creating New Spans","text":"<p>To create a span, you\u2019ll need a configured <code>Tracer</code>.</p> <p>Typically when you create a new span, you'll want it to be the active/current span. To do that, use <code>in_span</code>:</p> <pre><code>require \"opentelemetry/sdk\"\ndef do_work\nMyAppTracer.in_span(\"do_work\") do |span|\n# do some work that the 'do_work' span tracks!\nend\nend\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#creating-nested-spans","title":"Creating nested spans","text":"<p>If you have a distinct sub-operation you\u2019d like to track as a part of another one, you can create nested spans to represent the relationship:</p> <pre><code>require \"opentelemetry/sdk\"\ndef parent_work\nMyAppTracer.in_span(\"parent\") do |span|\n# do some work that the 'parent' span tracks!\nchild_work\n# do some more work afterwards\nend\nend\ndef child_work\nMyAppTracer.in_span(\"child\") do |span|\n# do some work that the 'child' span tracks!\nend\nend\n</code></pre> <p>In the preceding example, two spans are created - named <code>parent</code> and <code>child</code> - with <code>child</code> nested under <code>parent</code>. If you view a trace with these spans in a trace visualization tool, <code>child</code> will be nested under <code>parent</code>.</p>"},{"location":"docs/instrumentation/ruby/manual/#add-attributes-to-a-span","title":"Add attributes to a span","text":"<p>Attributes let you attach key/value pairs to a span so it carries more information about the current operation that it\u2019s tracking.</p> <p>You can use <code>set_attribute</code> to add a single attribute to a span:</p> <pre><code>require \"opentelemetry/sdk\"\ncurrent_span = OpenTelemetry::Trace.current_span\ncurrent_span.set_attribute(\"animals\", [\"elephant\", \"tiger\"])\n</code></pre> <p>You can use <code>add_attributes</code> to add a map of attributes:</p> <pre><code>require \"opentelemetry/sdk\"\ncurrent_span = OpenTelemetry::Trace.current_span\ncurrent_span.add_attributes({\n\"my.cool.attribute\" =&gt; \"a value\",\n\"my.first.name\" =&gt; \"Oscar\"\n})\n</code></pre> <p>You can also add attributes to a span as it's being created:</p> <pre><code>require \"opentelemetry/sdk\"\nMyAppTracer.in_span('foo', attributes: { \"hello\" =&gt; \"world\", \"some.number\" =&gt; 1024 }) do |span|\n#  do stuff with the span\nend\n</code></pre> <p>\u26a0 Spans are thread safe data structures that require locks when they are mutated. You should therefore avoid calling <code>set_attribute</code> multiple times and instead assign attributes in bulk with a Hash, either during span creation or with <code>add_attributes</code> on an existing span.</p> <p>\u26a0 Sampling decisions happen at the moment of span creation. If your sampler considers span attributes when deciding to sample a span, then you must pass those attributes as part of span creation. Any attributes added after creation will not be seen by the sampler, because the sampling decision has already been made.</p>"},{"location":"docs/instrumentation/ruby/manual/#add-semantic-attributes","title":"Add semantic attributes","text":"<p>Semantic Attributes are pre-defined Attributes that are well-known naming conventions for common kinds of data. Using Semantic Attributes lets you normalize this kind of information across your systems.</p> <p>To use Semantic Attributes in Ruby, add the appropriate gem:</p> <pre><code>gem install opentelemetry-semantic_conventions\n</code></pre> <p>Then you can use it in code:</p> <pre><code>require 'opentelemetry/sdk'\nrequire 'opentelemetry/semantic_conventions'\ncurrent_span = OpenTelemetry::Trace.current_span\ncurrent_span.add_attributes({\nOpenTelemetry::SemanticConventions::Trace::HTTP_METHOD =&gt; \"GET\",\nOpenTelemetry::SemanticConventions::Trace::HTTP_URL =&gt; \"https://opentelemetry.io/\",\n})\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#add-span-events","title":"Add Span Events","text":"<p>A span event is a human-readable message on a span that represents \"something happening\" during it's lifetime. For example, imagine a function that requires exclusive access to a resource that is under a mutex. An event could be created at two points - once, when we try to gain access to the resource, and another when we acquire the mutex.</p> <pre><code>require \"opentelemetry/sdk\"\nspan = OpenTelemetry::Trace.current_span\nspan.add_event(\"Acquiring lock\")\nif mutex.try_lock\nspan.add_event(\"Got lock, doing work...\")\n# some code here\nspan.add_event(\"Releasing lock\")\nelse\nspan.add_event(\"Lock already in use\")\nend\n</code></pre> <p>A useful characteristic of events is that their timestamps are displayed as offsets from the beginning of the span, allowing you to easily see how much time elapsed between them.</p> <p>Events can also have attributes of their own e.g.</p> <pre><code>require \"opentelemetry/sdk\"\nspan.add_event(\"Cancelled wait due to external signal\", attributes: {\n\"pid\" =&gt; 4328,\n\"signal\" =&gt; \"SIGHUP\"\n})\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#add-span-links","title":"Add Span Links","text":"<p>A span can be created with zero or more span links that causally link it to another span. A link needs a span context to be created.</p> <pre><code>require \"opentelemetry/sdk\"\nspan_to_link_from = OpenTelemetry::Trace.current_span\nlink = OpenTelemetry::Trace::Link.new(span_to_link_from.context)\nMyAppTracer.in_span(\"new-span\", links: [link])\n# do something that 'new_span' tracks\n# The link in 'new_span' casually associated it with the span it's linked from,\n# but it is not necessarily a child span.\nend\n</code></pre> <p>Span Links are often used to link together different traces that are related in some way, such as a long-running task that calls into sub-tasks asynchronously.</p> <p>Links can also be created with additional attributes:</p> <pre><code>link = OpenTelemetry::Trace::Link.new(span_to_link_from.context, attributes: { \"some.attribute\" =&gt; 12 })\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#set-span-status","title":"Set span status","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - StatusCode.ERROR. In rare scenarios, you could override the Error status with StatusCode.OK, but don\u2019t set StatusCode.OK on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>require \"opentelemetry/sdk\"\ncurrent_span = OpenTelemetry::Trace.current_span\nbegin\n1/0 # something that obviously fails\nrescue\ncurrent_span.status = OpenTelemetry::Trace::Status.error(\"error message here!\")\nend\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#record-exceptions-in-spans","title":"Record exceptions in spans","text":"<p>It can be a good idea to record exceptions when they happen. It\u2019s recommended to do this in conjunction with setting span status.</p> <pre><code>require \"opentelemetry/sdk\"\ncurrent_span = OpenTelemetry::Trace.current_span\nbegin\n1/0 # something that obviously fails\nrescue Exception =&gt; e\ncurrent_span.status = OpenTelemetry::Trace::Status.error(\"error message here!\")\ncurrent_span.record_exception(e)\nend\n</code></pre> <p>Recording an exception creates a Span Event on the current span with a stack trace as an attribute on the span event.</p> <p>Exceptions can also be recorded with additional attributes:</p> <pre><code>current_span.record_exception(ex, attributes: { \"some.attribute\" =&gt; 12 })\n</code></pre>"},{"location":"docs/instrumentation/ruby/manual/#context-propagation","title":"Context Propagation","text":"<p>Distributed Tracing tracks the progression of a single Request, called a Trace, as it is handled by Services that make up an Application. A Distributed Trace transverses process, network and security boundaries. Glossary</p> <p>This requires context propagation, a mechanism where identifiers for a trace are sent to remote processes.</p> <p>\u2139 The OpenTelemetry Ruby SDK will take care of context propagation as long as your service is leveraging auto-instrumented libraries. Please refer to the README for more details.</p> <p>In order to propagate trace context over the wire, a propagator must be registered with the OpenTelemetry SDK. The W3 TraceContext and Baggage propagators are configured by default. Operators may override this value by setting <code>OTEL_PROPAGATORS</code> environment variable to a comma separated list of propagators. For example, to add B3 propagation, set <code>OTEL_PROPAGATORS</code> to the complete list of propagation formats you wish to support:</p> <pre><code>export OTEL_PROPAGATORS=tracecontext,baggage,b3\n</code></pre> <p>Propagators other than <code>tracecontext</code> and <code>baggage</code> must be added as gem dependencies to your Gemfile, e.g.:</p> <pre><code>gem 'opentelemetry-propagator-b3'\n</code></pre>"},{"location":"docs/instrumentation/ruby/sampling/","title":"Sampling","text":"<p>Sampling is a process that restricts the amount of traces that are generated by a system. The Ruby SDK offers several head samplers.</p>"},{"location":"docs/instrumentation/ruby/sampling/#default-behavior","title":"Default behavior","text":"<p>By default, all spans are sampled, and thus, 100% of traces are sampled. If you do not need to manage data volume, don't bother setting a sampler.</p> <p>Specifically, the default sampler is a composite of ParentBased and ALWAYS_ON that ensures the root span in a trace is always sampled, and that all child spans respect use their parent's sampling flag to make a sampling decision. This guarantees that all spans in a trace are sampled by default.</p>"},{"location":"docs/instrumentation/ruby/sampling/#traceidratiobased-sampler","title":"TraceIDRatioBased Sampler","text":"<p>The most common head sampler to use is the TraceIdRatioBased sampler. It deterministically samples a percentage of traces that you pass in as a parameter.</p>"},{"location":"docs/instrumentation/ruby/sampling/#environment-variables","title":"Environment Variables","text":"<p>You can configure a <code>TraceIdRatioBased</code> sampler with environment variables:</p> <pre><code>export OTEL_TRACES_SAMPLER=\"traceidratio\"\nexport OTEL_TRACES_SAMPLER_ARG=\"0.1\"\n</code></pre> <p>This tells the SDK to sample spans such that only 10% of traces get exported.</p>"},{"location":"docs/instrumentation/ruby/sampling/#configuration-in-code","title":"Configuration in Code","text":"<p>Although it is possible to configure a <code>TraceIdRatioBased</code> sampler in code, it's not recommended. Doing so requires you to manually set up a Tracer Provider with all the right configuration options, which is hard to get right compared to just using <code>OpenTelemetry::SDK.configure</code>.</p>"},{"location":"docs/instrumentation/rust/_index/","title":"Rust","text":"<p>{{% lang_instrumentation_index_head rust /%}}</p>"},{"location":"docs/instrumentation/rust/_index/#crates","title":"Crates","text":"<p>OpenTelemetry for Rust publishes the following crates:</p> <ul> <li><code>opentelemetry</code></li> <li><code>opentelemetry-api</code></li> <li><code>opentelemetry-sdk</code></li> <li><code>opentelemetry-aws</code></li> <li><code>opentelemetry-contrib</code></li> <li><code>opentelemetry-datadog</code></li> <li><code>opentelemetry-dynatrace</code></li> <li><code>opentelemetry-http</code></li> <li><code>opentelemetry-jaeger</code></li> <li><code>opentelemetry-otlp</code></li> <li><code>opentelemetry-prometheus</code></li> <li><code>opentelemetry-semantic-conventions</code></li> <li><code>opentelemetry-stackdriver</code></li> <li><code>opentelemetry-zipkin</code></li> </ul>"},{"location":"docs/instrumentation/rust/_index/#further-reading","title":"Further Reading","text":"<ul> <li>Docs for Rust API &amp; SDK</li> <li>Examples</li> <li>Ecosystem</li> </ul>"},{"location":"docs/instrumentation/swift/_index/","title":"Swift","text":"<p>{{% lang_instrumentation_index_head swift /%}}</p>"},{"location":"docs/instrumentation/swift/_index/#further-reading","title":"Further Reading","text":"<ul> <li>OpenTelemetry for Swift on GitHub</li> <li>Installation</li> <li>Examples</li> </ul>"},{"location":"docs/instrumentation/swift/libraries/","title":"Instrumentation Libraries","text":"<p>OpenTelemetry-Swift provides several instrumentation libraries that generate instrumentation for you when they're installed and initialized.</p>"},{"location":"docs/instrumentation/swift/libraries/#sdkresourceextension","title":"<code>SDKResourceExtension</code>","text":"<p><code>SDKResourceExtension</code> provides details about the device as a Resource.</p>"},{"location":"docs/instrumentation/swift/libraries/#usage","title":"Usage","text":"<p>Use <code>DefaultResource.get()</code> to generate an all-in-one resource object. This resource can be added to a <code>TracerProvider</code> or <code>MetricProvider</code>.</p> <pre><code>OpenTelemetry.registerTracerProvider(traceProvider: TracerProviderBuilder()\n.with(resource: DefaultResource.get())\n.build())\n</code></pre>"},{"location":"docs/instrumentation/swift/libraries/#details","title":"Details","text":"<p><code>SDKResourceExtension</code> provides attributes in a resource object with details about the iOS device, OS details, and application details. It applies these values to the appropriate semantic attributes.</p>"},{"location":"docs/instrumentation/swift/libraries/#application-info","title":"Application Info","text":"Attribute Value example Description <code>service.name</code> <code>MyApplication</code> <code>CFBundleName</code>; The application name defined in the App's info.plist. <code>service.version</code> <code>1.0 (1234)</code> <code>CFBundleShortVersion</code> &amp; (<code>CFBundleVersion</code>); The application version as defined in the App's info.plist <code>service.namespace</code> <code>com.myCompany.myApplication</code> <code>CFBundleIdentifier</code>"},{"location":"docs/instrumentation/swift/libraries/#device-info","title":"Device Info","text":"Attribute Value example Description <code>device.model.identifier</code> <code>iphone13,3</code> fetched from <code>sysctl</code> depending on device type <code>device.id</code> <code>00000000-0000-0000000</code> <code>identifierForVendor</code> uuid string"},{"location":"docs/instrumentation/swift/libraries/#operating-system-info","title":"Operating System Info","text":"Attributes Value example Description <code>os.type</code> <code>darwin</code> predefined in <code>ResourceAttributes</code> <code>os.name</code> <code>iOS</code>, <code>watchOS</code>, <code>macOS</code> <code>UIDevice.current.systemName</code> or dependent on platform <code>os.version</code> <code>15.4.0</code> <code>ProcessInfo.processInfo.operatingSystemVersion</code> <code>os.description</code> <code>iOS Version 15.4 (Build 19E240)</code> A combination of os name, version and build."},{"location":"docs/instrumentation/swift/libraries/#nsurlsession-instrumentation","title":"<code>NSURLSession</code> Instrumentation","text":"<p>This instrumentation creates spans for all network requests made with NSURLSessions. It also injects distributed tracing headers in instrumented network requests. <code>NetworkStatus</code> is a dependency of this package, which provides network status attributes on network spans.</p> <p>Note: The NSURLSession instrumentation relies on the global tracer provider in the OpenTelemetry object. Custom tracer providers must be configured and set as the global provider prior to this instrumentation.</p>"},{"location":"docs/instrumentation/swift/libraries/#usage_1","title":"Usage","text":"<p>Initialize the class with <code>URLSessionInstrumentation(configuration: URLSessionInstrumentationConfiguration())</code> to automatically capture all network calls.</p> <p>This behavior can be modified or augmented by using the optional callbacks defined in <code>URLSessionInstrumentationConfiguration</code>:</p> <ul> <li><code>shouldInstrument: ((URLRequest) -&gt; (Bool)?)?</code></li> </ul> <p>Filter which requests you want to instrument, all by default.</p> <ul> <li><code>shouldRecordPayload: ((URLSession) -&gt; (Bool)?)?</code></li> </ul> <p>Implement if you want the session to record payload data, false by default.</p> <ul> <li><code>shouldInjectTracingHeaders: ((URLRequest) -&gt; (Bool)?)?</code></li> </ul> <p>Allow filtering which requests you want to inject headers to follow the trace,   true by default. You must also return true if you want to inject custom   headers.</p> <ul> <li><code>injectCustomHeaders: ((inout URLRequest, Span?) -&gt; Void)?</code></li> </ul> <p>Implement this callback to inject custom headers or modify the request in any   other way.</p> <ul> <li><code>nameSpan: ((URLRequest) -&gt; (String)?)?</code></li> </ul> <p>Modify the name for the given request instead of standard OpenTelemetry name.</p> <ul> <li><code>createdRequest: ((URLRequest, Span) -&gt; Void)?</code></li> </ul> <p>Called after request is created, it allows to add extra information to the   Span.</p> <ul> <li><code>receivedResponse: ((URLResponse, DataOrFile?, Span) -&gt; Void)?</code></li> </ul> <p>Called after response is received, it allows to add extra information to the   Span.</p> <ul> <li><code>receivedError: ((Error, DataOrFile?, HTTPStatus, Span) -&gt; Void)?</code></li> </ul> <p>Called after an error is received, it allows to add extra information to the   Span.</p> <p>Below is an example of initialization. <code>URLSessionInstrumentationConfiguration</code>'s construction can be passed the parameters defined above to suit the needs of the application.</p> <pre><code>let sessionInstrumentation = URLSessionInstrumentation(configuration: URLSessionInstrumentationConfiguration())\n</code></pre>"},{"location":"docs/instrumentation/swift/libraries/#details_1","title":"Details","text":"<p><code>NSURLSession</code> instrumentation also provides additional attributes providing details about the network state of the device at the time of network requests.</p> Attribute Value example Description <code>net.host.connection.type</code> <code>wifi</code>, <code>cell</code>, <code>unavailable</code> The type of connection utilized by the device at the time of the request. <code>net.host.connection.subtype</code> <code>EDGE</code> <code>LTE</code>, etc They type of cellular connection. Only populated if the connection type is <code>cell</code>. <code>net.host.carrier.name</code> <code>T-Mobile</code>, <code>Verizon</code>, etc The cellular carrier name. Only populated for cellular connection types. <code>net.host.carrier.icc</code> <code>DE</code> The ISO 3166-1 alpha-2 2-character country code associated with the mobile carrier network. <code>net.host.carrier.mcc</code> <code>310</code> Mobile Country Code <code>net.host.carrier.mnc</code> <code>001</code> Mobile network code"},{"location":"docs/instrumentation/swift/libraries/#signpostintegration","title":"<code>SignpostIntegration</code>","text":"<p>This package creates <code>os_signpost</code> <code>begin</code> and <code>end</code> calls when spans are started or ended. It allows automatic integration of applications instrumented with OpenTelemetry to show their spans in a profiling app like <code>Instruments</code>. It also exports the <code>OSLog</code> it uses for posting so the user can add extra signpost events. This functionality is shown in <code>Simple Exporter</code> example.</p>"},{"location":"docs/instrumentation/swift/libraries/#usage_2","title":"Usage","text":"<p>Just add SignpostIntegration as any other Span Processor (see the manual instrumentation) docs for details on configuring your providers:</p> <pre><code>OpenTelemetry.instance.tracerProvider.addSpanProcessor(SignPostIntegration())\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/","title":"Manual Instrumentation","text":""},{"location":"docs/instrumentation/swift/manual/#setup","title":"Setup","text":"<p>OpenTelemetry Swift provides limited functionality in its default configuration. For more useful functionality, some configuration is required.</p> <p>The default registered <code>TracerProvider</code> and <code>MetricProvider</code> are not configured with an exporter. There are several exporters available depending on your needs. Below we will explore configuring the OTLP exporter, which can be used for sending data to the collector.</p> <pre><code>import GRPC\nimport OpenTelemetryApi\nimport OpenTelemetrySdk\nimport OpenTelemetryProtocolExporter\n// initialize the OtlpTraceExporter\nlet otlpConfiguration = OtlpConfiguration(timeout: OtlpConfiguration.DefaultTimeoutInterval)\nlet grpcChannel = ClientConnection.usingPlatformAppropriateTLS(for: MultiThreadedEventLoopGroup(numberOfThreads:1))\n.connect(host: &lt;collector host&gt;, port: &lt;collector port&gt;)\nlet traceExporter = OtlpTraceExporter(channel: grpcChannel,\nconfig: otlpConfiguration)\n// build &amp; register the Tracer Provider using the built otlp trace exporter\nOpenTelemetry.registerTracerProvider(tracerProvider: TracerProviderBuilder()\n.add(spanProcessor:SimpleSpanProcessor(spanExporter: traceExporter))\n.with(resource: Resource())\n.build())\n</code></pre> <p>A similar pattern is used for the OtlpMetricExporter:</p> <pre><code>// otlpConfiguration &amp; grpcChannel can be reused\nOpenTelemetry.registerMeterProvider(meterProvider: MeterProviderBuilder()\n.with(processor: MetricProcessorSdk())\n.with(exporter: OtlpMetricExporter(channel: channel, config: otlpConfiguration))\n.with(resource: Resource())\n.build())\n</code></pre> <p>After configuring the MeterProvider &amp; TracerProvider all subsequently initialized instrumentation will be exporting using this OTLP exporter.</p>"},{"location":"docs/instrumentation/swift/manual/#acquiring-a-tracer","title":"Acquiring a Tracer","text":"<p>To do tracing, you will need a tracer. A tracer is acquired through the tracer provider and is responsible for creating spans. The OpenTelemetry manages the tracer provider as we defined and registered above. A tracer requires an instrumentation name, and an optional version to be created:</p> <pre><code>let  tracer = OpenTelemetry.instance.tracerProvider.get(instrumentationName: \"instrumentation-library-name\", instrumentationVersion: \"1.0.0\")\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#creating-spans","title":"Creating Spans","text":"<p>A span represents a unit of work or operation. Spans are the building blocks of Traces. To create a span use the span builder associated with the tracer:</p> <pre><code>let span =  let builder = tracer.spanBuilder(spanName: \"\\(name)\").startSpan()\n...\nspan.end()\n</code></pre> <p>It is required to call <code>end()</code> to end the span.</p>"},{"location":"docs/instrumentation/swift/manual/#creating-nested-spans","title":"Creating Nested Spans","text":"<p>Spans are used to build relationship between operations. Below is an example of how we can manually build relationship between spans.</p> <p>Below we have <code>parent()</code> calling <code>child()</code> and how to manually link spans of each of these methods.</p> <pre><code>func parent() {\nlet parentSpan = someTracer.spanBuilder(spanName: \"parent span\").startSpan()\nchild(span: parentSpan)\nparentSpan.end()\n}\nfunc child(parentSpan: Span) {\nlet childSpan = someTracer.spanBuilder(spanName: \"child span\")\n.setParent(parentSpan)\n.startSpan()\n// do work\nchildSpan.end()\n}\n</code></pre> <p>The parent-child relationship will be automatically linked if <code>activeSpan</code> is used:</p> <pre><code>func parent() {\nlet parentSpan = someTracer.spanBuilder(spanName: \"parent span\")\n.setActive(true) // automatically sets context\n.startSpan()\nchild()\nparentSpan.end()\n}\nfunc child() {\nlet childSpan = someTracer.spanBuilder(spanName: \"child span\")\n.startSpan() //automatically captures `active span` as parent\n// do work\nchildSpan.end()\n}\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#getting-the-current-span","title":"Getting the Current Span","text":"<p>Sometimes it's useful to do something with the current/active span. Here's how to access the current span from an arbitrary point in your code.</p> <pre><code>  let currentSpan = OpenTelemetry.instance.contextProvider.activeSpan\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#span-attributes","title":"Span Attributes","text":"<p>Spans can also be annotated with additional attributes. All spans will be automatically annotated with the <code>Resource</code> attributes attached to the tracer provider. The Opentelemetry-swift sdk already provides instrumentation of common attributes in the <code>SDKResourceExtension</code> instrumentation. In this example a span for a network request capturing details about that request using existing semantic conventions.</p> <pre><code>let span = tracer.spanBuilder(\"/resource/path\").startSpan()\nspan.setAttribute(\"http.method\", \"GET\");\nspan.setAttribute(\"http.url\", url.toString());\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#creating-span-events","title":"Creating Span Events","text":"<p>A Span Event can be thought of as a structured log message (or annotation) on a Span, typically used to denote a meaningful, singular point in time during the Span\u2019s duration.</p> <pre><code>            let attributes = [\n\"key\" : AttributeValue.string(\"value\"),\n\"result\" : AttributeValue.int(100)\n]\nspan.addEvent(name: \"computation complete\", attributes: attributes)\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#setting-span-status","title":"Setting Span Status","text":"<p>A status can be set on a span, typically used to specify that a span has not completed successfully - <code>SpanStatus.Error</code>. In rare scenarios, you could override the Error status with OK, but don\u2019t set OK on successfully-completed spans.</p> <p>The status can be set at any time before the span is finished:</p> <pre><code>func myFunction() {\nlet span = someTracer.spanBuilder(spanName: \"my span\").startSpan()\ndefer {\nspan.end()\n}\nguard let criticalData = get() else {\nspan.status = .error(description: \"something bad happened\")\nreturn\n}\n// do something\n}\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#recording-exceptions-in-spans","title":"Recording exceptions in Spans","text":"<p>Semantic conventions provide special demarcation for events that record exceptions:</p> <pre><code>let span = someTracer.spanBuilder(spanName: \"my span\").startSpan()\ndo {\ntry throwingFunction()\n} catch {\nspan.addEvent(name: SemanticAttributes.exception.rawValue,\nattributes: [SemanticAttributes.exceptionType.rawValue: AttributeValue.string(String(describing: type(of: error))),\nSemanticAttributes.exceptionEscaped.rawValue: AttributeValue.bool(false),\nSemanticAttributes.exceptionMessage.rawValue: AttributeValue.string(error.localizedDescription)])\n})\nspan.status = .error(description: error.localizedDescription)\n}\nspan.end()\n</code></pre>"},{"location":"docs/instrumentation/swift/manual/#sdk-configuration","title":"SDK Configuration","text":""},{"location":"docs/instrumentation/swift/manual/#processors","title":"Processors","text":"<p>Different Span processors are offered by OpenTelemetry-swift. The <code>SimpleSpanProcessor</code> immediately forwards ended spans to the exporter, while the <code>BatchSpanProcessor</code> batches them and sends them in bulk. Multiple Span processors can be configured to be active at the same time using the <code>MultiSpanProcessor</code>. For example, you may create a <code>SimpleSpanProcessor</code> that exports to a logger, and a <code>BatchSpanProcesssor</code> that exports to a OpenTelemetry Collector:</p> <pre><code>let otlpConfiguration = OtlpConfiguration(timeout: OtlpConfiguration.DefaultTimeoutInterval)\nlet grpcChannel = ClientConnection.usingPlatformAppropriateTLS(for: MultiThreadedEventLoopGroup(numberOfThreads:1))\n.connect(host: &lt;collector host&gt;, port: &lt;collector port&gt;)\nlet traceExporter = OtlpTraceExporter(channel: grpcChannel\nconfig: otlpConfiguration)\n// build &amp; register the Tracer Provider using the built otlp trace exporter\nOpenTelemetry.registerTracerProvider(tracerProvider: TracerProviderBuilder()\n.add(spanProcessor:BatchSpanProcessor(spanExporter: traceExporter))\n.add(spanProcessor:SimpleSpanProcessor(spanExporter: StdoutExporter))\n.with(resource: Resource())\n.build())\n</code></pre> <p>The batch span processor allows for a variety of parameters for customization including.</p>"},{"location":"docs/instrumentation/swift/manual/#exporters","title":"Exporters","text":"<p>OpenTelemetry-Swift provides the following exporters:</p> <ul> <li><code>InMemoryExporter</code>: Keeps the span data in memory. This is useful for testing   and debugging.</li> <li><code>DatadogExporter</code>: Converts OpenTelemetry span data to Datadog traces &amp; span   Events to Datadog logs.</li> <li><code>JaegerExporter</code>: Converts OpenTelemetry span data to Jaeger format and   exports to a Jaeger endpoint.</li> <li>Persistence exporter: An exporter decorator that provides data persistence to   existing metric and trace exporters.</li> <li><code>PrometheusExporter</code>: Converts metric data to Prometheus format and exports to   a Prometheus endpoint.</li> <li><code>StdoutExporter</code>: Exports span data to Stdout. Useful for debugging.</li> <li><code>ZipkinTraceExporter</code>: Exports span data to Zipkin format to a Zipkin   endpoint.</li> </ul>"},{"location":"docs/k8s-operator/_index/","title":"Kubernetes\u5f00\u653e\u9065\u6d4b\u64cd\u4f5c\u5668","text":""},{"location":"docs/k8s-operator/_index/#_1","title":"\u4ecb\u7ecd","text":"<p>OpenTelemetry\u7b97\u5b50\u662fKubernetes\u7b97\u5b50\u7684\u4e00\u4e2a\u5b9e\u73b0\u3002</p> <p>\u8fd0\u8425\u5546\u7ba1\u7406:</p> <ul> <li>OpenTelemetry \u6536\u96c6\u5668</li> <li>\u4f7f\u7528OpenTelemetry\u5de5\u5177\u5e93\u81ea\u52a8\u68c0\u6d4b\u5de5\u4f5c\u8d1f\u8f7d</li> </ul>"},{"location":"docs/k8s-operator/_index/#_2","title":"\u5f00\u59cb","text":"<p>\u8981\u5728\u73b0\u6709\u96c6\u7fa4\u4e2d\u5b89\u88c5\u64cd\u4f5c\u7b26\uff0c\u8bf7\u786e\u4fdd\u5b89\u88c5\u4e86cert-manager\u5e76\u8fd0\u884c:</p> <pre><code>$ kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml\n</code></pre> <p>\u4e00\u65e6<code>opentelemetry-operator</code>\u90e8\u7f72\u5c31\u7eea\uff0c\u521b\u5efa\u4e00\u4e2a\u5f00\u653e\u9065\u6d4b\u91c7\u96c6\u5668(otelcol)\u5b9e\u4f8b\uff0c\u5982\u4e0b\u6240\u793a:</p> <pre><code>$ kubectl apply -f - &lt;&lt;EOF\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: simplest\nspec:\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    processors:\n    exporters:\n      logging:\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: []\n          exporters: [logging]\nEOF\n</code></pre> <p>\u8981\u4e86\u89e3\u66f4\u591a\u914d\u7f6e\u9009\u9879\uff0c\u4ee5\u53ca\u4f7f\u7528OpenTelemetry\u5de5\u5177\u5e93\u8bbe\u7f6e\u5de5\u4f5c\u8d1f\u8f7d\u7684\u81ea\u52a8\u68c0\u6d4b\u6ce8\u5165\uff0c\u8bf7\u7ee7\u7eed\u9605\u8bfb\u8fd9\u91cc.</p>"},{"location":"docs/k8s-operator/automatic/","title":"\u6ce8\u5165\u81ea\u52a8\u4eea\u8868","text":"<p>\u5f00\u653e\u9065\u6d4b\u64cd\u4f5c\u5668\u652f\u6301\u4e3a.NET, Java, Nodejs\u548cPython\u670d\u52a1\u6ce8\u5165\u548c\u914d\u7f6e\u81ea\u52a8\u4eea\u5668\u5e93\u3002</p>"},{"location":"docs/k8s-operator/automatic/#_1","title":"\u5b89\u88c5","text":"<p>\u9996\u5148\uff0c\u5c06OpenTelemetry Operator\u5b89\u88c5\u5230\u96c6\u7fa4\u4e2d\u3002</p> <p>\u4f60\u53ef\u4ee5\u901a\u8fc7\u64cd\u4f5c\u5458\u91ca\u653e\u6e05\u5355\uff0c \u64cd\u4f5c\u5458\u638c\u8235\u56fe\uff0c\u6216\u4e0e\u64cd\u4f5c\u5458\u4e2d\u5fc3\u3002</p> <p>\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u60a8\u9700\u8981\u5b89\u88c5cert-manager\u3002 \u5982\u679c\u4f7f\u7528helm\u56fe\u8868\uff0c\u5219\u53ef\u4ee5\u9009\u62e9\u751f\u6210\u81ea\u7b7e\u540d\u8bc1\u4e66\u3002</p>"},{"location":"docs/k8s-operator/automatic/#opentelemetry","title":"\u521b\u5efaOpenTelemetry\u6536\u96c6\u5668(\u53ef\u9009)","text":"<p>\u5c06\u9065\u6d4b\u6570\u636e\u4ece\u5bb9\u5668\u53d1\u9001\u5230OpenTelemetry Collector\u800c\u4e0d\u662f\u76f4\u63a5\u53d1\u9001\u5230\u540e\u7aef\u662f\u6700\u4f73\u5b9e\u8df5\u3002 Collector\u6709\u52a9\u4e8e\u7b80\u5316\u79d8\u5bc6\u7ba1\u7406\uff0c\u4ece\u5e94\u7528\u7a0b\u5e8f\u4e2d\u89e3\u8026\u6570\u636e\u5bfc\u51fa\u95ee\u9898(\u4f8b\u5982\u9700\u8981\u91cd\u8bd5)\uff0c\u5e76\u5141\u8bb8\u60a8\u5411\u9065\u6d4b\u6dfb\u52a0\u989d\u5916\u7684\u6570\u636e\uff0c\u4f8b\u5982\u4f7f\u7528k8sattributesprocessor\u7ec4\u4ef6\u3002 \u5982\u679c\u60a8\u9009\u62e9\u4e0d\u4f7f\u7528\u6536\u96c6\u5668\uff0c\u5219\u53ef\u4ee5\u8df3\u5230\u4e0b\u4e00\u8282\u3002</p> <p>Operator\u4e3aOpenTelemetry Collector\u63d0\u4f9b\u4e00\u4e2a\u81ea\u5b9a\u4e49\u8d44\u6e90\u5b9a\u4e49(CRD)\uff0c\u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u7531Operator\u7ba1\u7406\u7684Collector\u5b9e\u4f8b\u3002 \u4e0b\u9762\u7684\u793a\u4f8b\u5c06Collector\u90e8\u7f72\u4e3a\u90e8\u7f72(\u9ed8\u8ba4\u8bbe\u7f6e)\uff0c\u4f46\u4e5f\u53ef\u4ee5\u4f7f\u7528\u5176\u4ed6\u90e8\u7f72\u6a21\u5f0f\u3002</p> <p>\u5f53\u4f7f\u7528<code>Deployment</code>\u6a21\u5f0f\u65f6\uff0c\u64cd\u4f5c\u5458\u8fd8\u5c06\u521b\u5efa\u4e00\u4e2a\u53ef\u7528\u4e8e\u4e0e\u6536\u96c6\u5668\u4ea4\u4e92\u7684\u670d\u52a1\u3002 \u670d\u52a1\u7684\u540d\u79f0\u662f\u9644\u52a0\u5728<code>-collector</code>\u524d\u9762\u7684<code>OpenTelemetryCollector</code>\u8d44\u6e90\u7684\u540d\u79f0\u3002 \u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d\uff0c\u8fd9\u5c06\u662f<code>demo-collector</code>\u3002</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: demo\nspec:\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    processors:\n      memory_limiter:\n        check_interval: 1s\n        limit_percentage: 75\n        spike_limit_percentage: 15\n      batch:\n        send_batch_size: 10000\n        timeout: 10s\n    exporters:\n      logging:\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [memory_limiter, batch]\n          exporters: [logging]\n        metrics:\n          receivers: [otlp]\n          processors: [memory_limiter, batch]\n          exporters: [logging]\n        logs:\n          receivers: [otlp]\n          processors: [memory_limiter, batch]\n          exporters: [logging]\nEOF\n</code></pre> <p>\u4e0a\u9762\u7684\u547d\u4ee4\u4f1a\u5bfc\u81f4Collector\u7684\u90e8\u7f72\uff0c\u60a8\u53ef\u4ee5\u5c06\u5176\u7528\u4f5cpod\u4e2d\u81ea\u52a8\u68c0\u6d4b\u7684\u7aef\u70b9\u3002</p>"},{"location":"docs/k8s-operator/automatic/#autoinstrumentation","title":"\u914d\u7f6eAutoinstrumentation","text":"<p>\u4e3a\u4e86\u80fd\u591f\u7ba1\u7406\u81ea\u52a8\u4eea\u8868\uff0c\u64cd\u4f5c\u4eba\u5458\u9700\u8981\u8fdb\u884c\u914d\u7f6e\uff0c\u4ee5\u4e86\u89e3\u8981\u5bf9\u54ea\u4e9b\u540a\u8231\u8fdb\u884c\u4eea\u8868\u4ee5\u53ca\u5bf9\u8fd9\u4e9b\u540a\u8231\u4f7f\u7528\u54ea\u79cd\u81ea\u52a8\u4eea\u8868\u3002 \u8fd9\u662f\u901a\u8fc7\u4eea\u8868CRD\u5b8c\u6210\u7684\u3002</p> <p>\u6b63\u786e\u521b\u5efaInstrumentation\u8d44\u6e90\u5bf9\u4e8e\u4f7f\u81ea\u52a8\u68c0\u6d4b\u5de5\u4f5c\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002 \u8981\u4f7f\u81ea\u52a8\u68c0\u6d4b\u6b63\u5e38\u5de5\u4f5c\uff0c\u9700\u8981\u786e\u4fdd\u6240\u6709\u7aef\u70b9\u548c\u73af\u5883\u53d8\u91cf\u90fd\u6b63\u786e\u3002</p>"},{"location":"docs/k8s-operator/automatic/#net","title":".NET","text":"<p>\u4e0b\u9762\u7684\u547d\u4ee4\u5c06\u521b\u5efa\u4e00\u4e2a\u57fa\u672c\u7684Instrumentation\u8d44\u6e90\uff0c\u8be5\u8d44\u6e90\u662f\u4e13\u95e8\u4e3aInstrumentation .NET\u670d\u52a1\u914d\u7f6e\u7684\u3002</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\n  name: demo-instrumentation\nspec:\n  exporter:\n    endpoint: http://demo-collector:4318\n  propagators:\n    - tracecontext\n    - baggage\n  sampler:\n    type: parentbased_traceidratio\n    argument: \"1\"\nEOF\n</code></pre> <p>By default, the Instrumentation resource that auto-instruments .NET services uses <code>otlp</code> with the <code>http/protobuf</code> protocol. This means that the configured endpoint must be able to receive OTLP over <code>http/protobuf</code>. Therefore, the example uses <code>http://demo-collector:4318</code>, which will connect to the <code>http</code> port of the otlpreceiver of the Collector created in the previous step.</p> <p>By default, the .NET auto-instrumentation ships with many instrumentation libraries. This makes instrumentation easy, but could result in too much or unwanted data. If there are any libraries you do not want to use you can set the <code>OTEL_DOTNET_AUTO_[SIGNAL]_[NAME]_INSTRUMENTATION_ENABLED=false</code> where <code>[SIGNAL]</code> is the type of the signal and <code>[NAME]</code> is the case-sensitive name of the library.</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\nname: demo-instrumentation\nspec:\nexporter:\nendpoint: http://demo-collector:4318\npropagators:\n- tracecontext\n- baggage\nsampler:\ntype: parentbased_traceidratio\nargument: '1'\ndotnet:\nenv:\n- name: OTEL_DOTNET_AUTO_TRACES_GRPCNETCLIENT_INSTRUMENTATION_ENABLED\nvalue: false\n- name: OTEL_DOTNET_AUTO_METRICS_PROCESS_INSTRUMENTATION_ENABLED\nvalue: false\n</code></pre> <p>For more details, see .NET Auto Instrumentation docs.</p>"},{"location":"docs/k8s-operator/automatic/#java","title":"Java","text":"<p>The following command creates a basic Instrumentation resource that is configured for instrumenting Java services.</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\n  name: demo-instrumentation\nspec:\n  exporter:\n    endpoint: http://demo-collector:4317\n  propagators:\n    - tracecontext\n    - baggage\n  sampler:\n    type: parentbased_traceidratio\n    argument: \"1\"\nEOF\n</code></pre> <p>By default, the Instrumentation resource that auto-instruments Java services uses <code>otlp</code> with the <code>grpc</code> protocol. This means that the configured endpoint must be able to receive OTLP over <code>grpc</code>. Therefore, the example uses <code>http://demo-collector:4317</code>, which connects to the <code>grpc</code> port of the otlpreceiver of the Collector created in the previous step.</p> <p>By default, the Java auto-instrumentation ships with many instrumentation libraries. This makes instrumentation easy, but could result in too much or unwanted data. If there are any libraries you do not want to use you can set the <code>OTEL_INSTRUMENTATION_[NAME]_ENABLED=false</code> where <code>[NAME]</code> is the name of the library. If you know exactly which libraries you want to use, you can disable the default libraries by setting <code>OTEL_INSTRUMENTATION_COMMON_DEFAULT_ENABLED=false</code> and then use <code>OTEL_INSTRUMENTATION_[NAME]_ENABLED=true</code> where <code>[NAME]</code> is the name of the library. For more details, see Suppressing specific auto-instrumentation.</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\nname: demo-instrumentation\nspec:\nexporter:\nendpoint: http://demo-collector:4317\npropagators:\n- tracecontext\n- baggage\nsampler:\ntype: parentbased_traceidratio\nargument: '1'\njava:\nenv:\n- name: OTEL_INSTRUMENTATION_KAFKA_ENABLED\nvalue: false\n- name: OTEL_INSTRUMENTATION_REDISCALA_ENABLED\nvalue: false\n</code></pre> <p>For more details, see Java Agent Configuration.</p>"},{"location":"docs/k8s-operator/automatic/#nodejs","title":"Node.js","text":"<p>\u4e0b\u9762\u7684\u547d\u4ee4\u521b\u5efa\u4e86\u4e00\u4e2a\u57fa\u672c\u7684Instrumentation\u8d44\u6e90\uff0c\u8be5\u8d44\u6e90\u914d\u7f6e\u7528\u4e8e\u68c0\u6d4bNode.js\u670d\u52a1\u3002</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\n  name: demo-instrumentation\nspec:\n  exporter:\n    endpoint: http://demo-collector:4317\n  propagators:\n    - tracecontext\n    - baggage\n  sampler:\n    type: parentbased_traceidratio\n    argument: \"1\"\nEOF\n</code></pre> <p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u81ea\u52a8\u68c0\u6d4bNode.js\u670d\u52a1\u7684Instrumentation\u8d44\u6e90\u4f7f\u7528' otlp '\u548c' grpc '\u534f\u8bae\u3002 \u8fd9\u610f\u5473\u7740\u914d\u7f6e\u7684\u7aef\u70b9\u5fc5\u987b\u80fd\u591f\u901a\u8fc7' grpc '\u63a5\u6536OTLP\u3002 \u56e0\u6b64\uff0c\u672c\u4f8b\u4f7f\u7528' http://demo-collector:4317 '\uff0c\u5b83\u8fde\u63a5\u5230\u5728\u4e0a\u4e00\u6b65\u4e2d\u521b\u5efa\u7684\u6536\u96c6\u5668\u7684otlreceiver\u7684' grpc '\u7aef\u53e3\u3002</p> <p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cNode.js\u81ea\u52a8\u68c0\u6d4b\u9644\u5e26\u4e86\u8bb8\u591a\u68c0\u6d4b\u5e93\u3002 \u76ee\u524d\uff0c\u8fd8\u6ca1\u6709\u529e\u6cd5\u9009\u62e9\u53ea\u52a0\u5165\u7279\u5b9a\u7684\u8f6f\u4ef6\u5305\u6216\u7981\u7528\u7279\u5b9a\u7684\u8f6f\u4ef6\u5305\u3002 \u5982\u679c\u60a8\u4e0d\u60f3\u4f7f\u7528\u9ed8\u8ba4\u6620\u50cf\u5305\u542b\u7684\u5305\uff0c\u90a3\u4e48\u60a8\u5fc5\u987b\u63d0\u4f9b\u81ea\u5df1\u7684\u6620\u50cf\uff0c\u8be5\u6620\u50cf\u53ea\u5305\u542b\u60a8\u60f3\u8981\u7684\u5305\uff0c\u6216\u8005\u4f7f\u7528\u624b\u52a8\u68c0\u6d4b\u3002</p> <p>\u66f4\u591a\u7ec6\u8282\u8bf7\u53c2\u89c1Node.js auto-instrumentation.</p>"},{"location":"docs/k8s-operator/automatic/#python","title":"Python","text":"<p>The following command will create a basic Instrumentation resource that is configured specifically for instrumenting Python services.</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\n  name: demo-instrumentation\nspec:\n  exporter:\n    endpoint: http://demo-collector:4318\n  propagators:\n    - tracecontext\n    - baggage\n  sampler:\n    type: parentbased_traceidratio\n    argument: \"1\"\nEOF\n</code></pre> <p>By default, the Instrumentation resource that auto-instruments python services uses <code>otlp</code> with the <code>http/protobuf</code> protocol. This means that the configured endpoint must be able to receive OTLP over <code>http/protobuf</code>. Therefore, the example uses <code>http://demo-collector:4318</code>, which will connect to the <code>http</code> port of the otlpreceiver of the Collector created in the previous step.</p> <p>As of operator v0.67.0, the Instrumentation resource automatically sets <code>OTEL_EXPORTER_OTLP_TRACES_PROTOCOL</code> and <code>OTEL_EXPORTER_OTLP_METRICS_PROTOCOL</code> to <code>http/protobuf</code> for Python services. If you use an older version of the Operator you MUST set these env variables to <code>http/protobuf</code>, or python auto-instrumentation will not work.</p> <p>By default the Python auto-instrumentation will detect the packages in your Python service and instrument anything it can. This makes instrumentation easy, but can result in too much or unwanted data. If there are any packages you do not want to instrument, you can set the <code>OTEL_PYTHON_DISABLED_INSTRUMENTATIONS</code> environment variable</p> <pre><code>apiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\nname: demo-instrumentation\nspec:\nexporter:\nendpoint: http://demo-collector:4318\npropagators:\n- tracecontext\n- baggage\nsampler:\ntype: parentbased_traceidratio\nargument: '1'\npython:\nenv:\n- name: OTEL_PYTHON_DISABLED_INSTRUMENTATIONS\nvalue:\n&lt;comma-separated list of package names to exclude from\ninstrumentation&gt;\n</code></pre> <p>See the Python Agent Configuration docs for more details.</p> <p>Now that your Instrumentation object is created, your cluster has the ability to auto-instrument services and send data to an endpoint. However, auto-instrumentation with the OpenTelemetry Operator follows an opt-in model. In order to activate autoinstrumentation, you'll need to add an annotation to your deployment.</p>"},{"location":"docs/k8s-operator/automatic/#_2","title":"\u5411\u73b0\u6709\u90e8\u7f72\u6dfb\u52a0\u6ce8\u91ca","text":"<p>\u6700\u540e\u4e00\u6b65\u662f\u9009\u62e9\u81ea\u52a8\u68c0\u6d4b\u670d\u52a1\u3002 \u8fd9\u662f\u901a\u8fc7\u66f4\u65b0\u4f60\u7684\u670d\u52a1\u7684<code>spec.template.metadata.annotations</code>\u6765\u5305\u542b\u4e00\u4e2a\u7279\u5b9a\u4e8e\u8bed\u8a00\u7684\u6ce8\u91ca\u6765\u5b9e\u73b0\u7684:</p> <ul> <li>.NET: <code>instrumentation.opentelemetry.io/inject-dotnet: \"true\"</code></li> <li>Java: <code>instrumentation.opentelemetry.io/inject-java: \"true\"</code></li> <li>Node.js: <code>instrumentation.opentelemetry.io/inject-nodejs: \"true\"</code></li> <li>Python: <code>instrumentation.opentelemetry.io/inject-python: \"true\"</code></li> </ul> <p>\u6ce8\u91ca\u7684\u53ef\u80fd\u503c\u53ef\u4ee5\u662f</p> <ul> <li><code>\"true\"</code> - to inject <code>Instrumentation</code> resource with default name from the   current namespace.</li> <li><code>\"my-instrumentation\"</code> - to inject <code>Instrumentation</code> CR instance with name   <code>\"my-instrumentation\"</code> in the current namespace.</li> <li><code>\"my-other-namespace/my-instrumentation\"</code> - to inject <code>Instrumentation</code> CR   instance with name <code>\"my-instrumentation\"</code> from another namespace   <code>\"my-other-namespace\"</code>.</li> <li><code>\"false\"</code> - do not inject</li> </ul> <p>\u6216\u8005\uff0c\u53ef\u4ee5\u5c06\u6ce8\u91ca\u6dfb\u52a0\u5230\u540d\u79f0\u7a7a\u95f4\u4e2d\uff0c\u8fd9\u5c06\u5bfc\u81f4\u8be5\u540d\u79f0\u7a7a\u95f4\u4e2d\u7684\u6240\u6709\u670d\u52a1\u9009\u62e9\u52a0\u5165\u81ea\u52a8\u68c0\u6d4b\u3002 \u8bf7\u53c2\u9605\u64cd\u4f5c\u5458\u81ea\u52a8\u68c0\u6d4b\u6587\u6863\u4e86\u89e3\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\u3002</p>"},{"location":"docs/migration/_index/","title":"Migration","text":""},{"location":"docs/migration/_index/#opentracing-and-opencensus","title":"OpenTracing and OpenCensus","text":"<p>OpenTelemetry was created as a merger of OpenTracing and OpenCensus. From the start, OpenTelemetry was considered to be the next major version of both OpenTracing and OpenCensus. Because of that, one of the key goals of the OpenTelemetry project is to provide backward compatibility with both projects and a migration story for existing users.</p> <p>If you come from one of these projects, you can follow the migration guides for both OpenTracing and OpenCensus</p>"},{"location":"docs/migration/_index/#jaeger-client","title":"Jaeger Client","text":"<p>The Jaeger community deprecated their Client Libraries and recommends using the OpenTelemetry APIs, SDKs and instrumentations.</p> <p>The Jaeger backend can receive trace data via the OpenTelemetry Protocol (OTLP) since v1.35. Therefore you can migrate your OpenTelemetry SDKs and collectors from using the Jaeger exporter to the OTLP exporter.</p>"},{"location":"docs/migration/opentracing/","title":"Migrating from OpenTracing","text":"<p>Backward compatibility with OpenTracing has been a priority for the OpenTelemetry project from the start. To ease migration, OpenTelemetry supports the use of both the OpenTelemetry and OpenTracing APIs in the same codebase. This allows OpenTracing instrumentation to be recorded using OpenTelemetry SDKs.</p> <p>To accomplish this, each OpenTelemetry SDK provides an OpenTracing shim, which acts as a bridge between the OpenTracing API and the OpenTelemetry SDK. Note that OpenTracing shims are disabled by default.</p>"},{"location":"docs/migration/opentracing/#language-version-support","title":"Language version support","text":"<p>Before using an OpenTracing shim, check your project's language and runtime component versions, and update if necessary. The minimum language versions of the OpenTracing and OpenTelemetry APIs are listed in the table below.</p> Language OpenTracing API OpenTelemetry API Go 1.13 1.16 Java 7 8 Python 2.7 3.6 Javascript 6 8.5 .NET 1.3 1.4 C++ 11 11 <p>Note that the OpenTelemetry API and SDKs generally have higher language version requirements than their OpenTracing counterparts.</p>"},{"location":"docs/migration/opentracing/#migration-overview","title":"Migration overview","text":"<p>Many codebases are currently instrumented with OpenTracing. These codebases use the OpenTracing API to instrument their application code and/or install OpenTracing plugins to instrument their libraries and frameworks.</p> <p>A general approach to migrating to OpenTelemetry can be summarized as follows:</p> <ol> <li>Install OpenTelemetry SDK(s), and remove the current OpenTracing    implementation -- for example, a Jaeger client.</li> <li>Install the OpenTelemetry instrumentation libraries, and remove the    OpenTracing equivalents.</li> <li>Update your dashboards, alerts, etc., to consume the new OpenTelemetry data.</li> <li>When writing new application code, write all new instrumentation using the    OpenTelemetry API.</li> <li>Progressively re-instrument your application using the OpenTelemetry API.    There is no hard requirement to remove existing OpenTracing API calls from    your application, they will continue to work.</li> </ol> <p>While migrating a sizable application can require significant effort, as suggested above, we recommend that OpenTracing users progressively migrate their application code. This will ease the burden of migration and help avoid breaks in observability.</p> <p>The steps below present a careful, incremental approach to transitioning to OpenTelemetry.</p>"},{"location":"docs/migration/opentracing/#step-1-install-the-opentelemetry-sdk","title":"Step 1: Install the OpenTelemetry SDK","text":"<p>Before changing any instrumentation, ensure that you can switch to the OpenTelemetry SDK without causing any break in the telemetry the application currently emits. Doing this step on its own \u2013 without simultaneously introducing any new instrumentation \u2013 is recommended, as it makes it easier to determine whether there is any kind of break in instrumentation.</p> <ol> <li>Replace the OpenTracing Tracer implementation you are currently using with    the OpenTelemetry SDK. For example, if you are using the Jaeger, remove the    Jaeger client and install the equivalent OpenTelemetry client.</li> <li>Install the OpenTracing Shim. This shim allows the OpenTelemetry SDK to    consume OpenTracing instrumentation.</li> <li>Configure the OpenTelemetry SDK to export data using the same protocol and    format that the OpenTracing client was using. For example, if you were using    an OpenTracing client that exported tracing data in Zipkin format, configure    the OpenTelemetry client to do the same.</li> <li>Alternatively, configure the OpenTelemetry SDK to emit OTLP, and send the    data to a Collector, where you can manage exporting data in multiple formats.</li> </ol> <p>Once you have the OpenTelemetry SDK installed, confirm that you can deploy your application and still receive the same OpenTracing-based telemetry. In other words, confirm that your dashboards, alerts, and other tracing-based analysis tools are still working.</p>"},{"location":"docs/migration/opentracing/#step-2-progressively-replace-instrumentation","title":"Step 2: Progressively replace instrumentation","text":"<p>Once the OpenTelemetry SDK is installed, all new instrumentation can now be written using the OpenTelemetry API. With few exceptions, OpenTelemetry and OpenTracing instrumentation will work together seamlessly (see limits on compatibility below).</p> <p>What about existing instrumentation? There is no hard requirement to migrate existing application code to OpenTelemetry. However, we do recommend migrating from any OpenTracing instrumentation libraries \u2013 libraries used to instrument web frameworks, HTTP clients, database clients, etc. \u2013 to their OpenTelemetry equivalents. This will improve support, as many OpenTracing libraries will be retired and may no longer be updated.</p> <p>It is important to note that when switching to an OpenTelemetry instrumentation library, the data which is produced will change. OpenTelemetry has an improved model for how we instrument software (what we refer to as our \"semantic conventions\"). In many cases, OpenTelemetry produces better, more comprehensive tracing data. However, \"better\" also means \"different.\" This means that existing dashboards, alerts, etc. based on older OpenTracing instrumentation libraries may no longer work when those libraries are replaced.</p> <p>For existing instrumentation, it is recommended to:</p> <ol> <li>Replace one piece of OpenTracing instrumentation with its OpenTelemetry    equivalent.</li> <li>Observe how this changes the telemetry which your application produces.</li> <li>Create new dashboards, alerts, etc which consume this new telemetry. Set up    these dashboards before deploying the new OpenTelemetry library to    production.</li> <li>Optionally, add processing rules to the Collector which converts the new    telemetry back into the old telemetry. The Collector can then be configured    to emit both versions of the same telemetry, creating a data overlap. This    allows new dashboards to populate themselves while you continue to use the    old dashboards.</li> </ol>"},{"location":"docs/migration/opentracing/#limits-on-compatibility","title":"Limits on compatibility","text":"<p>In this section, we describe limits on compatibility other than the language version constraints mentioned earlier.</p>"},{"location":"docs/migration/opentracing/#semantic-conventions","title":"Semantic conventions","text":"<p>As mentioned above, OpenTelemetry has an improved model for instrumenting software. This means that the \"tags\" which are set by OpenTracing instrumentation may be different from the \"attributes\" which are set by OpenTelemetry. In other words, when replacing existing instrumentation, the data OpenTelemetry produces may be different from the data OpenTracing produces.</p> <p>Again, for clarity: When changing instrumentation, be sure to also update any dashboards, alerts, etc. which relied on the old data.</p>"},{"location":"docs/migration/opentracing/#baggage","title":"Baggage","text":"<p>In OpenTracing, baggage is carried with a SpanContext object associated with a Span. In OpenTelemetry, context and propagation are lower-level concepts \u2013 spans, baggage, metrics instruments, and other items are carried within a context object.</p> <p>As a result of this change, baggage which is set using the OpenTracing API is not available to OpenTelemetry Propagators. As a result, mixing the OpenTelemetry and OpenTracing APIs is not recommended when using baggage.</p> <p>Specifically, when baggage is set using the OpenTracing API:</p> <ul> <li>It is not accessible via the OpenTelemetry API.</li> <li>It is not injected by the OpenTelemetry propagators.</li> </ul> <p>If you are using baggage, it is recommended that all baggage-related API calls be switched to OpenTelemetry at the same time. Be sure to check that any critical baggage items are still being propagated before rolling these changes into production.</p>"},{"location":"docs/migration/opentracing/#context-management-in-javascript","title":"Context management in Javascript","text":"<p>In Javascript, the OpenTelemetry API makes use of commonly available context managers, such as <code>async_hooks</code> for Node.js and <code>Zones.js</code> for the browser. These context managers make tracing instrumentation a much less invasive and onerous task, compared to adding a span as a parameter to every method which needs to be traced.</p> <p>However, the OpenTracing API predates the common use of these context managers. OpenTracing code which passes the current active span as a parameter may create problems when mixed with OpenTelemetry code that stores the active span in a context manager. Using both methods within the same trace may create broken or mismatched spans, and is not recommended.</p> <p>Instead of mixing the two APIs in the same trace, we recommend that you migrate complete code paths from OpenTracing to OpenTelemetry as a single unit, so that only one API is used at a time.</p>"},{"location":"docs/migration/opentracing/#specification-and-implementation-details","title":"Specification and implementation details","text":"<p>For details on how each OpenTracing shim works, see the appropriate language-specific documentation. For details on the design of the OpenTracing shim, see OpenTracing Compatibility.</p>"},{"location":"docs/specs/status/","title":"Specification Status Summary","text":"<p>OpenTelemetry is developed on a signal by signal basis. Tracing, metrics, baggage, and logging are examples of signals. Signals are built on top of context propagation, a shared mechanism for correlating data across distributed systems.</p> <p>Each signal consists of four core components:</p> <ul> <li>APIs</li> <li>SDKs</li> <li>OpenTelemetry Protocol (OTLP)</li> <li>Collector</li> </ul> <p>Signals also have contrib components, an ecosystem of plugins and instrumentation. All instrumentation shares the same semantic conventions, to ensure that they produce the same data when observing common operations, such as HTTP requests.</p> <p>To learn more about signals and components, see the OTel specification Overview.</p>"},{"location":"docs/specs/status/#component-lifecycle","title":"Component Lifecycle","text":"<p>Components follow a development lifecycle: Draft, Experimental, Stable, Deprecated, Removed.</p> <ul> <li>Draft components are under design, and have not been added to the   specification.</li> <li>Experimental components are released and available for beta testing.</li> <li>Stable components are backwards compatible and covered under long term   support.</li> <li>Deprecated components are stable but may eventually be removed.</li> </ul> <p>For complete definitions of lifecycles and long term support, see Versioning and stability.</p>"},{"location":"docs/specs/status/#current-status","title":"Current Status","text":"<p>The following is a high level status report for currently available signals. Note that while the OpenTelemetry clients conform to a shared specification, they are developed independently.</p> <p>Checking the current status for each client in the README of its github repo is recommended. Client support for specific features can be found in the specification compliance tables.</p> <p>Note that, for each of the following sections, the Collector status is the same as the Protocol status.</p>"},{"location":"docs/specs/status/#tracing","title":"Tracing","text":"<ul> <li>{{% spec_status \"API\" \"otel/trace/api\" \"Status\" %}}</li> <li>{{% spec_status \"SDK\" \"otel/trace/sdk\" \"Status\" %}}</li> <li>{{% spec_status \"Protocol\" \"otlp\" \"Status\" %}}</li> <li>Notes:</li> <li>The tracing specification is now completely stable, and covered by long term     support.</li> <li>The tracing specification is still extensible, but only in a backwards     compatible manner.</li> <li>OpenTelemetry clients are versioned to v1.0 once their tracing     implementation is complete.</li> </ul>"},{"location":"docs/specs/status/#metrics","title":"Metrics","text":"<ul> <li>{{% spec_status \"API\" \"otel/metrics/api\" \"Status\" %}}</li> <li>{{% spec_status \"SDK\" \"otel/metrics/sdk\" \"Status\" %}}</li> <li>{{% spec_status \"Protocol\" \"otlp\" \"Status\" %}}</li> <li>Notes:</li> <li>OpenTelemetry Metrics is currently under active development.</li> <li>The data model is stable and released as part of the OTLP protocol.</li> <li>Experimental support for metric pipelines is available in the Collector.</li> <li>Collector support for Prometheus is under development, in collaboration with     the Prometheus community.</li> </ul>"},{"location":"docs/specs/status/#baggage","title":"Baggage","text":"<ul> <li>{{% spec_status \"API\" \"otel/baggage/api\" \"Status\" %}}</li> <li>SDK: stable</li> <li>Protocol: N/A</li> <li>Notes:</li> <li>OpenTelemetry Baggage is now completely stable.</li> <li>Baggage is not an observability tool, it is a system for attaching arbitrary     keys and values to a transaction, so that downstream services may access     them. As such, there is no OTLP or Collector component to baggage.</li> </ul>"},{"location":"docs/specs/status/#logging","title":"Logging","text":"<ul> <li>{{% spec_status \"Bridge API\" \"otel/logs/bridge-api\" \"Status\" %}}</li> <li>{{% spec_status \"SDK\" \"otel/logs/sdk\" \"Status\" %}}</li> <li>{{% spec_status \"Event API\" \"otel/logs/event-api\" \"Status\" %}}</li> <li>{{% spec_status \"Protocol\" \"otlp\" \"Status\" %}}</li> <li>Notes:</li> <li>The logs data model is released as part of the OpenTelemetry Protocol.</li> <li>Log processing for many data formats has been added to the Collector, thanks     to the donation of Stanza to the OpenTelemetry project.</li> <li>The OpenTelemetry Log Bridge API allows for writing appenders which bridge     logs from existing log frameworks into OpenTelemetry. The Logs Bridge API is     not meant to be called directly by end users. Log appenders are under     development in many languages.</li> <li>The OpenTelemetry Log SDK is the standard implementation of the Log Bridge     API. Applications configure the SDK to indicate how logs are processed and     exported (e.g. using OTLP).</li> <li>The OpenTelemetry Event API allows log records to be emitted which conform     to the event semantic conventions. In contrast to the Log Bridge API,     the Event API is intended to be called by end users. The Event API is under     active development.</li> </ul>"},{"location":"ecosystem/demo/","title":"OpenTelemetry Demo","text":"<p>The OpenTelemetry Demo does the following:</p> <ul> <li>Provides a realistic example of a distributed system that can be used to   demonstrate OpenTelemetry instrumentation and observability.</li> <li>Builds a base for vendors, tooling authors, and others to extend and   demonstrate their OpenTelemetry integrations.</li> <li>Creates a living example for OpenTelemetry contributors to use for testing new   versions of the API, SDK, and other components or enhancements.</li> </ul> <p>If you find yourself asking questions like:</p> <ul> <li>How should I use the SDK for my language?</li> <li>What's the best way to use OpenTelemetry APIs?</li> <li>How should my services be configured?</li> <li>How should my OpenTelemetry Collector be configured?</li> <li>How do I consider the architecture of a system   using OpenTelemetry?</li> </ul> <p>For more information, see:</p> <ul> <li>Demo documentation</li> <li>Demo repo</li> </ul>"},{"location":"ecosystem/integrations/","title":"Integrations","text":"<p>OpenTelemetry integrates with or is integrated into various open source projects.</p>"},{"location":"ecosystem/integrations/#within-opentelemetry","title":"Within OpenTelemetry","text":"<p>OpenTelemetry provides integration with the following open source projects.</p> External Project* OpenTelemetry Supported Components Apache Kafka Collector Apache SkyWalking Collector Elasticsearch Collector, C++, Java, Python Fluent Bit Collector Graphite Collector Jaeger Collector, DotNet, Go, Java, JS, PHP, Python, Ruby, Rust OpenCensus Collector, Python OpenTracing DotNet, Go, Java, JS, Python, Ruby OpenMetrics 1 Collector Prometheus 1 Collector, C++, Go, Java, JS, Rust Zipkin Collector, DotNet, Go, Java, JS, PHP, Python, Rust W3C trace-context DotNet, Go, Java, JS, Python, Ruby <p>* Projects are listed alphabetically.</p>"},{"location":"ecosystem/integrations/#outside-opentelemetry","title":"Outside OpenTelemetry","text":"<p>The following open source projects use OpenTelemetry components.</p> External Project Applicable OpenTelemetry Components containerd Go CRI-O Go Docker buildx Go Jaeger Collector, Go Kubernetes Go Micrometer Java Quarkus Java <p>* Projects are listed alphabetically.</p> <ol> <li> <p>Projects only partially supported at this time. Full support coming soon!\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"ecosystem/vendors/","title":"Vendors","text":"<p>Distributions and vendors who natively support OpenTelemetry in their commercial products.</p> Company* Distri\u00adbution Native OTLP Learn more AppDynamics (Cisco) Yes Yes docs.appdynamics.com/... Aria by VMware (Wavefront) No Yes docs.wavefront.com/... Aspecto Yes Yes aspecto.io AWS Yes No aws-otel.github.io Azure Yes No docs.microsoft.com/... Coralogix Yes Yes coralogix.com/... DaoCloud Yes Yes docs.daocloud.io/... Datadog Yes Yes docs.datadoghq.com/... Dynatrace Yes Yes dynatrace.com/... Elastic Yes Yes elastic.co/... F5 No Yes opentelemetry-collector-contrib/... Google Cloud Platform No Yes opentelemetry-collector-contrib/... Grafana Labs No Yes grafana.com/... Helios Yes Yes gethelios.dev Honeycomb Yes Yes docs.honeycomb.io/... Instana No Yes ibm.com/docs/... ITRS Yes Yes docs.itrsgroup.com/docs/geneos/... KloudFuse No Yes kloudfuse.com Lightstep Yes Yes github.com/lightstep LogicMonitor Yes Yes logicmonitor.com/... Logz.io Yes No docs.logz.io/... LogScale by Crowdstrike (Humio) No Yes library.humio.com/... Lumigo Yes Yes lumigo.io New Relic No Yes newrelic.com/... Observe, Inc. Yes Yes observeinc.com observIQ Yes Yes observiq.com/... Oracle No Yes docs.oracle.com/... Promscale No Yes timescale.com/promscale Sentry Software Yes Yes sentrysoftware.com/... ServicePilot No Yes servicepilot.com/... SigNoz Yes Yes signoz.io SolarWinds Yes Yes documentation.solarwinds.com/... Splunk Yes Yes splunk.com/blog/... Sumo Logic Yes Yes help.sumologic.com/ TelemetryHub No Yes telemetryhub.com Teletrace Yes Yes docs.teletrace.io ThousandEyes (Cisco) No Yes docs.thousandeyes.com Traceloop No Yes traceloop.com Uptrace Yes Yes uptrace.dev <p>* Vendors are listed alphabetically.</p>"},{"location":"ecosystem/registry/_index/","title":"Registry","text":"<p>{{% blocks/lead color=\"white\" %}}</p>"},{"location":"ecosystem/registry/_index/#param-title","title":"{{% param title %}}","text":"<p>{{% param description %}}</p> <p>{{% /blocks/lead %}}</p> <p>{{% blocks/section color=\"dark\" %}}</p>"},{"location":"ecosystem/registry/_index/#what-do-you-need","title":"What do you need?","text":"<p>The OpenTelemetry Registry allows you to search for instrumentation libraries, tracer implementations, utilities, and other useful projects in the OpenTelemetry ecosystem.</p> <ul> <li>Not able to find an exporter for your language? Remember, the   OpenTelemetry Collector supports exporting to a variety of   systems and works with all OpenTelemetry Core Components!</li> <li>Are you a project maintainer? See,   Adding a project to the OpenTelemetry Registry.</li> <li>Check back regularly, the community and registry are growing!</li> </ul> <p>{{% /blocks/section %}}</p> <p>{{&lt; blocks/section color=\"white\" type=\"container-lg\" &gt;}}</p> <p>{{}} <p>{{&lt; /blocks/section &gt;}}</p>"},{"location":"ecosystem/registry/adding/","title":"Adding to the registry","text":"<p>Do you maintain or contribute to an integration for OpenTelemetry? We'd love to feature your project in the registry!</p> <p>To add your project, submit a pull request. You'll need to create a data file in data/registry for your project, by using the following template: registry-entry.yml.</p>"}]}